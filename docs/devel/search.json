[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Orchestrating Microbiome Analysis",
    "section": "",
    "text": "Overview",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "index.html#sec-building-oma",
    "href": "index.html#sec-building-oma",
    "title": "Orchestrating Microbiome Analysis",
    "section": "Building OMA book",
    "text": "Building OMA book\nThis book is automatically built to ensure that all code examples are functional. See E.2 Session info for details.\nIn addition to accessing this book online, you can copy and paste the executable code examples to run on your local computer. For package installation instructions, refer to 2.2 Package ecosystem. You can also build and view the entire book locally by following the steps provided here, or use Docker image E.1 Docker image.",
    "crumbs": [
      "Overview"
    ]
  },
  {
    "objectID": "pages/intro.html",
    "href": "pages/intro.html",
    "title": "1  Microbiome data science in Bioconductor",
    "section": "",
    "text": "1.1 Bioconductor\nBioconductor is a project that focuses on the development of high-quality open research software for life sciences (Gentleman et al. 2004; Huber et al. 2015). The software packages are primarily coded in R, and they undergo continuous testing and peer review to ensure high quality.\nCentral to the software in Bioconductor are data containers, which provide a structured presentation of data. A data container consists of slots that are dedicated to certain type of data, for example, to abundance table and sample metadata. Biological data is often complex and multidimensional, making data containers particularly beneficial. There are several key advantages to using data containers:\nThe most common data container in Bioconductor is SummarizedExperiment. It is further expanded to fulfill needs of certain application field. SummarizedExperiment and its derivatives, have already been widely adopted in microbiome research, single cell sequencing, and in other fields, allowing rapid adoption and the extension of emerging data science techniques across application domains. See Section 2.1 for more details on how to handle data containers from the SummarizedExperiment family.\nThe Bioconductor microbiome data science framework consists of:",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Microbiome data science in Bioconductor</span>"
    ]
  },
  {
    "objectID": "pages/intro.html#sec-bioconductor",
    "href": "pages/intro.html#sec-bioconductor",
    "title": "1  Microbiome data science in Bioconductor",
    "section": "",
    "text": "Gentleman, Robert C, Vincent J Carey, Douglas M Bates, Ben Bolstad, Marcel Dettling, Sandrine Dudoit, Byron Ellis, et al. 2004. “Bioconductor: Open Software Development for Computational Biology and Bioinformatics.” Genome Biology 5: R80.\n\nHuber, W., V. J. Carey, R. Gentleman, S. Anders, M. Carlson, B. S. Carvalho, H. C. Bravo, et al. 2015. “Orchestrating High-Throughput Genomic Analysis with Bioconductor.” Nature Methods 12 (2): 115–21. http://www.nature.com/nmeth/journal/v12/n2/full/nmeth.3252.html.\n\n\nBioconductor logo.\n\n\n\n\nEase of handling: Data subsetting and bookkeeping become more straightforward.\n\nDevelopment efficiency: Developers can create efficient methods, knowing the data will be in a consistent format.\n\nUser accessibility: Users can easily apply complex methods to their data.\n\n\n\n\n\nData containers, designed to organize multi-assay microbiome data\n\nR/Bioconductor packages that provide dedicated methods\n\nCommunity of users and developers\n\n\n\nData containers are central in Bioconductor.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Microbiome data science in Bioconductor</span>"
    ]
  },
  {
    "objectID": "pages/intro.html#sec-microbiome-bioc",
    "href": "pages/intro.html#sec-microbiome-bioc",
    "title": "1  Microbiome data science in Bioconductor",
    "section": "\n1.2 Microbiome data science in Bioconductor",
    "text": "1.2 Microbiome data science in Bioconductor\nThe phyloseq data container has been dominant in the microbiome field within Bioconductor over the past decade (McMurdie and Holmes 2013). However, there has been a growing popularity of tools based on the SummarizedExperiment framework.\n\nMcMurdie, PJ, and S Holmes. 2013. “Phyloseq: An r Package for Reproducible Interactive Analysis and Graphics of Microbiome Census Data.” PLoS ONE 8: e61217. https://doi.org/10.1371/journal.pone.0061217.\nAn optimal data container should efficiently store and manage large volumes of data, including modified or transformed copies. Furthermore, it should seamlessly integrate into the broader ecosystem of Bioconductor, minimizing duplication of effort and facilitating interoperability with other tools and packages.\n\n\nOptimal data container.\n\nTreeSummarizedExperiment was developed to address these requirements (Huang et al. 2021). The miaverse framework was subsequently built around the TreeSummarizedExperiment data container Chapter 2.\n\nHuang, Ruizhu, Charlotte Soneson, Felix G. M. Ernst, et al. 2021. “TreeSummarizedExperiment: A S4 Class for Data with Hierarchical Structure [Version 2; Peer Review: 3 Approved].” F1000Research 9: 1246. https://doi.org/10.12688/f1000research.26669.2.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Microbiome data science in Bioconductor</span>"
    ]
  },
  {
    "objectID": "pages/intro.html#sec-open-data",
    "href": "pages/intro.html#sec-open-data",
    "title": "1  Microbiome data science in Bioconductor",
    "section": "\n1.3 Open data science",
    "text": "1.3 Open data science\nOpen data science emphasizes sharing code and, where feasible, data alongside results (Shetty and Lahti 2019). Utilizing Bioconductor tools facilitates the development of efficient and reproducible data science workflows. Enhanced transparency in research accelerates scientific progress. As open science is a fundamental concept in microbiome research, this book, particularly in Chapter 28 aims to educate readers about reproducible reporting practices.\n\nShetty, Sudarshan, and Leo Lahti. 2019. “Microbiome Data Science.” Journal of Biosciences 44: 115. https://doi.org/10.1007/s12038-019-9930-2.\n\n\n\n\n\n\nSummary\n\n\n\n\nBioconductor is a large ecosystem for bioinformatics.\nData containers are fundamental in Bioconductor.\nSummarizedExperiment is the most common data container in Bioconductor.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Microbiome data science in Bioconductor</span>"
    ]
  },
  {
    "objectID": "pages/miaverse.html",
    "href": "pages/miaverse.html",
    "title": "2  miaverse",
    "section": "",
    "text": "2.1 Data containers\nAs discussed, miaverse is built upon TreeSummarizedExperiment (TreeSE) data container. TreeSummarizedExperiment is expanded from SingleCellExperiment (SCE) by incorporating additional slots tailored for microbiome analysis. SingleCellExperiment class is designed for single-cell sequencing (Lun and Risso 2020). Bioconductor offers wide variety of tools for this field including online book Orchestrating Single-Cell Analysis in Bioconductor (OSCA) (Amezquita et al. 2020). SingleCellExperiment, on the other hand, is further derived from SummarizedExperiment (SE) class. This hierarchical relationship among data containers means that all methods applicable to SingleCellExperiment and SummarizedExperiment objects can also be applied to TreeSummarizedExperiment objects.\nSummarizedExperiment is extended to SingleCellExperiment and it is further extended to TreeSummarizedExperiment.\nMultiAssayExperiment (MAE) (Ramos et al. 2017) provides an organized way to bind several different data containers together in a single object. For example, we can bind microbiome data (in TreeSE container) with metabolomic profiling data (in SE) container, with (partially) shared sample metadata. This is convenient and robust for instance, in subsetting and other data manipulation tasks. Microbiome data can be part of multiomics experiments and analysis strategies. We highlight how the methods used throughout in this book relate to this data framework by using the TreeSE, MAE, and classes beyond.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>miaverse</span>"
    ]
  },
  {
    "objectID": "pages/miaverse.html#sec-data-containers",
    "href": "pages/miaverse.html#sec-data-containers",
    "title": "2  miaverse",
    "section": "",
    "text": "Amezquita, Robert, Aaron Lun, Stephanie Hicks, and Raphael Gottardo. 2020. Orchestrating Single-Cell Analysis with Bioconductor. Bioconductor. https://bioconductor.org/books/release/OSCA/.\n\nSummarizedExperiment (SE) (Morgan et al. 2020) is a generic and highly optimized container for complex data structures. It has become a common choice for analyzing various types of biomedical profiling data, such as RNAseq, ChIp-Seq, microarrays, flow cytometry, proteomics, and single-cell sequencing.\nSingeCellExperiment (SCE) (Lun and Risso 2020) was developed as an extension to store copies of data to same data container.\nTreeSummarizedExperiment (TreeSE) (R. Huang 2020) was developed as an extension to incorporate hierarchical information (such as phylogenetic trees and sample hierarchies) and reference sequences.\n\n\nMorgan, Martin, Valerie Obenchain, Jim Hester, and Hervé Pagès. 2020. SummarizedExperiment: SummarizedExperiment Container. https://bioconductor.org/packages/SummarizedExperiment.\n\nLun, Aaron, and Davide Risso. 2020. SingleCellExperiment: S4 Classes for Single Cell Data.\n\nHuang, Ruizhu. 2020. TreeSummarizedExperiment: A S4 Class for Data with Tree Structures.\n\n\n\nRamos, Marcel, Lucas Schiffer, Angela Re, Rimsha Azhar, Azfar Basunia, Carmen Rodriguez Cabrera, Tiffany Chan, et al. 2017. “Software for the Integration of Multiomics Experiments in Bioconductor.” Cancer Research. https://doi.org/10.1158/0008-5472.CAN-17-0344.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>miaverse</span>"
    ]
  },
  {
    "objectID": "pages/miaverse.html#sec-packages",
    "href": "pages/miaverse.html#sec-packages",
    "title": "2  miaverse",
    "section": "\n2.2 Package ecosystem",
    "text": "2.2 Package ecosystem\nMethods for the(Tree)SummarizedExperiment and MultiAssayExperiment data containers are provided by multiple independent developers through R/Bioconductor packages. Some of these are listed below (tips on new packages are welcome).\nEspecially, Bioconductor packages include comprehensive manuals as they are required. Follow the links below to find package vignettes and other materials showing the utilization of packages and their methods.\n\n2.2.1 mia package family\nThe mia package family provides general methods for microbiome data wrangling, analysis and visualization.\n\n\nmia: Microbiome analysis tools (Ernst, Shetty, and Lahti 2020)\n\n\nmiaViz: Microbiome analysis specific visualization (Ernst, Borman, and Lahti 2022)\n\n\nmiaSim: Microbiome data simulations (Simsek et al. 2021)\n\n\nmiaTime: Microbiome time series analysis (Lahti 2021)\n\n\nErnst, Felix G. M., Sudarshan Shetty, and Leo Lahti. 2020. Mia: Microbiome Analysis.\n\nErnst, Felix G. M., Tuomas Borman, and Leo Lahti. 2022. miaViz: Microbiome Analysis Plotting and Visualization.\n\nSimsek, Yagmur, Leo Lahti, Daniel Garza, and Karoline Faust. 2021. “miaSim r Package.” microbiome.github.io/miaSim.\n\nLahti, L. 2021. miaTime: Time Series Analysis.\n\n2.2.2 SE supporting packages\nThe following DA methods support (Tree)SummarizedExperiment.\n\n\nANCOMBC (Lin and Peddada 2020) for differential abundance analysis\n\nbenchdamic (Calgaro et al. 2022) for benchmarking differential abundance methods\n\nALDEx2 (Gloor, Macklaim, and Fernandes 2016) for differential abundance analysis\n\nLin, Huang, and Shyamal Das Peddada. 2020. “Analysis of Compositions of Microbiomes with Bias Correction.” Nature Communications 11 (1): 1–11. https://doi.org/https://doi.org/10.1038/s41467-020-17041-7.\n\nCalgaro, Matteo, Chiara Romualdi, Davide Risso, and Nicola Vitulo. 2022. “Benchdamic: Benchmarking of Differential Abundance Methods for Microbiome Data.” Bioinformatics 39 (1). https://doi.org/10.1093/bioinformatics/btac778.\n\nGloor, Gregory B., Jean M. Macklaim, and Andrew D. Fernandes. 2016. “Displaying Variation in Large Datasets: Plotting a Visual Summary of Effect Sizes.” Journal of Computational and Graphical Statistics 25 (3): 971–79. https://doi.org/10.1080/10618600.2015.1131161.\n\n2.2.3 Other relevant packages\n\n\nMGnifyR for accessing and processing MGnify data in R\n\nMGnify Notebooks\nEMBL-EBI MGnify user guides and resources\n\n\n\nLinDA(Zhou et al. 2022) for differential abundance analysis\n\nvegan (Oksanen et al. 2020) for community ecologists\n\nCBEA (Nguyen QP, n.d.) for taxonomic enrichment analysis\n\nmicroSTASIS (Sánchez-Sánchez, Santonja, and Benítez-Páez 2022) for microbiota stability assessment via iterative clustering\n\nPLSDAbatch (Wang and Lê Cao 2023) for batch effect correction\n\ntreeclimbR (S. Huang Ruizhu 2021) for finding optimal signal levels in a tree\n\ndar for differential abundance testing\n\niSEEtree for interactive visualisation of microbiome data\n\nphilr (Silverman et al. (2017)) phylogeny-aware phILR transformation\n\nIntegratedLearner for multiomics classification and prediction\n\nMicrobiotaProcess (Xu et al. 2023) for the “tidy” analysis of microbiome and other ecological data\n\nTools for Microbiome Analysis site listed over 130 R packages for microbiome data science in 2023. Many of these are not in Bioconductor, or do not directly support the data containers used in this book but can be often used with minor modifications. The phyloseq-based tools can be used by converting the TreeSE data into phyloseq with convertToPhyloseq() (see Chapter 5).\n\nZhou, Huijuan, Kejun He, Jun Chen, and Xianyang Zhang. 2022. “LinDA: Linear Models for Differential Abundance Analysis of Microbiome Compositional Data.” Genome Biology 23 (1): 95. https://doi.org/10.1186/s13059-022-02655-5.\n\nOksanen, Jari, F. Guillaume Blanchet, Michael Friendly, Roeland Kindt, Pierre Legendre, Dan McGlinn, Peter R. Minchin, et al. 2020. Vegan: Community Ecology Package. https://CRAN.R-project.org/package=vegan.\n\nNguyen QP, Frost HR, Hoen AG. n.d. “CBEA: Competitive balances for taxonomic enrichment analysis.” PLoS Comput Biol 18 (5). https://doi.org/10.1371/journal.pcbi.1010091.\n\nSánchez-Sánchez, Pedro, Francisco J Santonja, and Alfonso Benítez-Páez. 2022. “Assessment of Human Microbiota Stability Across Longitudinal Samples Using Iteratively Growing-Partitioned Clustering.” Briefings in Bioinformatics 23 (2): bbac055. https://doi.org/10.1093/bib/bbac055.\n\nWang, Yiwen, and Kim-Anh Lê Cao. 2023. “PLSDA-batch: A Multivariate Framework to Correct for Batch Effects in Microbiome Data.” Briefings in Bioinformatics 24 (2): bbac622. https://doi.org/10.1093/bib/bbac622.\n\nHuang, Soneson, Ruizhu. 2021. “treeclimbR Pinpoints the Data-Dependent Resolution of Hierarchical Hypotheses.” Genome Biology 22 (2). https://doi.org/10.1186/s13059-021-02368-1.\n\nSilverman, Justin D, Alex D Washburne, Sayan Mukherjee, and Lawrence A David. 2017. “A Phylogenetic Transform Enhances Analysis of Compositional Microbiota Data.” eLife 6. https://doi.org/10.7554/eLife.21887.\n\nXu, Shuangbin, Li Zhan, Wenli Tang, Qianwen Wang, Zehan Dai, Lang Zhou, Tingze Feng, et al. 2023. “MicrobiotaProcess: A Comprehensive R Package for Deep Mining Microbiome.” The Innovation 4 (2): 100388. https://doi.org/10.1016/j.xinn.2023.100388.\n\n2.2.4 Open microbiome data\nHundreds of published microbiome datasets are readily available in these data containers (see Section 4.2).",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>miaverse</span>"
    ]
  },
  {
    "objectID": "pages/miaverse.html#sec-installation",
    "href": "pages/miaverse.html#sec-installation",
    "title": "2  miaverse",
    "section": "\n2.3 Installation",
    "text": "2.3 Installation\n\n2.3.1 Installing all packages\nYou can install all packages that are required to run every example in this book via the following command:\n\nremotes::install_github(\"microbiome/OMA\", dependencies = TRUE, upgrade = TRUE)\n\nOptionally, you can install all packages or just certain ones with the following script.\n\n#|\n\n# URL of the raw CSV file on GitHub. It includes all packages needed.\nurl &lt;- \"https://raw.githubusercontent.com/microbiome/OMA/devel/oma_packages/oma_packages.csv\"\n\n# Read the CSV file directly into R\ndf &lt;- read.csv(url)\npackages &lt;- df[[1]]\n\n# Get packages that are already installed installed\npackages_already_installed &lt;- packages[ packages %in% installed.packages() ]\n\n# Get packages that need to be installed\npackages_need_to_install &lt;- setdiff( packages, packages_already_installed )\n\n# Loads BiocManager into the session. Install it if it not already installed.\nif( !require(\"BiocManager\") ){\n    install.packages(\"BiocManager\")\n    library(\"BiocManager\")\n}\n\n# If there are packages that need to be installed, installs them with BiocManager\n# Updates old packages.\nif( length(packages_need_to_install) &gt; 0 ) {\n   install(packages_need_to_install, ask = FALSE)\n}\n\n# Load all packages into session. Stop if there are packages that were not\n# successfully loaded\npkgs_not_loaded &lt;- !sapply(packages, require, character.only = TRUE)\npkgs_not_loaded &lt;- names(pkgs_not_loaded)[ pkgs_not_loaded ]\nif( length(pkgs_not_loaded) &gt; 0 ){\n    stop(\"Error in loading the following packages into the session: '\", paste0(pkgs_not_loaded, collapse = \"', '\"), \"'\")\n}\n\n\n2.3.2 Installing specific packages\nYou can install R packages of your choice with the following procedures.\nBioconductor release version is the most stable and tested version but may miss some of the latest methods and updates.\n\nBiocManager::install(\"microbiome/mia\")\n\nBioconductor development version requires the installation of the latest R beta version. This is primarily recommended for those who already have experience with R/Bioconductor and need access to the latest updates.\n\nBiocManager::install(\"microbiome/mia\", version = \"devel\")\n\nGithub development version provides access to the latest but potentially unstable features. This is useful when you want access to all available tools.\n\ndevtools::install_github(\"microbiome/mia\")\n\n\n2.3.3 Troubleshoot in installing\nIf you encounter installation issue related to package dependencies please see the troubleshoot page here and Chapter 30.\n\n\n\n\n\n\nSummary\n\n\n\n\n\nTreeSummarizedExperiment is derived from SummarizedExperiment class.\n\nmiaverse is based on TreeSummarizedExperiment data container.\nWe can borrow methods from packages utilizing SingleCellExperiment and SummarizedExperiment.",
    "crumbs": [
      "Introduction",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>miaverse</span>"
    ]
  },
  {
    "objectID": "pages/containers.html",
    "href": "pages/containers.html",
    "title": "3  Data containers",
    "section": "",
    "text": "3.1 Rows and columns\nLet us load example data and store it in variable tse.\nlibrary(mia)\ndata(\"GlobalPatterns\", package = \"mia\")\ntse &lt;- GlobalPatterns\ntse\n##  class: TreeSummarizedExperiment \n##  dim: 19216 26 \n##  metadata(0):\n##  assays(1): counts\n##  rownames(19216): 549322 522457 ... 200359 271582\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(26): CL3 CC1 ... Even2 Even3\n##  colData names(7): X.SampleID Primer ... SampleType Description\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (19216 rows)\n##  rowTree: 1 phylo tree(s) (19216 leaves)\n##  colLinks: NULL\n##  colTree: NULL\nThe TreeSE object, similar to a standard data.frame or matrix, has rows and columns. Typically, samples are stored in columns, while features or taxa are stored in rows. You can extract subsets of the data, such as the first five rows and certain three columns. The object manages the linkages between data, ensuring, for example, that when you subset the data, for instance, both the assay and sample metadata are subsetted simultaneously, ensuring they remain matched with each other.\ntse &lt;- tse[1:5, c(1, 19, 16)]\ntse\n##  class: TreeSummarizedExperiment \n##  dim: 5 3 \n##  metadata(0):\n##  assays(1): counts\n##  rownames(5): 549322 522457 951 244423 586076\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(3): CL3 TRRsed1 NP2\n##  colData names(7): X.SampleID Primer ... SampleType Description\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (5 rows)\n##  rowTree: 1 phylo tree(s) (19216 leaves)\n##  colLinks: NULL\n##  colTree: NULL\nCompared to the original data the dimensions are for rows and columns 5 and 3, respectively.",
    "crumbs": [
      "Data containers & importing",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data containers</span>"
    ]
  },
  {
    "objectID": "pages/containers.html#sec-rows-and-cols",
    "href": "pages/containers.html#sec-rows-and-cols",
    "title": "3  Data containers",
    "section": "",
    "text": "Note\n\n\n\nSummarizedExperiment objects have rows and columns. Also MultiAssayExperiment, introduced in Section 3.7 have rows and cols but the structure is more complicated. You can find more examples on subsetting from Chapter 8.",
    "crumbs": [
      "Data containers & importing",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data containers</span>"
    ]
  },
  {
    "objectID": "pages/containers.html#sec-assay-slot",
    "href": "pages/containers.html#sec-assay-slot",
    "title": "3  Data containers",
    "section": "\n3.2 Assay data",
    "text": "3.2 Assay data\nThe microbiome is the collection of all microbes (such as bacteria, viruses, fungi, etc.) in the body. When studying these microbes, abundance data is needed, and that’s where assays come in.\nAn assay is a way of measuring the presence and abundance of different types of microbes in a sample. For example, if you want to know how many bacteria of a certain type are in your gut, you can use an assay to measure this. When storing assays, the original data is count-based. However, the original count-based taxonomic abundance tables may undergo different transformations, such as logarithmic, Centered Log-Ratio (CLR), or relative abundance. These are typically stored in assays. See Chapter 10 for more information on transformations.\nThe assays slot contains the experimental data as multiple count matrices. The result of assays is a list of matrices.\n\nassays(tse)\n##  List of length 1\n##  names(1): counts\n\nIndividual assays can be accessed via assay.\n\nassay(tse, \"counts\") |&gt; head()\n##         CL3 TRRsed1 NP2\n##  549322   0       0   1\n##  522457   0       0   0\n##  951      0       0   0\n##  244423   0       0   0\n##  586076   0       0   0\n\nSo, in summary, in the world of microbiome analysis, an assay is essentially a way to quantify and understand the composition of microbes in a given sample, which is super important for all kinds of research, ranging from human health to environment studies.\nFurthermore, to illustrate the use of multiple assays, we can create an empty matrix and add it to the object.\n\nmat &lt;- matrix(nrow = nrow(tse), ncol = ncol(tse))\nassay(tse, \"empty_table\", withDimnames=FALSE) &lt;- mat\nassays(tse)\n##  List of length 2\n##  names(2): counts empty_table\n\nNow there are two assays available in the tse object, counts and empty_table.\n\nassay(tse, \"empty_table\") |&gt; head()\n##         CL3 TRRsed1 NP2\n##  549322  NA      NA  NA\n##  522457  NA      NA  NA\n##  951     NA      NA  NA\n##  244423  NA      NA  NA\n##  586076  NA      NA  NA\n\nHere the dimension of the assay data remains unchanged. This is in fact a requirement for the assays.",
    "crumbs": [
      "Data containers & importing",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data containers</span>"
    ]
  },
  {
    "objectID": "pages/containers.html#coldata",
    "href": "pages/containers.html#coldata",
    "title": "3  Data containers",
    "section": "\n3.3 colData",
    "text": "3.3 colData\ncolData contains information about the samples used in the study. This information can include details such as the sample ID, the primers used in the analysis, the barcodes associated with the sample (truncated or complete), the type of sample (e.g. soil, fecal, mock) and a description of the sample.\n\ncolData(tse)\n##  DataFrame with 3 rows and 7 columns\n##          X.SampleID   Primer Final_Barcode Barcode_truncated_plus_T\n##            &lt;factor&gt; &lt;factor&gt;      &lt;factor&gt;                 &lt;factor&gt;\n##  CL3        CL3      ILBC_01        AACGCA                   TGCGTT\n##  TRRsed1    TRRsed1  ILBC_22        ACATGT                   ACATGT\n##  NP2        NP2      ILBC_19        ACAGTT                   AACTGT\n##          Barcode_full_length         SampleType\n##                     &lt;factor&gt;           &lt;factor&gt;\n##  CL3             CTAGCGTGCGT Soil              \n##  TRRsed1         CACGTGACATG Sediment (estuary)\n##  NP2             TCGCGCAACTG Ocean             \n##                                       Description\n##                                          &lt;factor&gt;\n##  CL3     Calhoun South Carolina Pine soil, pH 4.9\n##  TRRsed1 Tijuana River Reserve, depth 1          \n##  NP2     Newport Pier, CA surface water, Time 1\n\nTo illustrate, X.SampleID gives the sample identifier, SampleType indicates the sample type (e.g. soil, fecal matter, control) and Description provides an additional description of the sample.",
    "crumbs": [
      "Data containers & importing",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data containers</span>"
    ]
  },
  {
    "objectID": "pages/containers.html#sec-rowData",
    "href": "pages/containers.html#sec-rowData",
    "title": "3  Data containers",
    "section": "\n3.4 rowData",
    "text": "3.4 rowData\nrowData contains data on the features of the analyzed samples. This is particularly important in the microbiome field for storing taxonomic information. This taxonomic information is extremely important for understanding the composition and diversity of the microbiome in each sample analyzed. It enables identification of the different types of microorganisms present in samples. It also allows you to explore the relationships between microbiome composition and various environmental or health factors.\n\nrowData(tse)\n##  DataFrame with 5 rows and 7 columns\n##             Kingdom        Phylum        Class        Order        Family\n##         &lt;character&gt;   &lt;character&gt;  &lt;character&gt;  &lt;character&gt;   &lt;character&gt;\n##  549322     Archaea Crenarchaeota Thermoprotei           NA            NA\n##  522457     Archaea Crenarchaeota Thermoprotei           NA            NA\n##  951        Archaea Crenarchaeota Thermoprotei Sulfolobales Sulfolobaceae\n##  244423     Archaea Crenarchaeota        Sd-NA           NA            NA\n##  586076     Archaea Crenarchaeota        Sd-NA           NA            NA\n##               Genus                Species\n##         &lt;character&gt;            &lt;character&gt;\n##  549322          NA                     NA\n##  522457          NA                     NA\n##  951     Sulfolobus Sulfolobusacidocalda..\n##  244423          NA                     NA\n##  586076          NA                     NA",
    "crumbs": [
      "Data containers & importing",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data containers</span>"
    ]
  },
  {
    "objectID": "pages/containers.html#rowtree",
    "href": "pages/containers.html#rowtree",
    "title": "3  Data containers",
    "section": "\n3.5 rowTree",
    "text": "3.5 rowTree\nPhylogenetic trees also play an important role in the microbiome field. The TreeSE class can keep track of features and node relations via two functions, rowTree and rowLinks.\nA tree can be accessed via rowTree as phylo object.\n\nrowTree(tse)\n##  \n##  Phylogenetic tree with 19216 tips and 19215 internal nodes.\n##  \n##  Tip labels:\n##    549322, 522457, 951, 244423, 586076, 246140, ...\n##  Node labels:\n##    , 0.858.4, 1.000.154, 0.764.3, 0.995.2, 1.000.2, ...\n##  \n##  Rooted; includes branch lengths.\n\nThe links to the individual features are available through rowLinks.\n\nrowLinks(tse)\n##  LinkDataFrame with 5 rows and 5 columns\n##        nodeLab   nodeNum nodeLab_alias    isLeaf   whichTree\n##    &lt;character&gt; &lt;integer&gt;   &lt;character&gt; &lt;logical&gt; &lt;character&gt;\n##  1      549322         1       alias_1      TRUE       phylo\n##  2      522457         2       alias_2      TRUE       phylo\n##  3         951         3       alias_3      TRUE       phylo\n##  4      244423         4       alias_4      TRUE       phylo\n##  5      586076         5       alias_5      TRUE       phylo\n\nPlease note that there can be a 1:1 relationship between tree nodes and features, but this is not a must-have. This means there can be features that are not linked to nodes, and nodes that are not linked to features. To change the links in an existing object, the changeTree() function is available.",
    "crumbs": [
      "Data containers & importing",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data containers</span>"
    ]
  },
  {
    "objectID": "pages/containers.html#sec-alt-exp",
    "href": "pages/containers.html#sec-alt-exp",
    "title": "3  Data containers",
    "section": "\n3.6 Alternative Experiments",
    "text": "3.6 Alternative Experiments\nAlternative experiments complement assays. They can contain complementary data, which is no longer tied to the same dimensions as the assay data. However, the number of samples (columns) must be the same.\nThis can come into play, for instance, when one has taxonomic abundance profiles quantified using different measurement technologies, such as phylogenetic microarrays, amplicon sequencing, or metagenomic sequencing. Another common use case is including abundance tables for different taxonomic ranks. Such alternative experiments concerning the same set of samples can be stored as\n\nSeparate assays assuming that the taxonomic information can be mapped between features directly 1:1; or\nData in the altExp slot of the TreeSE, if the feature dimensions differ. Each element of the altExp slot is a SE or an object from a derived class with independent feature data.\n\nThe following shows how to store taxonomic abundance tables agglomerated at different taxonomic levels. However, the data could as well originate from entirely different measurement sources as long as the samples match.\nLet us first subset the data so that it has only two rows.\n\ntse_sub &lt;- tse[1:2, ]\n# Both have the same number of columns (samples)\ndim(tse)\n##  [1] 5 3\ndim(tse_sub)\n##  [1] 2 3\n\nThen we can add the new data object as an alternative experiment in the original data.\n\n# Add the new data object to the original data object as an alternative\n# experiment with the name \"Phylum\"\naltExp(tse, \"subsetted\") &lt;- tse_sub\n\n# Check the alternative experiment names available in the data\naltExpNames(tse)\n##  [1] \"subsetted\"\n\nWe can now subset the data by taking certain samples, for instance, and this acts on both altExp and assay data.\n\ntse_single_sample &lt;- tse[, 1]\ndim(altExp(tse_single_sample,\"subsetted\"))\n##  [1] 2 1\n\nFor more details on altExp, you can check the introduction to the SingleCellExperiment package (Lun and Risso 2020).\n\nLun, Aaron, and Davide Risso. 2020. SingleCellExperiment: S4 Classes for Single Cell Data.",
    "crumbs": [
      "Data containers & importing",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data containers</span>"
    ]
  },
  {
    "objectID": "pages/containers.html#sec-mae",
    "href": "pages/containers.html#sec-mae",
    "title": "3  Data containers",
    "section": "\n3.7 Multiple experiments",
    "text": "3.7 Multiple experiments\nMultiple experiments relate to complementary measurement types, such as transcriptomic or metabolomic profiling of the microbiome or the host. Multiple experiments can be represented using the same options as alternative experiments, or by using the MAE class (Ramos et al. 2017). Depending on how the datasets relate to each other the data can be stored as:\n\nRamos, Marcel, Lucas Schiffer, Angela Re, Rimsha Azhar, Azfar Basunia, Carmen Rodriguez Cabrera, Tiffany Chan, et al. 2017. “Software for the Integration of Multiomics Experiments in Bioconductor.” Cancer Research. https://doi.org/10.1158/0008-5472.CAN-17-0344.\n\n\naltExp if the samples can be matched directly 1:1; or\nAs MAE objects, in which the connections between samples are defined through a sampleMap. Each element on the ExperimentList of an MAE is matrix or matrix-like objects, including SE objects, and the number of samples can differ between the elements.\n\nThe MAE object can handle more complex relationships between experiments. It manages the linkages between samples and experiments, ensuring that the data remains consistent and well-organized.\n\ndata(\"HintikkaXOData\")\nmae &lt;- HintikkaXOData\nmae\n##  A MultiAssayExperiment object of 3 listed\n##   experiments with user-defined names and respective classes.\n##   Containing an ExperimentList class object of length 3:\n##   [1] microbiota: TreeSummarizedExperiment with 12706 rows and 40 columns\n##   [2] metabolites: TreeSummarizedExperiment with 38 rows and 40 columns\n##   [3] biomarkers: TreeSummarizedExperiment with 39 rows and 40 columns\n##  Functionality:\n##   experiments() - obtain the ExperimentList instance\n##   colData() - the primary/phenotype DataFrame\n##   sampleMap() - the sample coordination DataFrame\n##   `$`, `[`, `[[` - extract colData columns, subset, or experiment\n##   *Format() - convert into a long or wide DataFrame\n##   assays() - convert ExperimentList to a SimpleList of matrices\n##   exportClass() - save data to flat files\n\nThe sampleMap is a crucial component of the MAE object as it acts as the important bookkeeper, maintaining the information about which samples are associated with which experiments. This ensures that data linkages are correctly managed and preserved across different types of experiments.\nIn fact, we can have\n\nsampleMap(mae) |&gt; head()\n##  DataFrame with 6 rows and 3 columns\n##         assay     primary     colname\n##      &lt;factor&gt; &lt;character&gt; &lt;character&gt;\n##  1 microbiota          C1          C1\n##  2 microbiota          C2          C2\n##  3 microbiota          C3          C3\n##  4 microbiota          C4          C4\n##  5 microbiota          C5          C5\n##  6 microbiota          C6          C6\n\nFor illustration, let’s subset the data by taking first five samples.\n\nmae &lt;- mae[ , 1:5, ]\nmae\n##  A MultiAssayExperiment object of 3 listed\n##   experiments with user-defined names and respective classes.\n##   Containing an ExperimentList class object of length 3:\n##   [1] microbiota: TreeSummarizedExperiment with 12706 rows and 5 columns\n##   [2] metabolites: TreeSummarizedExperiment with 38 rows and 5 columns\n##   [3] biomarkers: TreeSummarizedExperiment with 39 rows and 5 columns\n##  Functionality:\n##   experiments() - obtain the ExperimentList instance\n##   colData() - the primary/phenotype DataFrame\n##   sampleMap() - the sample coordination DataFrame\n##   `$`, `[`, `[[` - extract colData columns, subset, or experiment\n##   *Format() - convert into a long or wide DataFrame\n##   assays() - convert ExperimentList to a SimpleList of matrices\n##   exportClass() - save data to flat files\n\n\n\n\n\n\n\nNote\n\n\n\nIf you have multiple experiments containing multiple measures from same patients, you can utilize the MultiAssayExperiment object to keep track of which samples belong to which patient.\n\n\nThe following dataset illustrates how to utilize the sample mapping system in MAE. It includes two omics: biogenic amines and fatty acids, collected from 10 chickens.\n\nmae &lt;- readRDS(system.file(\"extdata\", \"mae_holofood.Rds\", package = \"OMA\"))\nmae\n##  A MultiAssayExperiment object of 2 listed\n##   experiments with user-defined names and respective classes.\n##   Containing an ExperimentList class object of length 2:\n##   [1] BIOGENIC AMINES: TreeSummarizedExperiment with 7 rows and 14 columns\n##   [2] FATTY ACIDS: TreeSummarizedExperiment with 19 rows and 19 columns\n##  Functionality:\n##   experiments() - obtain the ExperimentList instance\n##   colData() - the primary/phenotype DataFrame\n##   sampleMap() - the sample coordination DataFrame\n##   `$`, `[`, `[[` - extract colData columns, subset, or experiment\n##   *Format() - convert into a long or wide DataFrame\n##   assays() - convert ExperimentList to a SimpleList of matrices\n##   exportClass() - save data to flat files\n\nWe can see that there are more than ten samples per omic dataset due to multiple time points collected for some animals. From the colData of MAE, we can observe the animal metadata shared between omics and time points, including information that remains constant throughout the trial.\n\ncolData(mae)\n##  DataFrame with 10 rows and 13 columns\n##                 marker.canonical_url         marker.type Treatment code\n##                            &lt;numeric&gt;              &lt;list&gt;    &lt;character&gt;\n##  SAMEA112904734                   NA TREATMENT,TRIAL,PEN             CO\n##  SAMEA112904735                   NA TREATMENT,TRIAL,PEN             CC\n##  SAMEA112904737                   NA TREATMENT,TRIAL,PEN             CC\n##  SAMEA112904741                   NA TREATMENT,TRIAL,PEN             CC\n##  SAMEA112904746                   NA TREATMENT,TRIAL,PEN             CC\n##  SAMEA112904748                   NA TREATMENT,TRIAL,PEN             CO\n##  SAMEA112904749                   NA TREATMENT,TRIAL,PEN             CC\n##  SAMEA112904755                   NA TREATMENT,TRIAL,PEN             CC\n##  SAMEA112904762                   NA TREATMENT,TRIAL,PEN             CO\n##  SAMEA112904763                   NA TREATMENT,TRIAL,PEN             CC\n##                 Treatment name  Trial code Trial description   Trial end\n##                    &lt;character&gt; &lt;character&gt;       &lt;character&gt; &lt;character&gt;\n##  SAMEA112904734      Probiotic          CB           Trial 2  2019-05-19\n##  SAMEA112904735        Control          CC           Trial 3  2019-07-14\n##  SAMEA112904737        Control          CB           Trial 2  2019-05-19\n##  SAMEA112904741        Control          CC           Trial 3  2019-07-14\n##  SAMEA112904746        Control          CB           Trial 2  2019-05-19\n##  SAMEA112904748      Probiotic          CC           Trial 3  2019-07-14\n##  SAMEA112904749        Control          CA           Trial 1  2019-03-11\n##  SAMEA112904755        Control          CB           Trial 2  2019-05-19\n##  SAMEA112904762      Probiotic          CC           Trial 3  2019-07-14\n##  SAMEA112904763        Control          CA           Trial 1  2019-03-11\n##                 Trial start         animal      system          canonical_url\n##                 &lt;character&gt;    &lt;character&gt; &lt;character&gt;            &lt;character&gt;\n##  SAMEA112904734  2019-04-21 SAMEA112904734     chicken https://www.ebi.ac.u..\n##  SAMEA112904735  2019-06-09 SAMEA112904735     chicken https://www.ebi.ac.u..\n##  SAMEA112904737  2019-04-21 SAMEA112904737     chicken https://www.ebi.ac.u..\n##  SAMEA112904741  2019-06-09 SAMEA112904741     chicken https://www.ebi.ac.u..\n##  SAMEA112904746  2019-04-21 SAMEA112904746     chicken https://www.ebi.ac.u..\n##  SAMEA112904748  2019-06-09 SAMEA112904748     chicken https://www.ebi.ac.u..\n##  SAMEA112904749  2019-02-04 SAMEA112904749     chicken https://www.ebi.ac.u..\n##  SAMEA112904755  2019-04-21 SAMEA112904755     chicken https://www.ebi.ac.u..\n##  SAMEA112904762  2019-06-09 SAMEA112904762     chicken https://www.ebi.ac.u..\n##  SAMEA112904763  2019-02-04 SAMEA112904763     chicken https://www.ebi.ac.u..\n##                 Average Daily Feed intake: Day 00 - 07\n##                                              &lt;numeric&gt;\n##  SAMEA112904734                                  19.39\n##  SAMEA112904735                                  22.35\n##  SAMEA112904737                                  18.18\n##  SAMEA112904741                                  21.68\n##  SAMEA112904746                                  19.75\n##  SAMEA112904748                                  21.10\n##  SAMEA112904749                                  18.67\n##  SAMEA112904755                                  23.36\n##  SAMEA112904762                                  21.15\n##  SAMEA112904763                                  19.67\n##                 Average Daily Feed intake: Day 00 - 07, unit\n##                                                  &lt;character&gt;\n##  SAMEA112904734                                            g\n##  SAMEA112904735                                            g\n##  SAMEA112904737                                            g\n##  SAMEA112904741                                            g\n##  SAMEA112904746                                            g\n##  SAMEA112904748                                            g\n##  SAMEA112904749                                            g\n##  SAMEA112904755                                            g\n##  SAMEA112904762                                            g\n##  SAMEA112904763                                            g\n\nThe sampleMap slot now contains mappings between each sample and the corresponding animal. There are as many rows as there are total samples.\nThe “colname” column refers to the samples in the omic dataset identified in the “assay” column, while the “primary” column provides information about the animals. You will notice that some animals are listed multiple times, reflecting the multiple omics and time points collected for those individuals.\n\nsampleMap(mae)\n##  DataFrame with 33 rows and 3 columns\n##                assay        primary        colname\n##             &lt;factor&gt;    &lt;character&gt;    &lt;character&gt;\n##  1   BIOGENIC AMINES SAMEA112904734 SAMEA112906114\n##  2   BIOGENIC AMINES SAMEA112904734 SAMEA112906592\n##  3   BIOGENIC AMINES SAMEA112904735 SAMEA112906338\n##  4   BIOGENIC AMINES SAMEA112904735 SAMEA112906810\n##  5   BIOGENIC AMINES SAMEA112904737 SAMEA112906123\n##  ...             ...            ...            ...\n##  29      FATTY ACIDS SAMEA112904755 SAMEA112906112\n##  30      FATTY ACIDS SAMEA112904755 SAMEA112906590\n##  31      FATTY ACIDS SAMEA112904762 SAMEA112906315\n##  32      FATTY ACIDS SAMEA112904762 SAMEA112906787\n##  33      FATTY ACIDS SAMEA112904763 SAMEA112905916\n\nFor information have a look at the intro vignette of the MultiAssayExperiment package.\n\n\n\n\n\n\nRecommended options for storing multiple data tables in microbiome studies\n\n\n\n\n\nTable 3.1: The assays are best suited for data transformations (one-to-one match between samples and columns across the assays). The alternative experiments are particularly suitable for alternative versions of the data that are of same type but may have a different number of features (e.g. taxonomic groups); this is for instance the case with taxonomic abundance tables agglomerated at different levels (e.g. genus vs. phyla) or alternative profiling technologies (e.g. amplicon sequencing vs. shallow shotgun metagenomics). For alternative experiments one-to-one match between samples (cols) is libraryd but the alternative experiment tables can have different numbers of features (rows). Finally, elements of the MAE provide the most flexible way to incorporate multi-omic data tables with flexible numbers of samples and features. We recommend these conventions as the basis for methods development and application in microbiome studies.\n\n\n\nOption\nRows (features)\nCols (samples)\nRecommended\n\n\n\nassays\nmatch\nmatch\nData transformations\n\n\naltExp\nfree\nmatch\nAlternative experiments\n\n\nMultiAssay\nfree\nfree (mapping)\nMulti-omic experiments\n\n\n\n\n\n\nMulti-assay analyses, discussed in sections Section 20.1 and Chapter 21, can be facilitated by the multi-assay data containers, TreeSummarizedExperiment and MultiAssayExperiment. These are scalable and contain different types of data in a single container, making this framework particularly suited for multi-assay microbiome data incorporating different types of complementary data sources in a single, reproducible workflow. An alternative experiment can be stored in altExp slot of the SE data container. Alternatively, both experiments can be stored side-by-side in an MAE data container.",
    "crumbs": [
      "Data containers & importing",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data containers</span>"
    ]
  },
  {
    "objectID": "pages/import.html",
    "href": "pages/import.html",
    "title": "4  Import",
    "section": "",
    "text": "4.1 Import microbiome data from files\nThe data containers can be constructed from scratch. For most common microbiome data formats, there is dedicated importers available which streamlines the importing.",
    "crumbs": [
      "Data containers & importing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Import</span>"
    ]
  },
  {
    "objectID": "pages/import.html#sec-loading-experimental-microbiome-data",
    "href": "pages/import.html#sec-loading-experimental-microbiome-data",
    "title": "4  Import",
    "section": "",
    "text": "4.1.1 Standard data formats\nSpecific import functions are provided for:\n\nBIOM files (see help(mia::importBIOM))\nQIIME2 files (see help(mia::importQIIME2))\nMothur files (see help(mia::importMothur))\nMetaPhlAn files (see help(mia::importMetaPhlAn))\nHUMAnN files (see help(mia::importHUMAnN))\ntaxpasta files (see help(mia::importTaxpasta))\n\nHere we show how Biom files are imported into a TreeSE object using as an example Tengeler2020, which is further described here. This dataset consists of 3 files, which can be fetched or downloaded from this repository:\n\nbiom file: abundance table and taxonomy information\ncsv file: sample metadata\ntree file: phylogenetic tree\n\nTo begin with, we store the data in a local directory within the working directory, such as data/, and define the source file paths.\n\nbiom_file_path &lt;- system.file(\n    \"extdata\", \"Aggregated_humanization2.biom\", package = \"OMA\")\nsample_meta_file_path &lt;- system.file(\n    \"extdata\", \"Mapping_file_ADHD_aggregated.csv\", package = \"OMA\")\ntree_file_path &lt;- system.file(\n    \"extdata\", \"Data_humanization_phylo_aggregation.tre\", package = \"OMA\")\n\nNow we can read in the biom file and convert it into a TreeSE object. In addition, we retrieve the rank names from the prefixes of the feature names and then remove them with the rank.from.prefix and prefix.rm optional arguments.\n\nlibrary(mia)\n\n# read biom and convert it to TreeSE\ntse &lt;- importBIOM(\n    biom_file_path,\n    rank.from.prefix = TRUE,\n    prefix.rm = TRUE,\n    artifact.rm = TRUE)\n\n# Check\ntse\n##  class: TreeSummarizedExperiment \n##  dim: 151 27 \n##  metadata(0):\n##  assays(1): counts\n##  rownames(151): 1726470 1726471 ... 17264756 17264757\n##  rowData names(6): kingdom phylum ... family genus\n##  colnames(27): A110 A111 ... A38 A39\n##  colData names(0):\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: NULL\n##  rowTree: NULL\n##  colLinks: NULL\n##  colTree: NULL\n\nThe assays slot includes a list of abundance tables. The imported abundance table is named as “counts”. Let us inspect only the first cols and rows.\n\nassay(tse, \"counts\")[1:3, 1:3]\n##            A110  A111  A12\n##  1726470  17722 11630    0\n##  1726471  12052     0 2679\n##  17264731     0   970    0\n\nThe rowdata includes taxonomic information from the biom file. The head() command shows just the beginning of the data table for an overview.\nknitr::kable() helps print the information more nicely.\n\nrowData(tse) |&gt; head()\n##  DataFrame with 6 rows and 6 columns\n##               kingdom          phylum            class              order\n##           &lt;character&gt;     &lt;character&gt;      &lt;character&gt;        &lt;character&gt;\n##  1726470     Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n##  1726471     Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n##  17264731    Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n##  17264726    Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n##  1726472     Bacteria Verrucomicrobia Verrucomicrobiae Verrucomicrobiales\n##  17264724    Bacteria   Bacteroidetes      Bacteroidia      Bacteroidales\n##                        family           genus\n##                   &lt;character&gt;     &lt;character&gt;\n##  1726470       Bacteroidaceae     Bacteroides\n##  1726471       Bacteroidaceae     Bacteroides\n##  17264731  Porphyromonadaceae Parabacteroides\n##  17264726      Bacteroidaceae     Bacteroides\n##  1726472  Verrucomicrobiaceae     Akkermansia\n##  17264724      Bacteroidaceae     Bacteroides\n\nWe notice that the imported biom file did not contain any colData yet, so only an empty dataframe appears in this slot.\n\ncolData(tse) |&gt; head()\n##  DataFrame with 6 rows and 0 columns\n\nLet us add colData from the sample metadata, which is stored in a CSV file.\n\n# CSV file with colnames in the first row and rownames in the first column\nsample_meta &lt;- read.csv(\n    sample_meta_file_path, sep = \",\", row.names = 1)\n\n# Add this sample data to colData of the taxonomic data object\n# Note that the data must be given in a DataFrame format\ncolData(tse) &lt;- DataFrame(sample_meta)\n\nNow the colData includes the sample metadata.\n\ncolData(tse) |&gt; head()\n##  DataFrame with 6 rows and 4 columns\n##         Treatment      Cohort TreatmentxCohort Description\n##       &lt;character&gt; &lt;character&gt;      &lt;character&gt; &lt;character&gt;\n##  A110        ADHD    Cohort_1    ADHD_Cohort_1        A110\n##  A12         ADHD    Cohort_1    ADHD_Cohort_1         A12\n##  A15         ADHD    Cohort_1    ADHD_Cohort_1         A15\n##  A19         ADHD    Cohort_1    ADHD_Cohort_1         A19\n##  A21         ADHD    Cohort_2    ADHD_Cohort_2         A21\n##  A23         ADHD    Cohort_2    ADHD_Cohort_2         A23\n\nFinally, we add a phylogenetic tree to the rowData slot. Such feature is available only in TreeSE objects. Similarly, Trees specifying the sample hierarchy can be stored in the colTree slot.\nHere, we read in the file containing the phylogenetic tree and insert it in corresponding slot of the TreeSE object.\n\n# Reads the tree file\ntree &lt;- ape::read.tree(tree_file_path)\n\n# Add tree to rowTree\nrowTree(tse) &lt;- tree\n\n# Check\ntse\n##  class: TreeSummarizedExperiment \n##  dim: 151 27 \n##  metadata(0):\n##  assays(1): counts\n##  rownames(151): 1726470 1726471 ... 17264756 17264757\n##  rowData names(6): kingdom phylum ... family genus\n##  colnames(27): A110 A12 ... A35 A38\n##  colData names(4): Treatment Cohort TreatmentxCohort Description\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (151 rows)\n##  rowTree: 1 phylo tree(s) (151 leaves)\n##  colLinks: NULL\n##  colTree: NULL\n\nNow the rowTree slot contains the phylogenetic tree:\n\nrowTree(tse) |&gt; head()\n\n\n4.1.2 Non-standard formats\nMicrobiome (taxonomic) profiling data is commonly distributed in various file formats. You can import such external data files as a TreeSE object, but the details depend on the file format. Here, we provide examples for common formats. Some datasets and raw files to learn how to import raw data and construct TreeSE/MAE containers are available in the microbiome data repository.\n\n4.1.2.1 CSV import\nCSV data tables can be imported with the standard R functions, then converted to the desired format. For detailed examples, you can check the Bioconductor course material by Martin Morgan. You can also check the example files and construct your own CSV files accordingly.\nRecommendations for the CSV files are the following. File names are arbitrary; we refer here to the same names as in the examples:\n\nAbundance table (assay_taxa.csv): data matrix (features x samples); first column provides feature IDs, the first row provides sample IDs; other values should be numeric (abundances).\nRow data (rowdata_taxa.csv): data table (features x info); first column provides feature IDs, the first row provides column headers; this file usually contains the taxonomic mapping between different taxonomic levels. Ideally, the feature IDs (row names) match one-to-one with the abundance table row names.\nColumn data (coldata.csv): data table (samples x info); first column provides sample IDs, the first row provides column headers; this file usually contains the sample metadata/phenodata (such as subject age, health etc). Ideally, the sample IDs match one-to-one with the abundance table column names.\n\nAfter you have set up the CSV files, you can read them in R:\n\ncount_file  &lt;- system.file(\"extdata\", \"assay_taxa.csv\", package = \"OMA\")\ntax_file    &lt;- system.file(\"extdata\", \"rowdata_taxa.csv\", package = \"OMA\")\nsample_file &lt;- system.file(\"extdata\", \"coldata.csv\", package = \"OMA\")\n\n# Load files\ncounts  &lt;- read.csv(count_file, row.names=1)   # Abundance table (e.g. ASV data; to assay data)\ntax     &lt;- read.csv(tax_file, row.names=1)     # Taxonomy table (to rowData)\nsamples &lt;- read.csv(sample_file, row.names=1)  # Sample data (to colData)\n\nAfter reading the data in R, ensure the following:\n\nabundance table (counts): numeric matrix, with feature IDs as rownames and sample IDs as column names.\nrowdata (tax): DataFrame, with feature IDs as rownames. If this is a data.frame you can use the function DataFrame() to change the format. Column names are free but in microbiome analysis they usually they refer to taxonomic ranks. The rownames in rowdata should match with rownames in abundance table.\ncoldata (samples): DataFrame, with sample IDs as rownames. If this is a data.frame you can use the function DataFrame() to change the format. Column names are free. The rownames in coldata should match with colnames in abundance table.\n\nAlways ensure that the tables have rownames! The TreeSE constructor compares rownames and ensures that, for example, right samples are linked with right patient.\nAlso, ensure that the row and column names match one-to-one between abundance table, rowdata, and coldata:\n\n# Match rows and columns\ncounts &lt;- counts[rownames(tax), rownames(samples)]\n\n# Let's ensure that the data is in correct (numeric matrix) format:\ncounts &lt;- as.matrix(counts)\n\nIf you hesitate about the format of the data, you can compare to one of the available demonstration datasets, and make sure that your data components have the same format.\nThere are many different source files and many different ways to read data in R. One can do data manipulation in R as well. Investigate the entries as follows.\n\n# coldata rownames match assay colnames\nall(rownames(samples) == colnames(counts)) # our dataset\n##  [1] TRUE\nclass(samples) # should be data.frame or DataFrame\n##  [1] \"data.frame\"\n\n# rowdata rownames match assay rownames\nall(rownames(tax) == rownames(counts)) # our dataset\n##  [1] TRUE\nclass(tax) # should be data.frame or DataFrame\n##  [1] \"data.frame\"\n\n# Counts\nclass(counts) # should be a numeric matrix\n##  [1] \"matrix\" \"array\"\n\n\n\n\n\n\n\nImportant!\n\n\n\nEnsure that colnames of assay match with rownames of colData, and rownames of assay match with rownames of rowData.\nIf your data do not have names, you have to be especially careful, since this can lead to errors!\n\n\n\n4.1.2.2 Constructing TreeSE\nNow, let’s create the TreeSE object from the input data tables. Here we also convert the data objects in their preferred formats:\n\ncounts –&gt; numeric matrix\nrowData –&gt; DataFrame\ncolData –&gt; DataFrame\n\nThe SimpleList could be used to include multiple alternative assays, if necessary.\n\n# Create a TreeSE\ntse_taxa &lt;- TreeSummarizedExperiment(\n    assays =  SimpleList(counts = counts),\n    colData = DataFrame(samples),\n    rowData = DataFrame(tax))\n\ntse_taxa\n##  class: TreeSummarizedExperiment \n##  dim: 12706 40 \n##  metadata(0):\n##  assays(1): counts\n##  rownames(12706): GAYR01026362.62.2014 CVJT01000011.50.2173 ...\n##    JRJTB:03787:02429 JRJTB:03787:02478\n##  rowData names(7): Phylum Class ... Species OTU\n##  colnames(40): C1 C2 ... C39 C40\n##  colData names(6): Sample Rat ... Fat XOS\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: NULL\n##  rowTree: NULL\n##  colLinks: NULL\n##  colTree: NULL\n\nNow you should have a ready-made TreeSE data object that can be used in downstream analyses.\n\n4.1.2.3 Constructing MAE\nTo construct a MAE object, just combine multiple TreeSE data containers.\nHere we import metabolite data from the same study.\n\ncount_file &lt;- system.file(\"extdata\", \"assay_metabolites.csv\", package = \"OMA\")\nsample_file &lt;- system.file(\"extdata\", \"coldata.csv\", package = \"OMA\")\n\n# Load files\ncounts  &lt;- read.csv(count_file, row.names=1)\nsamples &lt;- read.csv(sample_file, row.names=1)\n\n# Create a TreeSE for the metabolite data\ntse_metabolite &lt;- TreeSummarizedExperiment(\n    assays = SimpleList(concs = as.matrix(counts)),\n    colData = DataFrame(samples))\n\ntse_metabolite\n##  class: TreeSummarizedExperiment \n##  dim: 38 40 \n##  metadata(0):\n##  assays(1): concs\n##  rownames(38): Butyrate Acetate ... Malonate 1,3-dihydroxyacetone\n##  rowData names(0):\n##  colnames(40): C1 C2 ... C39 C40\n##  colData names(6): Sample Rat ... Fat XOS\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: NULL\n##  rowTree: NULL\n##  colLinks: NULL\n##  colTree: NULL\n\n\n\n\n\n\n\nImportant!\n\n\n\nWhen creating TreeSE, assay must be a matrix, and both colData and rowData must be DataFrame objects.\n\n\nNow we can combine these two experiments into MAE.\n\n# Create an ExperimentList that includes experiments\nexperiments &lt;- ExperimentList(\n    microbiome = tse_taxa, metabolite = tse_metabolite)\n\n# Create a MAE\nmae &lt;- MultiAssayExperiment(experiments = experiments)\n\nmae\n##  A MultiAssayExperiment object of 2 listed\n##   experiments with user-defined names and respective classes.\n##   Containing an ExperimentList class object of length 2:\n##   [1] microbiome: TreeSummarizedExperiment with 12706 rows and 40 columns\n##   [2] metabolite: TreeSummarizedExperiment with 38 rows and 40 columns\n##  Functionality:\n##   experiments() - obtain the ExperimentList instance\n##   colData() - the primary/phenotype DataFrame\n##   sampleMap() - the sample coordination DataFrame\n##   `$`, `[`, `[[` - extract colData columns, subset, or experiment\n##   *Format() - convert into a long or wide DataFrame\n##   assays() - convert ExperimentList to a SimpleList of matrices\n##   exportClass() - save data to flat files",
    "crumbs": [
      "Data containers & importing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Import</span>"
    ]
  },
  {
    "objectID": "pages/import.html#sec-example-data",
    "href": "pages/import.html#sec-example-data",
    "title": "4  Import",
    "section": "\n4.2 Data resources",
    "text": "4.2 Data resources\nOpen demonstration data for testing and benchmarking purposes is available from multiple locations. This chapter introduces some options. The other chapters of this book provide ample examples about the use of the data.\n\n4.2.1 Package data\nThe mia R package contains example datasets that are direct conversions from the alternative phyloseq container to the TreeSE container.\nList the available datasets in the mia package:\n\nlibrary(mia)\ndata(package=\"mia\")\n\nLoad the GlobalPatterns data from the mia package:\n\ndata(\"GlobalPatterns\", package=\"mia\")\nGlobalPatterns\n##  class: TreeSummarizedExperiment \n##  dim: 19216 26 \n##  metadata(0):\n##  assays(1): counts\n##  rownames(19216): 549322 522457 ... 200359 271582\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(26): CL3 CC1 ... Even2 Even3\n##  colData names(7): X.SampleID Primer ... SampleType Description\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (19216 rows)\n##  rowTree: 1 phylo tree(s) (19216 leaves)\n##  colLinks: NULL\n##  colTree: NULL\n\nR packages contain additional demonstration data sets (see the Datasets section of the reference page):\n\nmia reference\nmiaViz reference\nmiaTime reference\n\n4.2.2 ExperimentHub data\nExperimentHub provides a variety of data resources, including the microbiomeDataSets package (Morgan and Shepherd 2021; Lahti, Ernst, and Shetty 2021).\n\nMorgan, Martin, and Lori Shepherd. 2021. ExperimentHub: Client to Access ExperimentHub Resources.\n\nLahti, Leo, Felix G. M. Ernst, and Sudarshan Shetty. 2021. microbiomeDataSets: Experiment Hub Based Microbiome Datasets.\nA table of the available datasets is available through the availableDataSets() function.\n\nlibrary(microbiomeDataSets)\navailableDataSets()\n##              Dataset\n##  1  GrieneisenTSData\n##  2       LahtiMLData\n##  3        LahtiMData\n##  4      OKeefeDSData\n##  5 SilvermanAGutData\n##  6        SongQAData\n##  7   SprockettTHData\n\nAll data are downloaded from ExperimentHub and cached for local re-use. Check the man pages of each function for a detailed documentation of the data contents and references. Let us retrieve a MAE dataset:\n\n# mae &lt;- HintikkaXOData()\n# Since HintikkaXOData is now added to mia, we can load it directly from there\n# We suggest to check other datasets from microbiomeDataSets\ndata(HintikkaXOData, package = \"mia\")\nmae &lt;- HintikkaXOData\n\nData is available in SE, TreeSE and MAE data containers; see the for example Section 20.1 for more details.\n\n4.2.3 Curated metagenomic data\ncuratedMetagenomicData is a large collection of curated human microbiome datasets, provided as TreeSE objects (Pasolli et al. 2017). The resource provides curated human microbiome data including gene families, marker abundance, marker presence, pathway abundance, pathway coverage, and relative abundance for samples from different body sites. See the package homepage for more details on data availability and access.\n\nPasolli, Edoardo, Lucas Schiffer, Paolo Manghi, Audrey Renson, Valerie Obenchain, Duy Tin Truong, Francesco Beghini, et al. 2017. “Accessible, Curated Metagenomic Data Through ExperimentHub.” Nature Methods 14 (11): 1023–24. https://doi.org/https://doi.org/10.1038/nmeth.4468.\n\nVatanen, Tommi, Aleksandar D. Kostic, Eva d’Hennezel, Heli Siljander, Eric A. Franzosa, Moran Yassour, Raivo Kolde, et al. 2016. “Variation in Microbiome LPS Immunogenicity Contributes to Autoimmunity in Humans.” Cell 165 (May): 842–53. https://doi.org/10.1016/j.cell.2016.04.007.\nAs one example, let us retrieve the Vatanen (2016) (Vatanen et al. 2016) data set. This is a larger collection with a bit longer download time.\n\nlibrary(curatedMetagenomicData)\ntse &lt;- curatedMetagenomicData(\"Vatanen*\", dryrun = FALSE, counts = TRUE)\n\n\n4.2.4 Human microbiome compendium\nMicroBioMap dataset includes over 170k samples of publicly available 16S rRNA amplicon sequencing data, all processed using the same pipeline and reference database (Davis et al. 2024). After installing the MicroBioMap package (see the original website for instructions), you can load the compendium with\n\nDavis, Sean, Richard Abdill, Ran Blehkman, Samantha Graham, and Casey Greene. 2024. MicroBioMap: Access the Microbiome Compendium from r. https://github.com/seandavi/MicroBioMap.\n\nlibrary(MicroBioMap)\ncpd &lt;- getCompendium()\n\nThis returns a TreeSE object. Currently, the rowTree slot of the TreeSE is not populated.\nAfter loading the compendium, you will have immediate access to nearly 170,000 microbiome samples of publicly available 16S rRNA amplicon sequencing data, all processed using the same pipeline and reference database. For more use examples in R/Bioconductor, see the MicroBioMap vignette.\n\n4.2.5 Other data sources\nThe current collections provide access to vast microbiome data resources. The output has to be converted into TreeSE/MAE separately.\n\n\nMGnifyR provides access to EBI/MGnify\n\n\nHoloFoodR provides access to EBI/HoloFood\n\n\nqiitr provides access to QIITA\n\n\nqiime2R provides access to QIIME2",
    "crumbs": [
      "Data containers & importing",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Import</span>"
    ]
  },
  {
    "objectID": "pages/convert.html",
    "href": "pages/convert.html",
    "title": "5  Convert & export",
    "section": "",
    "text": "5.1 Conversions between data formats in R\nIf the data has already been imported in R in another format, it can be readily converted into TreeSE, as shown in our next example. Note that similar conversion functions to TreeSE are available for multiple data formats via the mia package (see convertFrom* for phyloseq, Biom, and DADA2).\nlibrary(mia)\n\n# phyloseq example data\ndata(GlobalPatterns, package = \"phyloseq\")\nGlobalPatterns_phyloseq &lt;- GlobalPatterns\nGlobalPatterns_phyloseq\n##  phyloseq-class experiment-level object\n##  otu_table()   OTU Table:         [ 19216 taxa and 26 samples ]\n##  sample_data() Sample Data:       [ 26 samples by 7 sample variables ]\n##  tax_table()   Taxonomy Table:    [ 19216 taxa by 7 taxonomic ranks ]\n##  phy_tree()    Phylogenetic Tree: [ 19216 tips and 19215 internal nodes ]\n# convert phyloseq to TSE\nGlobalPatterns_TSE &lt;- convertFromPhyloseq(GlobalPatterns_phyloseq)\nGlobalPatterns_TSE\n##  class: TreeSummarizedExperiment \n##  dim: 19216 26 \n##  metadata(0):\n##  assays(1): counts\n##  rownames(19216): 549322 522457 ... 200359 271582\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(26): CL3 CC1 ... Even2 Even3\n##  colData names(7): X.SampleID Primer ... SampleType Description\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (19216 rows)\n##  rowTree: 1 phylo tree(s) (19216 leaves)\n##  colLinks: NULL\n##  colTree: NULL\nWe can also convert TreeSE objects into phyloseq with respect to the shared components that are supported by both formats (i.e. taxonomic abundance table, sample metadata, taxonomic table, phylogenetic tree, sequence information). This is useful for instance when additional methods are available for phyloseq.\n# convert TSE to phyloseq\nGlobalPatterns_phyloseq2 &lt;- convertToPhyloseq(GlobalPatterns_TSE)\nGlobalPatterns_phyloseq2\n##  phyloseq-class experiment-level object\n##  otu_table()   OTU Table:         [ 19216 taxa and 26 samples ]\n##  sample_data() Sample Data:       [ 26 samples by 7 sample variables ]\n##  tax_table()   Taxonomy Table:    [ 19216 taxa by 7 taxonomic ranks ]\n##  phy_tree()    Phylogenetic Tree: [ 19216 tips and 19215 internal nodes ]\nConversion is possible between other data formats. Interested readers can refer to the following functions:",
    "crumbs": [
      "Data containers & importing",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Convert & export</span>"
    ]
  },
  {
    "objectID": "pages/convert.html#sec-conversions-between-data-formats-in-r",
    "href": "pages/convert.html#sec-conversions-between-data-formats-in-r",
    "title": "5  Convert & export",
    "section": "",
    "text": "convertFromDADA2\nconvertFromBIOM\nconvertToBIOM",
    "crumbs": [
      "Data containers & importing",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Convert & export</span>"
    ]
  },
  {
    "objectID": "pages/convert.html#sec-exporting-data-container",
    "href": "pages/convert.html#sec-exporting-data-container",
    "title": "5  Convert & export",
    "section": "\n5.2 Exporting data container",
    "text": "5.2 Exporting data container\n\n5.2.1 Export TreeSummarizedExperiment\nTransforming a TreeSE object into a dataframe is straightforward with the mia package. The meltSE function is particularly handy for this purpose. It allows you to melt various parts of a TreeSE object into a dataframe based on the parameters you specify.\nExporting a TreeSE data container can be done using feather package. TreeSE object has to be converted into a dataframe (data.frame and not DataFrame). The output file is a .feather file, which can be imported in other languages such as Julia or Python. For information, have a look at the FeatherFile Julia package and feather-format Python library.\n\ndata(GlobalPatterns, package = \"mia\")\ntse &lt;- GlobalPatterns\n\nmolten_tse &lt;- meltSE(\n    tse,\n    add_row_data = TRUE,\n    add_col_data = TRUE,\n    assay.type = \"counts\")\n\n# Export as a feather file\nlibrary(feather)\npath &lt;- \"path/to/tse.feather\"\nwrite_feather(molten_tse, path)\n\nAnother way could be using a CSV file. This works the same as for a feather file, make sure you have converted your TreeSE data container as a dataframe Here note that you can decide whether you want to write the row names or not.\n\nwrite.csv(molten_tse, \"path/to/tse.csv\", row.names=FALSE)\n\n\n5.2.2 Export MultiAssayExperiment\nExporting a MultiAssayExperiment data container can also be done using feather package.\n\n# Convert into a data.frame\nmolten_mae &lt;- longFormat(mae)\nmolten_mae &lt;- data.frame(molten_mae)\npath &lt;- \"path/to/mae.feather\"\nwrite_feather(molten_mae,path)\n\nAnd as a CSV file.\n\nwrite.csv(molten_mae, \"path/to/mae.csv\", row.names=FALSE)",
    "crumbs": [
      "Data containers & importing",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Convert & export</span>"
    ]
  },
  {
    "objectID": "pages/taxonomy.html",
    "href": "pages/taxonomy.html",
    "title": "6  Taxonomic information",
    "section": "",
    "text": "6.1 Assigning taxonomic information\nThere are a number of methods to assign taxonomic information. We like to give a short introduction about the methods available without ranking one over the other. This has to be your choice based on the result for the individual dataset.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Taxonomic information</span>"
    ]
  },
  {
    "objectID": "pages/taxonomy.html#assigning-taxonomic-information",
    "href": "pages/taxonomy.html#assigning-taxonomic-information",
    "title": "6  Taxonomic information",
    "section": "",
    "text": "6.1.1 DADA2\nThe dada2 package (Callahan et al. 2016) implements the assignTaxonomy() function, which takes as input the ASV sequences associated with each row of data and a training dataset. For more information visit the dada2 homepage.\n\nCallahan, Benjamin J, Paul J McMurdie, Michael J Rosen, Andrew W Han, Amy Jo A Johnson, and Susan P Holmes. 2016. “DADA2: High-Resolution Sample Inference from Illumina Amplicon Data.” Nature Methods 13: 581–83. https://doi.org/10.1038/nmeth.3869.\n\n6.1.2 DECIPHER\nThe DECIPHER package (Wright 2020) implements the IDTAXA algorithm to assign either taxonomic information or function information. For mia, only the first option is of interest for now and more information can be found on the DECIPHER website.\n\nWright, Erik. 2020. DECIPHER: Tools for Curating, Analyzing, and Manipulating Biological Sequences.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Taxonomic information</span>"
    ]
  },
  {
    "objectID": "pages/taxonomy.html#functions-to-access-taxonomic-information",
    "href": "pages/taxonomy.html#functions-to-access-taxonomic-information",
    "title": "6  Taxonomic information",
    "section": "\n6.2 Functions to access taxonomic information",
    "text": "6.2 Functions to access taxonomic information\n\n6.2.1 Check taxonomy ranks in data\ncheckTaxonomy() checks whether the taxonomic information is usable for mia\n\ncheckTaxonomy(tse)\n##  [1] TRUE\n\nSince the rowData can contain other data, taxonomyRanks() will return the columns that mia assumes to contain the taxonomic information.\n\ntaxonomyRanks(tse)\n##  [1] \"Kingdom\" \"Phylum\"  \"Class\"   \"Order\"   \"Family\"  \"Genus\"   \"Species\"\n\nThis can then be used to subset the rowData to columns needed.\n\nrowData(tse)[, taxonomyRanks(tse)]\n##  DataFrame with 19216 rows and 7 columns\n##             Kingdom        Phylum        Class        Order        Family\n##         &lt;character&gt;   &lt;character&gt;  &lt;character&gt;  &lt;character&gt;   &lt;character&gt;\n##  549322     Archaea Crenarchaeota Thermoprotei           NA            NA\n##  522457     Archaea Crenarchaeota Thermoprotei           NA            NA\n##  951        Archaea Crenarchaeota Thermoprotei Sulfolobales Sulfolobaceae\n##  244423     Archaea Crenarchaeota        Sd-NA           NA            NA\n##  586076     Archaea Crenarchaeota        Sd-NA           NA            NA\n##  ...            ...           ...          ...          ...           ...\n##  278222    Bacteria           SR1           NA           NA            NA\n##  463590    Bacteria           SR1           NA           NA            NA\n##  535321    Bacteria           SR1           NA           NA            NA\n##  200359    Bacteria           SR1           NA           NA            NA\n##  271582    Bacteria           SR1           NA           NA            NA\n##               Genus                Species\n##         &lt;character&gt;            &lt;character&gt;\n##  549322          NA                     NA\n##  522457          NA                     NA\n##  951     Sulfolobus Sulfolobusacidocalda..\n##  244423          NA                     NA\n##  586076          NA                     NA\n##  ...            ...                    ...\n##  278222          NA                     NA\n##  463590          NA                     NA\n##  535321          NA                     NA\n##  200359          NA                     NA\n##  271582          NA                     NA\n\ntaxonomyRankEmpty() checks for empty values in the given rank and returns a logical vector of length(x).\n\nall(!taxonomyRankEmpty(tse, rank = \"Kingdom\"))\n##  [1] TRUE\ntable(taxonomyRankEmpty(tse, rank = \"Genus\"))\n##  \n##  FALSE  TRUE \n##   8008 11208\ntable(taxonomyRankEmpty(tse, rank = \"Species\"))\n##  \n##  FALSE  TRUE \n##   1413 17803\n\n\n6.2.2 Get taxonomy labels\ngetTaxonomyLabels() is a multi-purpose function, which turns taxonomic information into a character vector of length(x)\n\ngetTaxonomyLabels(tse) |&gt; head()\n##  [1] \"Class:Thermoprotei\"               \"Class:Thermoprotei_1\"            \n##  [3] \"Species:Sulfolobusacidocaldarius\" \"Class:Sd-NA\"                     \n##  [5] \"Class:Sd-NA_1\"                    \"Class:Sd-NA_2\"\n\nBy default, this will use the lowest non-empty information to construct a string with the following scheme level:value. If all levels are the same, this part is omitted, but can be added by setting with.rank = TRUE.\n\nphylum &lt;- !is.na(rowData(tse)$Phylum) &\n    vapply(data.frame(apply(\n       rowData(tse)[, taxonomyRanks(tse)[3:7]], 1L, is.na)), all, logical(1))\ngetTaxonomyLabels(tse[phylum,]) |&gt; head()\n##  [1] \"Crenarchaeota\"    \"Crenarchaeota_1\"  \"Crenarchaeota_2\" \n##  [4] \"Actinobacteria\"   \"Actinobacteria_1\" \"Spirochaetes\"\ngetTaxonomyLabels(tse[phylum,], with.rank = TRUE) |&gt; head()\n##  [1] \"Phylum:Crenarchaeota\"    \"Phylum:Crenarchaeota_1\" \n##  [3] \"Phylum:Crenarchaeota_2\"  \"Phylum:Actinobacteria\"  \n##  [5] \"Phylum:Actinobacteria_1\" \"Phylum:Spirochaetes\"\n\nBy default the return value of getTaxonomyLabels() contains only unique elements by passing it through make.unique. This step can be omitted by setting make.unique = FALSE.\n\ngetTaxonomyLabels(tse[phylum,], with.rank = TRUE, make.unique = FALSE) |&gt; head()\n##  [1] \"Phylum:Crenarchaeota\"  \"Phylum:Crenarchaeota\"  \"Phylum:Crenarchaeota\" \n##  [4] \"Phylum:Actinobacteria\" \"Phylum:Actinobacteria\" \"Phylum:Spirochaetes\"\n\nTo apply the loop resolving function resolveLoop() from the TreeSummarizedExperiment package (Huang 2020) within getTaxonomyLabels(), set resolve.loops = TRUE.\n\n6.2.3 Get information on certain taxa\nThe function getUnique() gives a list of unique taxa for the specified taxonomic rank.\n\ngetUnique(tse, rank = \"Phylum\") |&gt; head()\n##  [1] \"Crenarchaeota\"  \"Euryarchaeota\"  \"Actinobacteria\" \"Spirochaetes\"  \n##  [5] \"MVP-15\"         \"Proteobacteria\"\n\nWith mapTaxonomy(), you can search information on certain taxa from the taxonomy table. For instance, we can check all the taxa that matches with “Escherichia”.\n\nmapTaxonomy(GlobalPatterns, taxa = \"Escherichia\")\n##  $Escherichia\n##  DataFrame with 1 row and 7 columns\n##             Kingdom         Phylum               Class             Order\n##         &lt;character&gt;    &lt;character&gt;         &lt;character&gt;       &lt;character&gt;\n##  249227    Bacteria Proteobacteria Gammaproteobacteria Enterobacteriales\n##                     Family       Genus     Species\n##                &lt;character&gt; &lt;character&gt; &lt;character&gt;\n##  249227 Enterobacteriaceae Escherichia          NA",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Taxonomic information</span>"
    ]
  },
  {
    "objectID": "pages/taxonomy.html#sec-fly-tree",
    "href": "pages/taxonomy.html#sec-fly-tree",
    "title": "6  Taxonomic information",
    "section": "\n6.3 Generate a hierarchy tree on the fly",
    "text": "6.3 Generate a hierarchy tree on the fly\nA hierarchy tree shows mapping between the taxonomic levels in taxonomic rank table (included in rowData), rather than the detailed phylogenetic relations. Usually, a phylogenetic tree refers to latter which is why we call here the generated tree as “hierarchy tree”.\nTo create a hierarchy tree, getHierarchyTree() used the information and returns a phylo object. Duplicate information from the rowData is removed.\n\ngetHierarchyTree(tse)\n##  \n##  Phylogenetic tree with 1645 tips and 1089 internal nodes.\n##  \n##  Tip labels:\n##    Species:Cenarchaeumsymbiosum, Species:pIVWA5, Species:CandidatusNitrososphaeragargensis, Species:SCA1145, Species:SCA1170, Species:Sulfolobusacidocaldarius, ...\n##  Node labels:\n##    root:ALL, Kingdom:Archaea, Phylum:Crenarchaeota, Class:C2, Class:Sd-NA, Class:Thaumarchaeota, ...\n##  \n##  Rooted; includes branch lengths.\n\n\ntse &lt;- addHierarchyTree(tse)\ntse\n##  class: TreeSummarizedExperiment \n##  dim: 19216 26 \n##  metadata(0):\n##  assays(1): counts\n##  rownames(19216): 549322 522457 ... 200359 271582\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(26): CL3 CC1 ... Even2 Even3\n##  colData names(7): X.SampleID Primer ... SampleType Description\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (19216 rows)\n##  rowTree: 1 phylo tree(s) (1645 leaves)\n##  colLinks: NULL\n##  colTree: NULL\n\nThe implementation is based on the toTree() function from the TreeSummarizedExperiment package (Huang 2020).\n\nHuang, Ruizhu. 2020. TreeSummarizedExperiment: A S4 Class for Data with Tree Structures.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Taxonomic information</span>"
    ]
  },
  {
    "objectID": "pages/taxonomy.html#set-taxonomy-ranks",
    "href": "pages/taxonomy.html#set-taxonomy-ranks",
    "title": "6  Taxonomic information",
    "section": "\n6.4 Set taxonomy ranks",
    "text": "6.4 Set taxonomy ranks\nIf your data includes taxonomy ranks that are not included by default in mia, you can set the ranks manually. By doing so, mia will be able to detect and utilize these taxonomy ranks from your data as expected.\nGet default ranks of mia.\n\ngetTaxonomyRanks()\n##   [1] \"domain\"       \"superkingdom\" \"kingdom\"      \"phylum\"      \n##   [5] \"class\"        \"order\"        \"family\"       \"genus\"       \n##   [9] \"species\"      \"strain\"\n\nSet ranks to your own ranks. Remember that the order is meaningful.\n\n# Set ranks\nsetTaxonomyRanks(c(\"test\", \"test2\", \"apple\"))\n\n# Get ranks\ngetTaxonomyRanks()\n##  [1] \"test\"  \"test2\" \"apple\"",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Taxonomic information</span>"
    ]
  },
  {
    "objectID": "pages/wrangling.html",
    "href": "pages/wrangling.html",
    "title": "7  Data wrangling",
    "section": "",
    "text": "7.1 Splitting\nYou can split the data based on variables by using the functions agglomerateByRanks() and splitOn(). The former is detailed in Chapter 9.\nIf you want to split the data based on a variable other than taxonomic rank, use splitOn(). It works for row-wise and column-wise splitting. We might want to split the data, Splitting the data may be useful, for example, if you want to analyze data from different cohorts separately.\nlibrary(mia)\ndata(\"GlobalPatterns\")\ntse &lt;- GlobalPatterns\n\nsplitOn(tse, \"SampleType\")\n##  List of length 9\n##  names(9): Soil Feces Skin Tongue ... Ocean Sediment (estuary) Mock",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "pages/wrangling.html#sec-add-or-modify-data",
    "href": "pages/wrangling.html#sec-add-or-modify-data",
    "title": "7  Data wrangling",
    "section": "\n7.2 Add or modify variables",
    "text": "7.2 Add or modify variables\nThe information contained by the colData of a TreeSE can be added and/or modified by accessing the desired variables. You might want to add or modify this data to include new variables or update existing ones, which can be essential for ensuring that all relevant metadata is available for subsequent analyses.\n\n# modify the Description entries\ncolData(tse)$Description &lt;- paste(\n    colData(tse)$Description, \"modified description\")\n\n# view modified variable\ntse$Description |&gt; head()\n##  [1] \"Calhoun South Carolina Pine soil, pH 4.9 modified description\"  \n##  [2] \"Cedar Creek Minnesota, grassland, pH 6.1 modified description\"  \n##  [3] \"Sevilleta new Mexico, desert scrub, pH 8.3 modified description\"\n##  [4] \"M3, Day 1, fecal swab, whole body study modified description\"   \n##  [5] \"M1, Day 1, fecal swab, whole body study  modified description\"  \n##  [6] \"M3, Day 1, right palm, whole body study modified description\"\n\nNew information can be added to the experiment by creating a new variable.\n\n# simulate new data\nnew_data &lt;- runif(ncol(tse))\n\n# store new data as new variable in colData\ncolData(tse)$NewVariable &lt;- new_data\n\n# view new variable\ntse$NewVariable |&gt; head()\n##  [1] 0.8179 0.8856 0.9790 0.5896 0.7695 0.5240\n\nAlternatively, you can add whole table by merging it with existing colData.\n\n# simulate new data\nnew_data &lt;- data.frame(var1 = runif(ncol(tse)), var2 = runif(ncol(tse)))\nrownames(new_data) &lt;- colnames(tse)\n\n# Combine existing data with new data\ncolData(tse) &lt;- cbind(colData(tse), new_data)\n\nSimilar steps can also be applied to rowData. If you have an assay whose rows and columns aling with the existing ones, you can add the assay easily to the TreeSE object.\nHere we add an assay that has random numbers but in real life these steps might come handy after you have transformed the data with custom transformation that cannot be found from mia.\n\n# Create a matrix with random values\nmat &lt;- rnorm(ncol(tse)*nrow(tse), 0, 1)\nmat &lt;- matrix(mat, ncol = ncol(tse), nrow = nrow(tse))\n# Add matrix to tse\nassay(tse, \"random\", withDimnames = FALSE) &lt;- mat\n\nassayNames(tse)\n##  [1] \"counts\" \"random\"\n\nNow we can see that the TreeSE object has now an additional assay called “random”. When adding new samples or features to your existing dataset, you can use cbind() to combine columns for new features or rbind() to add rows for new samples.\n\ntse2 &lt;- cbind(tse, tse)\ntse2\n##  class: TreeSummarizedExperiment \n##  dim: 19216 52 \n##  metadata(0):\n##  assays(2): counts random\n##  rownames(19216): 549322 522457 ... 200359 271582\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(52): CL3 CC1 ... Even2 Even3\n##  colData names(10): X.SampleID Primer ... var1 var2\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (19216 rows)\n##  rowTree: 1 phylo tree(s) (19216 leaves)\n##  colLinks: NULL\n##  colTree: NULL\n\nHowever, the aforementioned functions assume that the rows align correctly when combining columns, and vice versa. In practice, this is often not the case; for example, samples may have different feature sets. In such situations, using a merging approach is the appropriate method.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "pages/wrangling.html#merge-data",
    "href": "pages/wrangling.html#merge-data",
    "title": "7  Data wrangling",
    "section": "\n7.3 Merge data",
    "text": "7.3 Merge data\nmia package has mergeSEs() function that merges multiple SummarizedExperiment objects. For example, it is possible to combine multiple TreeSE objects which each includes one sample.\nmergeSEs() works much like standard joining operations. It combines rows and columns and allows you to specify the merging method.\n\n# Take subsets for demonstration purposes\ntse1 &lt;- tse[, 1]\ntse2 &lt;- tse[, 2]\ntse3 &lt;- tse[, 3]\ntse4 &lt;- tse[1:100, 4]\n\n\n# With inner join, we want to include all shared rows. When using mergeSEs\n# function all samples are always preserved.\ntse &lt;- mergeSEs(list(tse1, tse2, tse3, tse4), join = \"inner\")\ntse\n##  class: TreeSummarizedExperiment \n##  dim: 100 4 \n##  metadata(0):\n##  assays(1): counts\n##  rownames(100): 239672 243675 ... 104332 159421\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(4): CC1 CL3 M31Fcsw SV1\n##  colData names(10): X.SampleID Primer ... var1 var2\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (100 rows)\n##  rowTree: 1 phylo tree(s) (19216 leaves)\n##  colLinks: NULL\n##  colTree: NULL\n\n\n# Left join preserves all rows of the 1st object\ntse &lt;- mergeSEs(tse1, tse4, missing.values = 0, join = \"left\")\ntse\n##  class: TreeSummarizedExperiment \n##  dim: 19216 2 \n##  metadata(0):\n##  assays(1): counts\n##  rownames(19216): 239672 243675 ... 239967 254851\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(2): CL3 M31Fcsw\n##  colData names(10): X.SampleID Primer ... var1 var2\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (19216 rows)\n##  rowTree: 1 phylo tree(s) (19216 leaves)\n##  colLinks: NULL\n##  colTree: NULL",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "pages/wrangling.html#melting-data",
    "href": "pages/wrangling.html#melting-data",
    "title": "7  Data wrangling",
    "section": "\n7.4 Melting data",
    "text": "7.4 Melting data\nFor several custom analysis and visualization packages, such as those from tidyverse, the SE data can be converted to a long data.frame format with meltSE().\n\nlibrary(knitr)\n\n# Melt SE object\nmolten_tse &lt;- meltSE(\n    tse,\n    add.row = TRUE,\n    add.col = TRUE,\n    assay.type = \"counts\")\n\nmolten_tse |&gt; head() |&gt; kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeatureID\nSampleID\ncounts\nKingdom\nPhylum\nClass\nOrder\nFamily\nGenus\nSpecies\nX.SampleID\nPrimer\nFinal_Barcode\nBarcode_truncated_plus_T\nBarcode_full_length\nSampleType\nDescription\nNewVariable\nvar1\nvar2\n\n\n\n239672\nCL3\n0\nArchaea\nCrenarchaeota\nC2\nB10\nNA\nNA\nNA\nCL3\nILBC_01\nAACGCA\nTGCGTT\nCTAGCGTGCGT\nSoil\nCalhoun South Carolina Pine soil, pH 4.9 modified description\n0.8179\n0.7463\n0.1163\n\n\n239672\nM31Fcsw\n0\nArchaea\nCrenarchaeota\nC2\nB10\nNA\nNA\nNA\nM31Fcsw\nILBC_04\nAAGAGA\nTCTCTT\nTCGACATCTCT\nFeces\nM3, Day 1, fecal swab, whole body study modified description\n0.5896\n0.1172\n0.7187\n\n\n243675\nCL3\n0\nArchaea\nCrenarchaeota\nC2\nB10\nNA\nNA\nNA\nCL3\nILBC_01\nAACGCA\nTGCGTT\nCTAGCGTGCGT\nSoil\nCalhoun South Carolina Pine soil, pH 4.9 modified description\n0.8179\n0.7463\n0.1163\n\n\n243675\nM31Fcsw\n0\nArchaea\nCrenarchaeota\nC2\nB10\nNA\nNA\nNA\nM31Fcsw\nILBC_04\nAAGAGA\nTCTCTT\nTCGACATCTCT\nFeces\nM3, Day 1, fecal swab, whole body study modified description\n0.5896\n0.1172\n0.7187\n\n\n444679\nCL3\n0\nArchaea\nCrenarchaeota\nC2\nB10\nNA\nNA\nNA\nCL3\nILBC_01\nAACGCA\nTGCGTT\nCTAGCGTGCGT\nSoil\nCalhoun South Carolina Pine soil, pH 4.9 modified description\n0.8179\n0.7463\n0.1163\n\n\n444679\nM31Fcsw\n0\nArchaea\nCrenarchaeota\nC2\nB10\nNA\nNA\nNA\nM31Fcsw\nILBC_04\nAAGAGA\nTCTCTT\nTCGACATCTCT\nFeces\nM3, Day 1, fecal swab, whole body study modified description\n0.5896\n0.1172\n0.7187",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Data wrangling</span>"
    ]
  },
  {
    "objectID": "pages/subsetting.html",
    "href": "pages/subsetting.html",
    "title": "8  Subsetting",
    "section": "",
    "text": "8.1 Subset by sample (column-wise)\nSeveral criteria can be used to subset by sample:\nFor the sake of demonstration, here we will extract a subset containing only the samples of human origin (feces, skin or tongue), stored as SampleType within colData(tse) as well as in tse.\nFirst, we would like to see all the possible values that SampleType can have and how frequent those are:\n# Show the frequency of each value\ntse$SampleType |&gt; table() |&gt; kable()\n\n\n\nVar1\nFreq\n\n\n\nFeces\n4\n\n\nFreshwater\n2\n\n\nFreshwater (creek)\n3\n\n\nMock\n3\n\n\nOcean\n3\n\n\nSediment (estuary)\n3\n\n\nSkin\n3\n\n\nSoil\n3\n\n\nTongue\n2\nNext, we logical index across the columns of tse (make sure to leave the first index empty to select all rows) and filter for the samples of human origin. For this, we use the information on the samples from the meta data colData(tse).\n# Subset by sample\ntse_sub &lt;- tse[ , tse$SampleType %in% c(\"Feces\", \"Skin\", \"Tongue\")]\n\n# Show dimensions\ndim(tse_sub)\n##  [1] 19216     9",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Subsetting</span>"
    ]
  },
  {
    "objectID": "pages/subsetting.html#subset-by-sample-column-wise",
    "href": "pages/subsetting.html#subset-by-sample-column-wise",
    "title": "8  Subsetting",
    "section": "",
    "text": "origin\nsampling time\nsequencing method\nDNA / RNA barcode\ncohort\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAfter subsetting, expect the number of columns to equal the sum of the frequencies of the samples that you are interested in. For instance, ncols = Feces + Skin + Tongue = 4 + 3 + 2 = 9.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Subsetting</span>"
    ]
  },
  {
    "objectID": "pages/subsetting.html#subset-by-feature-row-wise",
    "href": "pages/subsetting.html#subset-by-feature-row-wise",
    "title": "8  Subsetting",
    "section": "\n8.2 Subset by feature (row-wise)",
    "text": "8.2 Subset by feature (row-wise)\nSimilarly, here we will extract a subset containing only the features that belong to the phyla Actinobacteria and Chlamydiae, stored as Phylum within rowData(tse). However, subsetting by feature implies a few more obstacles, such as the presence of NA elements and the possible need for agglomeration.\nAs previously, we would first like to see all the possible values that Phylum can have and how frequent those are:\n\n# Show the frequency of each value\nrowData(tse)$Phylum |&gt; table() |&gt; head() |&gt; kable()\n\n\n\nVar1\nFreq\n\n\n\nABY1_OD1\n7\n\n\nAC1\n1\n\n\nAD3\n9\n\n\nAcidobacteria\n1021\n\n\nActinobacteria\n1631\n\n\nArmatimonadetes\n61\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nAfter subsetting, expect the number of columns to equal the sum of the frequencies of the feature(s) that you are interested in. For instance, nrows = Actinobacteria + Chlamydiae = 1631 + 21 = 1652.\n\n\nDepending on your research question, you might or might not need to agglomerate the data in the first place: if you want to find the abundance of each and every feature that belongs to Actinobacteria and Chlamydiae, agglomeration is not needed. However, if you want to find the total abundance of all features that belong to Actinobacteria or Chlamydiae, agglomeration is recommended (see Chapter 9 for details).\nNext, we logically index across the rows of tse (make sure to leave the second index empty to select all columns) and filter for the features that fall in either Actinobacteria or Chlamydiae group. For this, we use the information on the samples from the metadata rowData(tse).\nThe first term with the %in% operator includes all the features of interest, whereas the second term after the AND operator & filters out all features that have an NA in place of the phylum variable.\n\n# Subset by feature\nselected &lt;- rowData(tse)$Phylum %in% c(\"Actinobacteria\", \"Chlamydiae\") &\n  !is.na(rowData(tse)$Phylum)\ntse_sub &lt;- tse[selected, ]\n\n# Show dimensions\ndim(tse_sub)\n##  [1] 1652   26",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Subsetting</span>"
    ]
  },
  {
    "objectID": "pages/subsetting.html#subset-by-samples-and-features",
    "href": "pages/subsetting.html#subset-by-samples-and-features",
    "title": "8  Subsetting",
    "section": "\n8.3 Subset by samples and features",
    "text": "8.3 Subset by samples and features\nFinally, we can subset data by sample and feature at once. The resulting subset contains all the samples of human origin and all the features of phyla Actinobacteria or Chlamydiae.\n\n# Subset by sample and feature and remove NAs\nselected_rows &lt;- rowData(tse)$Phylum %in% c(\"Actinobacteria\", \"Chlamydiae\") &\n      !is.na(rowData(tse)$Phylum)\nselected_cols &lt;- tse$SampleType %in% c(\"Feces\", \"Skin\", \"Tongue\")\ntse_sub &lt;- tse[selected_rows, selected_cols]\n\n# Show dimensions\ndim(tse_sub)\n##  [1] 1652    9\n\n\n\n\n\n\n\nNote\n\n\n\nThe dimensions of tse_sub are consistent with the previous subsets (9 columns filtered by sample and 1652 rows filtered by feature).\n\n\nIf a study was to consider and quantify the presence of Actinobacteria as well as Chlamydiae in different sites of the human body, tse_sub might be a suitable subset to start with.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Subsetting</span>"
    ]
  },
  {
    "objectID": "pages/subsetting.html#filtering-out-empty-samples",
    "href": "pages/subsetting.html#filtering-out-empty-samples",
    "title": "8  Subsetting",
    "section": "\n8.4 Filtering out empty samples",
    "text": "8.4 Filtering out empty samples\nSometimes data might contain, e.g., features that are not present in any of the samples. This can occur, for example, after data subsetting. In certain analyses, we might want to remove those instances. In this example, we are interested only those features that belong to Species Achromatiumoxaliferum.\n\nind &lt;- rowData(tse)$Species == \"Achromatiumoxaliferum\"\nind[is.na(ind)] &lt;- FALSE\ntse_sub &lt;- tse[ind, ]\n\nThen we can calculate, how many times each feature was detected in each samples.\n\nlibrary(scuttle)\n\ntse_sub &lt;- addPerCellQCMetrics(tse_sub)\n# List total counts of each sample\ntse_sub$total |&gt; head()\n##  [1] 0 0 0 0 0 0\n\nNow we can see that certain samples do not include any bacteria. We can remove those.\n\n# Remove samples that do not contain any bacteria\ntse_sub &lt;- tse_sub[ , tse_sub$total != 0]\ntse_sub\n##  class: TreeSummarizedExperiment \n##  dim: 3 7 \n##  metadata(0):\n##  assays(1): counts\n##  rownames(3): 7595 7594 137055\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(7): AQC1cm AQC4cm ... TRRsed2 TRRsed3\n##  colData names(10): X.SampleID Primer ... detected total\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (3 rows)\n##  rowTree: 1 phylo tree(s) (19216 leaves)\n##  colLinks: NULL\n##  colTree: NULL\n\nWe have now subsetted the dataset so that it only includes samples containing the selected features. A similar approach can also be applied to filter features based on the samples they appear in, ensuring both dimensions of the data are relevant to your analysis.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Subsetting</span>"
    ]
  },
  {
    "objectID": "pages/subsetting.html#filtering-out-zero-variance-features",
    "href": "pages/subsetting.html#filtering-out-zero-variance-features",
    "title": "8  Subsetting",
    "section": "\n8.5 Filtering out zero-variance features",
    "text": "8.5 Filtering out zero-variance features\nIn some datasets, certain features remain constant across all samples—they show no variance. If our goal is to study or model microbial differences between groups, these zero-variance features hold no value. For a feature to reflect differences between groups, it must exhibit variability.\nBy removing these invariant features, we can sharpen our focus on the more informative features. This not only reduces the number of comparisons but also helps our machine learning models learn from meaningful data without additional noise.\nTo filter these features, we begin by calculating their standard deviation. Then we visualize the variances with histogram.\n\n# Calculate\nrowData(tse)[[\"sd\"]] &lt;- rowSds(assay(tse, \"counts\"))\n# Plot\nhist(log(rowData(tse)[[\"sd\"]]))\n\n\n\n\n\n\n\nFrom the histogram of feature variances, we can establish a sensible threshold for filtering. For example, using a threshold of 0 would effectively remove a large set of features that show no variance.\nIt’s important to note that the data is on a log scale, meaning that a log-transformed value of 1 corresponds to 0 (i.e., log(1) = 0). This ensures that features with zero variance are correctly identified and filtered out.\n\nth &lt;- 1\n\nselected &lt;- rowData(tse)[[\"sd\"]] &gt; 1\ntse_sub &lt;- tse[selected, ]\ntse_sub\n##  class: TreeSummarizedExperiment \n##  dim: 12840 26 \n##  metadata(0):\n##  assays(1): counts\n##  rownames(12840): 549322 522457 ... 200359 271582\n##  rowData names(8): Kingdom Phylum ... Species sd\n##  colnames(26): CL3 CC1 ... Even2 Even3\n##  colData names(7): X.SampleID Primer ... SampleType Description\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (12840 rows)\n##  rowTree: 1 phylo tree(s) (19216 leaves)\n##  colLinks: NULL\n##  colTree: NULL\n\nNow the dataset includes the 12840 features comapred to previous 19216. The dataset now includes the features that vary. Note that this threshold choice depends on your research question, and this was a rather conservative choice retaining most of the features.\nAfter filtering, the dataset now contains 12840 features, compared to the original 19216 features. This means we are left with features that exhibit variance. Keep in mind that the choice of threshold depends on the specific research question, and in this case, we opted for a rather conservative threshold that retains most features.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Subsetting</span>"
    ]
  },
  {
    "objectID": "pages/subsetting.html#sec-subset_prev",
    "href": "pages/subsetting.html#sec-subset_prev",
    "title": "8  Subsetting",
    "section": "\n8.6 Subset based on prevalence",
    "text": "8.6 Subset based on prevalence\nWe can subset the data based on prevalence using subsetByPrevalent(), which filters taxa that exceed a specified prevalence threshold, helping to remove rare features that may be artefacts. Conversely, subsetByRare() allows us to retain only taxa below the threshold, enabling a focus on rare features within the dataset.\nHere, we apply a prevalence threshold of 10% and a detection threshold of 1. A feature is considered detected if it has at least one count in a sample, and prevalent if it is detected in at least 10% of the samples. The function subsetByPrevalent() retains the prevalent features, while subsetByRare() keeps the features that are not prevalent.\n\ntse_sub &lt;- subsetByRare(tse, rank = \"Genus\", prevalence = 0.1, detection = 1)\ntse_sub\n##  class: TreeSummarizedExperiment \n##  dim: 261 26 \n##  metadata(1): agglomerated_by_rank\n##  assays(1): counts\n##  rownames(261): Acaryochloris Acetobacter ... Zooshikella p-75-a5\n##  rowData names(8): Kingdom Phylum ... Species sd\n##  colnames(26): CL3 CC1 ... Even2 Even3\n##  colData names(7): X.SampleID Primer ... SampleType Description\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (261 rows)\n##  rowTree: 1 phylo tree(s) (19216 leaves)\n##  colLinks: NULL\n##  colTree: NULL\n\nIn some cases, agglomerating based on prevalence can provide more meaningful insights. This process is illustrated in Section 9.3.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Subsetting</span>"
    ]
  },
  {
    "objectID": "pages/agglomeration.html",
    "href": "pages/agglomeration.html",
    "title": "9  Agglomeration",
    "section": "",
    "text": "9.1 Agglomerate based on taxonomy rank\nOne of the main applications of taxonomic information in regards to count data is to agglomerate count data on taxonomic levels and track the influence of changing conditions through these levels. For this mia contains the agglomerateByRank() function.\nAt its simplest, the function takes a TreeSE object as input and outputs a TreeSE object agglomerated to a specified taxonomy level using the rank parameter. Additionally, we can choose to prune the phylogenetic tree to correspond to the agglomerated data.\n# Agglomerate\ntse_phylum &lt;- agglomerateByRank(tse, rank = \"Phylum\", update.tree = TRUE)\ntse_phylum\n##  class: TreeSummarizedExperiment \n##  dim: 66 26 \n##  metadata(1): agglomerated_by_rank\n##  assays(1): counts\n##  rownames(66): ABY1_OD1 AC1 ... ZB2 ZB3\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(26): CL3 CC1 ... Even2 Even3\n##  colData names(7): X.SampleID Primer ... SampleType Description\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (66 rows)\n##  rowTree: 1 phylo tree(s) (66 leaves)\n##  colLinks: NULL\n##  colTree: NULL\nThe output now contains 66 features, a reduction from the original 19216 rows. It’s important to note that the samples remain unchanged from the original dataset. Let’s take a look at the rowData to see how it looks.\nrowData(tse_phylum)\n##  DataFrame with 66 rows and 7 columns\n##                     Kingdom         Phylum       Class       Order\n##                 &lt;character&gt;    &lt;character&gt; &lt;character&gt; &lt;character&gt;\n##  ABY1_OD1          Bacteria       ABY1_OD1          NA          NA\n##  AC1               Bacteria            AC1          NA          NA\n##  AD3               Bacteria            AD3          NA          NA\n##  Acidobacteria     Bacteria  Acidobacteria          NA          NA\n##  Actinobacteria    Bacteria Actinobacteria          NA          NA\n##  ...                    ...            ...         ...         ...\n##  WS1               Bacteria            WS1          NA          NA\n##  WS2               Bacteria            WS2          NA          NA\n##  WS3               Bacteria            WS3          NA          NA\n##  ZB2               Bacteria            ZB2          NA          NA\n##  ZB3               Bacteria            ZB3          NA          NA\n##                      Family       Genus     Species\n##                 &lt;character&gt; &lt;character&gt; &lt;character&gt;\n##  ABY1_OD1                NA          NA          NA\n##  AC1                     NA          NA          NA\n##  AD3                     NA          NA          NA\n##  Acidobacteria           NA          NA          NA\n##  Actinobacteria          NA          NA          NA\n##  ...                    ...         ...         ...\n##  WS1                     NA          NA          NA\n##  WS2                     NA          NA          NA\n##  WS3                     NA          NA          NA\n##  ZB2                     NA          NA          NA\n##  ZB3                     NA          NA          NA\nAs we observe from the taxonomy table, all lower ranks below Phylum now contain NA values. This is expected, as we have agglomerated the data to the Phylum level, meaning that the lowest rank that rows can be uniquely mapped to is the Family rank.\nSince we specified update.tree = TRUE, the phylogenetic tree has also been agglomerated. This is evident from the tree, which now has only 66 tips, each corresponding to a single row in the dataset.\nrowTree(tse_phylum)\n##  \n##  Phylogenetic tree with 66 tips and 65 internal nodes.\n##  \n##  Tip labels:\n##    549322, 173903, 368907, 51888, 591769, 249529, ...\n##  Node labels:\n##    , 0.858.4, 1.000.21479, 0.946.619, 0.953.588, 0.940.473, ...\n##  \n##  Rooted; includes branch lengths.\nAdditionally, we can examine the counts assay to assess how the agglomeration has affected the counts.\nassay(tse_phylum, \"counts\") |&gt; head()\n##                     CL3    CC1    SV1 M31Fcsw M11Fcsw M31Plmr M11Plmr F21Plmr\n##  ABY1_OD1            11     33      0       0       0       0       0       0\n##  AC1                  0      0      0       0       0       0       0       0\n##  AD3               1299  15577     17       2       1       3       0       0\n##  Acidobacteria   269202 183132  92863     120     115     249    1901     332\n##  Actinobacteria   39601  90280 121703    2540     841   85825  103067   27295\n##  Armatimonadetes    782   1124   1972       0       1       4      20       8\n##                  M31Tong M11Tong LMEpi24M SLEpi20M AQC1cm AQC4cm AQC7cm   NP2\n##  ABY1_OD1              0       0        0        6      6     18     21     0\n##  AC1                   0       0        0        1     25    209    265     0\n##  AD3                   2       1        0        0      3      1      5     0\n##  Acidobacteria       150      62      365      469  14622  25997  26860   190\n##  Actinobacteria   123464    8822   444605   648008  26392  27519  30304 20047\n##  Armatimonadetes       4      10      463     1683    806    919   1296     7\n##                    NP3    NP5 TRRsed1 TRRsed2 TRRsed3  TS28   TS29  Even1\n##  ABY1_OD1            0      0       2       0       1     0      0      0\n##  AC1                 0      0       0       1       0     0      0      0\n##  AD3                 1      2       0       5       1     1      0      4\n##  Acidobacteria     242     89     830    5650    3110   108    108   1562\n##  Actinobacteria  19592 168762    1058    2290    2351 27569 130158 105541\n##  Armatimonadetes     1      2       2       0       4     1      4      7\n##                  Even2 Even3\n##  ABY1_OD1            0     0\n##  AC1                 0     0\n##  AD3                26     2\n##  Acidobacteria     565   310\n##  Actinobacteria  79261 89965\n##  Armatimonadetes     5     6\nThe values in the counts assay are significantly larger than in the original data, indicating that the values have been summed during agglomeration.\nNow when the data is agglomerated, we can check the abundances of certain phyla.\n# Store features of interest into phyla\nphyla &lt;- c(\"Actinobacteria\", \"Chlamydiae\")\n# subset by feature\ntse_sub &lt;- tse_phylum[phyla, ]\n# Show dimensions\nassay(tse_sub)\n##                   CL3   CC1    SV1 M31Fcsw M11Fcsw M31Plmr M11Plmr F21Plmr\n##  Actinobacteria 39601 90280 121703    2540     841   85825  103067   27295\n##  Chlamydiae       265   702     22       0       1       5      22       0\n##                 M31Tong M11Tong LMEpi24M SLEpi20M AQC1cm AQC4cm AQC7cm   NP2\n##  Actinobacteria  123464    8822   444605   648008  26392  27519  30304 20047\n##  Chlamydiae           0       0        3        8      9     26     35     6\n##                   NP3    NP5 TRRsed1 TRRsed2 TRRsed3  TS28   TS29  Even1\n##  Actinobacteria 19592 168762    1058    2290    2351 27569 130158 105541\n##  Chlamydiae        36      9       2      85      62     2      0      1\n##                 Even2 Even3\n##  Actinobacteria 79261 89965\n##  Chlamydiae         1     0\nFurthermore, we can observe that the agglomeration will be applied to every assay in the dataset. Let’s add another assay to the dataset and then perform agglomeration again, this time at the Family level.\n# Add another assay\nassay(tse, \"another_assay\", withDimnames = FALSE) &lt;- matrix(\n  runif(ncol(tse)*nrow(tse), 0, 1), ncol = ncol(tse), nrow = nrow(tse))\n\n# Agglomerate\ntse_family &lt;- agglomerateByRank(tse, rank = \"Family\")\n\nassayNames(tse_family)\n##  [1] \"counts\"        \"another_assay\"\nWe can now confirm that the agglomerated dataset contains two assays: “counts” and “another_assay,” consistent with the original data structure.\nIf the data is agglomerated by features, the ideal location to store the resulting dataset is as an alternative experiment, altExp slot (see Section 3.6). Let’s add the Phylum data there.\naltExp(tse, \"phylum\") &lt;- tse_phylum\naltExpNames(tse)\n##  [1] \"phylum\"\naltExpNames now consists of Phylum level data. This can be extended to use any taxonomic level listed in taxonomyRanks(tse). While it is certainly possible to agglomerate data one taxonomic level at a time, you can also aggregate data across all available ranks in a single step using the agglomerateByRanks() function. This function returns a TreeSE object that includes the agglomerated data in the altExp slot.\nIf you want the data as a list as discussed in Section 7.1, you can achieve this by specifying as.list = TRUE\ntse &lt;- agglomerateByRanks(tse)\naltExpNames(tse)\n##  [1] \"phylum\"  \"Kingdom\" \"Phylum\"  \"Class\"   \"Order\"   \"Family\"  \"Genus\"  \n##  [8] \"Species\"",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Agglomeration</span>"
    ]
  },
  {
    "objectID": "pages/agglomeration.html#agglomerate-based-on-taxonomy-rank",
    "href": "pages/agglomeration.html#agglomerate-based-on-taxonomy-rank",
    "title": "9  Agglomeration",
    "section": "",
    "text": "Note\n\n\n\nAs data was agglomerated, the number of rows should equal the number of phyla used to index (in this case, just 2).",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Agglomeration</span>"
    ]
  },
  {
    "objectID": "pages/agglomeration.html#aggregate-data-based-on-variable",
    "href": "pages/agglomeration.html#aggregate-data-based-on-variable",
    "title": "9  Agglomeration",
    "section": "\n9.2 Aggregate data based on variable",
    "text": "9.2 Aggregate data based on variable\nThe agglomerateByRank() function aggregates data while considering taxonomy information. For more flexible aggregations, the agglomerateByVariable() method is also available. In some cases, both functions may yield the same results; however, agglomerateByRank() ensures that the entire taxonomy of a feature is unique for successful agglomeration.\nFor example, a dataset might contain taxa with the same lower-level rank, even if their higher-level ranks differ. Thus, agglomerateByVariable() should not be used for aggregating taxonomy ranks.\nInstead, agglomerateByVariable() is designed to aggregate data based on other criteria, such as sample groups or clusters. For instance, we can aggregate the data by sample types. The function operates similarly to feature aggregation, but the by parameter must be set to “rows.”\n\n# Agglomerate samples based on type\ntse_sub &lt;- agglomerateByVariable(tse, by = \"cols\", group = \"SampleType\")\ntse_sub\n##  class: TreeSummarizedExperiment \n##  dim: 19216 9 \n##  metadata(0):\n##  assays(2): counts another_assay\n##  rownames(19216): 549322 522457 ... 200359 271582\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(9): Feces Freshwater ... Soil Tongue\n##  colData names(7): X.SampleID Primer ... SampleType Description\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(8): phylum Kingdom ... Genus Species\n##  rowLinks: a LinkDataFrame (19216 rows)\n##  rowTree: 1 phylo tree(s) (19216 leaves)\n##  colLinks: NULL\n##  colTree: NULL\n\nNow, the data includes as many columns as there are sample types.\nIn Section 15.1.2, we will explore how cluster information can be used to agglomerate data effectively.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Agglomeration</span>"
    ]
  },
  {
    "objectID": "pages/agglomeration.html#sec-agglomerate_prev",
    "href": "pages/agglomeration.html#sec-agglomerate_prev",
    "title": "9  Agglomeration",
    "section": "\n9.3 Agglomerate based on prevalence",
    "text": "9.3 Agglomerate based on prevalence\nSection 8.6 demonstrated how to select only prevalent or rare features. In some cases, it might be beneficial to combine these features that would otherwise be removed. The function agglomerateByPrevalence() accomplishes this by merging filtered features into a single feature called “Other” by default, preventing unnecessary loss of information. This is particularly useful for retaining features that may still represent a significant proportion when combined.\nHere, we demonstrate how to agglomerate the data using prevalence thresholds of 20% and 0.1%, respectively. This means that for a feature to be considered detected in a sample, its abundance must exceed 0.1%. Furthermore, the feature must be present in at least 20% of samples to be retained in the dataset rather than placed in the “Other” group.\nTo use relative abundances for the detection threshold, we must first transform the data to relative abundances. We will let the Chapter 10 to introduce transformations in more detail.\n\n# Transform\ntse &lt;- transformAssay(tse, method = \"relabundance\")\n# Agglomerate\ntse_prev &lt;- agglomerateByPrevalence(\n  tse,\n  assay.type = \"relabundance\",\n  prevalence = 20 / 100,\n  detection = 0.1 / 100\n  )\ntse_prev\n##  class: TreeSummarizedExperiment \n##  dim: 20 26 \n##  metadata(0):\n##  assays(3): counts another_assay relabundance\n##  rownames(20): 329744 326977 ... 108747 Other\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(26): CL3 CC1 ... Even2 Even3\n##  colData names(7): X.SampleID Primer ... SampleType Description\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(8): phylum Kingdom ... Genus Species\n##  rowLinks: a LinkDataFrame (20 rows)\n##  rowTree: 1 phylo tree(s) (19216 leaves)\n##  colLinks: NULL\n##  colTree: NULL\n\nWe have now successfully agglomerated the data based on prevalence. If we are interested in prevalent Phyla, we can certainly first agglomerate the data by Phylum rank and then by prevalence. The function agglomerateByPrevalence() allows us to accomplish both tasks simultaneously.\n\ntse_prev_phylum &lt;- agglomerateByPrevalence(\n  tse,\n  rank = \"Phylum\",\n  prevalence = 20 / 100,\n  detection =  1\n  )\ntse_prev_phylum\n##  class: TreeSummarizedExperiment \n##  dim: 48 26 \n##  metadata(2): agglomerated_by_rank agglomerated_by_rank\n##  assays(3): counts another_assay relabundance\n##  rownames(48): ABY1_OD1 AD3 ... WS3 Other\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(26): CL3 CC1 ... Even2 Even3\n##  colData names(7): X.SampleID Primer ... SampleType Description\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (48 rows)\n##  rowTree: 1 phylo tree(s) (19216 leaves)\n##  colLinks: NULL\n##  colTree: NULL",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Agglomeration</span>"
    ]
  },
  {
    "objectID": "pages/transformation.html",
    "href": "pages/transformation.html",
    "title": "10  Transformation",
    "section": "",
    "text": "10.1 Characteristics of microbiome data\nMicrobiome sequencing data has unique characteristics that must be addressed; otherwise, incorrect decisions might be made based on the results. Specifically, microbiome sequencing data is characterized by high variability, zero-inflation and compositionality. High variability expresses that abundance of taxa often varies by several orders of magnitude from sample to sample. Zero-inflation means that typically more than 70% of the values are zeros, which could be due to either physical absence (structural zeros) or insufficient sampling effort (sampling zeros). Compositionality means that a change in the absolute abundance of one taxon will lead to apparent variations in the relative abundances of other taxa in the same sample. If neglected, such properties may cause significant bias in the results of DAA or other statistical tests. Therefore, several approaches have been developed to address the unique properties of microbiome data and provide statistically reliable results.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Transformation</span>"
    ]
  },
  {
    "objectID": "pages/transformation.html#common-transformation-methods",
    "href": "pages/transformation.html#common-transformation-methods",
    "title": "10  Transformation",
    "section": "\n10.2 Common transformation methods",
    "text": "10.2 Common transformation methods\nLet us now summarize some commonly used transformations in microbiome data science; further details and benchmarkings available in the references.\n\n\n‘relabundance’ Relative transformation, also known as total sum scaling (TSS) and compositional transformation. This converts counts into percentages (at the scale [0, 1]) that sum up to\n\nMuch of the currently available taxonomic abundance data from high-throughput assays (16S, metagenomic sequencing) is compositional by nature, even if the data is provided as counts (Gloor et al. 2017).\n\n\n‘clr’ Centered log ratio transformation (Aitchison 1986) is used to reduce data skewness and compositionality bias in relative abundances, while bringing the data to the logarithmic scale. This transformation is frequently applied in microbial ecology (Gloor et al. 2017). However, this transformation only applies to positive values. Usual solution is to add pseudocount, which adds another type of bias in the data. The robust clr transformation (‘rclr’) aims to circumvent the need to add a pseudocount. While the resulting values from these transformations are difficult to interpret directly, this transformation may enhance comparability of relative differences between samples. It is part of a broader Aitchison family of transformations; the additive log ratio transformation (alr') is also available. The robustclr` (“rclr”) is similar to regular clr (see above) but allows data with zeroes and avoids the need to add pseudocount Martino et al. (2019).\n‘pa’ Presence/Absence transformation ignores abundances and only indicates whether the given feature is detected above the given threshold (default: 0). This simple transformation is relatively widely used in ecological research. It has shown good performance in microbiome-based classification performance (Giliberti et al. 2022, Karwowska2024).\n‘standardize’ Standardize(or ‘z-score’) transformation scales data to zero mean and unit variance. This is used to bring features (or samples) to more comparable levels in terms of mean and scale of the values. This can enhance visualization and interpretation of the data\n‘log’, ‘log2’, ‘log10’ Logarithmic transformations, used e.g. to reduce data skewness. With compositional data, the clr (or rclr) transformation is often preferred.\n‘hellinger’ Hellinger transformation is equal to the square root of relative abundances. This ecological transformation can be useful if we are interested in changes in relative abundances.\n‘rank’ Rank transformation replaces each value by its rank. Also see ‘rrank’ (relative rank transformation). This has use, for instance, in non-parametric statistics.\nOther available transformations include Chi square (‘chi.square’), Frequency transformation (‘frequency’), and Make margin sum of squares equal to one (‘normalize’)\n\n\nGloor, GB, JM Macklaim, V Pawlowsky-Glahn, and JJ Egozcue. 2017. “Microbiome Datasets Are Compositional: And This Is Not Optional.” Frontiers in Microbiology 8. https://doi.org/10.3389/fmicb.2017.02224.\n\nAitchison, J. 1986. The Statistical Analysis of Compositional Data. London, UK: Chapman & Hall.\n\nMartino, C, J. T. Morton, C. A. Marotz, L. R. Thompson, A Tripathi, R Knight, and K Zengler. 2019. “A Novel Sparse Compositional Technique Reveals Microbial Perturbations.” mSystems 4.\nTransformations on abundance assays can be performed with mia::transformAssay(), keeping both the original and the transformed assay(s). The transformed abundance assay is then stored back to the ‘assays’ slot in the data object. The function applies sample-wise or column-wise transformation when MARGIN = ‘cols’, feature-wise or row-wise transformation when MARGIN = ‘rows’. A complete list of available transformations and parameters, is available in the function help.\n\n\n\n\n\n\nImportant\n\n\n\nPseudocount is a small non-negative value added to the normalized data to avoid taking the logarithm of zero. It’s value can have a significant impact on the results when applying a logarithm transformation to normalized data, as the logarithm transformation is a nonlinear operation that can fundamentally change the data distribution (Costea et al. 2014).\nPseudocount should be chosen consistently across all normalization methods being compared, for example, by setting it to a value smaller than the minimum abundance value before transformation. Some tools, like ancombc2, take into account the effect of the pseudocount by performing sensitivity tests using multiple pseudocount values. See Chapter 16.\n\n\n\nCostea, Paul I., Georg Zeller, Shinichi Sunagawa, and Peer Bork. 2014. “A Fair Comparison.” Nature Methods 11: 359. https://doi.org/https://doi.org/10.1038/nmeth.2897.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Transformation</span>"
    ]
  },
  {
    "objectID": "pages/transformation.html#transformations-in-practice",
    "href": "pages/transformation.html#transformations-in-practice",
    "title": "10  Transformation",
    "section": "\n10.3 Transformations in practice",
    "text": "10.3 Transformations in practice\n\n# Load example data\nlibrary(mia)\ndata(\"GlobalPatterns\", package = \"mia\")\ntse &lt;- GlobalPatterns\n\n# Transform \"counts\" assay to relative abundances (\"relabundance\"), with\n# pseudocount 1\ntse &lt;- transformAssay(\n     tse, assay.type = \"counts\", method = \"relabundance\", pseudocount = 1)\n\n# Transform relative abundance assay (\"relabundance\") to \"clr\", using\n# pseudocount if necessary; name the resulting assay to \"clr\"\ntse &lt;- transformAssay(\n    x = tse, assay.type = \"relabundance\", method = \"clr\", pseudocount = TRUE,\n    name = \"clr\")\n\nGet the values in the resulting assay, and view some of the first entries of it with the head command.\n\nassay(tse, \"clr\") |&gt; head()\n##             CL3    CC1     SV1 M31Fcsw M11Fcsw M31Plmr M11Plmr F21Plmr\n##  549322 -0.9056 -1.054 -0.7109  -0.264 -0.2319 -0.3381 -0.4562 -0.2601\n##  522457 -0.9056 -1.054 -0.7109  -0.264 -0.2319 -0.3381 -0.4562 -0.2601\n##  951    -0.9056 -1.054 -0.7109  -0.264 -0.2319 -0.3381  0.1924 -0.2601\n##  244423 -0.9056 -1.054 -0.7109  -0.264 -0.2319 -0.3381 -0.4562 -0.2601\n##  586076 -0.9056 -1.054 -0.7109  -0.264 -0.2319 -0.3381 -0.4562 -0.2601\n##  246140 -0.9056 -1.054 -0.7109  -0.264 -0.2319 -0.3381 -0.4562 -0.2601\n##         M31Tong M11Tong LMEpi24M SLEpi20M AQC1cm  AQC4cm  AQC7cm     NP2\n##  549322 -0.2193 -0.1554  -0.3118   0.2891  2.465  3.4909  3.8475  0.4076\n##  522457 -0.2193 -0.1554  -0.3118  -0.2950 -0.653  0.1236  0.9658 -0.2330\n##  951    -0.2193 -0.1554  -0.3118  -0.2950 -0.653 -0.7237 -0.7218 -0.2330\n##  244423 -0.2193 -0.1554  -0.3118  -0.2950 -0.653  2.0279  2.3827 -0.2330\n##  586076 -0.2193 -0.1554  -0.3118  -0.2950 -0.653  0.1236 -0.1711 -0.2330\n##  246140 -0.2193 -0.1554  -0.3118  -0.2950 -0.653 -0.2128  0.4424 -0.2330\n##             NP3     NP5 TRRsed1 TRRsed2 TRRsed3    TS28    TS29   Even1\n##  549322 -0.3929 -0.3238 -0.2659 -0.4643 -0.4281 -0.2514 -0.2354 -0.3146\n##  522457 -0.3929 -0.3238 -0.2659 -0.4643 -0.4281 -0.2514 -0.2354 -0.3146\n##  951    -0.3929 -0.3238 -0.2659 -0.4643 -0.4281 -0.2514 -0.2354 -0.3146\n##  244423 -0.3929 -0.3238 -0.2659 -0.4643 -0.4281 -0.2514 -0.2354 -0.3146\n##  586076 -0.3929 -0.3238 -0.2659 -0.4643 -0.4281 -0.2514 -0.2354 -0.3146\n##  246140 -0.3929 -0.3238 -0.2659 -0.4643 -0.4281 -0.2514 -0.2354 -0.3146\n##           Even2   Even3\n##  549322 -0.2334 -0.2185\n##  522457 -0.2334 -0.2185\n##  951    -0.2334 -0.2185\n##  244423 -0.2334 -0.2185\n##  586076 -0.2334 -0.2185\n##  246140 -0.2334 -0.2185\n\nIn ‘pa’ transformation, abundance table is converted to presence/absence table that ignores abundances and only indicates whether the given feature is detected. This simple transformation is relatively widely used in ecological research. It has shown good performance in microbiome-based classification performance (Giliberti et al. 2022, Karwowska2024).\n\nGiliberti, R, S Cavaliere, IE Mauriello, D Ercolini, and E Pasolli. 2022. “Host Phenotype Classification from Human Microbiome Data Is Mainly Driven by the Presence of Microbial Taxa.” PLoS Comput Biol. 18 (4): e1010066. https://doi.org/10.1371/journal.pcbi.1010066.\n\n# Here, `assay.type` is not explicitly specified.\n# Then The function uses the \"counts\" assay for the transformation.\ntse &lt;- transformAssay(tse, method = \"pa\")\nassay(tse, \"pa\") |&gt; head()\n##         CL3 CC1 SV1 M31Fcsw M11Fcsw M31Plmr M11Plmr F21Plmr M31Tong M11Tong\n##  549322   0   0   0       0       0       0       0       0       0       0\n##  522457   0   0   0       0       0       0       0       0       0       0\n##  951      0   0   0       0       0       0       1       0       0       0\n##  244423   0   0   0       0       0       0       0       0       0       0\n##  586076   0   0   0       0       0       0       0       0       0       0\n##  246140   0   0   0       0       0       0       0       0       0       0\n##         LMEpi24M SLEpi20M AQC1cm AQC4cm AQC7cm NP2 NP3 NP5 TRRsed1 TRRsed2\n##  549322        0        1      1      1      1   1   0   0       0       0\n##  522457        0        0      0      1      1   0   0   0       0       0\n##  951           0        0      0      0      0   0   0   0       0       0\n##  244423        0        0      0      1      1   0   0   0       0       0\n##  586076        0        0      0      1      1   0   0   0       0       0\n##  246140        0        0      0      1      1   0   0   0       0       0\n##         TRRsed3 TS28 TS29 Even1 Even2 Even3\n##  549322       0    0    0     0     0     0\n##  522457       0    0    0     0     0     0\n##  951          0    0    0     0     0     0\n##  244423       0    0    0     0     0     0\n##  586076       0    0    0     0     0     0\n##  246140       0    0    0     0     0     0\n\nYou can now view the entire list of abundance assays in your data object with:\n\nassays(tse)\n##  List of length 4\n##  names(4): counts relabundance clr pa\n\n\n\n\n\n\n\nSummary\n\n\n\nMicrobiome data is characterized by the following features:\n\nCompositional\nHigh variability\nZero-inflated\n\nOSCA book provides additional information on normalization from the perspective of single-cell analysis.",
    "crumbs": [
      "Data wrangling",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Transformation</span>"
    ]
  },
  {
    "objectID": "pages/quality_control.html",
    "href": "pages/quality_control.html",
    "title": "11  Exploration & quality control",
    "section": "",
    "text": "11.1 Abundance\nAbundance visualization is an important data exploration approach. miaViz integrated the plotAbundanceDensity() function to plot the most abundant taxa along with several options.\nNext, a few demonstrations are shown using the (Lahti et al. 2014) dataset. A jitter plot based on relative abundance data, similar to the one presented at (Salosensaari et al. 2021) (Supplementary Fig.1), can be visualized as follows:\n# Load example data\nlibrary(miaTime)\nlibrary(miaViz)\ndata(hitchip1006)\ntse &lt;- hitchip1006\n\n# Add relative abundances\ntse &lt;- transformAssay(tse, MARGIN = \"cols\", method = \"relabundance\")\n\n# Use argument names\n# assay.type / assay.type / assay.type\n# depending on the mia package version\nplotAbundanceDensity(\n    tse, layout = \"jitter\",\n    assay.type = \"relabundance\",\n    n = 40, point_size=1, point.shape=19,\n    point.alpha=0.1) +\n    scale_x_log10(label=scales::percent)\nThe relative abundance values for the top-5 taxonomic features can be visualized as a density plot over a log-scaled axis, with “nationality” indicated by colors:\nplotAbundanceDensity(\n    tse, layout = \"density\",\n    assay.type = \"relabundance\",\n    n = 5, colour.by=\"nationality\",\n    point.alpha=1/10) +\n    scale_x_log10()",
    "crumbs": [
      "Exploration & QC",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Exploration & quality control</span>"
    ]
  },
  {
    "objectID": "pages/quality_control.html#abundance",
    "href": "pages/quality_control.html#abundance",
    "title": "11  Exploration & quality control",
    "section": "",
    "text": "Lahti, L, JSalojärvi, A Salonen, M Scheffer, and WM de Vos. 2014. “Tipping Elements in the Human Intestinal Ecosystem.” Nature Communications 2014: 1–10. https://doi.org/https://doi.org/10.1038/ncomms5344.\n\nSalosensaari, Aaro, Ville Laitinen, Aki Havulinna, Guillaume Méric, Susan Cheng, Markus Perola, Liisa Valsta, et al. 2021. “Taxonomic Signatures of Cause-Specific Mortality Risk in Human Gut Microbiome.” Nature Communications 12: 1–8. https://www.nature.com/articles/s41467-021-22962-y.",
    "crumbs": [
      "Exploration & QC",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Exploration & quality control</span>"
    ]
  },
  {
    "objectID": "pages/quality_control.html#prevalence",
    "href": "pages/quality_control.html#prevalence",
    "title": "11  Exploration & quality control",
    "section": "\n11.2 Prevalence",
    "text": "11.2 Prevalence\nPrevalence quantifies the frequency of samples where certain microbes were detected (above a given detection threshold). Prevalence can be given as sample size (N) or percentage (unit interval).\nInvestigating prevalence allows you either to focus on changes which pertain to the majority of the samples, or identify rare microbes, which may be conditionally abundant in a small number of samples.\nThe population prevalence (frequency) at a 1% relative abundance threshold (detection = 1/100 and as.relative = TRUE) can look like this.\n\ngetPrevalence(tse, detection = 1/100, sort = TRUE, as.relative = TRUE) |&gt;\n    head()\n##  Faecalibacterium prausnitzii et rel.           Ruminococcus obeum et rel. \n##                                0.9522                               0.9140 \n##    Oscillospira guillermondii et rel.        Clostridium symbiosum et rel. \n##                                0.8801                               0.8714 \n##      Subdoligranulum variable at rel.     Clostridium orbiscindens et rel. \n##                                0.8358                               0.8315\n\nThe function arguments detection and as.relative can also be used to access how many samples pass a threshold for raw counts. Here, the population prevalence (frequency) at the absolute abundance threshold (as.relative = FALSE) with a read count of 1 (detection = 1) is accessed.\n\ngetPrevalence(\n    tse, detection = 1, sort = TRUE, assay.type = \"counts\",\n    as.relative = FALSE) |&gt;\n    head()\n##             Uncultured Mollicutes      Uncultured Clostridiales II \n##                                 1                                1 \n##        Uncultured Clostridiales I               Tannerella et rel. \n##                                 1                                1 \n##    Sutterella wadsworthia et rel. Subdoligranulum variable at rel. \n##                                 1                                1\n\nIf the output is to be used for subsetting or storing the data in the rowData, set sort = FALSE.\n\n11.2.1 Prevalence analysis\nTo investigate microbiome prevalence at a selected taxonomic level, two approaches are available.\nFirst, the data can be agglomerated to the taxonomic level and then getPrevalence() can be applied to the resulting object.\n\n# Agglomerate taxa abundances to Phylum level\n#and add the new table to the altExp slot\naltExp(tse,\"Phylum\") &lt;- agglomerateByRank(tse, \"Phylum\")\n# Check prevalence for the Phylum abundance table\n#from the altExp slot\ngetPrevalence(\n    altExp(tse,\"Phylum\"), detection = 1/100, sort = TRUE,\n    assay.type = \"counts\", as.relative = TRUE) |&gt;\n    head()\n##       Firmicutes   Bacteroidetes  Actinobacteria  Proteobacteria \n##        1.0000000       0.9852302       0.4821894       0.2988705 \n##  Verrucomicrobia    Fusobacteria \n##        0.1277150       0.0008688\n\nAlternatively, the rank argument can be set to perform the agglomeration on the fly.\n\ngetPrevalence(\n    tse, rank = \"Phylum\", detection = 1/100, sort = TRUE,\n    assay.type = \"counts\", as.relative = TRUE) |&gt;\n    head()\n##       Firmicutes   Bacteroidetes  Actinobacteria  Proteobacteria \n##        1.0000000       0.9852302       0.4821894       0.2988705 \n##  Verrucomicrobia    Fusobacteria \n##        0.1277150       0.0008688\n\n\n\n\n\n\n\nNote\n\n\n\nBy default, na.rm = TRUE is used for agglomeration in getPrevalence(), whereas the default for agglomerateByRank() is FALSE to prevent accidental data loss.\n\n\nIf you only need the names of the prevalent taxa, getPrevalent() is available. This returns the taxa that exceed the given prevalence and detection thresholds.\n\ngetPrevalent(tse, detection = 0, prevalence = 50/100)\nprev &lt;- getPrevalent(\n    tse, detection = 0, prevalence = 50/100, rank = \"Phylum\", sort = TRUE)\nprev\n\n\n\n\n\n\n\nNote\n\n\n\nThe detection and prevalence thresholds are not the same, as detection can be applied to relative counts or absolute counts depending on whether as.relative is set TRUE or FALSE\n\n\nThe function getPrevalentAbundance() can be used to check the total relative abundance of the prevalent taxa (between 0 and 1).\n\n11.2.2 Rare taxa\nRelated functions are available for the analysis of rare taxa (rare_members(), rare_abundance(), low_abundance(), getRare(), subsetByRare()).\n\n11.2.3 Plotting prevalence\nTo plot the prevalence, add the prevalence of each taxon to rowData. Here, we are analyzing the Phylum-level abundances, which are stored in the altExp slot.\n\nrowData(altExp(tse,\"Phylum\"))$prevalence &lt;- getPrevalence(\n    altExp(tse,\"Phylum\"), detection = 1/100,\n    sort = FALSE,\n    assay.type = \"counts\", as.relative = TRUE)\n\nThe prevalences can then be plotted using the plotting functions from the scater package.\n\nlibrary(scater)\nplotRowData(altExp(tse,\"Phylum\"), \"prevalence\", colour_by = \"Phylum\")\n\n\n\n\n\n\n\nThe prevalence can also be visualized on the taxonomic tree with the miaViz package.\n\ntse &lt;- agglomerateByRanks(tse)\naltExps(tse) &lt;- lapply(\n    altExps(tse), function(y){\n        rowData(y)$prevalence &lt;- getPrevalence(\n            y, detection = 1/100,\n            sort = FALSE,\n            assay.type = \"counts\",\n            as.relative = TRUE)\n        return(y)\n    })\ntop_phyla &lt;- getTop(\n    altExp(tse,\"Phylum\"),\n    method=\"prevalence\",\n    top=5L,\n    assay.type=\"counts\")\ntop_phyla_mean &lt;- getTop(\n    altExp(tse,\"Phylum\"),\n    method=\"mean\",\n    top=5L,\n    assay.type=\"counts\")\n\nx &lt;- unsplitByRanks(tse, ranks = taxonomyRanks(tse)[1:6])\nx &lt;- addHierarchyTree(x)\n\nAfter some preparation, the data are assembled and can be plotted with plotRowTree().\n\nlibrary(miaViz)\n# Filter rows where Phylum is in top_phyla\nselected &lt;- rowData(x)$Phylum %in% top_phyla\n\n# Plot the data\nplotRowTree(\n    x[selected, ],\n    edge.colour.by = \"Phylum\",\n    tip.colour.by = \"prevalence\",\n    node.colour.by = \"prevalence\")\n\n\n\nPrevalence of top phyla as judged by prevalence\n\n\n\n\n# Filter for Phylum in top_phyla_mean\nselected &lt;- rowData(x)$Phylum %in% top_phyla_mean\n\n# Plot the data\nplotRowTree(\n    x[selected, ],\n    edge.colour.by = \"Phylum\",\n    tip.colour.by = \"prevalence\",\n    node.colour.by = \"prevalence\")\n\n\n\nPrevalence of top phyla as judged by mean abundance",
    "crumbs": [
      "Exploration & QC",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Exploration & quality control</span>"
    ]
  },
  {
    "objectID": "pages/quality_control.html#sec-qc",
    "href": "pages/quality_control.html#sec-qc",
    "title": "11  Exploration & quality control",
    "section": "\n11.3 Quality control",
    "text": "11.3 Quality control\nNext, let’s load the GlobalPatterns dataset to illustrate standard microbiome data summaries.\n\nlibrary(mia)\ndata(\"GlobalPatterns\", package=\"mia\")\ntse &lt;- GlobalPatterns\n\n\n11.3.1 Top taxa\nThe function getTop() identifies top taxa in the data.\n\n# Pick the top taxa\ntop_features &lt;- getTop(tse, method=\"median\", top=10)\n\n# Check the information for these\nrowData(tse)[top_features, taxonomyRanks(tse)][1:5, 1:3]\n##  DataFrame with 5 rows and 3 columns\n##             Kingdom         Phylum               Class\n##         &lt;character&gt;    &lt;character&gt;         &lt;character&gt;\n##  549656    Bacteria  Cyanobacteria         Chloroplast\n##  331820    Bacteria  Bacteroidetes         Bacteroidia\n##  317182    Bacteria  Cyanobacteria         Chloroplast\n##  94166     Bacteria Proteobacteria Gammaproteobacteria\n##  279599    Bacteria  Cyanobacteria    Nostocophycideae\n\n\n11.3.2 Unique taxa\nThe function getUnique returns unique taxa in the data.\n\n# Get unique taxa at rank Class\ngetUnique(tse, \"Class\", sort = TRUE)\n##    [1] \"0319-6G9\"              \"09D2Y74\"               \"12-24\"                \n##    [4] \"4C0d-2\"                \"5B-18\"                 \"A712011\"              \n##    [7] \"AB16\"                  \"ABS-6\"                 \"Acidobacteria\"        \n##   [10] \"Acidobacteria-5\"       \"Actinobacteria\"        \"Alphaproteobacteria\"  \n##   [13] \"Anaerolineae\"          \"Armatimonadia\"         \"BB34\"                 \n##   [16] \"BD4-9\"                 \"BPC102\"                \"BSV19\"                \n##   [19] \"Bacilli\"               \"Bacteroidia\"           \"Betaproteobacteria\"   \n##   [22] \"Bljii12\"               \"C2\"                    \"C6\"                   \n##   [25] \"CH21\"                  \"Caldisericia\"          \"Caldithrixae\"         \n##   [28] \"Chlamydiae\"            \"Chloracidobacteria\"    \"Chlorobia\"            \n##   [31] \"Chloroflexi\"           \"Chloroflexi-4\"         \"Chloroplast\"          \n##   [34] \"Chthonomonadetes\"      \"Clostridia\"            \"Dehalococcoidetes\"    \n##   [37] \"Deinococci\"            \"Deltaproteobacteria\"   \"Elusimicrobia\"        \n##   [40] \"Endomicrobia\"          \"Epsilonproteobacteria\" \"Erysipelotrichi\"      \n##   [43] \"FFCH393\"               \"FFCH6980\"              \"Fibrobacteres\"        \n##   [46] \"Flavobacteria\"         \"Fusobacteria\"          \"GKS2-174\"             \n##   [49] \"GN07\"                  \"GN08\"                  \"GN13\"                 \n##   [52] \"GN15\"                  \"GW-22\"                 \"Gammaproteobacteria\"  \n##   [55] \"Gemmatimonadetes\"      \"Halobacteria\"          \"Holophagae\"           \n##   [58] \"Ignavibacteria\"        \"JG37-AG-4\"             \"JS1\"                  \n##   [61] \"KSB3\"                  \"Koll-18\"               \"Ktedonobacteria\"      \n##   [64] \"Kueneniae\"             \"Lentisphaerae\"         \"Leptospirae\"          \n##   [67] \"MJK10\"                 \"ML615J-28\"             \"MSB-5A5\"              \n##   [70] \"MSB-5B5\"               \"MVS-40\"                \"Methanobacteria\"      \n##   [73] \"Methanomicrobia\"       \"Methylacidiphilae\"     \"Mollicutes\"           \n##   [76] \"Nitrospira\"            \"Nostocophycideae\"      \"ODP123\"               \n##   [79] \"OP11-2\"                \"OP11-3\"                \"OP8_1\"                \n##   [82] \"OP8_2\"                 \"OPB56\"                 \"OS-K\"                 \n##   [85] \"Opitutae\"              \"Oscillatoriophycideae\" \"PAUC37f\"              \n##   [88] \"PBS-25\"                \"PRR-11\"                \"PRR-12\"               \n##   [91] \"PW285\"                 \"Phycisphaerae\"         \"Planctomycea\"         \n##   [94] \"R76-B18\"               \"RA13C7\"                \"RB25\"                 \n##   [97] \"RB384\"                 \"S15B-MN24\"             \"S1a-1H\"               \n##  [100] \"SBRH58\"                \"SHA-114\"               \"SJA-176\"              \n##  [103] \"SJA-28\"                \"SJA-4\"                 \"SM1B09\"               \n##  [106] \"SOGA31\"                \"Sd-NA\"                 \"Solibacteres\"         \n##  [109] \"Spartobacteria\"        \"Sphingobacteria\"       \"Spirochaetes\"         \n##  [112] \"Sva0725\"               \"Synechococcophycideae\" \"Synergistia\"          \n##  [115] \"TG3-1\"                 \"TG3-2\"                 \"TK-SH13\"              \n##  [118] \"TK17\"                  \"TM7-1\"                 \"TM7-3\"                \n##  [121] \"TP21\"                  \"Thaumarchaeota\"        \"Thermomicrobia\"       \n##  [124] \"Thermoplasmata\"        \"Thermoprotei\"          \"Thermotogae\"          \n##  [127] \"Ucn15732\"              \"VC12-cl04\"             \"VHS-B5-50\"            \n##  [130] \"Verruco-5\"             \"Verrucomicrobiae\"      \"WM88\"                 \n##  [133] \"WWE1\"                  \"Zetaproteobacteria\"    \"agg27\"                \n##  [136] \"iii1-8\"                \"koll11\"                \"pMC2A209\"             \n##  [139] \"vadinHA49\"             NA\n\n\n11.3.3 Library size / read count\nThe total counts per sample can be calculated using perCellQCMetrics()/addPerCellQC() from the scater package. The former one just calculates the values, whereas the latter directly adds them to colData. mia provides the function summary for SE objects which returns the summary of counts for all samples and features including measures of central tendency.\n\nlibrary(scater)\n# Get an overview of sample and taxa counts\nsummary(tse, assay.type= \"counts\")\n##  $samples\n##  # A tibble: 1 × 6\n##    total_counts min_counts max_counts median_counts mean_counts stdev_counts\n##           &lt;dbl&gt;      &lt;dbl&gt;      &lt;dbl&gt;         &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;\n##  1     28216678      58688    2357181       1106849    1085257.      650145.\n##  \n##  $features\n##  # A tibble: 1 × 3\n##    total singletons per_sample_avg\n##    &lt;int&gt;      &lt;int&gt;          &lt;dbl&gt;\n##  1 19216       2134          4022.\n\n# Calculate total counts per sample\nperCellQCMetrics(tse)[1:5,]\n##  DataFrame with 5 rows and 3 columns\n##                sum  detected     total\n##          &lt;numeric&gt; &lt;numeric&gt; &lt;numeric&gt;\n##  CL3        864077      6964    864077\n##  CC1       1135457      7679   1135457\n##  SV1        697509      5729    697509\n##  M31Fcsw   1543451      2667   1543451\n##  M11Fcsw   2076476      2574   2076476\n\n# Calculate and add total counts to `colData`\ntse &lt;- addPerCellQC(tse)\ncolData(tse)[1:5,1:3]\n##  DataFrame with 5 rows and 3 columns\n##          X.SampleID   Primer Final_Barcode\n##            &lt;factor&gt; &lt;factor&gt;      &lt;factor&gt;\n##  CL3        CL3      ILBC_01        AACGCA\n##  CC1        CC1      ILBC_02        AACTCG\n##  SV1        SV1      ILBC_03        AACTGT\n##  M31Fcsw    M31Fcsw  ILBC_04        AAGAGA\n##  M11Fcsw    M11Fcsw  ILBC_05        AAGCTG\n\nThe distribution of calculated library sizes can be visualized as a histogram (left) or by sorting the samples by library size (right).\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(patchwork)\n\n# Create a histrogram showing distribution of library sizes\np1 &lt;- ggplot(colData(tse)) +\n        geom_histogram(aes(x = sum/1e6), color = \"black\", fill = \"gray\") +\n        labs(x = \"Library size (million reads)\", y = \"Frequency (n)\") +\n        theme_classic()\n\n# Order data in increasing order\ndf &lt;- as.data.frame(colData(tse)) |&gt;\n    arrange(sum) |&gt;\n    mutate(proportion = (1:n())/n())\n\n# Create a scatter plot showing how library sizes are distributed\np2 &lt;- ggplot(df, aes(y = proportion, x = sum/1e6)) +\n    geom_point() +\n    labs(x = \"Library size (million reads)\", y = \"Proportion of samples\") +\n    theme_classic()\n\np1 + p2\n\n\n\nLibrary size distribution.\n\n\n\nLibrary sizes and other variables from colData can be visualized using a specified function called plotColData().\n\n# Sort samples by read count,\n# order the factor levels,\n# and store back to tse as DataFrame\ncolData(tse) &lt;- as.data.frame(colData(tse)) |&gt;\n    arrange(X.SampleID) |&gt;\n    mutate(X.SampleID = factor(X.SampleID, levels=X.SampleID)) %&gt;%\n        DataFrame\nplotColData(tse,\"sum\",\"X.SampleID\", colour_by = \"SampleType\") +\n    theme(axis.text.x = element_text(angle = 45, hjust=1)) +\n    labs(y = \"Library size (N)\", x = \"Sample ID\")\n\n\n\nLibrary sizes per sample.\n\n\n\n\nplotColData(tse,\"sum\",\"SampleType\", colour_by = \"SampleType\") +\n    theme(axis.text.x = element_text(angle = 45, hjust=1))\n\n\n\nLibrary sizes per sample type.\n\n\n\nIn addition, data can be rarefied with rarefyAssay, which normalizes the samples to an equal number of reads. This remains controversial, however, and strategies to mitigate the information loss in rarefaction have been proposed (Schloss 2024a) (Schloss 2024b). Moreover, this practice has been discouraged for the analysis of differentially abundant microorganisms (see (McMurdie and Holmes 2014)).\n\nSchloss, Patrick D. 2024a. “Rarefaction Is Currently the Best Approach to Control for Uneven Sequencing Effort in Amplicon Sequence Analyses.” mSphere 9 (2): e00354–23. https://doi.org/10.1128/msphere.00354-23.\n\n———. 2024b. “Waste Not, Want Not: Revisiting the Analysis That Called into Question the Practice of Rarefaction.” mSphere 9 (1): e00355–23. https://doi.org/10.1128/msphere.00355-23.\n\nMcMurdie, Paul J, and Susan Holmes. 2014. “Waste Not, Want Not: Why Rarefying Microbiome Data Is Inadmissible.” PLoS Computational Biology 10 (4): e1003531.\n\n11.3.4 Contaminant sequences\nSamples might be contaminated with exogenous sequences. The impact of each contaminant can be estimated based on its frequencies and concentrations across the samples.\nThe following decontam functions are based on (Davis et al. 2018) and support such functionality:\n\nDavis, Nicole M, Diana M Proctor, Susan P Holmes, David A Relman, and Benjamin J Callahan. 2018. “Simple Statistical Identification and Removal of Contaminant Sequences in Marker-Gene and Metagenomics Data.” Microbiome 6 (1): 1–14.\n\n\nisContaminant(), isNotContaminant()\n\n\naddContaminantQC(), addNotContaminantQC()",
    "crumbs": [
      "Exploration & QC",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Exploration & quality control</span>"
    ]
  },
  {
    "objectID": "pages/composition.html",
    "href": "pages/composition.html",
    "title": "12  Community composition",
    "section": "",
    "text": "12.1 Composition barplot\nA typical way to visualize microbiome composition is by using a composition barplot which show relative abundance of selected taxa. In the following code chunk, relative abundance is calculated, and top taxa are retrieved for the phylum rank. Thereafter, the barplot is visualized ordering rank by abundance values and samples by “Bacteroidetes”:\nlibrary(miaViz)\ndata(\"GlobalPatterns\")\ntse &lt;- GlobalPatterns\n\n# Computing relative abundance\ntse &lt;- transformAssay(tse, assay.type = \"counts\", method = \"relabundance\")\n\n# Getting top taxa on a Phylum level\ntse &lt;- agglomerateByRank(tse, rank =\"Phylum\")\ntop_taxa &lt;- getTop(tse, top = 10, assay.type = \"relabundance\")\n\n# Renaming the \"Phylum\" rank to keep only top taxa and the rest to \"Other\"\nphylum_renamed &lt;- lapply(rowData(tse)$Phylum, function(x){\n    if (x %in% top_taxa) {x} else {\"Other\"}\n    })\nrowData(tse)$Phylum_sub &lt;- as.character(phylum_renamed)\n# Agglomerate the data based on specified taxa\ntse_sub &lt;- agglomerateByVariable(tse, by = \"rows\", f = \"Phylum_sub\")\n\n# Visualizing the composition barplot, with samples order by \"Bacteroidetes\"\nplotAbundance(\n    tse_sub, assay.type = \"relabundance\",\n    order.row.by = \"abund\", order.col.by = \"Bacteroidetes\")",
    "crumbs": [
      "Exploration & QC",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Community composition</span>"
    ]
  },
  {
    "objectID": "pages/composition.html#sec-composition-heatmap",
    "href": "pages/composition.html#sec-composition-heatmap",
    "title": "12  Community composition",
    "section": "\n12.2 Composition heatmap",
    "text": "12.2 Composition heatmap\nCommunity composition can be visualized with heatmap, where the horizontal axis represents samples and the vertical axis the taxa. The color of each intersection point represents abundance of a taxon in a specific sample.\nHere, abundances are first CLR (centered log-ratio) transformed to remove compositionality bias. Then standardize transformation is applied to CLR-transformed data. This shifts all taxa to zero mean and unit variance, allowing visual comparison between taxa that have different absolute abundance levels. After these rough visual exploration techniques, we can visualize the abundances at Phylum level.\n\ntse &lt;- GlobalPatterns\n# Agglomerate to phylum level\ntse &lt;- agglomerateByPrevalence(tse, rank = \"Phylum\")\n\n# Add clr-transformation on samples\ntse &lt;- transformAssay(\n    tse, assay.type = \"counts\", method = \"relabundance\", pseudocount = 1)\ntse &lt;- transformAssay(tse, assay.type = \"relabundance\", method = \"clr\")\n\n# Add scale features (taxa)\ntse &lt;- transformAssay(\n    tse, assay.type = \"clr\", MARGIN = \"rows\", method = \"standardize\",\n    name = \"clr_z\")\n\nWe can visualize heatmap with *sechm* package. It is a wrapper for ComplexHeatmap package (Gu 2022).\n\nlibrary(sechm)\n\n# Plot heatMap with sechm\nheatmap &lt;- sechm(\n    tse, assayName = \"clr_z\", features=rownames(tse),\n    show_rownames = TRUE, show_colnames = TRUE,\n    row_names_gp = gpar(fontsize = 6), column_names_gp = gpar(fontsize = 8),\n    breaks = 1\n    )\nheatmap\n\n\n\n\n\n\n\nAnother method to visualize community composition is by plotting a NeatMap, which means we use radial theta sorting when plotting the heatmap (Rajaram and Oono 2010). The getNeatOrder() function in the miaViz package allows us to achieve this. This method sorts data points based on their angular position in a 2D space, typically after an ordination technique such as PCA or NMDS has been applied.\n\nRajaram, Satwik, and Yoshi Oono. 2010. “NeatMap - Non-Clustering Heat Map Alternatives in R.” BMC Bioinformatics 11: 45. https://doi.org/10.1186/1471-2105-11-45.\nThe getNeatOrder() method calculates the angle (theta) for each point relative to the centroid and sorts data points based on these theta values in ascending order. This approach preserves the relationships between data points according to the ordination method’s spatial configuration, rather than relying on hierarchical clustering.\nFirst, we will load the necessary libraries and load GlobalPatterns, which is a TreeSE object. We agglomerate the data to phylum level to explore the phyla community.\nNow, we’ll create the NeatMap using the sechm package and the getNeatOrder() function.\n\nlibrary(scater)\nlibrary(sechm)\n\n# Perform PCA on the dataset\ntse &lt;- runPCA(tse, ncomponents = 10, assay.type = \"clr_z\")\n\n# Sort by radial theta using the first two principal components\nsorted_order &lt;- getNeatOrder(\n    reducedDim(tse, \"PCA\")[, c(1, 2)], centering = \"mean\")\ntse &lt;- tse[, sorted_order]\n\n# Plot NeatMap with sechm\nneatmap &lt;- sechm(\n    tse, assayName = \"clr_z\", features=rownames(tse),\n    show_rownames = TRUE, show_colnames = TRUE,\n    do.scale=FALSE, cluster_rows=FALSE, sortRowsOn = NULL,\n    row_names_gp = gpar(fontsize = 6), column_names_gp = gpar(fontsize = 8),\n    breaks = 1\n    )\nneatmap\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdditional heatmap visualization\n\n\n\nIn addition, there are also other packages that provide functions for more complex heatmaps, such as those provided by iheatmapr and ComplexHeatmap (Gu 2022). The utilization of *ComplexHeatmap* for clustered heatmaps is explained in chapter Section 15.3.\n\n\n\n\n\nGu, Zuguang. 2022. “Complex Heatmap Visualization.” iMeta 1 (3): e43. https://doi.org/https://doi.org/10.1002/imt2.43.",
    "crumbs": [
      "Exploration & QC",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Community composition</span>"
    ]
  },
  {
    "objectID": "pages/alpha_diversity.html",
    "href": "pages/alpha_diversity.html",
    "title": "13  Community diversity",
    "section": "",
    "text": "13.1 Alpha diversity estimation in practice",
    "crumbs": [
      "Diversity & similarity",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Community diversity</span>"
    ]
  },
  {
    "objectID": "pages/alpha_diversity.html#alpha-diversity-estimation-in-practice",
    "href": "pages/alpha_diversity.html#alpha-diversity-estimation-in-practice",
    "title": "13  Community diversity",
    "section": "",
    "text": "13.1.1 Calculate diversity measures\nAlpha diversity can be estimated with addAlpha() wrapper function that interact with other packages implementing the calculation, such as vegan (Oksanen et al. 2020).\n\nOksanen, Jari, F. Guillaume Blanchet, Michael Friendly, Roeland Kindt, Pierre Legendre, Dan McGlinn, Peter R. Minchin, et al. 2020. Vegan: Community Ecology Package. https://CRAN.R-project.org/package=vegan.\nThese functions calculate the given indices, and add them to the colData slot of the SummarizedExperiment object with the given name.\nThe estimated values can then be retrieved and analyzed directly from the colData, for example, by plotting them using plotColData() from the scater package (McCarthy et al. 2020). Here, we use the observed species as a measure of richness.\n\nMcCarthy, Davis, Kieran Campbell, Aaron Lun, and Quin Wills. 2020. Scater: Single-Cell Analysis Toolkit for Gene Expression Data in r. http://bioconductor.org/packages/scater/.\nCertain indices have additional options, here observed has detection parameter that control the detection threshold. Species over this threshold is considered as detected. See full list of options from from help(addAlpha).\n\n# First, let's load some example data.\nlibrary(mia)\ndata(\"GlobalPatterns\", package=\"mia\")\ntse &lt;- GlobalPatterns\n\n# Estimate (observed) richness\ntse &lt;- addAlpha(\n    tse, assay.type = \"counts\", index = \"observed\", name = \"observed\",\n    detection = 10)\n\n# Check some of the first values in colData\ntse$observed |&gt; head()\n##  [1] 3144 3791 2319  761  671 1004\n\n\n\n\n\n\n\nTip\n\n\n\nYou can calculate multiple indices simultaneously by specifying multiple indices in the index parameter.\nFor example: index = c(\"observed\", \"shannon\")\n\n\nLet’s visualize the results against selected colData variables (sample type and final barcode).\n\nlibrary(scater)\nplotColData(\n    tse,\n    \"observed\",\n    \"SampleType\",\n    colour_by = \"Final_Barcode\") +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n    labs(x = \"Sample types\", y = expression(Richness[Observed]))\n\n\n\nShannon diversity estimates plotted grouped by sample type with colour-labeled barcode.\n\n\n\nWe can then analyze the statistical significance. We use the non-parametric Wilcoxon or Mann-Whitney test, as it is more flexible than the commonly used Student’s t-Test, since it does not assume normality.\n\npairwise.wilcox.test(\n    tse[[\"observed\"]], tse[[\"SampleType\"]], p.adjust.method = \"fdr\")\n##  \n##      Pairwise comparisons using Wilcoxon rank sum exact test \n##  \n##  data:  tse[[\"observed\"]] and tse[[\"SampleType\"]] \n##  \n##                     Feces Freshwater Freshwater (creek) Mock Ocean\n##  Freshwater         0.4   -          -                  -    -    \n##  Freshwater (creek) 0.3   0.3        -                  -    -    \n##  Mock               0.3   0.3        0.3                -    -    \n##  Ocean              0.8   1.0        0.3                0.3  -    \n##  Sediment (estuary) 0.3   0.8        0.3                0.3  0.8  \n##  Skin               0.3   0.8        0.3                0.3  0.8  \n##  Soil               0.3   0.3        0.5                0.3  0.3  \n##  Tongue             0.3   0.5        0.3                0.8  0.5  \n##                     Sediment (estuary) Skin Soil\n##  Freshwater         -                  -    -   \n##  Freshwater (creek) -                  -    -   \n##  Mock               -                  -    -   \n##  Ocean              -                  -    -   \n##  Sediment (estuary) -                  -    -   \n##  Skin               1.0                -    -   \n##  Soil               0.3                0.3  -   \n##  Tongue             0.3                0.3  0.3 \n##  \n##  P value adjustment method: fdr\n\n\n13.1.2 Faith phylogenetic diversity\nThe Faith index is returned by the function addAlpha(). It utilizes the widely used function in picante W et al. (2010).\n\nW, Kembel Steven, Cowan Peter D, Helmus Matthew R, Cornwell William K, Morlon Helene, Ackerly David D, Blomberg Simon P, and Webb Campbell O. 2010. “Picante: R tools for integrating phylogenies and ecology.” Bioinformatics 26 (11): 1463–64. https://doi.org/https://doi.org/10.1093/bioinformatics/btq166.\n\ntse &lt;- addAlpha(tse, assay.type = \"counts\", index = \"faith\")\ntse$faith |&gt; head()\n##  [1] 250.5 262.3 208.5 117.9 119.8 135.8\n\n\n\n\n\n\n\nNote\n\n\n\nBecause tse is a TreeSummarizedExperiment object, its phylogenetic tree is used by default. However, the optional argument tree must be provided if tse does not contain one.",
    "crumbs": [
      "Diversity & similarity",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Community diversity</span>"
    ]
  },
  {
    "objectID": "pages/alpha_diversity.html#sec-compare-alpha",
    "href": "pages/alpha_diversity.html#sec-compare-alpha",
    "title": "13  Community diversity",
    "section": "\n13.2 Alpha diversity measure comparisons",
    "text": "13.2 Alpha diversity measure comparisons\nWe can compare alpha diversities for example by calculating correlation between them. Below, a visual comparison between shannon and faith indices is shown with a scatter plot.\n\ntse &lt;- addAlpha(tse, assay.type = \"counts\", index = \"shannon\")\n\nplotColData(tse, x = \"shannon\", y = \"faith\") +\n    labs(x=\"Shannon index\", y=\"Faith (phylogenetic) index\") +\n    geom_smooth(method = \"lm\")\n\n\n\n\n\n\n\n\ncor.test(tse[[\"shannon\"]], tse[[\"faith\"]])\n##  \n##      Pearson's product-moment correlation\n##  \n##  data:  tse[[\"shannon\"]] and tse[[\"faith\"]]\n##  t = 2.2, df = 24, p-value = 0.04\n##  alternative hypothesis: true correlation is not equal to 0\n##  95 percent confidence interval:\n##   0.02719 0.68822\n##  sample estimates:\n##     cor \n##  0.4102\n\nLet us visualize results from multiple alpha diversity measures against a given sample grouping available in colData (here, sample type). These have been readily stored in the colData slot, and they are thus directly available for plotting.\n\nlibrary(patchwork)\n\n# Create the plots\nplots &lt;- lapply(\n    c(\"observed\", \"shannon\", \"faith\"),\n    plotColData,\n    object = tse,\n    x = \"SampleType\",\n    colour_by = \"SampleType\")\n\n# Fine-tune visual appearance\nplots &lt;- lapply(\n    plots, \"+\",\n    theme(axis.text.x = element_blank(),\n          axis.title.x = element_blank(),\n          axis.ticks.x = element_blank()))\n\n# Plot the figures\nwrap_plots(plots, ncol = 1) +\n  plot_layout(guides = \"collect\")",
    "crumbs": [
      "Diversity & similarity",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Community diversity</span>"
    ]
  },
  {
    "objectID": "pages/alpha_diversity.html#visualizing-significance-in-group-wise-comparisons",
    "href": "pages/alpha_diversity.html#visualizing-significance-in-group-wise-comparisons",
    "title": "13  Community diversity",
    "section": "\n13.3 Visualizing significance in group-wise comparisons",
    "text": "13.3 Visualizing significance in group-wise comparisons\nNext, let’s compare the Shannon index between sample groups and visualize the statistical significance. Using the stat_compare_means function from the ggpubr package, we can add visually appealing p-values to our plots.\nTo add adjusted p-values, we have to first calculate them.\n\nlibrary(ggpubr)\nlibrary(tidyverse)\n\n\nindex &lt;- \"shannon\"\ngroup_var &lt;- \"SampleType\"\n\n# Subsets the data. Takes only those samples that are from feces, skin, or\n# tongue.\ntse_sub &lt;- tse[ , tse[[group_var]] %in% c(\"Feces\", \"Skin\", \"Tongue\") ]\n\n# Changes old levels with new levels\ntse_sub$SampleType &lt;- factor(tse_sub$SampleType)\n\n# Calculate p values\npvals &lt;- pairwise.wilcox.test(\n    tse_sub[[index]], tse_sub[[group_var]], p.adjust.method = \"fdr\")\n# Put them to data.frame format\npvals &lt;- pvals[[\"p.value\"]] |&gt;\n    as.data.frame()\nvarname &lt;- \"group1\"\npvals[[varname]] &lt;- rownames(pvals)\n# To long format\npvals &lt;- reshape(\n    pvals,\n    direction = \"long\",\n    varying = colnames(pvals)[ !colnames(pvals) %in% varname ],\n    times = colnames(pvals)[ !colnames(pvals) %in% varname ],\n    v.names = \"p\",\n    timevar = \"group2\",\n    idvar = \"group1\"\n    ) |&gt;\n    na.omit()\n# Add y-axis position\npvals[[\"y.position\"]] &lt;- apply(pvals, 1, function(x){\n    temp1 &lt;- tse[[index]][ tse[[group_var]] == x[[\"group1\"]] ]\n    temp2 &lt;- tse[[index]][ tse[[group_var]] == x[[\"group2\"]] ]\n    temp &lt;- max( c(temp1, temp2) )\n    return(temp)\n})\npvals[[\"y.position\"]] &lt;- max(pvals[[\"y.position\"]]) +\n    order(pvals[[\"y.position\"]]) * 0.2\n# Round values\npvals[[\"p\"]] &lt;- round(pvals[[\"p\"]], 3)\n\n# Create a boxplot\np &lt;- plotColData(\n    tse_sub, x = group_var, y = index,\n    show_boxplot = TRUE, show_violin = FALSE) +\n    theme(text = element_text(size = 10)) +\n    stat_pvalue_manual(pvals)\np\n\n\n\n\n\n\n\nArticle on ggpubr package provides further examples for estimating and highlighting significances.",
    "crumbs": [
      "Diversity & similarity",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Community diversity</span>"
    ]
  },
  {
    "objectID": "pages/beta_diversity.html",
    "href": "pages/beta_diversity.html",
    "title": "14  Community similarity",
    "section": "",
    "text": "14.1 Divergence\nDivergence measure refers to a difference in community composition between the given sample(s) and a reference sample. This can be evaluated with addDivergence(). Reference and algorithm for the calculation of divergence can be specified as reference and FUN, respectively.\ntse &lt;- addDivergence(\n    tse,\n    assay.type = \"counts\",\n    reference = \"median\",\n    FUN = getDissimilarity)",
    "crumbs": [
      "Diversity & similarity",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Community similarity</span>"
    ]
  },
  {
    "objectID": "pages/beta_diversity.html#sec-unsupervised-ordination",
    "href": "pages/beta_diversity.html#sec-unsupervised-ordination",
    "title": "14  Community similarity",
    "section": "\n14.2 Unsupervised ordination",
    "text": "14.2 Unsupervised ordination\nUnsupervised ordination methods analyze variation in the data without additional information on covariates or other supervision of the model. Among the different approaches, Multi-Dimensional Scaling (MDS) and non-metric MDS (NMDS) can be regarded as the standard. They are jointly referred to as PCoA. For this demonstration, we will analyse beta diversity in GlobalPatterns, and observe the variation between stool samples and those with a different origin.\n\n14.2.1 Comparing communities by beta diversity analysis\nA typical comparison of community compositions starts with a visual representation of the groups by a 2D ordination. Then we estimate relative abundances and MDS ordination based on Bray-Curtis index between the groups, and visualize the results.\nIn the following examples dissimilarity is calculated with the function supplied to the FUN argument. Several metrics of beta diversity are defined by the vegdist() function of the vegan package, which is often used in this context. However, such custom functions created by the user also work, as long as they return a dist object. In either case, this function is then applied to calculate reduced dimensions via an ordination method, the results of which can be stored in the reducedDim slot of the TreeSE. This entire process is contained by the runMDS() and runNMDS() functions.\n\n# Load package to plot reducedDim\nlibrary(scater)\n\n# Run PCoA on relabundance assay with Bray-Curtis distances\ntse &lt;- runMDS(\n    tse,\n    FUN = getDissimilarity,\n    method = \"bray\",\n    assay.type = \"relabundance\",\n    name = \"MDS_bray\")\n\nSample dissimilarity can be visualized on a lower-dimensional display (typically 2D) using the plotReducedDim() function from the scater package. This also provides tools to incorporate additional information encoded by color, shape, size and other aesthetics. Can you find any difference between the groups?\n\n# Create ggplot object\np &lt;- plotReducedDim(tse, \"MDS_bray\", colour_by = \"Group\")\n\n# Calculate explained variance\ne &lt;- attr(reducedDim(tse, \"MDS_bray\"), \"eig\")\nrel_eig &lt;- e / sum(e[e &gt; 0])\n\n# Add explained variance for each axis\np &lt;- p + labs(\n    x = paste(\"PCoA 1 (\", round(100 * rel_eig[[1]], 1), \"%\", \")\", sep = \"\"),\n    y = paste(\"PCoA 2 (\", round(100 * rel_eig[[2]], 1), \"%\", \")\", sep = \"\")\n    )\n\np\n\n\n\nMDS plot based on the Bray-Curtis distances on the GlobalPattern dataset.\n\n\n\nA few combinations of beta diversity metrics and assay types are typically used. For instance, Bray-Curtis dissimilarity and Euclidean distance are often applied to the relative abundance and the clr assays, respectively. Besides beta diversity metric and assay type, the PCoA algorithm is also a variable that should be considered. Below, we show how the choice of these three factors can affect the resulting lower-dimensional data.\n\n# Run NMDS on relabundance assay with Bray-Curtis distances\ntse &lt;- runNMDS(\n    tse,\n    FUN = getDissimilarity,\n    method = \"bray\",\n    assay.type = \"relabundance\",\n    name = \"NMDS_bray\")\n\n# Run MDS on clr assay with Aitchison distances\ntse &lt;- runMDS(\n    tse,\n    FUN = getDissimilarity,\n    method = \"euclidean\",\n    assay.type = \"clr\",\n    name = \"MDS_aitchison\")\n\n# Run NMDS on clr assay with Euclidean distances\ntse &lt;- runNMDS(\n    tse,\n    FUN = getDissimilarity,\n    method = \"euclidean\",\n    assay.type = \"clr\",\n    name = \"NMDS_aitchison\")\n\nMultiple ordination plots are combined into a multi-panel plot with the patchwork package, so that different methods can be compared to find similarities between them or select the most suitable one to visualize beta diversity in the light of the research question.\n\n# Load package for multi-panel plotting\nlibrary(patchwork)\n\n# Generate plots for all 4 reducedDims\nplots &lt;- lapply(\n    c(\"MDS_bray\", \"MDS_aitchison\", \"NMDS_bray\", \"NMDS_aitchison\"),\n    plotReducedDim,\n    object = tse,\n    colour_by = \"Group\")\n\n# Generate multi-panel plot\nwrap_plots(plots) +\n    plot_layout(guides = \"collect\")\n\n\n\nComparison of MDS and NMDS plots based on the Bray-Curtis or Aitchison distances on the GlobalPattern dataset.\n\n\n\nThe Unifrac method is a special case, as it requires data on the relationship of features in the form of a phylo tree. getDissimilarity() performs the calculation to return a dist object, which can again be used within runMDS().\n\ntse &lt;- runMDS(\n    tse,\n    FUN = getDissimilarity,\n    method = \"unifrac\",\n    name = \"unifrac\",\n    tree = rowTree(tse),\n    ntop = nrow(tse),\n    assay.type = \"counts\")\n\nplotReducedDim(tse, \"unifrac\", colour_by = \"Group\")\n\n\n\nUnifrac distances scaled by MDS of the GlobalPattern dataset.\n\n\n\n\n14.2.2 Rarefaction to mitigate impacts of uneven sequencing effort\nThe sequencing depth of a sample refers to the number of metagenomic reads obtained from the sequencing process. A variation in sequencing depth across the samples of a study may impact the calculation of alpha and beta diversity metrics (Patrick D. Schloss 2023). It is common to find significant variation in sequencing depth between samples. For instance, the samples of the TreeSummarizedExperiment dataset GlobalPatterns show up to a 40-fold difference in the number of metagenomic reads.\n\n# Calculate the list of sequencing depths across samples\nsequencing_depths &lt;- colSums(assay(tse))\n# Calculate variation between highest and lowest sequencing depth\ndepth_variation &lt;- max(sequencing_depths)/min(sequencing_depths)\ndepth_variation\n##  [1] 40.16\n\nTo address uneven sequencing effort, rarefaction aims to normalize metagenomic reads counts using subsampling. First, the user chooses the rarefaction depth and a number of iterations N. All the samples with metagenomic reads count below the rarefaction depth are removed and metagenomic reads are randomly drawn from the samples left to get subsamples fitting the rarefaction depth. Then a beta diversity metric is calculated from those subsamples and the process is iterated N times. Finally, beta diversity is estimated with the mean of all beta diversity values calculated on subsampled data.\nThere has been a long-lasting controversy surrounding the use of rarefaction in microbial ecology. The main concern is that rarefaction would omit data (McMurdie and Holmes 2014) (Patrick D. Schloss 2024). However, if the subsampling process is repeated a sufficient number of times, and if the rarefaction depth is set to the lowest metagenomic reads count found across all samples, no data will be omitted. Moreover, Patrick Schloss has demonstrated that rarefaction is “the only method that could control for variation in uneven sequencing effort when measuring commonly used alpha and beta diversity metrics” (Patrick D. Schloss 2023).\n\nMcMurdie, Paul J, and Susan Holmes. 2014. “Waste Not, Want Not: Why Rarefying Microbiome Data Is Inadmissible.” PLoS Computational Biology 10 (4): e1003531.\n\nSchloss, Patrick D. 2024. “Waste Not, Want Not: Revisiting the Analysis That Called into Question the Practice of Rarefaction.” mSphere 9 (1): e00355–23. https://doi.org/10.1128/msphere.00355-23.\n\nSchloss, Patrick D. 2023. “Rarefaction Is Currently the Best Approach to Control for Uneven Sequencing Effort in Amplicon Sequence Analyses.” bioRxiv, 2023–06. https://doi.org/10.1101/2023.06.23.546313.\nBefore applying rarefaction, selecting the most variable features can help minimize variation caused by random subsampling. These features have the highest read counts, while rare features tend to increase sampling variation. This approach facilitates comparison of results between non-rarefied and rarefied distance calculations later on.\n\n# Let us see what happens when we operate with ntop highest variance features\nntop &lt;- 5\n\n# Calculate the standard deviations for each row\nrow_sds &lt;- rowSds(assay(tse, \"counts\"))\n\n# Get the indices of the top 5 rows with the highest standard deviations\ntop_indices &lt;- order(row_sds, decreasing = TRUE)[1:ntop]\n\n# Subset the tse object based on the top indices\ntse_sub &lt;- tse[top_indices, ]\n\nLet us first convert the count assay to centered log ratio (clr) assay and calculate MDS with Aitchison distance without rarefaction:\n\n# Centered log-ratio transformation to properly apply Aitchison distance\n\ntse_sub &lt;- transformAssay(\n  tse_sub,\n  assay.type = \"counts\",\n  method = \"clr\",\n  pseudocount = 1\n  )\n\n# Run MDS on clr assay with Aitchison distance\ntse_sub &lt;- runMDS(\n  tse_sub,\n  FUN = getDissimilarity,\n  method = \"euclidean\",\n  assay.type = \"clr\",\n  name = \"MDS_aitchison\"\n  )\n\nThen let’s do the same with rarefaction:\n\n# Define custom transformation function..\nclr &lt;- function (x) {\n  vegan::decostand(x, method=\"clr\", pseudocount=1)\n}\n\n# Run transformation after rarefactions before calculating the beta diversity..\ntse_sub &lt;- runMDS(tse_sub,\n  assay.type = \"counts\",\n  ntop = nrow(tse_sub),\n  FUN = getDissimilarity,\n  method = \"euclidean\",\n  niter = 10, # Number of iterations\n  sample = min(colSums(assay(tse_sub, \"counts\"))), # Rarefaction depth\n  transf = clr, # Applied transformation\n  replace = TRUE,\n  name = \"MDS_aitchison_rarefied\"\n  )\n\n# Generate plots for non-rarefied and rarefied Bray-Curtis distances scaled by\n# MDS\nplots &lt;- lapply(\n  c(\"MDS_aitchison\", \"MDS_aitchison_rarefied\"),\n  plotReducedDim,\n  object = tse_sub)\n\n# Generate multi-panel plot\nwrap_plots(plots) +\n  plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\nntop is a runMDS() option. Here it is set to total number of features in GlobalPatterns dataset so that they are not filtered. If ntop was not set to the total number of features, only the ntop features with highest variance would be used for dimensionality reduction and the other features would be filtered.\nWhen rarefaction is not done, the getDissimilarity() utilizes vegan::vegdist() function while in rafection vegan::avgdist() is applied. The argument sample is set to the smallest metagenomic reads count across all samples. This ensures that no sample will be removed during the rarefaction process.\nThe argument niter is by default set to 100 but 10 iterations is often sufficient for beta diversity calculations.\nTo use transformations after the rarefaction of the samples and before the beta diversity calculation, we can use the argument transf.\nWe can also plot the correlation between principal coordinates PCx and PCy for both the rarefied and non-rarefied distance calculations:\n\nlibrary(ggpubr)\n\np &lt;- lapply(1:2, function(i){\n  # Principal axes are sign invariant;\n  # align the signs; if the correlation is negative then swap the other axis\n  original &lt;- reducedDim(tse_sub, \"MDS_aitchison\")[, i]\n  rarefied &lt;- reducedDim(tse_sub, \"MDS_aitchison_rarefied\")[, i]\n\n  temp  &lt;- ggplot(data = data.frame(original, rarefied), aes(x = original, y = rarefied)) +\n    geom_point() + geom_smooth(method = \"lm\") +\n    stat_cor(method = \"pearson\") +\n    labs(title = paste0(\"Principal coordinate \", i))\n  return(temp)\n})\nwrap_plots(p)\n\n\n\n\n\n\n\nThe mia package’s addAlpha() and getDissimilarity() functions support rarefaction in alpha and beta diversity calculations. Additionally, the rarefyAssay() function allows random subsampling of a given assay within a TreeSummarizedExperiment dataset.\n\n14.2.3 Other ordination methods\nOther dimension reduction methods, such as PCA and UMAP, are inherited from the scater package.\n\ntse &lt;- runPCA(\n    tse,\n    name = \"PCA\",\n    assay.type = \"counts\",\n    ncomponents = 10)\n\nplotReducedDim(tse, \"PCA\", colour_by = \"Group\")\n\n\n\nPCA plot on the GlobalPatterns data set containing sample from different sources.\n\n\n\nAs mentioned before, applicability of the different methods depends on your sample set and research question.\n\ntse &lt;- runUMAP(\n    tse,\n    name = \"UMAP\",\n    assay.type = \"counts\",\n    ncomponents = 3)\n\nplotReducedDim(tse, \"UMAP\", colour_by = \"Group\", ncomponents = c(1:3))\n\n\n\nUMAP plot on the GlobalPatterns data set containing sample from different sources.\n\n\n\n\n14.2.4 Explained variance\nThe percentage of explained variance is typically shown in PCA ordination plots. This quantifies the proportion of overall variance in the data that is captured by the PCA axes, or how well the ordination axes reflect the original distances.\nSometimes a similar measure is shown for MDS/PCoA. The interpretation is generally different, however, and hence we do not recommend using it. PCA is a special case of PCoA with Euclidean distances. With non-Euclidean dissimilarities PCoA uses a trick where the pointwise dissimilarities are first cast into similarities in a Euclidean space (with some information loss i.e. stress) and then projected to the maximal variance axes. In this case, the maximal variance axes do not directly reflect the correspondence of the projected distances and original distances, as they do for PCA.\nIn typical use cases, we would like to know how well the ordination reflects the original similarity structures; then the quantity of interest is the so-called “stress” function, which measures the difference in pairwise similarities between the data points in the original (high-dimensional) vs. projected (low-dimensional) space.\nHence, we propose that for PCoA and other ordination methods, users would report relative stress, which varies within the unit interval and is better if smaller. This can be calculated as shown below.\n\n# Quantify dissimilarities in the original feature space\nd0 &lt;- as.matrix(getDissimilarity(t(assay(tse, \"relabundance\")), \"bray\"))\n\n# PCoA Ordination\ntse &lt;- runMDS(\n  tse,\n  FUN = getDissimilarity,\n  name = \"PCoA\",\n  method = \"bray\",\n  assay.type = \"relabundance\")\n\n# Quantify dissimilarities in the ordination space\ndp &lt;- as.matrix(dist(reducedDim(tse, \"PCoA\")))\n\n# Calculate stress i.e. relative difference \n# in the original and projected dissimilarities\nstress &lt;- sum((dp - d0)^2) / sum(d0^2)\n\nA Shepard plot visualizes the original versus the ordinated dissimilarity between the observations.\n\nord &lt;- order(as.vector(d0))\ndf &lt;- data.frame(d0 = as.vector(d0)[ord],\n                 dmds = as.vector(dp)[ord])\n\nggplot(df, aes(x = d0, y = dmds)) +\n  geom_smooth() +\n  geom_point() +\n  labs(title = \"Shepard plot\",\n       x = \"Original distance\",\n       y = \"MDS distance\",\n       subtitle = paste(\"Stress:\", round(stress, 2))) +\n  theme_bw()",
    "crumbs": [
      "Diversity & similarity",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Community similarity</span>"
    ]
  },
  {
    "objectID": "pages/beta_diversity.html#supervised-constrained-ordination",
    "href": "pages/beta_diversity.html#supervised-constrained-ordination",
    "title": "14  Community similarity",
    "section": "\n14.3 Supervised / constrained ordination",
    "text": "14.3 Supervised / constrained ordination\ndbRDA is a supervised counterpart of PCoA. It maximize the variance with respect to the covariates provided by the user. This can be used to quantify associations between each covariate and community composition (beta diversity). The table below summarizes the relations between the supervised and unsupervised ordination methods.\n\n\n\n\n\n\n\n\nsupervised ordination\nunsupervised ordination\n\n\n\nEuclidean distance\nRDA\nPCA\n\n\nnon-Euclidean distance\ndbRDA\nPCoA/MDS, NMDS, UMAP\n\n\n\nIn summary, the “dbRDA” is the more general method that allows a wider variety dissimilarity, or beta diversity, indices. This method is available via mia::getRDA(), which calls vegan::dbrda(). By default, this uses Euclidean distances, which is equivalent to the ordinary RDA. However, the dbRDA method (mia::getRDA()) allows the use of other dissimilarity indices as well.\nLet us next demonstrate dbRDA with the enterotype dataset. Here samples correspond to patients. The colData lists the clinical status of each patient and a few covariates such as gender and age.\n\n# Load data\ndata(\"enterotype\", package = \"mia\")\ntse2 &lt;- enterotype\n\n# Apply relative transform\ntse2 &lt;- transformAssay(tse2, method = \"relabundance\")\n\n\n14.3.1 Redundancy analysis\ndbRDA can be perfomed with the addRDA() function. In addition to the arguments previously defined for unsupervised ordination, this function takes a formula to control for variables and an action to treat missing values. Along with clinical status, which is the main outcome, we control for gender and age, and exclude observations where one of these variables is missing.\n\n# Perform RDA\ntse2 &lt;- addRDA(\n    tse2,\n    assay.type = \"relabundance\",\n    formula = assay ~ ClinicalStatus + Gender + Age,\n    distance = \"bray\",\n    na.action = na.exclude)\n\n# Store results of PERMANOVA test\nrda_info &lt;- attr(reducedDim(tse2, \"RDA\"), \"significance\")\n\nThe importance of each variable on the similarity between samples (i.e. loadings) can be assessed from the results of PERMANOVA, automatically provided by the addRDA() function. It performs first dbRDA and then applies permutational test to its results.\nPermutational Analysis of Variance (PERMANOVA; (2001)) is a widely used non-parametric multivariate method that aims to estimate the actual statistical significance of differences in the observed community composition between two groups of samples.\n\nAnderson, Marti J. 2001. “A New Method for Non-Parametric Multivariate Analysis of Variance.” Austral Ecology 26 (1): 32–46. https://doi.org/10.1111/j.1442-9993.2001.01070.pp.x.\nPERMANOVA tests the hypothesis that the centroids and dispersion of the community are equivalent between the compared groups. A p-value smaller than the significance threshold indicates that the groups have a different community composition. This method is implemented with the adonis2 function from the vegan package. You can find more on PERMANOVA from here.\nWe see that both clinical status and age explain more than 10% of the variance, but only age has statistical significance.\n\nrda_info$permanova |&gt;\n   knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\nDf\nSumOfSqs\nF\nPr(&gt;F)\nTotal variance\nExplained variance\n\n\n\nModel\n6\n1.1157\n1.940\n0.038\n3.991\n0.2795\n\n\nClinicalStatus\n4\n0.5837\n1.522\n0.145\n3.991\n0.1463\n\n\nGender\n1\n0.1679\n1.751\n0.131\n3.991\n0.0421\n\n\nAge\n1\n0.5245\n5.471\n0.001\n3.991\n0.1314\n\n\nResidual\n30\n2.8757\nNA\nNA\n3.991\n0.7205\n\n\n\n\n\nNext, we proceed to visualize the weight and significance of each variable on the similarity between samples with an RDA plot, which can be generated with the plotRDA() function from the miaViz package.\n\n# Load packages for plotting function\nlibrary(miaViz)\n\n# Generate RDA plot coloured by clinical status\nplotRDA(tse2, \"RDA\", colour.by = \"ClinicalStatus\")\n\n\n\n\n\n\n\nFrom above, we can see that only age significantly describes differences between the microbial profiles of different samples. Such visual approach complements the previous results obtained with PERMANOVA.\n\n14.3.2 Visualize dbRDA loadings\nLet us visualize the model coefficients or loadings for species that exhibit the largest differences between the groups. This gives some insights into how the groups tend to differ from each other in terms of community composition.\n\n# Extract loadings for first eigenvector\nrda &lt;- reducedDim(tse2, \"RDA\")\nrda &lt;- attr(rda, \"rda\")\ncoef &lt;- rda$CCA$v\ncoef &lt;- coef[, 1, drop = FALSE]\n\n# Get the taxa with biggest weights\ntop_coef &lt;- head(coef[rev(order(abs(coef))), , drop = FALSE], 20)\n# Sort weights in increasing order\ntop_coef &lt;- top_coef[order(top_coef), ]\n\n# Create data.frame\ndf &lt;- data.frame(\n    x = top_coef,\n    y = factor(names(top_coef), unique(names(top_coef))))\n\n# Create a plot\nggplot(df, aes(x = x, y = y)) +\n    geom_bar(stat = \"identity\") +\n    labs(x = \"\", y= \"\", title = \"Top Taxa\") +\n    theme_bw()\n\n\n\n\n\n\n\nIn the example above, the largest differences between the two groups can be attributed to Bifidobacterium and -1.\n\n14.3.3 Checking the homogeneity condition\nIt is important to note that the application of PERMANOVA assumes homogeneous group dispersions (variances). This can be tested with the PERMDISP2 method (Anderson 2006) by using the same assay and distance method than in PERMANOVA.\n\n———. 2006. “Distance-Based Tests for Homogeneity of Multivariate Dispersions.” Biometrics 62: 245–53. https://doi.org/10.1111/j.1541-0420.2005.00440.x.\nTo ensure that the homogeneity assumption holds, we retrieve the corresponding information from the results of RDA. None of the p-values is lower than the significance threshold, and thus homogeneity is observed.\n\n\n\n\n\n\nNote\n\n\n\nPERMANOVA assumes that the group dispersion is homogeneous. Homogeneous dispersion means that the variation within groups is smaller than the variation between groups, making the groups distinct. If this assumption is not met, the results can be misleading.\naddRDA() performs homogeneity test automatically.\n\n\n\nrda_info$homogeneity |&gt;\n    knitr::kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDf\nSum Sq\nMean Sq\nF\nN.Perm\nPr(&gt;F)\nTotal variance\nExplained variance\n\n\n\nClinicalStatus\n4\n0.2511\n0.0628\n2.7440\n999\n0.113\n1.0288\n0.2440\n\n\nGender\n1\n0.0103\n0.0103\n0.4158\n999\n0.543\n0.9283\n0.0111\n\n\nAge\n29\n0.3272\n0.0113\n17.0255\n999\n0.417\n0.3319\n0.9860\n\n\n\n\n\nAs the group dispersion is homogenic, PERMANOVA can be seen as an appropriate choice for comparing community compositions.",
    "crumbs": [
      "Diversity & similarity",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Community similarity</span>"
    ]
  },
  {
    "objectID": "pages/beta_diversity.html#case-studies",
    "href": "pages/beta_diversity.html#case-studies",
    "title": "14  Community similarity",
    "section": "\n14.4 Case studies",
    "text": "14.4 Case studies\n\n14.4.0.1 Visualizing the most dominant genus on PCoA\nIn this section, we visualize the most dominant genus on PCoA. A similar visualization was proposed by (2021). First, let us agglomerate the data at the Genus level and identify the dominant taxa for each sample.\n\nSalosensaari, Aaro, Ville Laitinen, Aki Havulinna, Guillaume Méric, Susan Cheng, Markus Perola, Liisa Valsta, et al. 2021. “Taxonomic Signatures of Cause-Specific Mortality Risk in Human Gut Microbiome.” Nature Communications 12: 1–8. https://www.nature.com/articles/s41467-021-22962-y.\n\n# Agglomerate to genus level\ntse_genus &lt;- agglomerateByRank(tse, rank = \"Genus\")\n\n# Convert to relative abundances\ntse_genus &lt;- transformAssay(\n    tse, method = \"relabundance\", assay.type = \"counts\")\n\n# Add info on dominant genus per sample\ntse_genus &lt;- addDominant(\n    tse_genus, assay.type = \"relabundance\", name = \"dominant_taxa\")\n# Overview\nsummarizeDominance(\n    tse_genus, rank = \"Genus\", digits = 3, name = \"dominant_taxa\")\n##  # A tibble: 17 × 3\n##    dominant_taxa                n rel_freq\n##    &lt;chr&gt;                    &lt;int&gt;    &lt;dbl&gt;\n##  1 Bacteroides                  5    0.192\n##  2 Crenothrix                   3    0.115\n##  3 Faecalibacterium             2    0.077\n##  4 Prochlorococcus              2    0.077\n##  5 Streptococcus                2    0.077\n##  6 CandidatusNitrososphaera     1    0.038\n##  # ℹ 11 more rows\n\nNext, we perform PCoA with Bray-Curtis dissimilarity.\n\ntse_genus &lt;- runMDS(\n    tse_genus,\n    FUN = getDissimilarity,\n    name = \"PCoA_BC\",\n    method = \"bray\",\n    assay.type = \"relabundance\")\n\nFinally, we get the top taxa and and visualize their abundances on PCoA. Note that a 3D interactive version of the plot below can be found in Appendix C.\n\n# Getting the top taxa\ntop_taxa &lt;- getTop(tse_genus, top = 6, assay.type = \"relabundance\")\n\n# Naming all the rest of non top-taxa as \"Other\"\nmost_abundant &lt;- lapply(\n    colData(tse_genus)$dominant_taxa, function(x){\n        if (x %in% top_taxa) {x} else {\"Other\"}\n    })\n\n# Storing the previous results as a new column within colData\ncolData(tse_genus)$most_abundant &lt;- as.character(most_abundant)\n\n# Calculating percentage of the most abundant\nmost_abundant_freq &lt;- table(as.character(most_abundant))\nmost_abundant_percent &lt;- round(\n    most_abundant_freq / sum(most_abundant_freq) * 100,\n    1)\n\n# Retrieving the explained variance\ne &lt;- attr(reducedDim(tse_genus, \"PCoA_BC\"), \"eig\")\nvar_explained &lt;- e / sum(e[e &gt; 0]) * 100\n\n# Define colors for visualization\nmy_colors &lt;- c(\n    \"black\", \"blue\", \"lightblue\", \"darkgray\", \"magenta\", \"darkgreen\", \"red\")\n\n# Visualization\np &lt;- plotReducedDim(tse_genus, \"PCoA_BC\", colour_by = \"most_abundant\") +\n    scale_colour_manual(\n        values = my_colors,\n        labels = paste0(\n            names(most_abundant_percent), \"(\", most_abundant_percent, \"%)\")) +\n    labs(\n        x = paste(\"PC 1 (\", round(var_explained[1], 1), \"%)\"),\n        y = paste(\"PC 2 (\", round(var_explained[2], 1), \"%)\"),\n        color = \"\")\n\np\n\n\n\n\n\n\n\nSimilarly, we visualize and compare the sub-population.\n\n# Calculating the frequencies and percentages for both categories\nfreq_TRUE  &lt;- table(as.character(most_abundant[tse_genus$Group]))\nfreq_FALSE &lt;- table(as.character(most_abundant[!tse_genus$Group]))\npercent_TRUE  &lt;- round(freq_TRUE  / sum(freq_TRUE)  * 100, 1)\npercent_FALSE &lt;- round(freq_FALSE / sum(freq_FALSE) * 100, 1)\n\n# Visualization\nplotReducedDim(\n    tse_genus[ , colData(tse_genus)$Group == TRUE], \"PCoA_BC\",\n    colour_by = \"most_abundant\") +\n\n    scale_colour_manual(\n        values = my_colors,\n        labels = paste0(names(percent_TRUE), \"(\", percent_TRUE, \"%)\")) +\n\n  labs(\n      x = paste(\"PC 1 (\", round(var_explained[1], 1), \"%)\"),\n      y = paste(\"PC 2 (\", round(var_explained[2], 1), \"%)\"),\n      title = \"Group = TRUE\", color = \"\")\n\n\n\n\n\n\n\nplotReducedDim(\n    tse_genus[ , colData(tse_genus)$Group == FALSE], \"PCoA_BC\",\n    colour_by = \"most_abundant\") +\n\n    scale_colour_manual(\n        values = my_colors,\n        labels = paste0(names(percent_FALSE), \"(\", percent_FALSE, \"%)\")) +\n\n    labs(\n        x = paste(\"PC 1 (\", round(var_explained[1], 1), \"%)\"),\n        y = paste(\"PC 2 (\", round(var_explained[2], 1), \"%)\"),\n        title = \"Group = FALSE\", color = \"\")\n\n\n\n\n\n\n\n\n\n\n\n\n\nSummary\n\n\n\nAs a final note, we provide a comprehensive list of functions for the evaluation of dissimilarity indices available in the mia and scater packages. The calculate methods return a reducedDim object as an output, whereas the run methods store the reducedDim object into the specified TreeSE.\n\nCanonical Correspondence Analysis (CCA): getCCA() and runCCA()\n\ndbRDA: getRDA() and runRDA(0); our recommended default method to assess differences in community composition (beta diversity)\nDouble Principal Coordinate Analysis (DPCoA): getDPCoA() and runDPCoA()\n\nJensen-Shannon Divergence (JSD): calculateJSD() and runJSD()\n\nMDS: calculateMDS() and runMDS()\n\nNMDS: getNMDS() and runNMDS()\n\nOverlap: calculateOverlap() and runOverlap()\n\nPERMANOVA: (e.g. from vegan::adonis2()) can be used to assess significance when comparing community composition between groups. Retrieving the loadings and components is more tricky, however.\nt-distributed Stochastic Neighbor Embedding (t-SNE): calculateTSNE() and runTSNE()\n\nUMAP: calculateUMAP() and runUMAP()\n\n\nFor more information on sample clustering, you can refer to:\n\nHow to extract information from clusters\nChapter Chapter 15 on community typing",
    "crumbs": [
      "Diversity & similarity",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Community similarity</span>"
    ]
  },
  {
    "objectID": "pages/clustering.html",
    "href": "pages/clustering.html",
    "title": "15  Community typing",
    "section": "",
    "text": "15.1 Clustering\nClustering techniques aim to find groups, called clusters, that share a pattern in the data. In the microbiome context, clustering techniques are included in microbiome community typing methods. For example, clustering allow samples to be distinguished from each other based on their microbiome community composition. Clustering scheme consists of two steps, the first is to compute the sample dissimilarities with a given distance metrics, and the second is to form the clusters based on the dissimilarity matrix. The data can be clustered either based on features or samples. The examples below are focused on sample clustering.\nThere are multiple clustering algorithms available. bluster is a Bioconductor package providing tools for clustering data in the SummarizedExperiment container. It offers multiple algorithms such as hierarchical clustering, DBSCAN, and K-means.\n# Load dependencies\nlibrary(bluster)\nIn the examples of this chapter we use peerj13075 data for microbiota community typing. This chapter illustrates how different results can be obtained depending on the choice of the algorithm. To reduce calculation time we decided to agglomerate taxa onto ‘Class’ level and filter out the least prevalent taxa as well as less commonly detected within a sample resulting in 25 features in the data.\nlibrary(mia)\ndata(\"peerj13075\", package = \"mia\")\ntse &lt;- peerj13075\n\n# Filter out most taxa to ease the calculation\naltExp(tse, \"prevalent\") &lt;- agglomerateByPrevalence(\n    tse, rank = \"class\", prevalence = 20/100, detection = 1/100)",
    "crumbs": [
      "Diversity & similarity",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Community typing</span>"
    ]
  },
  {
    "objectID": "pages/clustering.html#clustering",
    "href": "pages/clustering.html#clustering",
    "title": "15  Community typing",
    "section": "",
    "text": "15.1.1 Hierarchical clustering\nThe hierarchical clustering aims to find hierarchy between samples/features. There are two approaches: agglomerative (“bottom-up”) and divisive (“top-down”). In agglomerative approach, each observation is first in a unique cluster, after which the algorithm continues to agglomerate similar data points into clusters. The divisive approach, instead, starts with one cluster that contains all observations. Clusters are split recursively into clusters that differ the most. The clustering can be continued until each cluster contains only one observation.\nIn this example we use addCluster() function from mia to cluster the data. addCluster() function allows to choose a clustering algorithm and offers multiple parameters to shape the result. HclustParam() parameter is chosen for hierarchical clustering. HclustParam() parameter itself has parameters on its own HclustParam documentation. A parameter, by defines whether to cluster features or samples. Here we cluster counts data, for which we compute the dissimilarities with the Bray-Curtis distance. Here, again, we use ward.d2 method. Returning statistical information can be chosen by using full parameter. Finally, the clust.col parameter allows us to choose the name of the column in the colData (default name is clusters).\n\nlibrary(vegan)\n\nset.seed(174923)\naltExp(tse, \"prevalent\") &lt;- addCluster(\n    altExp(tse, \"prevalent\"),\n    assay.type = \"counts\",\n    by = \"cols\",\n    HclustParam(method = \"ward.D2\", dist.fun = getDissimilarity, metric = \"bray\"),\n    full = TRUE,\n    clust.col = \"hclust\")\n\ntable(altExp(tse, \"prevalent\")$hclust)\n##  \n##   1  2  3  4  5  6 \n##  13  5  8 16 11  5\n\nHierarchical clustering suggests six clusters to describe the data.\nNow, we visualize the hierarchical structure of the clusters with a dendrogram tree. In dendrograms, the tree is split where the branch length is the largest. In each splitting point, the tree is divided into two clusters leading to the hierarchy. In this example, each sample is labelled by their dominant taxon to visualize ecological differences between the clusters.\n\nlibrary(dendextend)\n\n# Get hclust data from metadata\nhclust_data &lt;- metadata(altExp(tse, \"prevalent\"))$clusters$hclust\n\n# Get the dendrogram object\ndendro &lt;- as.dendrogram(hclust_data)\nk &lt;- length(unique(altExp(tse, \"prevalent\")$hclust))\n\n# Color the branches by clusters\ncols &lt;- scales::hue_pal()(k)\n\n# Order the colors to be equivalent to the factor levels\ncols &lt;- cols[c(1,4,5,3,2,6)]\ndend &lt;- color_branches(dendro, k = k, col = unlist(cols))\n\n# Label the samples by their dominant taxon\naltExp(tse, \"prevalent\") &lt;- addDominant(altExp(tse, \"prevalent\"))\nlabels(dend) &lt;- altExp(tse, \"prevalent\")$dominant_taxa\ndend &lt;- color_labels(dend, k = k, col = unlist(cols))\n\n# Adjust frame for the figure\npar(mar=c(9, 3, 0.5, 0.5))\n# Plot dendrogram\ndend |&gt; set(\"labels_cex\", 0.8) |&gt; plot()\n\n\n\n\n\n\n\nWe can also visualize the clusters by projecting the data onto two-dimensional surface that captures the most variability in the data. In this example, we use multi-dimensional scaling (MDS) (see Section 14.2).\n\nlibrary(scater)\n\n# Add the MDS dimensions for plotting\naltExp(tse, \"prevalent\") &lt;- runMDS(\n    altExp(tse, \"prevalent\"),\n    assay.type = \"counts\",\n    FUN = vegan::vegdist,\n    method = \"bray\")\n\n\nplotReducedDim(\n    altExp(tse, \"prevalent\"), \"MDS\", colour_by = \"hclust\",\n    theme_size = 13, point_size = 4) +\n    labs(color = \"HClust\", title = \"Hclust\") + theme_minimal()\n\n\n\n\n\n\n\n\n15.1.2 Agglomeration based on clusters\nAnother way to agglomerate the data is to cluster the taxa. To do so, we usually start by doing a compositionality aware transformation such as CLR, followed by the application of a standard clustering method.\nHere is an example that does a CLR transformation followed by the hierarchical clustering algorithm. We will use the kendall dissimilarity.\n\n# The result of the CLR transform is stored in the assay clr\ntse &lt;- transformAssay(tse, method = \"clr\", pseudocount = 1)\n\ntse &lt;- transformAssay(\n    tse, assay.type = \"clr\", method = \"standardize\", MARGIN = \"rows\")\n\n# Declare the Kendall dissimilarity computation function\nkendall_dissimilarity &lt;- function(x) {\n    as.dist(1 - cor(t(x), method = \"kendall\"))\n}\n\n# Cluster (with Kendall dissimilarity) on the features of the `standardize`\n# assay\ntse &lt;- addCluster(\n    tse,\n    assay.type = \"standardize\",\n    clust.col = \"hclustKendall\",\n    MARGIN = \"rows\",\n    HclustParam(dist.fun = kendall_dissimilarity, method = \"ward.D2\"))\n\nResults are stored in the rowData column specified with the clust.col parameter.\nTo better visualize the results and the distribution of the clusters, we can plot the histogram of the clusters.\n\nlibrary(ggplot2)\n\np &lt;- ggplot(rowData(tse), aes(x = hclustKendall)) +\n    geom_bar() +\n    labs(title = \"CAG size distribution (1 - tau)\",\n         x = \"Clusters\", y = \"Feature count (n)\")\np\n\n\n\n\n\n\n\nThen we can merge data to clusters.\n\n# Aggregate clusters as a sum of each cluster values\ntse_merged &lt;- agglomerateByVariable(tse, by = \"rows\", f = \"hclustKendall\")\ntse_merged\n##  class: TreeSummarizedExperiment \n##  dim: 4 58 \n##  metadata(0):\n##  assays(3): counts clr standardize\n##  rownames(4): 1 2 3 4\n##  rowData names(7): kingdom phylum ... genus hclustKendall\n##  colnames(58): ID1 ID2 ... ID57 ID58\n##  colData names(5): Sample Geographical_location Gender Age Diet\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(1): prevalent\n##  rowLinks: NULL\n##  rowTree: NULL\n##  colLinks: NULL\n##  colTree: NULL\n\nWe can note that it worked as planned since there are now as many rows as there were clusters.\nYou can find more information on agglomeration from Chapter 9.\n\n15.1.3 Dirichlet Multinomial Mixtures (DMM)\nThis section focuses on Dirichlet-Multinomial MixturenModel analysis. It is a Bayesian clustering technique that allows to search for sample patterns that reflect sample similarity in the data using both prior information and the data.\nIn this example, we cluster the data with DMM clustering. In the example below, we calculate model fit using Laplace approximation ro reduce the calculation time. The cluster information is added in the metadata with an optional name. In this example, we use a prior assumption that the optimal number of clusters to describe the data would be in the range from 1 to 6.\n\n# Run the model and calculates the most likely number of clusters from 1 to 6\nset.seed(1495723)\naltExp(tse, \"prevalent\") &lt;- addCluster(\n    altExp(tse, \"prevalent\"),\n    assay.type = \"counts\",\n    name = \"DMM\",\n    DmmParam(k = 1:6, type = \"laplace\"),\n    MARGIN = \"samples\",\n    full = TRUE,\n    clust.col = \"dmmclust\")\n\nThe plot below represents the Laplace approximation to the model evidence for each of the six models. We can see that the best number of clusters is two, as the minimum value of Laplace approximation to the negative log model evidence for DMM models as a function of k, determines the optimal k. The optimal k suggests to fit a model with k mixtures of Dirichlet distributions as a prior.\n\nlibrary(miaViz)\np &lt;- plotDMNFit(altExp(tse, \"prevalent\"), type = \"laplace\", name = \"DMM\")\np + theme_minimal(base_size = 11)\n\n\n\n\n\n\n\nThe plot above suggests that two clusters describe the data the best. Now we can plot which taxa define the key cluster features.\n\n# Get the estimates on how much each phyla contributes on each cluster\nbest_model &lt;- metadata(altExp(tse, \"prevalent\"))$DMM$dmm[2]\ndrivers &lt;- as.data.frame(best_model[[1]]@fit$Estimate)\n\n# Plot by utilizng miaViz::plotLoadings\nplotLoadings(as.matrix(drivers), ncomponents = 2)\n\n\n\n\n\n\n\nAs well as in hierarchical clustering, we can also visualize the clusters by projecting the data onto two-dimensional surface calculated using MDS. The plot rather clearly demonstrates the cluster division.\n\n# DMM clusters\nplotReducedDim(altExp(tse, \"prevalent\"), \"MDS\", theme_size = 13) +\n              geom_point(size = 3, alpha = 0.6,\n                      aes(color = altExp(tse, \"prevalent\")$dmmclust)) +\n              labs(color = \"DMMclust\", title = \"DMM\") + theme_minimal()",
    "crumbs": [
      "Diversity & similarity",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Community typing</span>"
    ]
  },
  {
    "objectID": "pages/clustering.html#dimensionality-reduction",
    "href": "pages/clustering.html#dimensionality-reduction",
    "title": "15  Community typing",
    "section": "\n15.2 Dimensionality reduction",
    "text": "15.2 Dimensionality reduction\nDimensionality reduction can be considered as a part of community typing, where the aim is to find underlying structure in the data. Dimensionality reduction relies in the idea that the data can be describe in a lower rank representation, where latent features with different loads of the observed ones describe the sample set. This representation stores the information about sample dissimilarity with significantly reduced amount of data dimensions. Unlike clustering, where each sample is assigned into one cluster, dimensionality reduction allows continuous memberships for all samples into all community types. Dimensionality reduction techniques are explained in chapter Chapter 14 in more detail.\n\n15.2.1 Non-negative matrix factorization\nIn this section, we will particularly focus on Non-negative Matrix Factorization (NMF). NMF decomposes the original data X into two lower rank matrices: H representing key taxa characteristics of each community type and W representing continuous sample memberships across all community types. NMF algorithm calculates the minimum distance between the original data and it’s approximation using Kullback-Leibler divergence.\nHere, we use mia wrapper getNMF. To reduce calculation time, we set the number of components k to four instead of optimizing the number of components that describe the original data the best. The matrix returned by getNMF contains the sample scores, while the NMF output and NMF feature loadings are stored in the attributes NMF_output and loadings, respectively.\n\nlibrary(NMF)\n\n# Calculate NMF\nset.seed(3221)\nres &lt;- getNMF(altExp(tse, \"prevalent\"), k = 4)\n\n# Obtain the relative abundance of ES in each sample\nwrel &lt;- t(apply(res, 1, function (x) {x/sum(x)}))\n\n# Define the community type of a sample with the highest relative abundance\naltExp(tse, \"prevalent\")$NMFcomponent &lt;- as.factor(apply(wrel, 1, which.max))\ntable(altExp(tse, \"prevalent\")$NMFcomponent)\n##  \n##   1  2  3  4 \n##  11 14 28  5\n\nNow, we can plot the NMF community types calculated based on maximum membership for each sample onto a two-dimensional surface.\n\n# NMF community types\nplotReducedDim(\n    altExp(tse, \"prevalent\"), \"MDS\", colour_by = \"NMFcomponent\",\n    point_size = 3, theme_size = 13) +\n\n    labs(color = \"NMFcomponent\", title = \"NMF\") + theme_minimal()",
    "crumbs": [
      "Diversity & similarity",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Community typing</span>"
    ]
  },
  {
    "objectID": "pages/clustering.html#sec-clustered-heatmap",
    "href": "pages/clustering.html#sec-clustered-heatmap",
    "title": "15  Community typing",
    "section": "\n15.3 Heatmaps with clusters",
    "text": "15.3 Heatmaps with clusters\nIn Section 12.2, we visualized community composition with heatmaps. We can visualize the data similarly but add addition information on clusters.\n\nlibrary(ComplexHeatmap)\n\n# Agglomerate to Genus level\ntse &lt;- agglomerateByPrevalence(tse, rank = \"genus\")\n\n# Apply clr and scale data\ntse &lt;- transformAssay(tse, method = \"clr\", pseudocount = TRUE)\ntse &lt;-  transformAssay(\n    tse, assay.type = \"clr\", method = \"standardize\", MARGIN = \"rows\")\n# Gets the assay table\nmat &lt;- assay(tse, \"standardize\")\n\nNow we can cluster rows.\n\nlibrary(ape)\nlibrary(ggtree)\n\n# Hierarchical clustering\ntse &lt;- addCluster(\n    tse, assay.type = \"standardize\", HclustParam(method = \"complete\"),\n    full = TRUE)\ntaxa_hclust &lt;- metadata(tse)[[\"clusters\"]][[\"hclust\"]]\n# Creates a phylogenetic tree\ntaxa_tree &lt;- as.phylo(taxa_hclust)\nggtree(taxa_tree)\n\n\n\n\n\n\n\nBased on the phylo tree, we decide to create eight clusters.\n\n# Hierarchical clustering with k = 3\ntse &lt;- addCluster(\n    tse, assay.type = \"standardize\",\n    HclustParam(method = \"complete\", cut.fun = cutree, k = 8))\n\nFor columns, we can utilize k-means clustering. First we have to specify the number of clusters.\n\nlibrary(factoextra)\nlibrary(NbClust)\nlibrary(patchwork)\n\n# Elbow method\np1 &lt;- fviz_nbclust(assay(tse, \"standardize\"), kmeans, method = \"wss\")\n# Silhouette method\np2 &lt;- fviz_nbclust(assay(tse, \"standardize\"), kmeans, method = \"silhouette\")\n\np1 + p2\n\n\n\n\n\n\n\nBased on the results, we split the columns into six clusters.\n\n# Hierarchical clustering with k = 4\ntse &lt;- addCluster(\n    tse, assay.type = \"standardize\", by = \"cols\",\n    KmeansParam(centers = 6))\n\n# Prints samples and their clusters\ncolData(tse)[[\"clusters\"]]\n##   ID1  ID2  ID3  ID4  ID5  ID6  ID7  ID8  ID9 ID10 ID11 ID12 ID13 ID14 ID15 \n##     6    1    2    3    2    3    1    1    1    2    1    5    5    1    2 \n##  ID16 ID17 ID18 ID19 ID20 ID21 ID22 ID23 ID24 ID25 ID26 ID27 ID28 ID29 ID30 \n##     6    1    1    6    1    6    2    2    1    6    1    2    2    2    2 \n##  ID31 ID32 ID33 ID34 ID35 ID36 ID37 ID38 ID39 ID40 ID41 ID42 ID43 ID44 ID45 \n##     3    5    5    5    5    5    5    4    4    4    2    1    3    6    2 \n##  ID46 ID47 ID48 ID49 ID50 ID51 ID52 ID53 ID54 ID55 ID56 ID57 ID58 \n##     6    4    6    3    3    6    2    6    1    4    3    2    3 \n##  Levels: 1 2 3 4 5 6\n\nNow we can create a heatmap with additional annotations.\n\n# Order the data based on clusters\ntse &lt;- tse[\n    order(rowData(tse)[[\"clusters\"]]),\n    order(colData(tse)[[\"clusters\"]])]\n# Get data for plotting\nmat &lt;- assay(tse, \"standardize\")\ntaxa_clusters &lt;- rowData(tse)[, \"clusters\", drop = FALSE] |&gt;\n  as.data.frame()\nsample_data &lt;- colData(tse)[, c(\"clusters\", \"Gender\"), drop = FALSE] |&gt;\n  as.data.frame()\ncolnames(sample_data) &lt;- c(\"clusters_col\", \"gender\")\n\n# Determines the scaling of colors\n# Scale colors\nbreaks &lt;- seq(\n    -ceiling(max(abs(mat))), ceiling(max(abs(mat))),\n    length.out = ifelse( max(abs(mat))&gt;5, 2*ceiling(max(abs(mat))), 10 ) )\ncolors &lt;- colorRampPalette(c(\"darkblue\", \"blue\", \"white\", \"red\", \"darkred\"))(length(breaks)-1)\n\npheatmap(\n    mat, annotation_row = taxa_clusters,\n    annotation_col = sample_data,\n    cluster_cols = FALSE, cluster_rows = FALSE,\n    breaks = breaks,\n    color = colors)\n\n\n\n\n\n\n\n\n\n\n\n\n\nAdditional Community Typing\n\n\n\nFor more community typing techniques applied to the ‘SprockettTHData’ data set, see the attached .Rmd file.\nLink:\n\nRmd",
    "crumbs": [
      "Diversity & similarity",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Community typing</span>"
    ]
  },
  {
    "objectID": "pages/differential_abundance.html",
    "href": "pages/differential_abundance.html",
    "title": "16  Differential abundance",
    "section": "",
    "text": "16.1 Statistical challenges of microbiome data\nAs discussed in Section 10.1, data display unique properties that are exclusively addressed by DAA tools developed for microbiome analysis.\nWe recommend to have a look at Nearing et al. (2022). In this study, multiple DAA methods were applied to 38 different datasets and their results were compared to one another. The study highlighted that different methods might yield varying results due to differing assumptions and normalization techniques. Interestingly, Pelto et al. (2024) concluded that elementary DAA methods achieve the highest consistency.\nRecently, Yang and Chen (2022) comprehensively evaluated DAA methods via a semi-parametric framework and 106 real datasets, concluding that different methods can produce contradictory results, creating the risk of cherry-picking the most favorable options for one’s own hypothesis. Therefore, it is highly recommended to perform DAA with multiple methods to verify if the findings are consistent across different approaches.\nBuilt on the findings of Calgaro et al. (2020), the benchdamic (Calgaro et al. 2022) package could offer a valuable support in this regard through a comprehensive evaluation process. It serves both practitioners by comparing DA methods from existing literature, and method developers by providing an impartial tool to evaluate their new approaches in comparison to what is already available. For more details, refer to its extensive vignette.",
    "crumbs": [
      "Association",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Differential abundance</span>"
    ]
  },
  {
    "objectID": "pages/differential_abundance.html#statistical-challenges-of-microbiome-data",
    "href": "pages/differential_abundance.html#statistical-challenges-of-microbiome-data",
    "title": "16  Differential abundance",
    "section": "",
    "text": "Pelto, Juho, Kari Auranen, Janne Kujala, and Leo Lahti. 2024. “Elementary Methods Provide More Replicable Results in Microbial Differential Abundance Analysis.” https://arxiv.org/abs/2404.02691.\n\n\n\nCalgaro, Matteo, Chiara Romualdi, Levi Waldron, Davide Risso, and Nicola Vitulo. 2020. “Assessment of Statistical Methods from Single Cell, Bulk RNA-Seq, and Metagenomics Applied to Microbiome Data.” Genome Biology 21 (1): 191. https://doi.org/10.1186/s13059-020-02104-1.\n\nCalgaro, Matteo, Chiara Romualdi, Davide Risso, and Nicola Vitulo. 2022. “Benchdamic: Benchmarking of Differential Abundance Methods for Microbiome Data.” Bioinformatics 39 (1). https://doi.org/10.1093/bioinformatics/btac778.\n\n16.1.0.1 Approaches to Handle Zero-Inflated Data :\nThe first approach to target zero-inflated data consists of specialized models, such as over-dispersed count models and zero-inflated mixture models. DESeq2, edgeR and corncorb are based on over-dispersed count models, whereas metagenomeSeq, RAIDA, ZIBB and Omnibus implement zero-inflated mixture models to address zero-inflation. Typically, these models assume a negative binomial, beta-binomial or normal/log-normal distribution.\nAnother approach to deal with zero-inflated data is zero imputation where zeross are replaced with estimated values. ALDEx2 and eBay apply a Bayesian model to impute the zeros when working with proportion data, accounting for sampling variability and sequencing depth variation. Other methods, such as MaAsLin2 and ANCOMBC impute the zeros with a pseudo-count strategy.\n\n16.1.0.2 Approaches to handle Compositional Data :\nTo address the compositionality of microbiome data, several approaches have been developed to perform robust normalization with methods specifically designed to reduce the bias found in compositional data. Some examples include :\n\nTrimmed mean of M-values (TMM) normalization used by edgeR.\nRelative log expression (RLE) normalization used by DESeq2.\nCumulative sum scaling (CSS) normalization used by metagenomeSeq.\nCentered log-ratio transformation (CLR) normalization used by ALDEx2.\nGeometric mean of pairwise ratios (GMPR) normalization used by Omnibus and Wrench normalization (Kumar et al. 2018), which corrects the compositional bias by an empirical Bayes approach.\n\n\nKumar, M. Senthil, V. Eric Slud, Kwame Okrah, C. Stephanie Hicks, Sridhar Hannenhalli, and Corrada Héctor Bravo. 2018. “Analysis and Correction of Compositional Bias in Sparse Sequencing Count Data.” BMC Genomics 19 (November). https://doi.org/10.1186/s12864-018-5160-5.\nOther methods to deal with compositional data entail reference taxa approach used by DACOMP and RAIDA, analyzing the pattern of pairwise log ratios as done by ANCOM and bias-correction applied by ANCOMBC.",
    "crumbs": [
      "Association",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Differential abundance</span>"
    ]
  },
  {
    "objectID": "pages/differential_abundance.html#using-the-tools",
    "href": "pages/differential_abundance.html#using-the-tools",
    "title": "16  Differential abundance",
    "section": "\n16.2 Using the tools",
    "text": "16.2 Using the tools\nIn this section we demonstrate the use of four methods that can be recommended based on recent literature (ANCOM-BC (Lin and Peddada 2020), ALDEx2 (Gloor, Macklaim, and Fernandes 2016), Maaslin2 (Mallick, Rahnavard, and McIver 2020), LinDA (H. Zhou et al. 2022) and ZicoSeq (Yang and Chen 2022)).\nThe purpose of this section is to show how to perform DAA in R, not how to correctly do causal inference. Depending on your experimental setup and your theory, you must determine how to specify any model exactly. E.g., there might be confounding factors that might drive (the absence of) differences between the shown groups that we ignore here for simplicity. Or your dataset is repeated sampling design, matched-pair design or the general longitudinal design. We will demonstrate how to include covariates in those models. We picked a dataset that merely has microbial abundances in a TSE object as well as a grouping variable in the sample data. We simplify the examples by only including two of the three groups.\n\nlibrary(mia)\nlibrary(knitr)\n\n# Import dataset\ndata(\"Tengeler2020\", package = \"mia\")\ntse &lt;- Tengeler2020\n\n# Show patient status by cohort\ntable(tse$patient_status, tse$cohort) |&gt;\n  kable()\n\n\n\n\nCohort_1\nCohort_2\nCohort_3\n\n\n\nADHD\n4\n5\n4\n\n\nControl\n6\n5\n3\n\n\n\n\n\n\n16.2.1 Preparing the data for DAA\nBefore starting the analysis, it is recommended to reduce the size and complexity of the data to make the results more reproducible. For this purpose, we agglomerate the features by genus and filter them by a prevalence threshold of 10%.\n\n# Agglomerate by genus and subset by prevalence\ntse &lt;- subsetByPrevalent(tse, rank = \"Genus\", prevalence = 10/100)\n\n# Transform count assay to relative abundances\ntse &lt;- transformAssay(tse, assay.type = \"counts\", method = \"relabundance\")\n\nWhile some DAA tools provide optional arguments for prevalence filtering, here we filtered the tse object directly. This way, we ensure that the input data remains the same when multiple tools are used.\n\n16.2.2 ALDEx2\nIn this section, we will show how to perform DAA with ALDEx2, which can be regarded as the method of choice for its consistency, as it normally identifies features that are also found by complementary methods (Nearing et al. 2022). A more extensive introduction to its functionality is available in the ALDEx2 vignette.\nALDEx2 estimates technical variation within each sample per taxon by utilizing the Dirichlet distribution. It furthermore applies the CLR transformation (or closely related log-ratio transforms). Depending on the experimental setup, it will perform a two sample Welch’s t-test and Wilcoxon test or a one-way ANOVA and Kruskal-Wallis test. For more complex study designs, there is a possibility to utilize the glm functionality within ALDEx2. The Benjamini-Hochberg procedure is applied by default to correct for multiple testing.\n\n# Load package\nlibrary(ALDEx2)\n\n# Generate Monte Carlo samples of the Dirichlet distribution for each sample.\n# Convert each instance using the centered log-ratio transform.\n# This is the input for all further analyses.\nset.seed(123)\nx &lt;- aldex.clr(assay(tse), tse$patient_status)\n\nThe t-test:\n\n# calculates expected values of the Welch's t-test and Wilcoxon rank\n# test on the data returned by aldex.clr\nx_tt &lt;- aldex.ttest(x, paired.test = FALSE, verbose = FALSE)\n\nEffect sizes:\n\n# Determines the median clr abundance of the feature in all samples and in\n# groups, the median difference between the two groups, the median variation\n# within each group and the effect size, which is the median of the ratio\n# of the between group difference and the larger of the variance within groups\nx_effect &lt;- aldex.effect(x, CI = TRUE, verbose = FALSE)\n\n# combine all outputs\naldex_out &lt;- data.frame(x_tt, x_effect)\n\nNow, we can create a so called Bland-Altman or MA plot (left). It shows the association between the relative abundance and the magnitude of the difference per sample. Next to that, we can also create a plot that shows the dispersion on the x-axis instead of log-ratio abundance. Red dots represent genera that are differentially abundant (\\(q \\leq 0.1\\)) between the 2 groups. Black points are rare taxa and grey ones are abundant taxa. The dashed line represent an effect size of 1. Gloor, Macklaim, and Fernandes (2016) provides more information on these plots.\n\npar(mfrow = c(1, 2))\n\naldex.plot(\n    aldex_out,\n    type = \"MA\",\n    test = \"welch\",\n    xlab = \"Log-ratio abundance\",\n    ylab = \"Difference\",\n    cutoff = 0.05)\n\naldex.plot(\n    aldex_out,\n    type = \"MW\",\n    test = \"welch\",\n    xlab = \"Dispersion\",\n    ylab = \"Difference\",\n    cutoff = 0.05)\n\n\n\n\n\n\n\nThe evaluation as differential abundant in above plots is based on the corrected p-value. According to the ALDEx2 developers, the safest approach is to identify those features where the 95% CI of the effect size does not cross 0. As we can see in below table, this is not the case for any of the identified genera (see overlap column, which indicates the proportion of overlap). Also, the authors recommend to focus on effect sizes and CIs rather than interpreting the p-value. To keep the comparison simple, we will here use the p-value as decision criterion. But please be aware that the effect size together with the CI is a better answer to the question we are typically interested in.\n\nlibrary(tidyverse)\n\naldex_out |&gt;\n  rownames_to_column(var = \"Genus\") |&gt;\n  # here we choose the wilcoxon output rather than t-test output\n  filter(wi.eBH &lt;= 0.05)  |&gt;\n  dplyr::select(Genus, we.eBH, wi.eBH, effect, overlap) |&gt;\n  kable()\n\n\n\nGenus\nwe.eBH\nwi.eBH\neffect\noverlap\n\n\n[Ruminococcus]_gauvreauii_group\n0.1082\n0.0355\n0.8719\n0.1321\n\n\n\n\n\n16.2.3 ANCOM-BC\nThe analysis of composition of microbiomes with bias correction (ANCOM-BC) (Lin and Peddada 2020) is a recently developed method for differential abundance testing. It is based on an earlier published approach (Mandal et al. 2015). The previous version of ANCOM was among the methods that produced the most consistent results and is probably a conservative approach (Nearing et al. 2022). However, the new ANCOM-BC method operates quite differently compared to the former ANCOM method.\n\nNearing, Jacob T., Gavin M. Douglas, Molly G. Hayes, Jocelyn MacDonald, Dhwani K. Desai, Nicole Allward, Casey M. A. Jones, et al. 2022. “Microbiome Differential Abundance Methods Produce Different Results Across 38 Datasets.” Nature Communications 13 (1): 342. https://doi.org/10.1038/s41467-022-28034-z.\nAs the only method, ANCOM-BC incorporates the so called sampling fraction into the model. The latter term could be empirically estimated by the ratio of the library size to the microbial load. According to the authors, ignoring variations in this sampling fraction would bias DAA results. Furthermore, this method provides p-values and confidence intervals for each taxon. It also controls the FDR and it is computationally simple to implement.\nNote that the original method was implemented in the ancombc() function (see extended tutorial). The method has since then been updated and new features have been added to enable multi-group comparisons and repeated measurements among other improvements. We do not cover the more advanced features of ANCOMBC in this tutorial as these features are documented in detail in this tutorial.\nWe now proceed with a simple example. First, we specify a formula. In this formula, other covariates could potentially be included to adjust for confounding. We show this further below. Again, please make sure to check the function documentation as well as the linked tutorials to learn about the additional arguments that we specify.\n\n# Load package\nlibrary(ANCOMBC)\n\n# Run ANCOM-BC at the genus level and only including the prevalent genera\nancombc2_out &lt;- ancombc2(\n    data = tse,\n    assay.type = \"counts\",\n    fix_formula = \"patient_status\",\n    p_adj_method = \"fdr\",\n    prv_cut = 0,\n    group = \"patient_status\",\n    struc_zero = TRUE,\n    neg_lb = TRUE,\n    # multi group comparison is deactivated automatically\n    global = TRUE)\n\nThe object out contains all model output. Again, see the documentation of the function under Value for details. Our question whether taxa are differentially abundant can be answered by looking at the res object, which contains dataframes with the coefficients, standard errors, p-values and q-values. Below we show the first entries of this dataframe.\n\n# store the FDR adjusted results\nancombc2_out$res |&gt;\n  dplyr::select(taxon, lfc_patient_statusControl, q_patient_statusControl) |&gt;\n  filter(q_patient_statusControl &lt; 0.05) |&gt;\n  arrange(q_patient_statusControl) |&gt;\n  head() |&gt;\n  kable()\n\n\n\n\n\n\n\n\ntaxon\nlfc_patient_statusControl\nq_patient_statusControl\n\n\n\nCoprobacter\n-1.785\n0.0033\n\n\nRuminococcus_1\n2.238\n0.0115\n\n\nuncultured_bacterium\n-1.439\n0.0250\n\n\nSubdoligranulum\n1.226\n0.0472\n\n\n\n\n\n\n16.2.4 MaAsLin2\nLet us next illustrate MaAsLin2 (Mallick, Rahnavard, and McIver 2020). This method is based on generalized linear models and flexible for different study designs and covariate structures. For details, check their Biobakery tutorial.\n\n# Load package\nlibrary(Maaslin2)\n\n# maaslin expects features as columns and samples as rows\n# for both the abundance table as well as metadata\n\n# We can specify different GLMs/normalizations/transforms.\n# specifying a ref is especially important if you have more than 2 levels\nmaaslin2_out &lt;- Maaslin2(\n    input_data = as.data.frame(t(assay(tse))),\n    input_metadata = as.data.frame(colData(tse)),\n    output = \"DAA example\",\n    transform = \"AST\",\n    fixed_effects = \"patient_status\",\n    # you can also fit MLM by specifying random effects\n    # random_effects = c(...),\n    reference = \"patient_status,Control\",\n    normalization = \"TSS\",\n    standardize = FALSE,\n    # filtering was previously performed\n    min_prevalence = 0)\n\nWhich genera are identified as differentially abundant? (leave out “head” to see all).\n\nmaaslin2_out$results |&gt;\n  filter(qval &lt; 0.05) |&gt;\n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nfeature\nmetadata\nvalue\ncoef\nstderr\npval\nname\nqval\nN\nN.not.zero\n\n\n\nX.Ruminococcus._gauvreauii_group\npatient_status\nADHD\n-0.0674\n0.0133\n0.0000\npatient_statusADHD\n0.0015\n27\n21\n\n\nCatabacter\npatient_status\nADHD\n0.0295\n0.0092\n0.0037\npatient_statusADHD\n0.0448\n27\n9\n\n\nFaecalibacterium\npatient_status\nADHD\n0.1223\n0.0372\n0.0030\npatient_statusADHD\n0.0448\n27\n11\n\n\nX.Clostridium._innocuum_group\npatient_status\nADHD\n-0.0692\n0.0213\n0.0033\npatient_statusADHD\n0.0448\n27\n25\n\n\n\n\n\nThis will create a folder that is called like in the output specified above. It contains also figures to visualize difference between significant taxa.\n\n16.2.5 PhILR\nPhILR is a tree-based method that tests group-wise associations based on balances. A detailed introduction to this method is available in this Bioconductor tutorial.\n\n16.2.6 Comparison of methods\nAlthough the methods described above yield unidentical results, they are expected to agree on a few differentially abundant taxa. To draw more informed conclusions, it is good practice to compare the outcomes of different methods in terms of found features, their effect sizes and significances, as well as other method-specific aspects. Such comparative approach is outlined in this exercise.",
    "crumbs": [
      "Association",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Differential abundance</span>"
    ]
  },
  {
    "objectID": "pages/differential_abundance.html#daa-with-confounding",
    "href": "pages/differential_abundance.html#daa-with-confounding",
    "title": "16  Differential abundance",
    "section": "\n16.3 DAA with confounding",
    "text": "16.3 DAA with confounding\nConfounders can be defined as variables that are related to and affect the apparent dynamics between the response and the main independent variable. They are common in experimental studies. Generally, they can be classified into three groups:\n\nBiological confounders, such as age and sex\nTechnical confounders produced during sample collection, processing and analysis\nConfounders resulting from experimental models, such as batch effects and sample history\n\nControlling for confounders is an important practice to reach an unbiased conclusion. To perform causal inference, it is crucial that the method is able to include confounders in the model. This is not possible with statistical tests of general use, such as the Wilcoxon test. In contrast, methods that target DAA, such as those described in this chapter, allow controlling for confounders. In the following examples, we will perform DAA with a main independent variable and a few confounders.\n\n16.3.1 Selecting confounders\nIn addition to patient status, we will now control for two confounders: cohort and library size. The former is a categorical variable with three factors, whereas the latter is a discrete numerical variable. Remarkably, most DAA methods accept these two and several other data types.\nFor demonstration, library size is treated as a confounder and included in the formulas of the DAA methods. Although this is a satisfactory approach to control for uneven sequencing efforts across samples, rarefaction generally represents a better solution (Schloss 2023). With that said, library size can be readily computed and added to the colData.\n\nSchloss, Patrick D. 2023. “Rarefaction Is Currently the Best Approach to Control for Uneven Sequencing Effort in Amplicon Sequence Analyses.” bioRxiv, 2023–06. https://doi.org/10.1101/2023.06.23.546313.\n\n# Compute and store library size in colData\ncolData(tse)$library_size &lt;- colSums(assay(tse, \"counts\"))\n\n\n16.3.2 ANCOM-BC\nHere, confounders can be added to the formula along with patient status, the main outcome variable. This way, the model evaluates whether differentially abundant taxa are associated with one of the variables when the other two are kept constant.\n\n# perform the analysis\nancombc2_out &lt;- ancombc2(\n    tse,\n    assay.type = \"counts\",\n    fix_formula = \"patient_status + cohort + library_size\",\n    p_adj_method = \"fdr\",\n    lib_cut = 0,\n    group = \"patient_status\",\n    struc_zero = TRUE,\n    neg_lb = TRUE,\n    alpha = 0.05,\n    # multi-group comparison is deactivated automatically\n    global = TRUE)\n\nIn the output, each taxon is assigned with several effect sizes (lfc, which stands for log-fold change) and adjusted p-values (q). For categorica variables such as patient status and cohort, the statistics indicate whether the abundance of a given taxon is significantly different between the specified group (column name) and the reference group (the group that does not appear in the column names), whereas for numerical variables such as library size, they indicate whether the abundance of a given taxon varies with that variable.\n\nancombc2_out$res |&gt;\n  dplyr::select(starts_with(c(\"taxon\", \"lfc\", \"q\"))) |&gt;\n  arrange(q_patient_statusControl) |&gt;\n  head() |&gt;\n  kable()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ntaxon\nlfc_(Intercept)\nlfc_patient_statusControl\nlfc_cohortCohort_2\nlfc_cohortCohort_3\nlfc_library_size\nq_(Intercept)\nq_patient_statusControl\nq_cohortCohort_2\nq_cohortCohort_3\nq_library_size\n\n\n\nHungatella\n-0.0891\n-0.4026\n-0.1234\n-0.1142\n0\n0\n0\n0\n0\n0.6142\n\n\nRuminococcaceae_UCG-013\n-0.9540\n-0.4127\n0.6761\n-0.0223\n0\n0\n0\n0\n0\n0.0003\n\n\nBacteroides\n-0.3276\n-0.8330\n0.1644\n0.7621\n0\n0\n0\n0\n0\n0.3779\n\n\nAkkermansia\n-0.8795\n0.1553\n0.3039\n0.4643\n0\n0\n0\n0\n0\n0.0771\n\n\nEscherichia-Shigella\n-1.1800\n-0.5911\n1.3255\n0.2350\n0\n0\n0\n0\n0\n0.0054\n\n\nAlistipes\n0.0654\n-0.1158\n-0.4058\n0.0132\n0\n0\n0\n0\n0\n0.0084",
    "crumbs": [
      "Association",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Differential abundance</span>"
    ]
  },
  {
    "objectID": "pages/differential_abundance.html#further-information-on-tools-for-daa",
    "href": "pages/differential_abundance.html#further-information-on-tools-for-daa",
    "title": "16  Differential abundance",
    "section": "\n16.4 Further information on tools for DAA :",
    "text": "16.4 Further information on tools for DAA :\n\n16.4.0.1 LinDA\nLinDA covers linear models for differential abundance analysis of microbiome compositional data (H. Zhou et al. (2022)). This is very similar to ANCOMBC with few differences:\n\nLinDA corrects for the compositional bias differently using the mode of all regression coefficients.\nIt is faster (100x-1000x than ANCOMBC and according to the authors);\nIt supports hierarchical models. The latest ANCOMBC versions are also supporting hierarchical models.\n\nNevertheless, LinDA seems a promising tool that achieves a very good power/fdr trade-off together with ANCOMBC according to the review. The speed improvements might make it critical especially for datasets that have higher sample or feature set sizes.\n\n16.4.0.2 ZicoSeq\nSubsequently, we demonstrate DAA with ZicoSeq, a method based on linear models and permutation. Further details can be found in this tutorial. This approach has been assessed to exhibit high power and a low false discovery rate, which has the following components:\n\nWinsorization to decrease the influence of outliers;\nPosterior sampling based on a beta mixture prior to address sampling variability and zero inflation;\nReference-based multiple-stage normalization to address compositional effects;Additional resources\n\n\n\n\n\n\n\nAdditional resources\n\n\n\nDAA can be performed by several means. Although most of them provide similar functionality, some may be more suitable than others given a certain study design or data type. Commonly used DAA tools include:\n\nALDEx2 (Gloor, Macklaim, and Fernandes 2016)\n\nANCOM (Mandal et al. 2015)\n\nANCOMBC (Lin and Peddada 2020)\n\ncorncob (Martin, Witten, and Willis 2021)\n\nDACOMP (Brill, Amnon, and Ruth 2022)\n\nDESeq2 (Love, Huber, and Anders 2014)\n\neBay (Liu, Zhao, and Wang 2020)\n\nedgeR (Y. Chen, Lun, and Smyth 2016)\n\nfastANCOM (C. Zhou et al. 2022)\n\nLDM (Hu and Satten 2020)\n\nlefser (Khleborodova 2021)\n\nlimma (Ritchie et al. 2015)\n\nLinDA (H. Zhou et al. 2022)\n\nMaAsLin2 (Mallick, Rahnavard, and McIver 2020)\n\nmetagenomeSeq (Paulson, Talukder, and Bravo 2017)\n\nOmnibus (J. Chen et al. 2018)\n\nRAIDA (Sohn, Du, and An 2015)\n\nt-test\nWilcoxon test\nZicoSeq (Yang and Chen 2022)\n\nZINQ (Ling et al. 2021)\n\nBIRDMAn (Rahman et al. 2023)\n\n\n\n\n\n\n\nRahman, Gibraan, James T. Morton, Cameron Martino, Gregory D. Sepich-Poore, Celeste Allaband, Caitlin Guccione, Yang Chen, Daniel Hakim, Mehrbod Estaki, and Rob Knight. 2023. “BIRDMAn: A Bayesian Differential Abundance Framework That Enables Robust Inference of Host-Microbe Associations.” bioRxiv. https://doi.org/10.1101/2023.01.30.526328.\n\nLing, Wodan, Zhao Ni, M. Plantinga Anna, J. Launer Lenore, A. Fodor Anthony, A. Meyer Katie, and C. Wu Michael. 2021. “Powerful and Robust Non-Parametric Association Testing for Microbiome Data via a Zero-Inflated Quantile Approach (ZINQ).” Microbiome 181 (September). https://doi.org/10.1186/s40168-021-01129-3.\n\nYang, Lu, and Jun Chen. 2022. “A Comprehensive Evaluation of Microbial Differential Abundance Analysis Methods: Current Status and Potential Solutions.” Microbiome 10 (130): 2049–2618. https://doi.org/10.1186/s40168-022-01320-0.\n\nSohn, Michael B., Ruofei Du, and Lingling An. 2015. “A Robust Approach for Identifying Differentially Abundant Features in Metagenomic Samples.” Bioinformatics 31 (July). https://doi.org/10.1093/bioinformatics/btv165.\n\nChen, Jun, Emily King, Rebecca Deek, Zhi Wei, Yue Yu, Diane Grill, and Karla Ballman. 2018. “An Omnibus Test for Differential Distribution Analysis of Microbiome Sequencing Data.” Bioinformatics 34 (February).\n\nPaulson, JN, H Talukder, and HC Bravo. 2017. “Longitudinal Differential Abundance Analysis of Marker-Gene Surveys Using Smoothing Splines.” Biorxiv. https://doi.org/10.1101/099457.\n\nMallick, Himel, Ali Rahnavard, and Lauren J. McIver. 2020. MaAsLin 2: Multivariable Association in Population-Scale Meta-Omics Studies. http://huttenhower.sph.harvard.edu/maaslin2.\n\nZhou, Huijuan, Kejun He, Jun Chen, and Xianyang Zhang. 2022. “LinDA: Linear Models for Differential Abundance Analysis of Microbiome Compositional Data.” Genome Biology 23 (1): 95. https://doi.org/10.1186/s13059-022-02655-5.\n\nRitchie, Matthew E, Belinda Phipson, Di Wu, Yifang Hu, Charity W Law, Wei Shi, and Gordon K Smyth. 2015. “limma Powers Differential Expression Analyses for RNA-Sequencing and Microarray Studies.” Nucleic Acids Research 43 (7): e47. https://doi.org/10.1093/nar/gkv007.\n\nKhleborodova, Asya. 2021. Lefser: R Implementation of the LEfSE Method for Microbiome Biomarker Discovery. https://github.com/waldronlab/lefser.\n\nHu, Yijuan, and Glen A Satten. 2020. “Testing Hypotheses about the Microbiome Using the Linear Decomposition Model (LDM).” Bioinformatics 36 (July): 4106--4115.\n\nZhou, Chao, Huimin Wang, Hongyu Zhao, and Tao Wang. 2022. “fastANCOM: A Fast Method for Analysis of Compositions of Microbiomes.” Bioinformatics 38 (March): 2039–41.\n\nChen, Yunshun, Aaron TL Lun, and Gordon K Smyth. 2016. “From Reads to Genes to Pathways: Differential Expression Analysis of RNA-Seq Experiments Using Rsubread and the edgeR Quasi-Likelihood Pipeline.” F1000Research 5: 1438. https://doi.org/10.12688/f1000research.8987.2.\n\nLiu, Tiantian, Hongyu Zhao, and Tao Wang. 2020. “An Empirical Bayes Approach to Normalization and Differential Abundance Testing for Microbiome Data.” BMC Bioinformatics 21 (June). https://doi.org/10.1186/s12859-020-03552-z.\n\nLove, Michael I., Wolfgang Huber, and Simon Anders. 2014. “Moderated Estimation of Fold Change and Dispersion for RNA-Seq Data with DESeq2.” Genome Biology 15: 550. https://doi.org/10.1186/s13059-014-0550-8.\n\nBrill, Barak, Amir Amnon, and Heller Ruth. 2022. “Testing for Differential Abundance in Compositional Counts Data, with Application to Microbiome Studies.” The Annals of Applied Statistics 16 (December).\n\nMartin, Bryan D, Daniela Witten, and Amy D Willis. 2021. Corncob: Count Regression for Correlated Observations with the Beta-Binomial. https://CRAN.R-project.org/package=corncob.\n\nLin, Huang, and Shyamal Das Peddada. 2020. “Analysis of Compositions of Microbiomes with Bias Correction.” Nature Communications 11 (1): 1–11. https://doi.org/https://doi.org/10.1038/s41467-020-17041-7.\n\nMandal, Siddhartha, Will Van Treuren, Richard A. White, Merete Eggesbø, Rob Knight, and Shyamal D. Peddada. 2015. “Analysis of Composition of Microbiomes: A Novel Method for Studying Microbial Composition.” Microbial Ecology in Health & Disease 26 (0). https://doi.org/10.3402/mehd.v26.27663.\n\nGloor, Gregory B., Jean M. Macklaim, and Andrew D. Fernandes. 2016. “Displaying Variation in Large Datasets: Plotting a Visual Summary of Effect Sizes.” Journal of Computational and Graphical Statistics 25 (3): 971–79. https://doi.org/10.1080/10618600.2015.1131161.",
    "crumbs": [
      "Association",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Differential abundance</span>"
    ]
  },
  {
    "objectID": "pages/correlation.html",
    "href": "pages/correlation.html",
    "title": "17  Correlation",
    "section": "",
    "text": "17.1 Association between taxa\nHere we demonstrate, how to analyse which bacteria co-exists in the dataset.\nlibrary(mia)\n\ndata(\"peerj13075\")\ntse &lt;- peerj13075\n\n# Agglomerate to certain taxonomy level\ntse &lt;- agglomerateByPrevalence(tse, rank = \"class\")\n\n# Apply clr-transform and scale\ntse &lt;- transformAssay(tse, method = \"clr\", pseudocount = TRUE)\ntse &lt;- transformAssay(\n    tse, assay.type = \"clr\", method = \"standardize\", MARGIN = \"rows\")\n\n# Get correlation results\nres &lt;- getCrossAssociation(\n    tse, tse, assay.type1 = \"clr\", assay.type2 = \"clr\",\n    test.signif = TRUE, mode = \"matrix\")\nWe can visualize the result with heatmap as we do later in this chapter, or we can visualize the results with correlation network plot as done below.\nlibrary(qgraph)\n\n# Create correlation network plot\nqgraph(\n    res$cor, layout = \"spring\", labels = colnames(res$cor),\n    label.cex = 1.2, theme = \"colorblind\",\n    node.width = 1.5, node.height = 2)\nYou can find more on networks from Chapter 18.",
    "crumbs": [
      "Association",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "pages/correlation.html#association-between-taxa-and-sample-metadata",
    "href": "pages/correlation.html#association-between-taxa-and-sample-metadata",
    "title": "17  Correlation",
    "section": "\n17.2 Association between taxa and sample metadata",
    "text": "17.2 Association between taxa and sample metadata\nNow, we can calculate alpha diversity indices, and evaluate if they have significant association with taxa.\n\n# Calculate diversity measures\nindex &lt;- c(\n    \"shannon\", \"log_modulo_skewness\", \"coverage\", \"inverse_simpson\", \"gini\")\ntse &lt;- addAlpha(tse, index = index)\n\n# Get correlation results\nres &lt;- getCrossAssociation(\n    tse, tse, assay.type1 = \"clr\", col.var2 = index,\n    test.signif = TRUE, mode = \"matrix\")\n\nBelow, we present the results using a heatmap visualization.\n\nlibrary(ComplexHeatmap)\nlibrary(shadowtext)\n\n# Function for marking significant correlations with \"X\"\nadd_signif &lt;- function(j, i, x, y, width, height, fill) {\n    # If the p-value is under threshold\n    if( !is.na(res$p_adj[i, j]) & res$p_adj[i, j] &lt; 0.05 ){\n        # Print \"X\"\n        grid.shadowtext(\n            sprintf(\"%s\", \"X\"), x, y, gp = gpar(fontsize = 8, col = \"#f5f5f5\"))\n    }\n}\n\n# Create a heatmap\np &lt;- Heatmap(res$cor,\n    # Print values to cells\n    cell_fun = add_signif,\n    heatmap_legend_param = list(\n        title = \"correlation\", legend_height = unit(5, \"cm\")),\n    column_names_rot = 45\n    )\np",
    "crumbs": [
      "Association",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "pages/correlation.html#sec-alpha-correlation",
    "href": "pages/correlation.html#sec-alpha-correlation",
    "title": "17  Correlation",
    "section": "\n17.3 Association between sample metadata variables",
    "text": "17.3 Association between sample metadata variables\nFinally, we demonstrate how to calculate correlation between sample metadata variables. Here we estimate correlation between alpha diversity measures.\nCompared to the solution in Section 13.2, getCrossAssociation() allows us to calculate correlations in bulk easily, without the need for looping.\n\n# Get correlation results\nres &lt;- getCrossAssociation(\n    tse, tse, col.var1 = index, col.var2 = index,\n    test.signif = TRUE, mode = \"matrix\")\n\n# Create a heatmap and store it\np &lt;- Heatmap(res$cor,\n    # Print values to cells\n    cell_fun = add_signif,\n    heatmap_legend_param = list(\n        title = \"correlation\", legend_height = unit(5, \"cm\")),\n    column_names_rot = 45\n    )\np\n\n\n\n\n\n\n\n\n\n\n\n\n\nCross-association\n\n\n\nSee Section 20.1 for further information on correlation and association analyses.",
    "crumbs": [
      "Association",
      "<span class='chapter-number'>17</span>  <span class='chapter-title'>Correlation</span>"
    ]
  },
  {
    "objectID": "pages/network_learning.html",
    "href": "pages/network_learning.html",
    "title": "18  Network learning & analysis",
    "section": "",
    "text": "18.1 Network learning",
    "crumbs": [
      "Networks",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Network learning & analysis</span>"
    ]
  },
  {
    "objectID": "pages/network_learning.html#network-learning",
    "href": "pages/network_learning.html#network-learning",
    "title": "18  Network learning & analysis",
    "section": "",
    "text": "18.1.1 Typical workflow\nFigure 18.1 shows the workflow for learning/constructing a microbial association network as proposed by Peschel et al. (2021). The respective steps are explained below.\n\n\n\n\n\n\n\nFigure 18.1: The typical input is a \\(p\\) x \\(n\\) dimensional count matrix coming from a sequencing process, where \\(n\\) is the number of samples and \\(p\\) the number of features / ASVs / OTUs. Steps 1 through 6 are explained below. Each matrix resulting from steps 4, 5, and 6 plays a specific role in the final network: The adjacency matrix is used for edge colors, dissimilarity for layout, and similarity for edge weights. In weighted networks, the similarity matrix equals the adjacency matrix.\n\n\n\n\n\nZero replacement: Since the following steps usually require non-zero entries in the read count matrix, zero counts must be replaced. A simple solution is to add a pseudo count to the data. Other possible approaches are implemented in the R package zCompositions\nNormalization: To avoid compositional effects, the data are normalized using a compositionality aware transformation. A common approach is the centered log-ratio (clr) transformation, which moves the data from a \\(p\\)-dimensional simplex to Euclidean space so that standard statistical analysis methods are valid. A variance stabilizing transformation (vst) is also a suitable approach for normalizing microbial count data (Badri et al. 2020).\n\nAssociation estimation: This is the crucial step in network learning to obtain statistical relations between the taxa. Common association measures include correlation, conditional dependence (which we will equate to partial correlation), and proportionality. Further information on these three types of association and their application can be found in Section 18.6. The following list gives a selection of compositionality aware approaches:\n\n\nCompositionality aware correlation estimation methods:\n\nPearson’s correlation coefficient (+ normalization)\nSpearman’s rank correlation coefficient (+ normalization)\nCovariance shrinkage (corpcor package) (+ normalization)\nSparCC (implemented in SpiecEasi); applied in Section 18.7.1\n\nCCREPE (ccrepe package)\nCCLasso (R code on GitHub)\n\n\n\nCompositionality aware measures of conditional dependence / partial correlation:\n\n\nSpiecEasi with Meinshausen and Bühlmann (MB) neighborhood selection; applied in Section 18.7.3\n\n\nSpiecEasi with the graphical lasso (glasso)\ngCoda (R code on GitHub)\n\nSPRING; applied in Section 18.1.4\n\n\n\n\nProportionality measures (proportionality aware by definition):\n\npropr\n\nShrinkage proportionality estimator; applied in Section 18.7.2\n\n\n\n\n\nSparsification: Transforming the estimated associations directly into adjacencies would lead to a dense network where all nodes are connected and only weighted network measures are meaningful. Therefore, the association matrix is usually sparsified to select edges of interest. A common sparsification approach for correlations is thresholding, where correlations with a magnitude below the threshold are set to zero. Another possibility is a statistical test (Student’s t-test or permutation test) with the null hypothesis that the correlation is equal to zero. SpiecEasi uses the StARS stability selection approach (Liu, Roeder, and Wasserman 2010) to decide on an appropriate sparsification level of the inferred conditional dependence graph.\n\nTransformation into dissimilarity: A common next step is to simply use the absolute values of the sparsified associations as the edge weights. In this way, correlations of high magnitude (both positive and negative) will have a high edge weight. From a biological point of view, it would also make sense to assign a low edge weight to taxa that are strongly negatively associated, which would correspond to a high dissimilarity value. Here we follow Dongen and Enright (2012) to directly transform the sparse associations \\(r_{ij}^*\\) into dissimilarities, which can later be used for shortest path network measures. Depending on the desired handling of negative associations, one of the two proposed transformations should be chosen:\n5a: “signed”: \\(d_{ij} = \\sqrt{0.5(1-r^*_{ij})}\\), where strongly negatively associated taxa have the largest distance and are placed further apart in the network.\n5b: “unsigned”: \\(d_{ij} = \\sqrt{1-{r_{ij}^*}^2}\\), resulting in a small distance between strongly associated taxa (regardless of the sign).\n\nTransformation into similarity / edge weight: Finally, the dissimilarities are transformed into similarities by \\(s_{ij} = 1 - d_{ij}\\), which are used as edge weights. Thus, the similarity matrix is equal to the adjacency matrix in a weighted network.\n\nThe main association measure used in this chapter is the SPRING (“Semi-Parametric Rank-based approach for INference in Graphical model”) method proposed by Yoon, Gaynanova, and Müller (2019). SPRING learns conditional dependency graphs for compositional data and follows the neighborhood selection method introduced by Meinshausen and Bühlmann (2006) (“MB”). We will show how to apply the method directly, as well as how to use it in conjunction with the R package NetCoMi, which is specifically designed for the construction and analysis of networks for microbiome data.\nSee Section 18.6 for a comparison of all three association types (correlation, partial correlation, and proportionality) with more information on each measure and applications.\nWe demonstrate the workflow using the the PeerJ data set (Potbhare et al. 2022). It contains skin microbial profiles of 58 subjects.\n\nPotbhare, Renuka, Ameeta RaviKumar, Eveliina Munukka, Leo Lahti, and Richa Ashma. 2022. “Skin Microbiota Diversity Among Genetically Unrelated Individuals of Indian Origin.” PeerJ 10: e13075. https://doi.org/10.7717/peerj.13075.\n\nlibrary(mia)\n\ndata(\"peerj13075\", package = \"mia\")\ntse &lt;- peerj13075\ndim(tse)\n##  [1] 674  58\n\n\n18.1.2 Install packages\nThree packages used in this chapter are available on GitHub only: SpiecEasi, SPRING, and NetCoMi. We recommend that you install these packages before proceeding.\n\nif(!require(SpiecEasi)){\n  devtools::install_github(\"zdk123/SpiecEasi\")\n}\n\nif(!require(SPRING)){\n  devtools::install_github(\"GraceYoon/SPRING\")\n}\n\nif(!require(NetCoMi)){\n  devtools::install_github(\n      \"stefpeschel/NetCoMi\", force = TRUE, ref = \"TSE\",\n       dependencies = c(\"Depends\", \"Imports\", \"LinkingTo\"),\n       repos = c(\"https://cloud.r-project.org/\", BiocManager::repositories()))\n}\n\n\n18.1.3 Data preparation\nBefore applying the network learning methods, we perform some data preparation steps:\n\nAggregation to genus level\nAdd relative abundance assay\nPrevalence filtering (keep genera with prevalence &gt; 20%)\nAdd assay with log10 transformed abundances\nAdd assay with clr transformed abundances\n\n\n# Agglomerate to genus level\ntse &lt;- agglomerateByRank(tse, rank = \"genus\")\n\n# Add relative abundances\ntse &lt;- transformAssay(\n    tse,\n    assay.type = \"counts\",\n    method = \"relabundance\",\n    MARGIN = \"cols\")\n\n# Filter by prevalence\ntse &lt;- subsetByPrevalent(\n    tse,\n    prevalence = 0.2,\n    detection = 0,\n    assay.type = \"relabundance\")\n\n# Add log10-transformed abundances\ntse &lt;- transformAssay(tse, method = \"log10\", pseudocount = 1)\n\n# Add clr-transformed abundances\ntse &lt;- transformAssay(tse, method = \"clr\", pseudocount = 1)\n\ndim(tse)\n##  [1] 147  58\n\n\n18.1.4 SPRING network\nAs explained in Section 18.1.1, we use SPRING (“Semi-Parametric Rank-based approach for INference in Graphical model”) as association measure. We first use the SPRING function directly to construct a conditional dependency graph.\nNeither zero replacement nor normalization (steps 1 and 2 in our workflow) are required because SPRING uses a modified clr (mclr) transformation that can handle zero counts, and the correlation estimation method itself can also deal with zeros in the data. mclr is similar to the clr transformation except that mclr considers only the non-zero values. More precisely, the geometric mean is derived from positive values only, and zero counts remain zero after the transformation. This approach is similar to the “robust clr” (rclr) transformation included in the vegan package, except that mclr applies a positive shift to all non-zero values to make them strictly positive. See (Yoon, Gaynanova, and Müller 2019) for details.\n\nYoon, Grace, Christian L Müller, and Irina Gaynanova. 2021. “Fast Computation of Latent Correlations.” Journal of Computational and Graphical Statistics 30 (4): 1249–56.\nThe Rmethod argument is set to “approx” to estimate the correlations using a hybrid multi-linear interpolation approach proposed by Yoon, Müller, and Gaynanova (2021). This method considerably reduces the runtime while controlling the approximation error.\nSPRING uses the StARS (“Stability Approach to Regularization Selection”) method (Liu, Roeder, and Wasserman 2010) to obtain a sparse association matrix. Thus, also step 4 of our workflow is already included. We set the StARS threshold to 0.05 to get a sparser graph.\n\nlibrary(SPRING)\n\n\nset.seed(13075)\nspring_est &lt;- SPRING(\n    t(assay(tse, \"counts\")),\n    Rmethod = \"approx\",\n    thresh = 0.05,\n    lambdaseq = \"data-specific\")\n\n\n# Get index of the optimal lambda selected by StARS\nopt.K &lt;- spring_est$output$stars$opt.index\n\n# Store partial correlation matrix belonging to the optimal lambda as matrix\nspring_cor &lt;- SpiecEasi::symBeta(as.matrix(spring_est$output$est$beta[[opt.K]]))\nspring_cor &lt;- as.matrix(spring_cor)\nrownames(spring_cor) &lt;- colnames(spring_cor) &lt;- rownames(tse)\ndiag(spring_cor) &lt;- 1\n\nAs explained in Section 18.1.1, the estimated associations are sparsified and transformed into dissimilarities, and finally transformed into similarities, which are the adjacency values. We write a function for these steps, which will be reused later.\nSince SPRING already includes a sparsification approach, the thresh argument is not needed here, but will be needed in Section 18.6 for other association measures.\nTo be consistent with the workflow, we provide two dissimilarity transformations: “signed” and “unsigned” (see Section 18.1.1 for an explanation). These transformations were introduced by Dongen and Enright (2012). We use the “signed” transformation in our examples so that strongly negatively associated genera have low edge weights.\n\nDongen, Stijn van, and Anton J. Enright. 2012. “Metric distances derived from cosine similarity and Pearson and Spearman correlations.” arXiv Preprint 2: 2–6. http://arxiv.org/abs/1208.3145.\nThe output of the function is an igraph object, which can be plotted and analyzed using functions from the igraph package.\n\n# Arguments:\n# - assoMat: association matrix\n# - threshold: associations below the threshold are set to zero\n# - dissTrans: dissimilarity transformation (\"signed\" or \"unsigned\")\n\ntransform_asso &lt;- function(assoMat, thresh = NULL, dissTrans = \"signed\") {\n  # Sparsification\n  if (!is.null(thresh)) {\n      assoMat[abs(assoMat) &lt; thresh] &lt;- 0\n  }\n\n  # Compute dissimilarity matrix\n  if (dissTrans == \"signed\") {\n      dissMat &lt;- sqrt(0.5 * (1 - assoMat))\n  } else {\n      dissMat &lt;- sqrt(1 - assoMat^2)\n  }\n\n  # Dissimilarity between nodes with zero correlation is set to 1\n  # (these nodes are unconnected and thus should have maximum dissimilarity)\n  dissMat[assoMat == 0] &lt;- 1\n\n  # Compute similarity matrix\n  simMat &lt;- 1 - dissMat\n\n  # Turn into igraph object\n  graphObj &lt;- SpiecEasi::adj2igraph(simMat)\n\n  return(list(graph = graphObj, adja = simMat, asso = assoMat, diss = dissMat))\n}\n\n\n# Create graph object\nspring_graph &lt;- transform_asso(spring_cor)$graph\n\n\n18.1.5 NetCoMi network\nThe NetCoMi (Peschel et al. 2021) package is specifically designed to construct, analyze, and compare networks for microbiome data and implements the complete workflow described in Section 18.1.1. Instead of using several functions for each of the steps, NetCoMi provides a single function for network construction (netConstruct()), so the package streamlines the workflow considerably. The user can choose from a variety of methods for data preprocessing, association estimation, sparsification, and transformation. The returned microNet object can then be passed to netAnalyze() (the network analysis function) so that all necessary information is available for the network analysis workflow.\n\nPeschel, Stefanie, Christian L Müller, Erika von Mutius, Anne-Laure Boulesteix, and Martin Depner. 2021. “NetCoMi: network construction and comparison for microbiome data in R.” Briefings in Bioinformatics 22 (4): bbaa290. https://doi.org/10.1093/bib/bbaa290.\n\nlibrary(NetCoMi)\n\nWe again use SPRING as one of the association measures available in NetCoMi to construct a conditional dependency graph.\nTo demonstrate how taxa are filtered with netConstruct(), we will use the unfiltered tse object this time. The filtering is the same as before: Taxa occurring in less than 20% of the samples are removed.\n\nnetcomi_net &lt;- netConstruct(\n    tse,\n    taxRank = \"genus\",\n    filtTax = \"numbSamp\",\n    filtTaxPar = list(numbSamp = 0.2),\n    measure = \"spring\",\n    measurePar = list(thresh = 0.05, Rmethod = \"approx\"),\n    sparsMethod = \"none\",\n    dissFunc = \"signed\",\n    seed = 13075)\n\nnetConstruct() returns an object of the class microNet, which contains all matrices generated during network construction.\nThe object also contains an edge list, giving each edge’s estimated association, dissimilarity, and adjacency. Let’s take a quick look at the edges with the highest and lowest edge weights:\n\nedgelist &lt;- netcomi_net$edgelist1[\n    order(netcomi_net$edgelist1$adja, decreasing = TRUE), ]\nedgelist |&gt; head()\n##                  v1                    v2   asso   diss   adja\n##  73     Citrobacter           Escherichia 0.3682 0.5621 0.4379\n##  63    Buttiauxella              Serratia 0.2426 0.6154 0.3846\n##  69   Chitinivibrio Pseudogracilibacillus 0.2203 0.6244 0.3756\n##  19        Algicola           Siccibacter 0.2193 0.6248 0.3752\n##  111     Haliangium          Marinobacter 0.2148 0.6266 0.3734\n##  143 Planomicrobium         Virgibacillus 0.2006 0.6322 0.3678\nedgelist |&gt; tail()\n##                 v1             v2       asso   diss   adja\n##  132 Mycobacterium Salinibacillus  0.0017483 0.7065 0.2935\n##  24      Amphritea    Providencia  0.0014085 0.7066 0.2934\n##  102       Erwinia    Siccibacter  0.0013114 0.7066 0.2934\n##  116     Holophaga   Methylarcula  0.0007828 0.7068 0.2932\n##  17       Algicola     Lysobacter  0.0005191 0.7069 0.2931\n##  95   Enterobacter     Janibacter -0.0013921 0.7076 0.2924\n\nAs before, the adjacency matrix is converted into an igraph object. Further steps like sparsification and transformation are not necessary because they are done internally by netConstruct().\n\nnetcomi_graph &lt;- SpiecEasi::adj2igraph(abs(netcomi_net$adjaMat1))",
    "crumbs": [
      "Networks",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Network learning & analysis</span>"
    ]
  },
  {
    "objectID": "pages/network_learning.html#sec-network-analysis",
    "href": "pages/network_learning.html#sec-network-analysis",
    "title": "18  Network learning & analysis",
    "section": "\n18.2 Network analysis with igraph",
    "text": "18.2 Network analysis with igraph\nThe computed network is now analyzed using appropriate methods. We will first use the igraph package to analyze the SPRING network. NetCoMi’s netAnalyze() function will be used later to analyze the constructed microNet object.\n\n18.2.1 Network plot\nTo get an overview of the network structure, a first common analysis method is to plot the network. We here use the igraph package, which is a state-of-the-art package for network analysis and visualization. Other packages that could be used for network plotting are the qgraph package or the ggnet2 package. Since we will use igraph for network analysis later on, we are using its plotting function here as well.\nWe use the Fruchterman-Reingold layout (a force-directed layout) for node placement. By placing strongly connected nodes close together and those with low edge weight far apart, this layout results in an easy-to-read network plot.\nThe node sizes are proportional to a taxon’s log10-transformed abundance, which we previously added to the tse object, averaged across all samples. The values are rescaled to be visually distinguishable.\nSince we created two graph objects, one with SPRING and one with NetCoMi, we plot them side by side. The two plots should be identical.\n\nlibrary(igraph)\n\n\n# Node sizes\nvsize &lt;- (colMeans(t(assay(tse, \"log10\"))) + 1) * 3\n\n# Fruchterman-Reingold layout from igraph package\nset.seed(13075)\nlay_fr &lt;- layout_with_fr(spring_graph)\n\npar(mfrow = c(1,2))\nplot(spring_graph, layout = lay_fr, vertex.size = vsize,\n     vertex.label = NA, main = \"SPRING network\")\nplot(netcomi_graph, layout = lay_fr, vertex.size = vsize,\n     vertex.label = NA, main = \"NetCoMi network\\n(with SPRING associations)\")\n\n\n\n\n\n\n\n\n18.2.2 Centrality measures\nCentrality measures express the importance of nodes within the network. Common measures are the degree, betweenness, closeness, and eigenvector centrality. The igraph package provides functions to compute these measures. We wrap a function around the code to reuse it later.\n\nget_centr &lt;- function(graph_obj) {\n  # We access igraph directly with \"::\" because there are more packages loaded\n  # in this chapter that contain a degree() function.\n  df &lt;- data.frame(Degree = igraph::degree(graph_obj))\n  df$Betweenness &lt;- betweenness(graph_obj)\n  df$Closeness &lt;- closeness(graph_obj, normalized = TRUE)\n  df$Eigenvector &lt;- eigen_centrality(graph_obj)$vector\n  return(df)\n}\n\ncentr_df &lt;- get_centr(spring_graph)\nrownames(centr_df) &lt;- rownames(spring_cor)\ncentr_df |&gt; head(15)\n##                   Degree Betweenness Closeness Eigenvector\n##  Abyssicoccus          0           0       NaN   9.278e-18\n##  Acidaminococcus       2           0    0.6464   1.862e-01\n##  Acinetobacter         3           5    0.5544   1.257e-01\n##  Actinomyces           0           0       NaN   9.278e-18\n##  Actinoplanes          2          99    0.5104   1.099e-02\n##  Aerococcus            0           0       NaN   9.278e-18\n##  Aeromonas             4         351    0.7477   2.023e-01\n##  Agromyces             6         435    0.7733   5.293e-01\n##  Algicola              4         264    0.7206   1.500e-01\n##  Alicyclobacillus      0           0       NaN   9.278e-18\n##  Alteribacillus        0           0       NaN   9.278e-18\n##  Ammoniibacillus       1           0    0.5064   5.419e-02\n##  Amphritea             5         382    0.6256   1.335e-02\n##  Amycolatopsis         1           0    0.6117   1.338e-01\n##  Anaerococcus          2         392    0.4064   1.288e-03\n\nThe closeness centrality is “NaN” for some genera. These are unconnected nodes, as can be seen by the zero degree and betweenness centrality.\n\n18.2.3 Scale node sizes by degree\nCentrality measures can be visualized in the network plot by scaling the node sizes according to one of these measures. We plot the Spring graph using the same layout as before and with the node sizes scaled according to all four centrality measures.\nOf the four centrality measures, only the degree has a range suitable to be used as node size. The other centrality measures must be rescaled because their range is either too small or too large. The following scaling is a suggestion that works for this example. The values might be adapted for other data sets.\n\nget_vsizes &lt;- function(centr_df) {\n    df &lt;- as.matrix(centr_df)\n    df[, \"Betweenness\"] &lt;- log(df[, \"Betweenness\"])\n    df[, \"Closeness\"] &lt;- df[, \"Closeness\"] * 10\n    df[, \"Eigenvector\"] &lt;- df[, \"Eigenvector\"] * 10\n    df[is.infinite(df) | is.na(df)] &lt;- 0\n    return(df)\n}\n\nvsize_df &lt;- get_vsizes(centr_df )\nvsize_df |&gt; head()\n##                  Degree Betweenness Closeness Eigenvector\n##  Abyssicoccus         0       0.000     0.000   9.278e-17\n##  Acidaminococcus      2       0.000     6.464   1.862e+00\n##  Acinetobacter        3       1.609     5.544   1.257e+00\n##  Actinomyces          0       0.000     0.000   9.278e-17\n##  Actinoplanes         2       4.595     5.104   1.099e-01\n##  Aerococcus           0       0.000     0.000   9.278e-17\n\n\npar(mfrow = c(2,2))\nfor (i in seq_along(centr_df)) {\n    plot(spring_graph, layout = lay_fr, vertex.size = vsize_df[, i],\n        vertex.label = NA, main = colnames(centr_df)[i])\n}\n\n\n\n\n\n\n\nWe observe that the two-node component at the bottom has a much higher closeness centrality than the nodes belonging to the main component of the network. Obviously, closeness centrality as commonly defined is misleading when the network consists of disconnected components. Nodes belonging to smaller components are seen as closer to others than in larger components. To overcome this problem, centrality values, and especially closeness centrality, are often calculated only for the largest connected component (LCC), which we will do below.\n\n# Extract the LCC\ndg_net &lt;- igraph::decompose.graph(spring_graph)\nidx_lcc &lt;- which.max(unlist(lapply(dg_net, function(x) length(igraph::V(x)))))\nlcc &lt;- dg_net[[idx_lcc]]\n\n# Compute centrality values for the LCC\ncentr_df_lcc &lt;- get_centr(lcc)\n\n# Replace centrality values by those for LCC and set all others to zero\nlcc_nodes &lt;- as.numeric(rownames(centr_df_lcc))\ncentr_df[lcc_nodes, ] &lt;- centr_df_lcc\ncentr_df[-lcc_nodes, ] &lt;- 0\n\n# Node/vertex sizes\nvsize_df &lt;- get_vsizes(centr_df)\n\n\npar(mfrow = c(2,2))\nfor (i in seq_along(centr_df)) {\n    plot(spring_graph, layout = lay_fr, vertex.size = vsize_df[, i],\n        vertex.label = NA, main = colnames(centr_df)[i])\n}\n\n\n\n\n\n\n\nNote that NetCoMi follows a different approach to overcome this problem. NetCoMi uses the definition of closeness centrality proposed by Tore Opsahl, which is well defined even for disconnected networks and assigns higher closeness centrality values to nodes in larger components. This is more intuitive because nodes in a larger component are connected to a larger number of other nodes than in small components.\n\n18.2.4 Degree distribution\nThe degree distribution is another popular measure that expresses the probability distribution of degrees over the entire network. It thus provides insight into the overall network structure. We plot the degree distribution for all four association estimation methods to compare the network structure.\n\nlibrary(ggplot2)\n\n\n# Compute degree distribution\nddist&lt;- igraph::degree.distribution(spring_graph)\n\n# Data frame needed for ggplot2\ndf &lt;- data.frame(\n    Degree = as.factor((seq_along(ddist)) - 1), Fraction = ddist)\n\nggplot(data = df, aes(x = Degree, y = Fraction, group = 1)) +\n    geom_line() +\n    geom_point() +\n    labs(title = \"Degree distribution\") +\n    theme_bw()\n\n\n\n\n\n\n\nThe network has a large number of singletons and sparsely connected nodes, and only a small number of nodes with a higher degree of 7 or more.\n\n18.2.5 Clustered heatmaps\nUsing the ComplexHeatmap package, we plot a heatmap of the association matrix estimated with SPRING. Rows and columns are sorted according to the clusters identified via hierarchical clustering.\n\nlibrary(ComplexHeatmap)\nlibrary(circlize)\n\nWe select the 50 nodes with the highest sum of edge weights to get a smaller heatmap.\n\nsel &lt;- names(sort(rowSums(spring_cor), decreasing = TRUE))[seq_len(50)]\nadja_sel &lt;- spring_cor[sel, sel]\n\n\n# Color vector\ncol &lt;- colorRamp2(\n    c(-1, -0.5, 0, 0.5, 1),\n    c(\"royalblue4\", \"lightblue\", \"white\", \"orange\", \"firebrick3\"))\n\nHeatmap(\n    adja_sel,\n    col = col,\n    rect_gp = gpar(col = \"gray\", lwd = 1),\n    show_row_names = FALSE,\n    show_column_names = FALSE,\n    name = \"Association\")\n\n\n\n\n\n\n\nThe associations are generally quite low, and there are no prominent clusters detected by hierarchical clustering.\n\n18.2.6 Global network measures\nGlobal measures describe the overall network structure. We take a look at three common measures: density, transitivity, and average path length. The values are again computed with igraph functions.\n\n18.2.6.1 Density\nDefinition: Proportion of present edges from all possible edges.\n\nedge_density(spring_graph)\n##  [1] 0.01444\n\n\n18.2.6.2 Transitivity (clustering coefficient)\nHere, we consider only the global clustering coefficient, which is defined as the ratio of triangles to connected triples.\n\ntransitivity(spring_graph)\n##  [1] 0.1456\n\n\n18.2.6.3 Average path length\nDefinition: Mean of the shortest distance between each pair of nodes.\n\naverage.path.length(spring_graph)\n##  [1] 1.699",
    "crumbs": [
      "Networks",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Network learning & analysis</span>"
    ]
  },
  {
    "objectID": "pages/network_learning.html#network-analysis-with-netcomi",
    "href": "pages/network_learning.html#network-analysis-with-netcomi",
    "title": "18  Network learning & analysis",
    "section": "\n18.3 Network analysis with NetCoMi",
    "text": "18.3 Network analysis with NetCoMi\nThe netcomi_net object of class microNet created before is now passed to netAnalyze() to perform network analysis with NetCoMi.\nThe function computes several common network characteristics such as centrality measures, cluster assignment, the graphlet correlation matrix, as well as global network measures.\nThe user has several options to choose from, such as a clustering method, how to define hubs, and whether or not to normalize centrality values. See the help page ?netAnalyze for a description of the arguments.\nBy default, a heatmap of the Graphlet Correlation Matrix (GCM) is returned (with graphlet correlations in the upper triangle and significance codes resulting from Student’s t-test in the lower triangle). See ?calcGCM and ?testGCM for details.\n\nnetcomi_netprops &lt;- netAnalyze(\n    netcomi_net,\n    clustMethod = \"cluster_fast_greedy\",\n    hubPar = \"eigenvector\",\n    normDeg = FALSE)\n\n\n\n\n\n\n\n\nsummary(netcomi_netprops, numbNodes = 5)\n##  \n##  Component sizes\n##  ```````````````              \n##  size: 103 2  1\n##     #:   1 1 42\n##  ______________________________\n##  Global network properties\n##  `````````````````````````\n##  Largest connected component (LCC):\n##                                   \n##  Relative LCC size         0.70068\n##  Clustering coefficient    0.21253\n##  Modularity                0.70495\n##  Positive edge percentage 99.35065\n##  Edge density              0.02932\n##  Natural connectivity      0.01173\n##  Vertex connectivity       1.00000\n##  Edge connectivity         1.00000\n##  Average dissimilarity*    0.99084\n##  Average path length**     3.81101\n##  \n##  Whole network:\n##                                   \n##  Number of components     44.00000\n##  Clustering coefficient    0.21253\n##  Modularity                0.70787\n##  Positive edge percentage 99.35484\n##  Edge density              0.01444\n##  Natural connectivity      0.00782\n##  -----\n##  *: Dissimilarity = 1 - edge weight\n##  **: Path length = Units with average dissimilarity\n##  \n##  ______________________________\n##  Clusters\n##  - In the whole network\n##  - Algorithm: cluster_fast_greedy\n##  ```````````````````````````````` \n##                                    \n##  name:  0  1  2  3  4 5  6 7 8 9 10\n##     #: 42 16 11 14 20 9 17 8 5 3  2\n##  \n##  ______________________________\n##  Hubs\n##  - In alphabetical/numerical order\n##  - Based on empirical quantiles of centralities\n##  ```````````````````````````````````````````````                      \n##   Agromyces            \n##   Aneurinibacillus     \n##   Anoxybacillus        \n##   Chitinivibrio        \n##   Erwinia              \n##   Geobacillus          \n##   Janibacter           \n##   Pseudogracilibacillus\n##  \n##  ______________________________\n##  Centrality measures\n##  - In decreasing order\n##  - Centrality of disconnected components is zero\n##  ````````````````````````````````````````````````\n##  Degree (unnormalized):\n##                         \n##  Anoxybacillus        10\n##  Erwinia              10\n##  Chitinivibrio         9\n##  Janibacter            8\n##  Escherichia/Shigella  7\n##  \n##  Betweenness centrality (normalized):\n##                      \n##  Janibacter    0.3941\n##  Chitinivibrio 0.3137\n##  Enterobacter  0.2780\n##  Buttiauxella  0.2454\n##  Erwinia       0.2095\n##  \n##  Closeness centrality (normalized):\n##                              \n##  Chitinivibrio         0.5247\n##  Janibacter            0.5067\n##  Anoxybacillus         0.4841\n##  Pseudogracilibacillus 0.4659\n##  Erwinia               0.4653\n##  \n##  Eigenvector centrality (normalized):\n##                              \n##  Anoxybacillus         1.0000\n##  Chitinivibrio         0.9831\n##  Pseudogracilibacillus 0.8657\n##  Janibacter            0.8361\n##  Aneurinibacillus      0.6890\n\nInterpretation of some findings:\n\nThe largest connected component (LCC) has 103 nodes and the network contains 42 singletons.\n10 clusters have been identified, containing 2 to 20 nodes.\nThere are 8 hub nodes detected which by definition are the nodes with the highest eigenvector centrality.\nThe average path length in the LCC is 3.811. This means that on average it takes 3.811 steps (step length is the average dissimilarity) to get from one node to another. Note that the average path length in NetCoMi is defined differently than in the igraph package, which is why the values differ.\nLow values of edge density and the connectivity measures indicate that the network is rather sparse and not robust to perturbations (i.e., removal of nodes or edges).",
    "crumbs": [
      "Networks",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Network learning & analysis</span>"
    ]
  },
  {
    "objectID": "pages/network_learning.html#network-visualization",
    "href": "pages/network_learning.html#network-visualization",
    "title": "18  Network learning & analysis",
    "section": "\n18.4 Network visualization",
    "text": "18.4 Network visualization\nFurther insight into the network structure can be gained by visualizing the network. We have already seen examples of how to plot a network using the igraph package. Here we will use NetCoMi’s plot function. It takes as input the microNetProps object returned by netAnalyze(), which contains all computed network properties. This has the advantage that the user can choose which properties to plot by simply changing some arguments. The plot function is based on qgraph, which is another state-of-the-art R package for network visualization. The help page can be accessed via ?plot.microNetProps.\n\n18.4.1 Highlight node properties\nIn the first plot, node colors represent the detected clusters and node sizes are scaled by eigenvector centrality. Hub nodes are highlighted by default. Singletons are not included in the plot. To improve the readability NetCoMi’s “intelligent” label shortening approach is used.\nNote that nodes are sometimes placed too close together so that the labels overlap. You may need to play around with the repulsion argument until you find a value where the labels are legible, but also the clusters are still well recognizable.\n\nplot(netcomi_netprops,\n     repulsion = 0.98,\n     rmSingles = TRUE,\n     shortenLabels = \"intelligent\",\n     labelScale = FALSE,\n     nodeSize = \"eigenvector\",\n     nodeSizeSpread = 3,\n     nodeColor = \"cluster\",\n     hubBorderCol = \"gray40\",\n     cexNodes = 1.8,\n     edgeTranspHigh = 20,\n     title1 = \"Network properties highlighted\",\n     showTitle = TRUE,\n     cexTitle = 2.3,\n     mar = c(1, 3, 4, 8))\n\nlegend(0.7, 1.1, cex = 1.7, title = \"estimated correlation:\",\n       legend = c(\"+\",\"-\"), lty = 1, lwd = 3, col = c(\"#009900\",\"red\"),\n       bty = \"n\", horiz = TRUE)\n\n\n\n\n\n\n\n\n18.4.2 Highlight data features\nWe now color nodes according to their phylum. The node sizes are proportional to a taxon’s sum of mclr-transformed abundances. As already mentioned in Section 18.1.4, this is the normalization method used by SPRING. A color palette from RColorBrewer is used here.\n\nlibrary(RColorBrewer)\n\n\n# Generate vector with phylum names for node coloring\nphyla &lt;- as.factor(rowData(tse)$phylum)\nnames(phyla) &lt;- rowData(tse)$genus\n\n# Create color vector\ncolvec &lt;- RColorBrewer::brewer.pal(length(levels(phyla)), \"Set3\")\n\nplot(netcomi_netprops,\n     repulsion = 0.98,\n     rmSingles = TRUE,\n     shortenLabels = \"intelligent\",\n     labelScale = FALSE,\n     nodeSize = \"mclr\",\n     nodeColor = \"feature\",\n     featVecCol = phyla,\n     colorVec =  colvec,\n     nodeTransp = 20,\n     highlightHubs = FALSE,\n     cexNodes = 1.8,\n     edgeTranspHigh = 20,\n     title1 = \"Data features highlighted\",\n     showTitle = TRUE,\n     cexTitle = 2.3,\n     mar = c(1, 10, 4, 6))\n\n# Add legends\nlegend(0.7, 1.1, cex = 1.7, title = \"estimated correlation:\",\n       legend = c(\"+\",\"-\"), lty = 1, lwd = 3, col = c(\"#009900\",\"red\"),\n       bty = \"n\", horiz = TRUE)\n\n# Colors used in the legend should be equally transparent as in the plot\ncol_transp &lt;- colToTransp(colvec, 20)\n\nlegend(-1.8, 1.1, cex = 1.7, pt.cex = 2.5, title = \"Phylum:\",\n       legend=levels(phyla), col = col_transp, bty = \"n\", pch = 16)\n\n\n\n\n\n\n\nA few things to observe:\n\nGenera belonging to the same phylum tend to cluster together, though not perfectly.\nGenera with a low total count play a rather unimportant role in the network, i.e., they have a low centrality.\nThere is only one negative edge in the network. This edge is between two clusters, as expected when using the “signed” transformation.",
    "crumbs": [
      "Networks",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Network learning & analysis</span>"
    ]
  },
  {
    "objectID": "pages/network_learning.html#which-methods-to-choose",
    "href": "pages/network_learning.html#which-methods-to-choose",
    "title": "18  Network learning & analysis",
    "section": "\n18.5 Which method(s) to choose?",
    "text": "18.5 Which method(s) to choose?\nThroughout all the steps from primary data to potentially significant network features, there is a variety of methods and parameters to choose from. However, there is no general consensus in the community on the “right” way to estimate and analyze microbial networks. In the absence of a “best method” for inferring and analyzing microbial networks, researchers may be tempted to try different methods and report only the optimal results or those that fit some prior knowledge. This carries the risk of “overfitting” the analysis to the existing data so that the results are not replicable for new data (Ullmann et al. 2023).\n\nUllmann, Theresa, Stefanie Peschel, Philipp Finger, Christian L Müller, and Anne-Laure Boulesteix. 2023. “Over-Optimism in Unsupervised Microbiome Analysis: Insights from Network Learning and Clustering.” PLoS Computational Biology 19 (1): e1010820. https://doi.org/10.1371/journal.pcbi.1010820.\nTherefore, the selection of the workflow building blocks should be set up once and independently of any hypothesis about the data, thus avoiding the fallacy of starting to “fish” for results that best fit a previously formulated hypothesis. For example, one should ask prior to the analysis whether correlation or conditional dependence as a measure of association better fits the research question and choose the method accordingly. Another example is the choice of transformation from estimated association to dissimilarity (i.e., “signed” or “unsigned”), which completely changes the interpretation and characteristics of the network. This choice should be made based on the research question before starting the analysis.",
    "crumbs": [
      "Networks",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Network learning & analysis</span>"
    ]
  },
  {
    "objectID": "pages/network_learning.html#sec-more-about-association",
    "href": "pages/network_learning.html#sec-more-about-association",
    "title": "18  Network learning & analysis",
    "section": "\n18.6 More about association measures",
    "text": "18.6 More about association measures\nAs mentioned in the introduction of this chapter, there are three types of association measures that are commonly used to express relationships between taxa: correlation, conditional dependence, and proportionality. Below, we provide a brief explanation of each of these measures, along with lists of available compositionality-aware approaches.\n\n\nCorrelation: Two popular measures of ecological association are Pearson’s correlation coefficient and Spearman’s rank correlation coefficient, both of which can be inferred from empirical (sample) covariances. However, in the \\(p\\gg n\\) setting, which most microbiome datasets are in, sample covariances and correlations are unreliable because the parameters being estimated are typically underdetermined. One way to improve sample covariance estimates is to assume that the underlying covariance matrix is sparse and use a regularized covariance estimator to implement this structural assumption. The Schäfer-Strimmer shrinkage estimator (Schäfer and Strimmer 2005) is one possible method for estimating a sparse correlation matrix. Other popular methods, especially designed to estimate correlations for compositional data, are SparCC (“Sparse Correlations for Compositional data”) by J. Friedman and Alm (2012), CCREPE (“Compositionality Corrected by REnormalization and PErmutation”) by Faust et al. (2012), and CCLasso (“Correlation inference for Compositional data through Lasso”) by Huaying Fang et al. (2015). The latter three methods already include a compositionality aware normalization, and SparCC also includes a zero replacement approach.\n\nConditional dependence: Since standard correlations include both direct and indirect dependencies, conditional dependence or partial correlation is often preferred for measuring association. Unlike (marginal) correlation, it expresses the relationship between two features conditioned on all other features in the data set. The approach and R package SpiecEasi (“Sparse InversE Covariance estimation for Ecological Association and Statistical Inference”) by Kurtz et al. (2015) is specifically designed for inferring ecological networks from microbiome data and includes two approaches for estimating conditional dependence structures between taxa: Neighborhood Selection; short “MB” (Meinshausen and Bühlmann 2006) and (inverse) covariance selection (Jerome Friedman, Hastie, and Tibshirani 2008), which is based on a penalized maximum likelihood approach and is also known as “graphical lasso”. Another approach and R package for inferring partial correlations from microbiome data is SPRING (“Semi-Parametric Rank-based approach for INference in Graphical model”) by Yoon, Gaynanova, and Müller (2019). They also use the MB neighborhood selection method, but introduce a novel semi-parametric rank-based approach for sparse partial correlation estimation that can naturally handle the excess of zeros in the data. gCoda (H. Fang et al. 2017) is another conditional dependence measure based on penalized maximum likelihood estimation. All of the aforementioned conditional dependence measures address the high dimensionality of microbiome data.\n\nProportionality: Lovell et al. (2015) introduce proportionality as an alternative measure of pairwise association for compositional data. The idea is that if the relative abundances between two taxa \\(i\\) and \\(j\\) are proportional, then their corresponding absolute abundances are also proportional: \\(\\frac{\\omega_i}{m} \\propto \\frac{\\omega_j}{m} \\Rightarrow \\omega_i \\propto \\omega_j\\), where \\(m\\) is the sum of counts in the sample. It follows that proportionality is identical for the observed (relative) read counts and the true unobserved counts. The proportionality measure proposed by Lovell et al. (2015) is based on log-ratio variance \\(var(log \\frac{x_i}{x_j})\\), which is zero when \\(\\omega_i\\) and \\(\\omega_j\\) are perfectly proportional. Proportionality is implemented in the R package propr. Badri et al. (2020) extend the proportionality measure to a so-called “shrinkage proportionality estimator”. It combines proportionality with the covariance shrinkage approach to obtain consistent association estimates even with small sample sizes.\n\nSchäfer, Juliane, and Korbinian Strimmer. 2005. “A shrinkage approach to large-scale covariance matrix estimation and implications for functional genomics.” Statistical Applications in Genetics and Molecular Biology 4 (1): 1–30. https://doi.org/10.2202/1544-6115.1175.\n\nFaust, Karoline, J. Fah Sathirapongsasuti, Jacques Izard, Nicola Segata, Dirk Gevers, Jeroen Raes, and Curtis Huttenhower. 2012. “Microbial Co-occurrence Relationships in the Human Microbiome.” PLoS Computational Biology 8 (7): e1002606. https://doi.org/10.1371/journal.pcbi.1002606.\n\nFang, Huaying, Chengcheng Huang, Hongyu Zhao, and Minghua Deng. 2015. “CCLasso: Correlation inference for compositional data through Lasso.” Bioinformatics 31 (19): 3172–80. https://doi.org/10.1093/bioinformatics/btv349.\n\nFriedman, Jerome, Trevor Hastie, and Robert Tibshirani. 2008. “Sparse inverse covariance estimation with the graphical lasso.” Biostatistics (Oxford, England) 9 (3): 432–41. https://doi.org/10.1093/BIOSTATISTICS/KXM045.\n\nYoon, Grace, Irina Gaynanova, and Christian L Müller. 2019. “Microbial networks in SPRING - Semi-parametric rank-based correlation and partial correlation estimation for quantitative microbiome data.” Frontiers in Genetics 10: 516. https://doi.org/10.3389/fgene.2019.00516.\n\nFang, H, C Huang, H Zhao, and M Deng. 2017. “gCoda: Conditional Dependence Network Inference for Compositional Data.” Journal of Computational Biology 24 (7): 699–708. https://doi.org/10.1089/cmb.2017.0054.",
    "crumbs": [
      "Networks",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Network learning & analysis</span>"
    ]
  },
  {
    "objectID": "pages/network_learning.html#comparison-of-association-measures",
    "href": "pages/network_learning.html#comparison-of-association-measures",
    "title": "18  Network learning & analysis",
    "section": "\n18.7 Comparison of association measures",
    "text": "18.7 Comparison of association measures\nIn this section, we provide three additional examples for constructing a network using each of the three types of association:\n\nCorrelation using SparCC\n\nPartial correlation using SpiecEasi\n\nProportionality using the shrinkage proportionality measure\n\n\n18.7.1 SparCC\nThe first association measure we look at is SparCC (“Sparse Correlations fo Compositional data”), introduced by J. Friedman and Alm (2012). It estimates Pearson correlations while taking into account the compositional structure of the data. The SpiecEasi package provides an implementation of this method.\n\nFriedman, J, and EJ Alm. 2012. “Inferring Correlation Networks from Genomic Survey Data.” PLoS Computational Biology 8 (9): e1002687. https://doi.org/10.1371/journal.pcbi.1002687.\n\n# Set seed for reproducibility\nset.seed(13075)\n# Compute correlation matrix\nsparcc_cor &lt;- SpiecEasi::sparcc(t(assay(tse, \"counts\")))$Cor\nrownames(sparcc_cor) &lt;- colnames(sparcc_cor) &lt;- rownames(tse)\n\nWe reuse the transform_asso() function created in Section 18.1.4, which sparsifies the association matrix, transforms it into a similarity matrix, and finally returns an igraph object.\nTwo threshold values are used to see the effect of sparsification later in the network plot.\n\nsparcc_trans03 &lt;- transform_asso(sparcc_cor, thresh = 0.3)\nsparcc_trans04 &lt;- transform_asso(sparcc_cor, thresh = 0.4)\n\nsparcc_graph03 &lt;- sparcc_trans03$graph\nsparcc_graph04 &lt;- sparcc_trans04$graph\n\n\n18.7.2 Shrinkage proportionality\nIn the second example, microbial associations are measured by proportionality, originally introduced by Lovell et al. (2015). We use the shrinkage proportionality estimator proposed by Badri et al. (2020), which gives consistent results even for small sample sizes. Since there is no R package implementing this estimator, we use the rho_shrink_est() function provided in the GitHub repository associated with the paper. The function is slightly modified to take normalized counts as input.\n\nLovell, David, Vera Pawlowsky-Glahn, Juan José Egozcue, Samuel Marguerat, and Jürg Bähler. 2015. “Proportionality: A Valid Alternative to Correlation for Relative Data.” PLoS Computational Biology 11 (3): 1–12. https://doi.org/10.1371/journal.pcbi.1004075.\n\nBadri, Michelle, Zachary D. Kurtz, Richard Bonneau, and Christian L. Müller. 2020. “Shrinkage improves estimation of microbial associations under different normalization methods.” NAR Genomics and Bioinformatics 2 (4). https://doi.org/10.1093/NARGAB/LQAA100.\n\nlibrary(corpcor)\n\n\n# norm_counts: clr-transformed count matrix with samples in rows\nrho_shrink_est &lt;- function(norm_counts, ...) {\n    shrunk_cov &lt;- cov.shrink(norm_counts, ...)\n    p &lt;- ncol(norm_counts)\n    J &lt;- matrix(rep(diag(shrunk_cov), p), p)\n    rho &lt;- 2 * shrunk_cov / (J + t(J))\n    (rho + t(rho)) / 2\n}\n\n\n# Apply the shrinkage proportionality estimator to the clr-transformed counts\nprop_est &lt;- as(rho_shrink_est(t(assay(tse, \"clr\"))), \"matrix\")\n##  Estimating optimal shrinkage intensity lambda.var (variance vector): 0.0857 \n##  \n##  Estimating optimal shrinkage intensity lambda (correlation matrix): 0.3634\n\nAgain, we use our transformation function to convert the association matrix into a graph object.\n\nprop_trans &lt;- transform_asso(prop_est, thresh = 0.4)\nprop_graph &lt;- prop_trans$graph\n\n\n18.7.3 SpiecEasi - MB\nAs third example, we use the SpiecEasi (“Sparse InversE Covariance estimation for Ecological Association and Statistical Inference”) approach proposed by Kurtz et al. (2015) to estimate a sparse conditional dependency graph. The neighborhood selection method (“MB”) introduced by Meinshausen and Bühlmann (2006) is used for network learning. The approach is implemented in the R package SpiecEasi.\n\nKurtz, ZD, CL Müller, ER Miraldi, DR Littman, MJ Blaser, and Bonneau RA. 2015. “Sparse and Compositionally Robust Inference of Microbial Ecological Networks.” PLoS Computational Biology 11 (5): e1004226. https://doi.org/10.1371/journal.pcbi.1004226.\n\nMeinshausen, Nicolai, and Peter Bühlmann. 2006. “High-dimensional graphs and variable selection with the Lasso.” Annals of Statistics 34 (3): 1436–62. https://doi.org/10.1214/009053606000000281.\n\nlibrary(SpiecEasi)\n\n\nset.seed(13075)\nse_mb_est &lt;- spiec.easi(\n    t(assay(tse, \"counts\")),\n    method = 'mb', nlambda = 20,\n    pulsar.params = list(rep.num = 20))\n\nSince SpiecEasi uses the StARS (“Stability Approach to Regularization Selection”) method (Liu, Roeder, and Wasserman 2010) to obtain a sparse association matrix, we don’t need to set a threshold here. We store the partial correlations corresponding to the StARS-optimal lambda and convert them into an igraph object.\n\nLiu, Han, Kathryn Roeder, and Larry Wasserman. 2010. “Stability Approach to Regularization Selection (StARS) for High Dimensional Graphical Models.” Advances in Neural Information Processing Systems. https://doi.org/10.48550/arxiv.1006.3316.\n\n# Get optimal matrix with partial correlations\nse_mb_cor &lt;- as.matrix(getOptBeta(se_mb_est))\nse_mb_cor &lt;- as.matrix(symBeta(se_mb_cor))\nrownames(se_mb_cor) &lt;- colnames(se_mb_cor) &lt;- rownames(tse)\ndiag(se_mb_cor) &lt;- 1\n\n# Create graph object\nse_mb_graph &lt;- transform_asso(se_mb_cor)$graph\n\n\n18.7.4 Network plots\nThe graph objects can now be plotted using the igraph package. The same layout is used in all four plots so that the networks are comparable.\n\nlibrary(igraph)\n\n\n# Node sizes\nvsize &lt;- (colMeans(t(assay(tse, \"log10\"))) + 1) * 3\n\n# Use Fruchterman-Reingold (force-directed) layout\nset.seed(13075)\nlay_fr &lt;- layout_with_fr(se_mb_graph)\n\npar(mfrow = c(2,2))\nplot(sparcc_graph03, layout = lay_fr, vertex.size = vsize,\n     vertex.label = NA, main = \"SparCC (thresh 0.3)\")\nplot(sparcc_graph04, layout = lay_fr, vertex.size = vsize,\n     vertex.label = NA, main = \"SparCC (thresh 0.4)\")\nplot(prop_graph, layout = lay_fr, vertex.size = vsize,\n     vertex.label = NA, main = \"Shrinkage proportionality\\n(thresh 0.4)\")\nplot(se_mb_graph, layout = lay_fr, vertex.size = vsize,\n     vertex.label = NA, main = \"SpiecEasi (MB)\")\n\n\n\n\n\n\n\nA few observations: The density of SparCC (threshold 0.4), proportionality and SpiecEasi is comparable, while the SparCC correlation network with threshold 0.3 is much denser. However, there are edges in the proportionality and SpiecEasi networks that are not present in the two SparCC networks. The SpiecEasi network has less highly connected nodes than the other three networks, but more nodes with one or two connections.\nWe will look at the degree distribution in the next section to quantify these observations.\n\n18.7.5 Network analysis\nHere we repeat some of the network analysis approaches explained in Section 18.2. The analyses are performed simultaneously for the three association measures as well as the SPRING network constructed in Section 18.1.4. Therefore, we start by creating a list of all the graph objects we need for the analyses.\n\ngraphlist &lt;- list(\n    SparCC = sparcc_graph04,\n    Proportionality = prop_graph,\n    SpiecEasi = se_mb_graph,\n    SPRING = spring_graph)\n\n\n18.7.5.1 Degree distribution\nThe degree distribution is plotted for all four measures to compare the overall network structure.\n\nlibrary(ggplot2)\n\n\n# Compute degree distributions\nddlist &lt;- lapply(graphlist, igraph::degree.distribution)\n\n# Maximum degree\nmaxdeg &lt;- max(lengths(ddlist))\n\n# Make list elements the same length\nfor(i in seq_along(graphlist)) {\n    length(ddlist[[i]]) &lt;- maxdeg\n}\n\n# Data frame needed for ggplot2\ndf &lt;- data.frame(\n    Degree = rep(seq_len(maxdeg), length(graphlist)),\n    Fraction = unlist(ddlist),\n    Method = rep(names(graphlist), each = maxdeg))\n\nggplot(df, aes(x = Degree, y = Fraction, group = Method)) +\n    geom_line(aes(color = Method)) +\n    geom_point(aes(color = Method)) +\n    theme_bw()\n\n\n\n\n\n\n\nThe SparCC and shrinkage proportionality networks have a considerably higher proportion of singletons (zero-degree nodes) than the two conditional dependency graphs, but a lower proportion of nodes with degrees between one and five. The SpiecEasi and SPRING graphs, on the other hand, have a higher proportion of low degree nodes, but no highly connected nodes with a degree greater than eleven.\n\n18.7.5.2 Clustered heatmaps\nUsing the ComplexHeatmap package, we plot heatmaps of the association matrices for the four considered association measures. Rows and columns are sorted according to the clusters identified via hierarchical clustering.\n\nlibrary(ComplexHeatmap)\nlibrary(circlize)\nlibrary(patchwork)\n\nFor each association measure, we select the 50 nodes with the highest sum of edge weights.\n\n# Function for selecting taxa with highest sum of edge weights\nselect_taxa &lt;- function(adja, ntaxa = 50) {\n    sel &lt;- names(sort(rowSums(adja), decreasing = TRUE))[seq_len(ntaxa)]\n    adja[sel, sel]\n}\n\nassolist &lt;- list()\nassolist$SparCC &lt;- select_taxa(sparcc_trans04$adja)\nassolist$Proportionality &lt;- select_taxa(prop_trans$adja)\nassolist$SpiecEasi &lt;- select_taxa(se_mb_cor)\nassolist$SPRING &lt;- select_taxa(spring_cor)\n\n\n# Color vector for the legend\ncol &lt;- colorRamp2(\n    c(-1, -0.5, 0, 0.5, 1),\n    c(\"royalblue4\", \"lightblue\", \"white\", \"orange\", \"firebrick3\"))\n\nhm_list &lt;- list()\n\nfor(i in seq_along(assolist)) {\n    if (i %in% c(2, 4)) {\n        showlegend &lt;- TRUE\n    } else {\n        showlegend &lt;- FALSE\n    }\n\n    hm_list[[i]] &lt;- Heatmap(\n        assolist[[i]],\n        col = col,\n        rect_gp = gpar(col = \"gray\", lwd = 1),\n        show_row_names = FALSE,\n        show_column_names = FALSE,\n        column_title = names(assolist)[i],\n        name = \"Association\",\n        show_heatmap_legend = showlegend) |&gt;\n\n        draw() |&gt;\n        grid.grabExpr()\n}\n\n# Plot with wrap_plots() function from patchwork package\nwrap_plots(hm_list, ncol = 2, widths = c(8, 10, 8, 10))\n\n\n\n\n\n\n\nThe SparCC and the proportionality network show a block structure, where each block corresponds to a cluster. The clusters are less pronounced in the conditional dependence networks. The latter also generally have lower edge weights.\n\n18.7.5.3 Global network measures\nFor each association measure, the three global network measures density, transitivity, and average path length are computed and stored in a data frame for comparison.\n\n# Compute density and store in a data frame\nglob &lt;- data.frame(Density = unlist(lapply(graphlist, edge_density)))\n\n# Transitivity\nglob$Transitivity &lt;- unlist(lapply(graphlist, transitivity))\n\n# Average path length\nglob$Av.path &lt;- unlist(lapply(graphlist, average.path.length))\n\nglob\n##                  Density Transitivity Av.path\n##  SparCC          0.01510       0.5458  0.8932\n##  Proportionality 0.01295       0.5402  1.1847\n##  SpiecEasi       0.02162       0.2145  1.6322\n##  SPRING          0.01444       0.1456  1.6993",
    "crumbs": [
      "Networks",
      "<span class='chapter-number'>18</span>  <span class='chapter-title'>Network learning & analysis</span>"
    ]
  },
  {
    "objectID": "pages/network_comparison.html",
    "href": "pages/network_comparison.html",
    "title": "19  Network comparison",
    "section": "",
    "text": "19.1 Data preparation\nWe perform the same data preprocessing steps as in Chapter 18.\nlibrary(NetCoMi)\nlibrary(mia)\ndata(\"peerj13075\", package = \"mia\")\ntse &lt;- peerj13075\n# Agglomerate to genus level\ntse &lt;- agglomerateByRank(tse, rank = \"genus\")\n\n# Add relative abundances\ntse &lt;- transformAssay(\n    tse,\n    assay.type = \"counts\",\n    method = \"relabundance\",\n    MARGIN = \"cols\")\n\n# Filter by prevalence\ntse &lt;- subsetByPrevalent(\n    tse,\n    prevalence = 0.2,\n    detection = 0,\n    assay.type = \"relabundance\")\n\n# Add log10-transformed abundances\ntse &lt;- transformAssay(tse, method = \"log10\", pseudocount = 1)\n\n# Add clr-transformed abundances\ntse &lt;- transformAssay(tse, method = \"clr\", pseudocount = 1)\nBased on “Diet”, the tse object is then split into two groups: One with mixed diet subjects, and one with vegetarian subjects. Both subsets have nearly the same sample size and are therefore comparable.\ntable(tse$Diet)\n##  \n##  Mixed   Veg \n##     28    30\ntse_list &lt;- splitOn(tse, group = \"Diet\", use.names = TRUE, by = \"cols\")",
    "crumbs": [
      "Networks",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Network comparison</span>"
    ]
  },
  {
    "objectID": "pages/network_comparison.html#network-learning-and-analysis",
    "href": "pages/network_comparison.html#network-learning-and-analysis",
    "title": "19  Network comparison",
    "section": "\n19.2 Network learning and analysis",
    "text": "19.2 Network learning and analysis\nThe approach starts again with network construction and analysis, but this time we pass the two data sets to netConstruct() to perform a network comparison.\nThe rep.num argument is set to 10 to perform only 10 repetitions in the model selection approach. This speeds up the permutation tests performed later, and has a negligible effect for this data set.\n\nspring_net_diet &lt;- netConstruct(\n    data = tse_list$Mixed,\n    data2 = tse_list$Veg,\n    taxRank = \"genus\",\n    filtTax = \"highestFreq\",\n    filtTaxPar = list(highestFreq  = 100),\n    measure = \"spring\",\n    measurePar = list(\n        nlambda = 20,\n        rep.num = 10,\n        thresh = 0.05,\n        Rmethod = \"approx\"),\n    sparsMethod = \"none\",\n    dissFunc = \"signed\",\n    verbose = 3,\n    seed = 13075)\n\nAll network measures are now computed for both networks. Also, both GCMs are plotted together with a third matrix containing the differences between the GCMs and significance codes that express if the differences are significantly different from zero.\n\nspring_netprops_diet &lt;- netAnalyze(\n    spring_net_diet,\n    clustMethod = \"cluster_fast_greedy\",\n    hubPar = \"eigenvector\",\n    normDeg = FALSE)\n\n\n\n\n\n\n\nIn both of the networks, some graphlet correlations are significantly different from zero. However, none of the correlations are significantly different between the groups.\n\nsummary(spring_netprops_diet, groupNames = c(\"Mixed diet\", \"Vegetarian\"))\n##  \n##  Component sizes\n##  ```````````````\n##  Mixed diet:                   \n##  size: 18 8 4 3 2  1\n##     #:  1 1 1 1 3 43\n##  Vegetarian:                 \n##  size: 21 5 4 2  1\n##     #:  1 1 1 3 46\n##  ______________________________\n##  Global network properties\n##  `````````````````````````\n##  Largest connected component (LCC):\n##                           Mixed diet Vegetarian\n##  Relative LCC size           0.21951    0.25610\n##  Clustering coefficient      0.10393    0.22433\n##  Modularity                  0.51500    0.47707\n##  Positive edge percentage   80.00000  100.00000\n##  Edge density                0.13072    0.12381\n##  Natural connectivity        0.07312    0.06253\n##  Vertex connectivity         1.00000    1.00000\n##  Edge connectivity           1.00000    1.00000\n##  Average dissimilarity*      0.96009    0.96154\n##  Average path length**       2.22768    2.24622\n##  \n##  Whole network:\n##                           Mixed diet Vegetarian\n##  Number of components       50.00000   52.00000\n##  Clustering coefficient      0.07506    0.16530\n##  Modularity                  0.75184    0.66821\n##  Positive edge percentage   88.57143  100.00000\n##  Edge density                0.01054    0.01084\n##  Natural connectivity        0.01342    0.01347\n##  -----\n##  *: Dissimilarity = 1 - edge weight\n##  **: Path length = Units with average dissimilarity\n##  \n##  ______________________________\n##  Clusters\n##  - In the whole network\n##  - Algorithm: cluster_fast_greedy\n##  ```````````````````````````````` \n##  Mixed diet:                          \n##  name:  0 1 2 3 4 5 6 7 8 9\n##     #: 43 8 6 6 6 4 3 2 2 2\n##  \n##  Vegetarian:                        \n##  name:  0 1 2 3 4 5 6 7 8\n##     #: 46 9 8 4 5 4 2 2 2\n##  \n##  ______________________________\n##  Hubs\n##  - In alphabetical/numerical order\n##  - Based on empirical quantiles of centralities\n##  ```````````````````````````````````````````````\n##    Mixed diet           Vegetarian\n##   Citrobacter            Aeromonas\n##       Erwinia              Erwinia\n##   Escherichia Escherichia/Shigella\n##      Serratia           Salmonella\n##    Shewanella          Siccibacter\n##  \n##  ______________________________\n##  Centrality measures\n##  - In decreasing order\n##  - Centrality of disconnected components is zero\n##  ````````````````````````````````````````````````\n##  Degree (unnormalized):\n##                        Mixed diet Vegetarian\n##                Erwinia          6          6\n##            Citrobacter          4          0\n##               Serratia          4          3\n##          Streptococcus          3          0\n##                Pantoea          2          1\n##                            ______     ______\n##                Erwinia          6          6\n##              Aeromonas          1          5\n##   Escherichia/Shigella          2          5\n##            Siccibacter          0          5\n##             Salmonella          2          3\n##  \n##  Betweenness centrality (normalized):\n##                        Mixed diet Vegetarian\n##                Erwinia    0.60294    0.54737\n##               Serratia    0.41912        0.1\n##          Streptococcus    0.27941          0\n##           Enterobacter    0.24265          0\n##            Citrobacter    0.24265          0\n##                            ______     ______\n##                Erwinia    0.60294    0.54737\n##   Escherichia/Shigella    0.11765    0.53158\n##              Aeromonas          0    0.36842\n##            Siccibacter          0        0.3\n##          Thiolamprovum          0    0.20526\n##  \n##  Closeness centrality (normalized):\n##                        Mixed diet Vegetarian\n##                Erwinia    0.85251    0.80605\n##               Serratia    0.78452    0.56308\n##            Citrobacter    0.71265          0\n##           Enterobacter    0.64822    0.49217\n##          Streptococcus    0.61535          0\n##                            ______     ______\n##   Escherichia/Shigella    0.57246    0.80747\n##                Erwinia    0.85251    0.80605\n##              Aeromonas     0.4768    0.74282\n##            Siccibacter          0    0.72705\n##             Salmonella    0.57364    0.66777\n##  \n##  Eigenvector centrality (normalized):\n##                        Mixed diet Vegetarian\n##               Serratia          1    0.41577\n##                Erwinia    0.97703          1\n##            Citrobacter    0.80991          0\n##            Escherichia    0.60982          0\n##             Shewanella    0.41174     0.1238\n##                            ______     ______\n##                Erwinia    0.97703          1\n##   Escherichia/Shigella    0.38659    0.96856\n##            Siccibacter          0      0.888\n##              Aeromonas    0.26033    0.68516\n##             Salmonella     0.3153    0.64405\n\nFor each centrality measure, the five nodes with the highest centrality in each group are plotted by default.\nWe notice some differences in the network properties. The differential network analysis performed in the next section will show if the differences are significant.",
    "crumbs": [
      "Networks",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Network comparison</span>"
    ]
  },
  {
    "objectID": "pages/network_comparison.html#differential-network-analysis",
    "href": "pages/network_comparison.html#differential-network-analysis",
    "title": "19  Network comparison",
    "section": "\n19.3 Differential network analysis",
    "text": "19.3 Differential network analysis\n\n19.3.1 Visual comparison\nWe start with a visual comparison of the two networks using NetCoMi’s plot function. The same configuration as in Chapter 18 is used.\n\nplot(spring_netprops_diet,\n     repulsion = 0.97,\n     rmSingles = TRUE,\n     labelScale = FALSE,\n     nodeSize = \"eigenvector\",\n     nodeSizeSpread = 2,\n     nodeColor = \"cluster\",\n     sameColThresh = 2,\n     hubBorderCol = \"darkgray\",\n     cexNodes = 2,\n     edgeTranspHigh = 20,\n     title1 = \"Mixed diet\",\n     title2 = \"Vegetarian\",\n     showTitle = TRUE,\n     cexTitle = 2,\n     mar = c(1, 4, 4, 4))\n\n# Overlay a transparent plot on which the legend is plotted\npar(fig=c(0, 1, 0, 1), oma=c(0, 0, 0, 0), mar=c(0, 0, 0, 0), new=TRUE)\nplot(0, 0, type='n', bty='n', xaxt='n', yaxt='n')\n\nlegend(-0.2, -0.9, cex = 1.5, title = \"estimated correlation:\",\n       legend = c(\"+\",\"-\"), lty = 1, lwd = 3, col = c(\"#009900\",\"red\"),\n       bty = \"n\", horiz = TRUE)\n\n\n\n\n\n\n\nThe layout is computed separately for each network, making it difficult to visually compare certain associations. It is therefore recommended to use the same layout for both groups (argument sameLayout). Instead of simply copying one layout to the other network, we set layoutGroup to “union”. This ensures that the nodes are placed as optimally as possible for both networks.\n\nplot(spring_netprops_diet,\n     sameLayout = TRUE,\n     repulsion = 0.95,\n     rmSingles = \"inboth\",\n     labelScale = FALSE,\n     nodeSize = \"eigenvector\",\n     nodeSizeSpread = 2,\n     nodeColor = \"cluster\",\n     sameColThresh = 2,\n     hubBorderCol = \"darkgray\",\n     cexNodes = 2,\n     edgeTranspHigh = 20,\n     title1 = \"Mixed diet\",\n     title2 = \"Vegetarian\",\n     showTitle = TRUE,\n     cexTitle = 2,\n     mar = c(1, 4, 4, 4))\n\n# Add legend\npar(fig=c(0, 1, 0, 1), oma=c(0, 0, 0, 0), mar=c(0, 0, 0, 0), new=TRUE)\nplot(0, 0, type='n', bty='n', xaxt='n', yaxt='n')\nlegend(-0.2, -0.8, cex = 1.7, title = \"estimated correlation:\",\n       legend = c(\"+\",\"-\"), lty = 1, lwd = 3, col = c(\"#009900\",\"red\"),\n       bty = \"n\", horiz = TRUE)\n\n\n\n\n\n\n\nA few notes:\n\nDifferences in the edge weights can now be seen at first glance. For example, Serratia and Citrobacter are strongly associated in the mixed diet group, but not at all in the vegetarian group.\nClusters must share at least two nodes (sameColThresh argument) to be colored equally in both networks, which is why the color of some clusters differs between the groups.\nThe clustering generally differs markedly. In particular, the cluster assignment of many of the nodes in the largest connected component differs between the two groups.\n\nAs in Chapter 18, we also generate a network plot using phylum names to color the nodes and mclr-transformed abundances to scale node sizes.\n\nlibrary(RColorBrewer)\n\n\n# Generate vector with phylum names for node coloring\nphyla &lt;- as.factor(rowData(tse)$phylum)\nnames(phyla) &lt;- rowData(tse)$genus\n\n# Create color vector\ncolvec &lt;- RColorBrewer::brewer.pal(length(levels(phyla)), \"Set3\")\n\np_diet &lt;- plot(\n    spring_netprops_diet,\n    sameLayout = TRUE,\n    repulsion = 0.95,\n    rmSingles = \"inboth\",\n    labelScale = FALSE,\n    nodeSize = \"clr\",\n    nodeColor = \"feature\",\n    featVecCol = phyla,\n    colorVec =  colvec,\n    nodeTransp = 20,\n    sameColThresh = 2,\n    highlightHubs = FALSE,\n    cexNodes = 2,\n    edgeTranspHigh = 20,\n   title1 = \"Mixed diet\",\n   title2 = \"Vegetarian\",\n   showTitle = TRUE,\n   cexTitle = 2,\n   mar = c(1, 4, 4, 4))\n\n# Add legends\n# Colors used in the legend should be equally transparent as in the plot\ncol_transp &lt;- colToTransp(colvec, 20)\n\npar(fig=c(0, 1, 0, 1), oma=c(0, 0, 0, 0), mar=c(0, 0, 0, 0), new=TRUE)\nplot(0, 0, type='n', bty='n', xaxt='n', yaxt='n')\nlegend(-0.15, -0.8, cex = 1.7, title = \"estimated correlation:\",\n       legend = c(\"+\",\"-\"), lty = 1, lwd = 3, col = c(\"#009900\",\"red\"),\n       bty = \"n\", horiz = TRUE)\nlegend(-0.15, 1.3, cex = 1.7, pt.cex = 2.5, title = \"Phylum:\",\n       legend=levels(phyla), col = col_transp, bty = \"n\", pch = 16)\n\n\n\n\n\n\n\n\n19.3.2 Quantitative comparison\nnetCompare() enables a quantitative network comparison using comparative measures such as Jaccard’s Index, Adjusted Rand Index, and permutation tests.\nTo test for statistical significance of differences in network properties, we perform permutation tests with 1000 permutations. Multiple CPU cores are used to save run time. The association matrices estimated for all permutations are stored in an external file. We will reuse them later when performing differential association analysis. They could also be used to rerun netCompare() with different parameter settings.\nNote that unless running on a cluster with considerably more CPU cores, a network comparison with permutation tests may take several hours. You should test the code below with a small number of permutations to make sure it works before applying it to your data.\n\nspring_netcomp_diet &lt;- netCompare(\n    spring_netprops_diet,\n    permTest = TRUE,\n    nPerm = 1000,\n    cores = 6,\n    seed = 13075,\n    storeAssoPerm = TRUE,\n    fileStoreAssoPerm = \"general/network_data/spring_assoPerm\",\n    verbose = TRUE)\n\n\nsummary(spring_netcomp_diet,\n        groupNames = c(\"Mixed diet\", \"Vegetarian\"),\n        numbNodes = 5)\n##  \n##  Comparison of Network Properties\n##  ----------------------------------\n##  CALL: \n##  netCompare(x = spring_netprops_diet, permTest = TRUE, verbose = TRUE, \n##      nPerm = 1000, cores = 19, libPathsClust = \"/dss/dsshome1/07/di93fen/R\", \n##      seed = 13075, storeAssoPerm = TRUE, fileStoreAssoPerm = \"general/network_data/spring_assoPerm\")\n##  \n##  ______________________________\n##  Global network properties\n##  `````````````````````````\n##  Largest connected component (LCC):\n##                           Mixed diet   Vegetarian    abs.diff.     p-value\n##  Relative LCC size             0.220        0.256        0.037    0.838162\n##  Clustering coefficient        0.104        0.224        0.120    0.450549\n##  Modularity                    0.515        0.477        0.038    0.801199\n##  Positive edge percentage     80.000      100.000       20.000    0.000999\n##  Edge density                  0.131        0.124        0.007    0.910090\n##  Natural connectivity          0.073        0.063        0.011    0.812188\n##  Vertex connectivity           1.000        1.000        0.000    1.000000\n##  Edge connectivity             1.000        1.000        0.000    1.000000\n##  Average dissimilarity*        0.960        0.962        0.001    0.945055\n##  Average path length**         2.228        2.246        0.019    0.984016\n##                              \n##  Relative LCC size           \n##  Clustering coefficient      \n##  Modularity                  \n##  Positive edge percentage ***\n##  Edge density                \n##  Natural connectivity        \n##  Vertex connectivity         \n##  Edge connectivity           \n##  Average dissimilarity*      \n##  Average path length**       \n##  \n##  Whole network:\n##                           Mixed diet   Vegetarian    abs.diff.     p-value\n##  Number of components         50.000       52.000        2.000     0.93706\n##  Clustering coefficient        0.075        0.165        0.090     0.46254\n##  Modularity                    0.752        0.668        0.084     0.24975\n##  Positive edge percentage     88.571      100.000       11.429     0.02398\n##  Edge density                  0.011        0.011        0.000     0.97303\n##  Natural connectivity          0.013        0.013        0.000     0.89011\n##                              \n##  Number of components        \n##  Clustering coefficient      \n##  Modularity                  \n##  Positive edge percentage *  \n##  Edge density                \n##  Natural connectivity        \n##  -----\n##  p-values: one-tailed test with null hypothesis diff=0\n##   *: Dissimilarity = 1 - edge weight\n##  **: Path length = Units with average dissimilarity\n##  \n##  ______________________________\n##  Jaccard index (similarity betw. sets of most central nodes)\n##  ```````````````````````````````````````````````````````````\n##                      Jacc   P(&lt;=Jacc)     P(&gt;=Jacc)    \n##  degree             0.560      0.9944       0.01637 *  \n##  betweenness centr. 0.294      0.4777       0.71860    \n##  closeness centr.   0.560      0.9944       0.01637 *  \n##  eigenvec. centr.   0.560      0.9944       0.01637 *  \n##  hub taxa           0.111      0.1431       0.97399    \n##  -----\n##  Jaccard index in [0,1] (1 indicates perfect agreement)\n##  \n##  ______________________________\n##  Adjusted Rand index (similarity betw. clusterings)\n##  ``````````````````````````````````````````````````\n##          wholeNet       LCC\n##  ARI        0.367     0.035\n##  p-value    0.000     0.563\n##  -----\n##  ARI in [-1,1] with ARI=1: perfect agreement betw. clusterings\n##                     ARI=0: expected for two random clusterings\n##  p-value: permutation test (n=1000) with null hypothesis ARI=0\n##  \n##  ______________________________\n##  Graphlet Correlation Distance\n##  `````````````````````````````\n##          wholeNet         LCC  \n##  GCD       1.5980      2.1770  \n##  p-value   0.4226      0.7143  \n##  -----\n##  GCD &gt;= 0 (GCD=0 indicates perfect agreement between GCMs)\n##  p-value: permutation test with null hypothesis GCD=0\n##  \n##  ______________________________\n##  Centrality measures\n##  - In decreasing order\n##  - Centrality of disconnected components is zero\n##  ````````````````````````````````````````````````\n##  Degree (unnormalized):\n##                       Mixed diet Vegetarian abs.diff. adj.p-value  \n##  Siccibacter                   0          5         5           1  \n##  Aeromonas                     1          5         4           1  \n##  Citrobacter                   4          0         4           1  \n##  Escherichia/Shigella          2          5         3           1  \n##  Streptococcus                 3          0         3           1  \n##  \n##  Betweenness centrality (normalized):\n##                       Mixed diet Vegetarian abs.diff. adj.p-value  \n##  Escherichia/Shigella      0.118      0.532     0.414           1  \n##  Aeromonas                 0.000      0.368     0.368           1  \n##  Serratia                  0.419      0.100     0.319           1  \n##  Siccibacter               0.000      0.300     0.300           1  \n##  Streptococcus             0.279      0.000     0.279           1  \n##  \n##  Closeness centrality (normalized):\n##                Mixed diet Vegetarian abs.diff. adj.p-value  \n##  Siccibacter        0.000      0.727     0.727      0.2676  \n##  Citrobacter        0.713      0.000     0.713      0.9799  \n##  Streptococcus      0.615      0.000     0.615      0.2676  \n##  Escherichia        0.587      0.000     0.587      0.9799  \n##  Xenorhabdus        0.000      0.527     0.527      0.2676  \n##  \n##  Eigenvector centrality (normalized):\n##                       Mixed diet Vegetarian abs.diff. adj.p-value  \n##  Siccibacter               0.000      0.888     0.888      0.6553  \n##  Citrobacter               0.810      0.000     0.810      1.0000  \n##  Escherichia               0.610      0.000     0.610      1.0000  \n##  Serratia                  1.000      0.416     0.584      1.0000  \n##  Escherichia/Shigella      0.387      0.969     0.582      1.0000  \n##  \n##  _________________________________________________________\n##  Significance codes: ***: 0.001, **: 0.01, *: 0.05, .: 0.1\n\nInterpreting some results:\n\nAlmost all global network properties are significantly different between the groups (for \\(\\alpha=0.1\\)), thus reflecting the different overall network structure we already have seen in the network plots.\nFor the Jaccard index of degree, closeness, and eigenvector centrality, the probability P(&gt;=Jacc) is significant, meaning that the sets of the most central nodes are quite similar for these three measures. The Jaccard index for the hub nodes, on the other hand, is low because the two networks share only one hub node (“Erwinia”).\nAs indicated by some similarities in the clusterings, the adjusted Rand index (ARI) of the whole network is significantly different from zero and thus from random clustering. The ARI of the largest connected component (LCC), however, is close to zero due to the different clusterings in the LCC.\nThe two GCD values are significantly different from zero, indicating substantial differences in the overall network structures.\nAll nodes are also tested for having significantly different centrality (only the five nodes with the highest absolute difference are shown in the summary). For \\(\\alpha=0.05\\), some nodes have a significantly different closeness centrality, and for \\(\\alpha=0.1\\) also a significantly different eigenvector centrality. Most of these nodes have a high centrality in the one group, but are not connected in the other group.",
    "crumbs": [
      "Networks",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Network comparison</span>"
    ]
  },
  {
    "objectID": "pages/network_comparison.html#differential-association-analysis",
    "href": "pages/network_comparison.html#differential-association-analysis",
    "title": "19  Network comparison",
    "section": "\n19.4 Differential association analysis",
    "text": "19.4 Differential association analysis\nThe diffnet() function provides statistical tests to assess whether the associations themselves are significantly different between the two groups. NetCoMi also provides a plot function to generate a differential network, where two nodes are connected if they are differentially associated between the groups.\nSince we have already computed the permutation association matrices before, we can reuse them here (argument fileLoadAssoPerm).\nThe local false discovery rate is controlled at level 0.2 to account for multiplicity.\n\nspring_diffnet &lt;- diffnet(\n    spring_net_diet,\n    diffMethod = \"perm\",\n    fileLoadAssoPerm = \"general/network_data/spring_assoPerm\",\n    adjust = \"lfdr\")\n\n\nsum(spring_diffnet$pAdjustVec &lt; 0.05)\n##  [1] 0\nsum(spring_diffnet$pvalsVec &lt; 0.05)\n##  [1] 12\n\nSome of the unadjusted p-values are below the usual 5% significance level. However, none of the differences remain significant after adjusting for multiple testing so that the differential network would be empty.\nTo demonstrate the interpretation of a differential network, we set adjust to “none”, which is actually statistically incorrect.\n\nspring_diffnet_unadj &lt;- diffnet(\n    spring_net_diet,\n    pvalsVec = spring_diffnet$pvalsVec,\n    diffMethod = \"perm\",\n    alpha = 0.05,\n    adjust = \"none\")\n\nThe diffnet object is now plotted using NetCoMi’s plot() function.\n\nplot(spring_diffnet_unadj,\n     cexLabels = 1,\n     cexNodes = 1.3,\n     cexLegend = 2.5,\n     cexTitle = 3,\n     mar = c(3,2,5,15),\n     legendGroupnames = c(\"Mixed diet\", \"Vegetarian\"),\n     legendPos = c(1.2,1.5),\n     legendArgs = list(lwd = 4),\n     fade = FALSE)\n\n\n\n\n\n\n\nEdge colors represent the direction of the associations in the two groups. For example, if two OTUs are positively correlated in the mixed diet group and uncorrelated in the vegetarian group (such as Serratia and Citrobacter), the edge color is dark green.",
    "crumbs": [
      "Networks",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Network comparison</span>"
    ]
  },
  {
    "objectID": "pages/network_comparison.html#sec-netcomp-methods",
    "href": "pages/network_comparison.html#sec-netcomp-methods",
    "title": "19  Network comparison",
    "section": "\n19.5 Network comparison methods",
    "text": "19.5 Network comparison methods\nWhile many approaches exist for the detection of differential correlations, e.g. (Yu et al. 2019; McKenzie et al. 2016; Siska and Kechris 2017), the literature on the more general case of differential association detection is scarce. Bhuva et al. (2019) compare various methods in a simulation study, which again includes many differential correlation approaches, but also more general methods such as latent differential graphical models. Gill, Datta, and Datta (2010) introduce an approach to analyze whether the connectivity of individual nodes is different between two groups using permutation tests, which is applicable to any kind of association. He et al. (2019) propose a test to infer the differential network structure for two conditional dependence networks.\n\nYu, Danyang, Zeyu Zhang, Kimberly Glass, Jessica Su, Dawn L. DeMeo, Kelan Tantisira, Scott T. Weiss, and Weiliang Qiu. 2019. “New Statistical Methods for Constructing Robust Differential Correlation Networks to characterize the interactions among microRNAs.” Scientific Reports 9 (1): 1–12. https://doi.org/10.1038/s41598-019-40167-8.\n\nMcKenzie, Andrew T., Igor Katsyv, Won Min Song, Minghui Wang, and Bin Zhang. 2016. “DGCA: A comprehensive R package for Differential Gene Correlation Analysis.” BMC Systems Biology 10 (1): 1–25. https://doi.org/10.1186/s12918-016-0349-1.\n\nSiska, Charlotte, and Katerina Kechris. 2017. “Differential correlation for sequencing data.” BMC Research Notes 10 (1): 1–9. https://doi.org/10.1186/s13104-016-2331-9.\n\nBhuva, Dharmesh D., Joseph Cursons, Gordon K. Smyth, and Melissa J. Davis. 2019. “Differential co-expression-based detection of conditional relationships in transcriptional data: comparative analysis and application to breast cancer.” Genome Biology 20 (1). https://doi.org/10.1186/S13059-019-1851-8.\n\nGill, Ryan, Somnath Datta, and Susmita Datta. 2010. “A statistical framework for differential network analysis from microarray data.” BMC Bioinformatics 11 (1): 95.\n\nHe, Hao, Shaolong Cao, Ji gang Zhang, Hui Shen, Yu Ping Wang, and Hong wen Deng. 2019. “A Statistical Test for Differential Network Analysis Based on Inference of Gaussian Graphical Model.” Scientific Reports 9 (1): 1–8. https://doi.org/10.1038/s41598-019-47362-7.\n\nShojaie, Ali. 2021. “Differential network analysis: A statistical perspective.” Wiley Interdisciplinary Reviews: Computational Statistics 13 (2): e1508. https://doi.org/10.1002/WICS.1508.\n\nLichtblau, Yvonne, Karin Zimmermann, Berit Haldemann, Dido Lenze, Michael Hummel, and Ulf Leser. 2017. “Comparative assessment of differential network analysis methods.” Briefings in Bioinformatics 18 (5): 837–50. https://doi.org/10.1093/bib/bbw061.\n\nJardim, Vinícius Carvalho, Suzana De Siqueira Santos, Andre Fujita, and Marcos Silveira Buckeridge. 2019. “BioNetStat: A tool for biological networks differential analysis.” Frontiers in Genetics 10 (JUN): 1–13. https://doi.org/10.3389/fgene.2019.00594.\nPerforming differential network analysis is challenging because network measures do not follow classical statistical distributions. Shojaie (2021) provide an overview of differential network analysis methods, but focus only on changes in edge sets. Lichtblau et al. (2017) compare differential network analysis methods that incorporate multiple local and global network measures. Jardim et al. (2019) present a tool “BioNetStat” for differential analysis of biological networks, which is able to compare certain network measures between groups.\nThe NetCoMi package used for network comparison in this chapter includes the following differential network analysis approaches::\n\n\nPermutation approach to test global network measures (e.g., transitivity, connectivity, or average path length) as well as centrality measures for group differences.\n\nJaccard index to assess the similarity between sets of most central nodes\n\nAdjusted Rand index to assess the similarity between clusterings\n\nGraphlet Correlation Distance (GCM)\n\nSee (Peschel et al. 2021) for an explanation of the first three approaches. The GCM was proposed by Yaveroğlu et al. (2014).\n\nPeschel, Stefanie, Christian L Müller, Erika von Mutius, Anne-Laure Boulesteix, and Martin Depner. 2021. “NetCoMi: network construction and comparison for microbiome data in R.” Briefings in Bioinformatics 22 (4): bbaa290. https://doi.org/10.1093/bib/bbaa290.\n\nYaveroğlu, Ömer Nebil, Noël Malod-Dognin, Darren Davis, Zoran Levnajic, Vuk Janjic, Rasa Karapandza, Aleksandar Stojmirovic, and Nataša Pržulj. 2014. “Revealing the Hidden Language of Complex Networks.” Scientific Reports 4 (1): 1–9. https://doi.org/10.1038/srep04547.\n\nFisher, Ronald Aylmer. 1970. “Statistical Methods for Research Workers.” In Breakthroughs in statistics: Methodology and distribution, 66–70. Springer.\n\nSiska, Charlotte, Russell Bowler, and Katerina Kechris. 2016. “The discordant method: A novel approach for differential correlation.” Bioinformatics 32 (5): 690–96. https://doi.org/10.1093/bioinformatics/btv633.\nTwo methods (Fisher’s z-test (Fisher 1970) and the Discordant method (Siska, Bowler, and Kechris 2016)) are available for identifying differential correlations, and permutation tests for the more general case of identifying differential associations. See (Peschel et al. 2021) for details. NetCoMi offers also a function for plotting a differential network.",
    "crumbs": [
      "Networks",
      "<span class='chapter-number'>19</span>  <span class='chapter-title'>Network comparison</span>"
    ]
  },
  {
    "objectID": "pages/cross_correlation.html",
    "href": "pages/cross_correlation.html",
    "title": "20  Cross-association",
    "section": "",
    "text": "20.1 Cross-association Analysis\nCross-association analysis is a straightforward approach that can reveal strength and type of associations between data sets. For instance, we can analyze if higher presence of a specific taxon relates to higher levels of a biomolecule. Correlation analyses within dataset were already discussed in Chapter 17.\n# Load the data\ndata(HintikkaXOData, package = \"mia\")\nmae &lt;- HintikkaXOData\n# Available alternative experiments\nexperiments(mae)\n##  ExperimentList class object of length 3:\n##   [1] microbiota: TreeSummarizedExperiment with 12706 rows and 40 columns\n##   [2] metabolites: TreeSummarizedExperiment with 38 rows and 40 columns\n##   [3] biomarkers: TreeSummarizedExperiment with 39 rows and 40 columns\n# Microbiome data\ngetWithColData(mae, \"microbiota\")\n##  class: TreeSummarizedExperiment \n##  dim: 12706 40 \n##  metadata(0):\n##  assays(1): counts\n##  rownames(12706): GAYR01026362.62.2014 CVJT01000011.50.2173 ...\n##    JRJTB:03787:02429 JRJTB:03787:02478\n##  rowData names(7): Phylum Class ... Species OTU\n##  colnames(40): C1 C2 ... C39 C40\n##  colData names(6): Sample Rat ... Fat XOS\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: NULL\n##  rowTree: NULL\n##  colLinks: NULL\n##  colTree: NULL\n# Metabolite data\ngetWithColData(mae, \"metabolites\")\n##  class: TreeSummarizedExperiment \n##  dim: 38 40 \n##  metadata(0):\n##  assays(1): nmr\n##  rownames(38): Butyrate Acetate ... Malonate 1,3-dihydroxyacetone\n##  rowData names(0):\n##  colnames(40): C1 C2 ... C39 C40\n##  colData names(6): Sample Rat ... Fat XOS\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: NULL\n##  rowTree: NULL\n##  colLinks: NULL\n##  colTree: NULL\n# Biomarker data\ngetWithColData(mae, \"biomarkers\")\n##  class: TreeSummarizedExperiment \n##  dim: 39 40 \n##  metadata(0):\n##  assays(1): signals\n##  rownames(39): Triglycerides_liver CLSs_epi ... NPY_serum\n##    Glycogen_liver\n##  rowData names(0):\n##  colnames(40): C1 C2 ... C39 C40\n##  colData names(6): Sample Rat ... Fat XOS\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: NULL\n##  rowTree: NULL\n##  colLinks: NULL\n##  colTree: NULL\nNext we can perform a cross-association analysis. Let us analyze if individual bacteria genera are correlated with concentrations of individual metabolites. This helps to answer the following question: “If bacterium X is present, is the concentration of metabolite Y lower or higher”?\n# Agglomerate microbiome data at family level\nmae[[1]] &lt;- agglomerateByPrevalence(mae[[1]], rank = \"Family\", na.rm = TRUE)\n# Does log10 transform for microbiome data\nmae[[1]] &lt;- transformAssay(mae[[1]], method = \"log10\", pseudocount = TRUE)\n\n# Give unique names, so that we do not have problems when we are creating a plot\nrownames(mae[[1]]) &lt;- getTaxonomyLabels(mae[[1]])\n\n# Cross correlates data sets\nres &lt;- getCrossAssociation(\n    mae,\n    experiment1 = 1,\n    experiment2 = 2,\n    assay.type1 = \"log10\",\n    assay.type2 = \"nmr\",\n    method = \"spearman\",\n    test.signif = TRUE,\n    p_adj_threshold = NULL,\n    cor_threshold = NULL,\n    # Remove when mia is fixed\n    mode = \"matrix\",\n    sort = TRUE,\n    show.warnings = FALSE)\nNext, we create a heatmap depicting all cross-correlations between bacterial genera and metabolite concentrations.\nlibrary(ComplexHeatmap)\nlibrary(shadowtext)\n\n# Function for marking significant correlations with \"X\"\nadd_signif &lt;- function(j, i, x, y, width, height, fill) {\n    # If the p-value is under threshold\n    if( !is.na(res$p_adj[i, j]) & res$p_adj[i, j] &lt; 0.05 ){\n        # Print \"X\"\n        grid.shadowtext(\n            sprintf(\"%s\", \"X\"), x, y, gp = gpar(fontsize = 8, col = \"#f5f5f5\"))\n    }\n}\n\n# Create a heatmap\np &lt;- Heatmap(res$cor,\n    # Print values to cells\n    cell_fun = add_signif,\n    heatmap_legend_param = list(\n        title = \"correlation\", legend_height = unit(5, \"cm\")),\n    column_names_rot = 45\n    )\np",
    "crumbs": [
      "Multiomics",
      "<span class='chapter-number'>20</span>  <span class='chapter-title'>Cross-association</span>"
    ]
  },
  {
    "objectID": "pages/multiassay_ordination.html",
    "href": "pages/multiassay_ordination.html",
    "title": "21  Ordination-based multiassay analysis",
    "section": "",
    "text": "21.1 Multi-Omics Factor Analysis\nMulti-Omics Factor Analysis (MOFA) is an unsupervised method for integrating multi-omic data sets in a downstream analysis (Argelaguet 2018). It could be seen as a generalization of principal component analysis. Yet, with the ability to infer a latent (low-dimensional) representation, shared among the multiple (-omics) data sets in hand.\nWe use the R MOFA2 package for the analysis, and install the corresponding dependencies.\nlibrary(mia)\n# Load the data\ndata(HintikkaXOData, package = \"mia\")\nmae &lt;- HintikkaXOData\nThe mae object could be used straight to create the MOFA model. Yet, we transform our assays since the model assumes normality per default, and Gaussian model is recommended (see MOFA2 FAQ). However, Poisson and Bernoulli distribution models are also offered.\nNote that duplicates, such as “uncultured”, might appear when aggregating the microbiome data by a taxonomic rank. To check for duplicates, run any(duplicated(rownames(mae[[1]]))). If it returns TRUE, then the duplicates are present. We can add rownames(mae[[1]]) &lt;- getTaxonomyLabels(mae[[1]], make.unique=TRUE) to remove them.\nlibrary(MOFA2)\n# For simplicity, classify all high-fat diets as high-fat, and all the low-fat\n# diets as low-fat diets\ncolData(mae)$Diet &lt;- ifelse(\n    colData(mae)$Diet == \"High-fat\" | colData(mae)$Diet == \"High-fat + XOS\",\n    \"High-fat\", \"Low-fat\")\n\n# Agglomerate microbiome data\nmae[[1]] &lt;- agglomerateByPrevalence(mae[[1]], rank = \"Genus\")\n# Transforming microbiome data with clr and by scaling\nmae[[1]] &lt;- transformAssay(mae[[1]], method = \"clr\", pseudocount = TRUE)\nmae[[1]] &lt;- transformAssay(\n    mae[[1]], assay.type = \"clr\", method = \"standardize\", MARGIN = \"rows\")\n\n# Transforming metabolomic data with log10 and by scaling\nmae[[2]] &lt;- transformAssay(mae[[2]], assay.type = \"nmr\", method = \"log10\")\nmae[[2]] &lt;- transformAssay(\n    mae[[2]], assay.type = \"log10\", method = \"standardize\")\n\n# Transforming biomarker data by scaling\nmae[[3]] &lt;- transformAssay(\n    mae[[3]], assay.type = \"signals\", method = \"standardize\", MARGIN = \"rows\")\n\n# Removing the assays no longer needed\nassays(mae[[1]]) &lt;- assays(mae[[1]])[\"standardize\"]\nassays(mae[[2]]) &lt;- assays(mae[[2]])[\"standardize\"]\nassays(mae[[3]]) &lt;- assays(mae[[3]])[\"standardize\"]\n\n# Building our mofa model\nmodel &lt;- create_mofa_from_MultiAssayExperiment(\n    mae,\n    groups = \"Diet\",\n    extract_metadata = TRUE)\nmodel\n##  Untrained MOFA model with the following characteristics: \n##   Number of views: 3 \n##   Views names: microbiota metabolites biomarkers \n##   Number of features (per view): 112 38 39 \n##   Number of groups: 2 \n##   Groups names: High-fat Low-fat \n##   Number of samples (per group): 20 20 \n##\nModel options can be defined as follows:\nmodel_opts &lt;- get_default_model_options(model)\nmodel_opts$num_factors &lt;- 5\nmodel_opts |&gt; head()\n##  $likelihoods\n##   microbiota metabolites  biomarkers \n##   \"gaussian\"  \"gaussian\"  \"gaussian\" \n##  \n##  $num_factors\n##  [1] 5\n##  \n##  $spikeslab_factors\n##  [1] FALSE\n##  \n##  $spikeslab_weights\n##  [1] FALSE\n##  \n##  $ard_factors\n##  [1] TRUE\n##  \n##  $ard_weights\n##  [1] TRUE\nTraining options for the model are defined in the following way:\ntrain_opts &lt;- get_default_training_options(model)\ntrain_opts |&gt; head()\n##  $maxiter\n##  [1] 1000\n##  \n##  $convergence_mode\n##  [1] \"fast\"\n##  \n##  $drop_factor_threshold\n##  [1] -1\n##  \n##  $verbose\n##  [1] FALSE\n##  \n##  $startELBO\n##  [1] 1\n##  \n##  $freqELBO\n##  [1] 5\nThe model is then prepared with prepare_mofa() and trained with run_mofa():\nmodel &lt;- prepare_mofa(\n  object = model,\n  model_options = model_opts\n)\n\n# Some systems may require the specification `use_basilisk = TRUE`\n# so it has been added to the following code\nmodel &lt;- run_mofa(model, use_basilisk = TRUE)\n##  \n##          #########################################################\n##          ###           __  __  ____  ______                    ### \n##          ###          |  \\/  |/ __ \\|  ____/\\    _             ### \n##          ###          | \\  / | |  | | |__ /  \\ _| |_           ### \n##          ###          | |\\/| | |  | |  __/ /\\ \\_   _|          ###\n##          ###          | |  | | |__| | | / ____ \\|_|            ###\n##          ###          |_|  |_|\\____/|_|/_/    \\_\\              ###\n##          ###                                                   ### \n##          ######################################################### \n##         \n##   \n##          \n##  use_float32 set to True: replacing float64 arrays by float32 arrays to speed up computations...\n##  \n##  Successfully loaded view='microbiota' group='High-fat' with N=20 samples and D=112 features...\n##  Successfully loaded view='microbiota' group='Low-fat' with N=20 samples and D=112 features...\n##  Successfully loaded view='metabolites' group='High-fat' with N=20 samples and D=38 features...\n##  Successfully loaded view='metabolites' group='Low-fat' with N=20 samples and D=38 features...\n##  Successfully loaded view='biomarkers' group='High-fat' with N=20 samples and D=39 features...\n##  Successfully loaded view='biomarkers' group='Low-fat' with N=20 samples and D=39 features...\n##  \n##  \n##  Model options:\n##  - Automatic Relevance Determination prior on the factors: True\n##  - Automatic Relevance Determination prior on the weights: True\n##  - Spike-and-slab prior on the factors: False\n##  - Spike-and-slab prior on the weights: False\n##  Likelihoods:\n##  - View 0 (microbiota): gaussian\n##  - View 1 (metabolites): gaussian\n##  - View 2 (biomarkers): gaussian\n##  \n##  \n##  \n##  \n##  ######################################\n##  ## Training the model with seed 42 ##\n##  ######################################\n##  \n##  \n##  ELBO before training: -38460.42 \n##  \n##  Iteration 1: time=0.00, ELBO=-11274.06, deltaELBO=27186.360 (70.68659170%), Factors=5\n##  Iteration 2: time=0.00, Factors=5\n##  Iteration 3: time=0.00, Factors=5\n##  Iteration 4: time=0.00, Factors=5\n##  Iteration 5: time=0.00, Factors=5\n##  Iteration 6: time=0.00, ELBO=-9939.68, deltaELBO=1334.375 (3.46947657%), Factors=5\n##  Iteration 7: time=0.00, Factors=5\n##  Iteration 8: time=0.00, Factors=5\n##  Iteration 9: time=0.00, Factors=5\n##  Iteration 10: time=0.00, Factors=5\n##  Iteration 11: time=0.00, ELBO=-9863.77, deltaELBO=75.913 (0.19737939%), Factors=5\n##  Iteration 12: time=0.00, Factors=5\n##  Iteration 13: time=0.00, Factors=5\n##  Iteration 14: time=0.00, Factors=5\n##  Iteration 15: time=0.00, Factors=5\n##  Iteration 16: time=0.00, ELBO=-9832.74, deltaELBO=31.036 (0.08069500%), Factors=5\n##  Iteration 17: time=0.00, Factors=5\n##  Iteration 18: time=0.00, Factors=5\n##  Iteration 19: time=0.00, Factors=5\n##  Iteration 20: time=0.00, Factors=5\n##  Iteration 21: time=0.00, ELBO=-9801.57, deltaELBO=31.161 (0.08102186%), Factors=5\n##  Iteration 22: time=0.00, Factors=5\n##  Iteration 23: time=0.00, Factors=5\n##  Iteration 24: time=0.00, Factors=5\n##  Iteration 25: time=0.00, Factors=5\n##  Iteration 26: time=0.00, ELBO=-9793.82, deltaELBO=7.757 (0.02016822%), Factors=5\n##  Iteration 27: time=0.00, Factors=5\n##  Iteration 28: time=0.00, Factors=5\n##  Iteration 29: time=0.00, Factors=5\n##  Iteration 30: time=0.00, Factors=5\n##  Iteration 31: time=0.00, ELBO=-9790.66, deltaELBO=3.159 (0.00821374%), Factors=5\n##  Iteration 32: time=0.00, Factors=5\n##  Iteration 33: time=0.00, Factors=5\n##  Iteration 34: time=0.00, Factors=5\n##  Iteration 35: time=0.00, Factors=5\n##  Iteration 36: time=0.00, ELBO=-9788.54, deltaELBO=2.119 (0.00550859%), Factors=5\n##  Iteration 37: time=0.00, Factors=5\n##  Iteration 38: time=0.00, Factors=5\n##  Iteration 39: time=0.00, Factors=5\n##  Iteration 40: time=0.00, Factors=5\n##  Iteration 41: time=0.00, ELBO=-9786.85, deltaELBO=1.692 (0.00439837%), Factors=5\n##  Iteration 42: time=0.00, Factors=5\n##  Iteration 43: time=0.00, Factors=5\n##  Iteration 44: time=0.00, Factors=5\n##  Iteration 45: time=0.00, Factors=5\n##  Iteration 46: time=0.00, ELBO=-9785.32, deltaELBO=1.528 (0.00397286%), Factors=5\n##  Iteration 47: time=0.00, Factors=5\n##  Iteration 48: time=0.00, Factors=5\n##  Iteration 49: time=0.00, Factors=5\n##  Iteration 50: time=0.00, Factors=5\n##  Iteration 51: time=0.00, ELBO=-9783.93, deltaELBO=1.390 (0.00361446%), Factors=5\n##  Iteration 52: time=0.00, Factors=5\n##  Iteration 53: time=0.00, Factors=5\n##  Iteration 54: time=0.00, Factors=5\n##  Iteration 55: time=0.00, Factors=5\n##  Iteration 56: time=0.00, ELBO=-9782.78, deltaELBO=1.147 (0.00298238%), Factors=5\n##  Iteration 57: time=0.00, Factors=5\n##  Iteration 58: time=0.00, Factors=5\n##  Iteration 59: time=0.00, Factors=5\n##  Iteration 60: time=0.00, Factors=5\n##  Iteration 61: time=0.00, ELBO=-9781.88, deltaELBO=0.903 (0.00234912%), Factors=5\n##  Iteration 62: time=0.00, Factors=5\n##  Iteration 63: time=0.00, Factors=5\n##  Iteration 64: time=0.00, Factors=5\n##  Iteration 65: time=0.00, Factors=5\n##  Iteration 66: time=0.00, ELBO=-9781.15, deltaELBO=0.733 (0.00190536%), Factors=5\n##  Iteration 67: time=0.00, Factors=5\n##  Iteration 68: time=0.00, Factors=5\n##  Iteration 69: time=0.00, Factors=5\n##  Iteration 70: time=0.00, Factors=5\n##  Iteration 71: time=0.00, ELBO=-9780.52, deltaELBO=0.622 (0.00161814%), Factors=5\n##  Iteration 72: time=0.00, Factors=5\n##  Iteration 73: time=0.00, Factors=5\n##  Iteration 74: time=0.00, Factors=5\n##  Iteration 75: time=0.00, Factors=5\n##  Iteration 76: time=0.00, ELBO=-9779.98, deltaELBO=0.546 (0.00142075%), Factors=5\n##  Iteration 77: time=0.00, Factors=5\n##  Iteration 78: time=0.00, Factors=5\n##  Iteration 79: time=0.00, Factors=5\n##  Iteration 80: time=0.00, Factors=5\n##  Iteration 81: time=0.00, ELBO=-9779.49, deltaELBO=0.489 (0.00127231%), Factors=5\n##  Iteration 82: time=0.00, Factors=5\n##  Iteration 83: time=0.00, Factors=5\n##  Iteration 84: time=0.00, Factors=5\n##  Iteration 85: time=0.00, Factors=5\n##  Iteration 86: time=0.00, ELBO=-9779.04, deltaELBO=0.446 (0.00116022%), Factors=5\n##  Iteration 87: time=0.00, Factors=5\n##  Iteration 88: time=0.00, Factors=5\n##  Iteration 89: time=0.00, Factors=5\n##  Iteration 90: time=0.00, Factors=5\n##  Iteration 91: time=0.00, ELBO=-9778.63, deltaELBO=0.412 (0.00107075%), Factors=5\n##  Iteration 92: time=0.00, Factors=5\n##  Iteration 93: time=0.00, Factors=5\n##  Iteration 94: time=0.00, Factors=5\n##  Iteration 95: time=0.00, Factors=5\n##  Iteration 96: time=0.00, ELBO=-9778.25, deltaELBO=0.384 (0.00099829%), Factors=5\n##  Iteration 97: time=0.00, Factors=5\n##  Iteration 98: time=0.00, Factors=5\n##  Iteration 99: time=0.00, Factors=5\n##  Iteration 100: time=0.00, Factors=5\n##  Iteration 101: time=0.00, ELBO=-9777.89, deltaELBO=0.362 (0.00094041%), Factors=5\n##  Iteration 102: time=0.00, Factors=5\n##  Iteration 103: time=0.00, Factors=5\n##  Iteration 104: time=0.00, Factors=5\n##  Iteration 105: time=0.00, Factors=5\n##  Iteration 106: time=0.00, ELBO=-9777.54, deltaELBO=0.343 (0.00089062%), Factors=5\n##  Iteration 107: time=0.00, Factors=5\n##  Iteration 108: time=0.00, Factors=5\n##  Iteration 109: time=0.00, Factors=5\n##  Iteration 110: time=0.00, Factors=5\n##  Iteration 111: time=0.00, ELBO=-9777.22, deltaELBO=0.327 (0.00085053%), Factors=5\n##  Iteration 112: time=0.00, Factors=5\n##  Iteration 113: time=0.00, Factors=5\n##  Iteration 114: time=0.00, Factors=5\n##  Iteration 115: time=0.00, Factors=5\n##  Iteration 116: time=0.00, ELBO=-9776.90, deltaELBO=0.314 (0.00081733%), Factors=5\n##  Iteration 117: time=0.00, Factors=5\n##  Iteration 118: time=0.00, Factors=5\n##  Iteration 119: time=0.00, Factors=5\n##  Iteration 120: time=0.00, Factors=5\n##  Iteration 121: time=0.00, ELBO=-9776.60, deltaELBO=0.303 (0.00078783%), Factors=5\n##  Iteration 122: time=0.00, Factors=5\n##  Iteration 123: time=0.00, Factors=5\n##  Iteration 124: time=0.00, Factors=5\n##  Iteration 125: time=0.00, Factors=5\n##  Iteration 126: time=0.00, ELBO=-9776.30, deltaELBO=0.294 (0.00076567%), Factors=5\n##  Iteration 127: time=0.00, Factors=5\n##  Iteration 128: time=0.00, Factors=5\n##  Iteration 129: time=0.00, Factors=5\n##  Iteration 130: time=0.00, Factors=5\n##  Iteration 131: time=0.00, ELBO=-9776.02, deltaELBO=0.286 (0.00074251%), Factors=5\n##  Iteration 132: time=0.00, Factors=5\n##  Iteration 133: time=0.00, Factors=5\n##  Iteration 134: time=0.00, Factors=5\n##  Iteration 135: time=0.00, Factors=5\n##  Iteration 136: time=0.00, ELBO=-9775.74, deltaELBO=0.281 (0.00073046%), Factors=5\n##  Iteration 137: time=0.00, Factors=5\n##  Iteration 138: time=0.00, Factors=5\n##  Iteration 139: time=0.00, Factors=5\n##  Iteration 140: time=0.00, Factors=5\n##  Iteration 141: time=0.00, ELBO=-9775.46, deltaELBO=0.277 (0.00071921%), Factors=5\n##  Iteration 142: time=0.00, Factors=5\n##  Iteration 143: time=0.00, Factors=5\n##  Iteration 144: time=0.00, Factors=5\n##  Iteration 145: time=0.00, Factors=5\n##  Iteration 146: time=0.00, ELBO=-9775.19, deltaELBO=0.272 (0.00070694%), Factors=5\n##  Iteration 147: time=0.00, Factors=5\n##  Iteration 148: time=0.00, Factors=5\n##  Iteration 149: time=0.00, Factors=5\n##  Iteration 150: time=0.00, Factors=5\n##  Iteration 151: time=0.00, ELBO=-9774.92, deltaELBO=0.270 (0.00070197%), Factors=5\n##  Iteration 152: time=0.00, Factors=5\n##  Iteration 153: time=0.00, Factors=5\n##  Iteration 154: time=0.00, Factors=5\n##  Iteration 155: time=0.00, Factors=5\n##  Iteration 156: time=0.00, ELBO=-9774.65, deltaELBO=0.268 (0.00069757%), Factors=5\n##  Iteration 157: time=0.00, Factors=5\n##  Iteration 158: time=0.00, Factors=5\n##  Iteration 159: time=0.00, Factors=5\n##  Iteration 160: time=0.00, Factors=5\n##  Iteration 161: time=0.00, ELBO=-9774.38, deltaELBO=0.267 (0.00069391%), Factors=5\n##  Iteration 162: time=0.00, Factors=5\n##  Iteration 163: time=0.00, Factors=5\n##  Iteration 164: time=0.00, Factors=5\n##  Iteration 165: time=0.00, Factors=5\n##  Iteration 166: time=0.00, ELBO=-9774.12, deltaELBO=0.266 (0.00069097%), Factors=5\n##  Iteration 167: time=0.00, Factors=5\n##  Iteration 168: time=0.00, Factors=5\n##  Iteration 169: time=0.00, Factors=5\n##  Iteration 170: time=0.00, Factors=5\n##  Iteration 171: time=0.00, ELBO=-9773.85, deltaELBO=0.265 (0.00068801%), Factors=5\n##  Iteration 172: time=0.00, Factors=5\n##  Iteration 173: time=0.00, Factors=5\n##  Iteration 174: time=0.00, Factors=5\n##  Iteration 175: time=0.00, Factors=5\n##  Iteration 176: time=0.00, ELBO=-9773.59, deltaELBO=0.265 (0.00068873%), Factors=5\n##  Iteration 177: time=0.00, Factors=5\n##  Iteration 178: time=0.00, Factors=5\n##  Iteration 179: time=0.00, Factors=5\n##  Iteration 180: time=0.00, Factors=5\n##  Iteration 181: time=0.00, ELBO=-9773.33, deltaELBO=0.263 (0.00068332%), Factors=5\n##  Iteration 182: time=0.00, Factors=5\n##  Iteration 183: time=0.00, Factors=5\n##  Iteration 184: time=0.00, Factors=5\n##  Iteration 185: time=0.00, Factors=5\n##  Iteration 186: time=0.00, ELBO=-9773.06, deltaELBO=0.262 (0.00068149%), Factors=5\n##  Iteration 187: time=0.00, Factors=5\n##  Iteration 188: time=0.00, Factors=5\n##  Iteration 189: time=0.00, Factors=5\n##  Iteration 190: time=0.00, Factors=5\n##  Iteration 191: time=0.00, ELBO=-9772.80, deltaELBO=0.259 (0.00067342%), Factors=5\n##  Iteration 192: time=0.00, Factors=5\n##  Iteration 193: time=0.00, Factors=5\n##  Iteration 194: time=0.00, Factors=5\n##  Iteration 195: time=0.00, Factors=5\n##  Iteration 196: time=0.00, ELBO=-9772.55, deltaELBO=0.257 (0.00066771%), Factors=5\n##  Iteration 197: time=0.00, Factors=5\n##  Iteration 198: time=0.00, Factors=5\n##  Iteration 199: time=0.00, Factors=5\n##  Iteration 200: time=0.00, Factors=5\n##  Iteration 201: time=0.00, ELBO=-9772.30, deltaELBO=0.253 (0.00065654%), Factors=5\n##  Iteration 202: time=0.00, Factors=5\n##  Iteration 203: time=0.00, Factors=5\n##  Iteration 204: time=0.00, Factors=5\n##  Iteration 205: time=0.00, Factors=5\n##  Iteration 206: time=0.00, ELBO=-9772.05, deltaELBO=0.247 (0.00064343%), Factors=5\n##  Iteration 207: time=0.00, Factors=5\n##  Iteration 208: time=0.00, Factors=5\n##  Iteration 209: time=0.00, Factors=5\n##  Iteration 210: time=0.00, Factors=5\n##  Iteration 211: time=0.00, ELBO=-9771.81, deltaELBO=0.241 (0.00062637%), Factors=5\n##  Iteration 212: time=0.00, Factors=5\n##  Iteration 213: time=0.00, Factors=5\n##  Iteration 214: time=0.00, Factors=5\n##  Iteration 215: time=0.00, Factors=5\n##  Iteration 216: time=0.00, ELBO=-9771.57, deltaELBO=0.233 (0.00060504%), Factors=5\n##  Iteration 217: time=0.00, Factors=5\n##  Iteration 218: time=0.00, Factors=5\n##  Iteration 219: time=0.00, Factors=5\n##  Iteration 220: time=0.00, Factors=5\n##  Iteration 221: time=0.00, ELBO=-9771.35, deltaELBO=0.222 (0.00057816%), Factors=5\n##  Iteration 222: time=0.00, Factors=5\n##  Iteration 223: time=0.00, Factors=5\n##  Iteration 224: time=0.00, Factors=5\n##  Iteration 225: time=0.00, Factors=5\n##  Iteration 226: time=0.00, ELBO=-9771.14, deltaELBO=0.213 (0.00055305%), Factors=5\n##  Iteration 227: time=0.00, Factors=5\n##  Iteration 228: time=0.00, Factors=5\n##  Iteration 229: time=0.00, Factors=5\n##  Iteration 230: time=0.00, Factors=5\n##  Iteration 231: time=0.00, ELBO=-9770.94, deltaELBO=0.202 (0.00052452%), Factors=5\n##  Iteration 232: time=0.00, Factors=5\n##  Iteration 233: time=0.00, Factors=5\n##  Iteration 234: time=0.00, Factors=5\n##  Iteration 235: time=0.00, Factors=5\n##  Iteration 236: time=0.00, ELBO=-9770.75, deltaELBO=0.190 (0.00049300%), Factors=5\n##  Iteration 237: time=0.00, Factors=5\n##  Iteration 238: time=0.00, Factors=5\n##  Iteration 239: time=0.00, Factors=5\n##  Iteration 240: time=0.00, Factors=5\n##  Iteration 241: time=0.00, ELBO=-9770.57, deltaELBO=0.178 (0.00046309%), Factors=5\n##  \n##  Converged!\n##  \n##  \n##  \n##  #######################\n##  ## Training finished ##\n##  #######################\n##  \n##  \n##  Saving model in /tmp/RtmpAgsoU5/mofa_20241006-073820.hdf5...\nThe explained variance is visualized with the plot_variance_explained() function.\nlibrary(patchwork)\nlibrary(ggplot2)\n\nplot_list &lt;- plot_variance_explained(\n    model,\n    x = \"view\", y = \"factor\",\n    plot_total = TRUE)\n\nwrap_plots(plot_list, nrow = 2) +\n    plot_annotation(\n        title = \"Variance Explained per factor and assay\",\n        theme = theme(plot.title = element_text(hjust = 0.5)))\nFrom the plot, we can observe that the microbiota accounts for most of the variability in the data. Biomarkers do not significantly explain the variability. The variability in the microbiota is primarily captured in factors 1 and 2, while metabolites are primarily represented in factor 2.\nWe can then visualize the top weights for microbiota and metabolites for the first two factors to analyze co-varying features.\nplot_list &lt;- lapply(\n    c(\"microbiota\", \"metabolites\"),\n    plot_top_weights,\n    object = model,\n    factors = c(1, 2),\n    nfeatures = 10\n    )\n\nwrap_plots(plot_list, ncol = 1) & theme(text = element_text(size = 8))\nFrom the visualization, we can see that glycerol, lactate, and choline are positively associated with factor 2, while acetate is negatively associated among the metabolites. In terms of microbiota, Ruminococcaceae and Ruminodostridium, for instance, are positively associated with the same factor. This indicates that these features co-vary in the data, suggesting a positive association with glycerol, lactate, and choline, and a negative association with acetate and these microbes.\nMore tutorials and examples of using the package are found at MOFA2 tutorials.",
    "crumbs": [
      "Multiomics",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Ordination-based multiassay analysis</span>"
    ]
  },
  {
    "objectID": "pages/multiassay_ordination.html#sec-mofa",
    "href": "pages/multiassay_ordination.html#sec-mofa",
    "title": "21  Ordination-based multiassay analysis",
    "section": "",
    "text": "Argelaguet, Ricard et al. 2018. “Multi-Omics Factor Analysis—a Framework for Unsupervised Integration of Multi-Omics Data Sets.” Molecular Systems Biology 14 (6): e8124. https://doi.org/10.15252/msb.20178124.",
    "crumbs": [
      "Multiomics",
      "<span class='chapter-number'>21</span>  <span class='chapter-title'>Ordination-based multiassay analysis</span>"
    ]
  },
  {
    "objectID": "pages/integrated_learner.html",
    "href": "pages/integrated_learner.html",
    "title": "22  Multi-omics prediction and classification",
    "section": "",
    "text": "22.1 Import and preprocess data\nWe use the publicly available Inflammatory Bowel Diseases (IBD) data from the curatedMetagenomicData package (Lloyd-Price et al. 2019), where we aim to predict IBD disease status based on both taxonomic (species abundances) and functional (pathway abundances) profiles.\nlibrary(curatedMetagenomicData)\nlibrary(dplyr)\nlibrary(mia)\n\ntse1 &lt;- sampleMetadata |&gt;\n  filter(study_name == \"HMP_2019_ibdmdb\") |&gt;\n  returnSamples(\"relative_abundance\", rownames = \"short\")\n\ntse2 &lt;- sampleMetadata |&gt;\n  filter(study_name == \"HMP_2019_ibdmdb\") |&gt;\n  returnSamples(\"pathway_abundance\", rownames = \"short\")\n\n# Create a MAE object\nmae &lt;- MultiAssayExperiment(\n    ExperimentList(microbiota = tse1, pathway = tse2)\n    )\nmae\n##  A MultiAssayExperiment object of 2 listed\n##   experiments with user-defined names and respective classes.\n##   Containing an ExperimentList class object of length 2:\n##   [1] microbiota: TreeSummarizedExperiment with 579 rows and 1627 columns\n##   [2] pathway: SummarizedExperiment with 22113 rows and 1627 columns\n##  Functionality:\n##   experiments() - obtain the ExperimentList instance\n##   colData() - the primary/phenotype DataFrame\n##   sampleMap() - the sample coordination DataFrame\n##   `$`, `[`, `[[` - extract colData columns, subset, or experiment\n##   *Format() - convert into a long or wide DataFrame\n##   assays() - convert ExperimentList to a SimpleList of matrices\n##   exportClass() - save data to flat files\nLet’s first check how many patients are in each group.\ntable(mae[[1]]$disease) / ncol(mae[[1]])\n##  \n##      IBD healthy \n##   0.7382  0.2618\nThe dataset appears to be imbalanced, with nearly three-quarters of the patients having IBD. This imbalance may impact the training process and how the model learns to predict outcomes for underrepresented group members.\nFurther data pre-processing is necessary to handle near-zero-variance features in this dataset. A combination of variance and prevalence filtering is applied to the dataset to include only meaningful features.\n# Subset by prevalence\nmae[[1]] &lt;- subsetByPrevalent(\n    mae[[1]], assay.type = \"relative_abundance\", prevalence = 0.1,\n    include.lowest = TRUE)\nmae[[2]] &lt;- subsetByPrevalent(\n    mae[[2]], assay.type = \"pathway_abundance\", prevalence = 0.1,\n    include.lowest = TRUE)\n\n# Subset those features that have near zero variance\nrowData(mae[[1]])[[\"sd\"]] &lt;- rowSds(assay(mae[[1]], \"relative_abundance\"))\nrowData(mae[[2]])[[\"sd\"]] &lt;- rowSds(assay(mae[[2]], \"pathway_abundance\"))\nmae[[1]] &lt;- mae[[1]][ rowData(mae[[1]])[[\"sd\"]] &gt; 0.001, ]\nmae[[2]] &lt;- mae[[2]][ rowData(mae[[2]])[[\"sd\"]] &gt; 0.001, ]\n\n# Transform the data with CLR\nmae[[1]] &lt;- transformAssay(\n  mae[[1]], assay.type = \"relative_abundance\", method = \"clr\",\n  pseudocount = TRUE)\nmae[[2]] &lt;- transformAssay(\n  mae[[2]], assay.type = \"pathway_abundance\", method = \"clr\",\n  pseudocount = TRUE)\nUltimately, 250 features are retained, consisting of 125 pathways and 79 species.",
    "crumbs": [
      "Multiomics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Multi-omics prediction and classification</span>"
    ]
  },
  {
    "objectID": "pages/integrated_learner.html#import-and-preprocess-data",
    "href": "pages/integrated_learner.html#import-and-preprocess-data",
    "title": "22  Multi-omics prediction and classification",
    "section": "",
    "text": "Lloyd-Price, Jason, Cesar Arze, Ashwin N. Ananthakrishnan, Melanie Schirmer, Julian Avila-Pacheco, Tiffany W. Poon, Elizabeth Andrews, et al. 2019. “Multi-Omics of the Gut Microbial Ecosystem in Inflammatory Bowel Diseases.” Nature 569 (7758): 655–62. https://doi.org/https://doi.org/10.1038/s41586-019-1237-9.",
    "crumbs": [
      "Multiomics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Multi-omics prediction and classification</span>"
    ]
  },
  {
    "objectID": "pages/integrated_learner.html#fit-model",
    "href": "pages/integrated_learner.html#fit-model",
    "title": "22  Multi-omics prediction and classification",
    "section": "\n22.2 Fit model",
    "text": "22.2 Fit model\nWe randomly select 20% of the samples for the validation set, ensuring they are not used in training. This approach provides a more robust estimate of how well the model generalizes to unseen data.\n\nset.seed(377)\ncolData(mae)[[\"validation_set\"]] &lt;- sample(\n    c(TRUE, FALSE), size = ncol(mae[[1]]), replace = TRUE, prob = c(0.2, 0.8))\n\nNow, we are ready to fit the model using the IntegratedLearner package, which supports early, late, and intermediate fusion methods (Mallick et al. 2023). Under the hood, it leverages the SuperLearner package. The process begins by fitting “base learners” for each layer, with separate models trained for each omic dataset. Then, a “meta learner” integrates the outputs from these individual models to make the final predictions. For “base learners” and “meta learner”, we use random forest and rank loss minimization models, respectively.\n\nMallick, Himel, Anupreet Porwal, Satabdi Saha, Piyali Basak, Vladimir Svetnik, and Erina Paul. 2023. “An Integrated Bayesian Framework for Multi-Omics Prediction and Classification.” Statistics in Medicine 43 (5): 983–1002. https://doi.org/10.1002/sim.9953.\n\nlibrary(IntegratedLearner)\nlibrary(SuperLearner)\n\n# Fit the model\nfit &lt;- IntegratedLearnerFromMAE(\n  mae,\n  # Select experiments and assays\n  experiment = names(experiments(mae)),\n  assay.type = c(\"clr\", \"clr\"),\n  # Select columns from sample metadata\n  outcome.col = \"disease\",\n  valid.col = \"validation_set\",\n  # Options for base and meta models\n  base_learner = \"SL.randomForest\",\n  meta_learner = \"SL.nnls.auc\",\n  # The outcome is binary\n  family = binomial()\n)\n##  Running base model for layer  1 ...\n##  Running base model for layer  2 ... \n##  Running stacked model...\n##  Running concatenated model...\n##  Time for model fit : 1.615 minutes \n##  ========================================\n##  Model fit for individual layers: SL.randomForest \n##  Model fit for stacked layer: SL.nnls.auc \n##  Model fit for concatenated layer: SL.randomForest \n##  ========================================\n##  AUC metric for training data: \n##  Individual layers: \n##  microbiota    pathway \n##       0.971      0.947 \n##  ======================\n##  Stacked model:0.97 \n##  ======================\n##  Concatenated model:0.965 \n##  ======================\n##  ========================================\n##  AUC metric for test data: \n##  Individual layers: \n##  microbiota    pathway \n##       0.961      0.929 \n##  ======================\n##  Stacked model:0.96 \n##  ======================\n##  Concatenated model:0.949 \n##  ======================\n##  ========================================\n##  Weights for individual layers predictions in IntegratedLearner: \n##  microbiota    pathway \n##       0.949      0.051 \n##  ========================================\n\nThe output include the following models:\n- Individual models: Trained separately for each omic dataset.\n- Stacked model (late fusion): Combines the predictions from each individual model into a single meta-model.\n- Concatenated model (early fusion): Trains a model where all features are merged before training.",
    "crumbs": [
      "Multiomics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Multi-omics prediction and classification</span>"
    ]
  },
  {
    "objectID": "pages/integrated_learner.html#visualize-results",
    "href": "pages/integrated_learner.html#visualize-results",
    "title": "22  Multi-omics prediction and classification",
    "section": "\n22.3 Visualize results",
    "text": "22.3 Visualize results\nWe can summarize the model performance using a Receiver Operating Characteristic (ROC) plot.\n\nlibrary(tidyverse)\nlibrary(cowplot)\n\np &lt;- IntegratedLearner:::plot.learner(fit)\n\n\n\n\n\n\n\nBased on the ROC plot described below, we observe that the AUC is 0.929 when considering only the pathway abundance data in the model, and 0.961 for the model including only the species abundance data. The AUC increases to 0.949 when using the early fusion model and reaches 0.96 with the late fusion model. Overall, most integrated classifiers outperform individual layers in distinguishing between T2D and healthy controls.\nThe model’s performance can also be evaluated and summarized using a confusion matrix.\n\nlibrary(caret)\n\nobs &lt;- factor(fit$Y_test)\npred &lt;- ifelse(fit$yhat.test$stacked &gt; 0.5, levels(obs)[[2]], levels(obs)[[1]])\npred &lt;- factor(pred, levels = levels(obs))\nconf &lt;- confusionMatrix(data = pred, reference = obs)\nconf\n##  Confusion Matrix and Statistics\n##  \n##            Reference\n##  Prediction   1   2\n##           1 257  22\n##           2   2  70\n##                                        \n##                 Accuracy : 0.932       \n##                   95% CI : (0.9, 0.956)\n##      No Information Rate : 0.738       \n##      P-Value [Acc &gt; NIR] : &lt; 2e-16     \n##                                        \n##                    Kappa : 0.81        \n##                                        \n##   Mcnemar's Test P-Value : 0.000105    \n##                                        \n##              Sensitivity : 0.992       \n##              Specificity : 0.761       \n##           Pos Pred Value : 0.921       \n##           Neg Pred Value : 0.972       \n##               Prevalence : 0.738       \n##           Detection Rate : 0.732       \n##     Detection Prevalence : 0.795       \n##        Balanced Accuracy : 0.877       \n##                                        \n##         'Positive' Class : 1           \n##  \n\nThe model appears to be performing well the the accuracy being 93.16%. The model seems to precict correctly almost all IBD patients. It is also worth noting that over three-quarters of the controls are classified correctly\nLastly, we may be interested in identifying the features that contribute most to predicting the outcome. To do this, we first extract feature importance scores from the individual models. Next, we scale these importance scores based on the weights assigned to each layer in the stacked model. This process provides us with the overall importance of each feature in the final model.\n\nlibrary(ggplot2)\n\n# Get individual models\nmodels &lt;- fit$model_fits$model_layers\n# Get importances\nimportances &lt;- lapply(seq_len(length(models)), function(i){\n  # Get importances\n  temp &lt;- models[[i]]$importance\n  # Scale based on weight in stacked model\n  temp &lt;- temp * fit$weights[[i]]\n  return(temp)\n  })\n# Combine and order to most important features\nimportances &lt;- do.call(rbind, importances)\nimportances &lt;- importances[\n  order(importances, decreasing = TRUE), , drop = FALSE]\n# Add features to column\nimportances &lt;- importances |&gt; as.data.frame()\nimportances[[\"Feature\"]] &lt;- factor(\n  rownames(importances), levels = rownames(importances))\n# Convert to 0-1 scale\nimportances[[1]] &lt;- importances[[1]] / sum(importances[[1]])\n# Get top 20 importances\ntop_n &lt;- 20\nimportances &lt;- importances[ seq_len(top_n), ]\n\n# Plot as a bar plot\np &lt;- ggplot(importances, aes(x = MeanDecreaseGini, y = Feature)) +\n  geom_bar(stat = \"identity\")\np\n\n\n\n\n\n\n\nFrom the plot, we can observe that Alistipes putredinis and Alistipes putredinis appear to have the greatest predictive power among all the features in determining the outcome. However, the predictive power appears to be fairly evenly distributed across all features.\n\n\n\n\n\n\nSummary\n\n\n\nFor more details on modeling with IntegratedLearner, refer to IntegratedLearner vignette.",
    "crumbs": [
      "Multiomics",
      "<span class='chapter-number'>22</span>  <span class='chapter-title'>Multi-omics prediction and classification</span>"
    ]
  },
  {
    "objectID": "pages/machine_learning.html",
    "href": "pages/machine_learning.html",
    "title": "23  Machine learning",
    "section": "",
    "text": "23.1 Unsupervised machine learning\n“Unsupervised” means that the labels (e.g., patient status) are not known, and patterns are learned based solely on the data, such as an abundance table. Unsupervised ML is also known as data mining, where patterns are extracted from large datasets.\nCommon tasks in unsupervised machine learning include dimension reduction and clustering that we already discussed in Chapter 14 and Chapter 15, respectively.",
    "crumbs": [
      "Machine learning & statistical modeling",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Machine learning</span>"
    ]
  },
  {
    "objectID": "pages/machine_learning.html#supervised-machine-learning",
    "href": "pages/machine_learning.html#supervised-machine-learning",
    "title": "23  Machine learning",
    "section": "\n23.2 Supervised machine learning",
    "text": "23.2 Supervised machine learning\n“Supervised” means that the training data is introduced beforehand. The training data contains labels (e.g., patient status), and the model is fitted based on the training data. After fitting, the model is utilized to predict labels of data whose labels are not known. Common tasks for supervised machine learning includes classification (predict classes) and regression (predict numeric values).\n\n\n\n\n\n\nData leakage is a common pitfall.\n\n\n\nData leakage occurs when information from the test set influences the model training process, leading to overly optimistic performance estimates. This can happen, for example, if preprocessing steps like scaling are applied to both the training and test data together, allowing the model to indirectly “see” the test data during training.\nIn supervised machine learning, the goal is to train a model that can predict outcomes for unseen data. To evaluate a model’s generalization ability, the data is typically split into training and test sets, often with a ratio of 70% training to 30% testing (or 80% vs 20%). The test set is kept separate and untouched during training. Training is usually enhanced with cross-validation to improve the model’s robustness. After training, the model’s performance is assessed using the test set, providing an estimate of its ability to predict new samples accurately.\nHowever, when the dataset is small, splitting it into training and test sets might not be feasible. In such cases, cross-validation alone can be used to provide a rough estimate of the model’s performance. While this approach is not as reliable as having a separate test set, it can still give valuable insights into how well the model might perform on new data.\n\n\n\nlibrary(mia)\nlibrary(curatedMetagenomicData)\nlibrary(dplyr)\n\nsamples &lt;- sampleMetadata[ sampleMetadata[[\"study_name\"]] == \"QinJ_2012\", ]\n\ntse &lt;- returnSamples(\n    samples, dataType = \"relative_abundance\",\n    counts = TRUE, rownames = \"short\")\n\ntable(tse[[\"disease\"]])\n##  \n##      T2D healthy \n##      170     193\n\nWe have binary classification problem. We are aiming to predict type 2 diabetes from control samples. Let’s first preprocess the data.\n\n# We calculate all available alpha diversity measures\nvariables_before &lt;- colnames(colData(tse))\ntse &lt;- addAlpha(tse, assay.type = \"relative_abundance\")\n# By comparing variables, we get which indices were calculated\nindex &lt;- colnames(colData(tse))[ !colnames(colData(tse)) %in% variables_before ]\n\n# Agglomerate based on prevalence\n# tse &lt;- agglomerateByPrevalence(tse, prevalence = 0.5, detection = 0.01)\n# Apply CLR transform\ntse &lt;- transformAssay(\n    tse, assay.type = \"relative_abundance\", method = \"clr\", MARGIN = \"cols\",\n    pseudocount = TRUE)\n\n# Get assay\nassay &lt;- assay(tse, \"clr\")\n# Transpose assay\nassay &lt;- t(assay)\n# Add alpha diversity measures\nassay &lt;- cbind(assay, colData(tse)[, index, drop = FALSE])\n# Drop variables that have zero variance\nind &lt;- sapply(assay, sd, na.rm = TRUE)\nind &lt;- is.na(ind) | ind == 0\nassay &lt;- assay[, !ind, drop = FALSE]\n# Convert into data.frame\nassay &lt;- as.data.frame(assay)\n# Get labels, i.e., known outcome\nlabels &lt;- tse[[\"disease\"]]\n\nIn the example below, we use mikropml package. We aim to predict diagnosis (adenoma, colorectal cancer, or control) based on the microbial data.\n\nlibrary(mikropml)\n\n#  Combine data into single data.frame\ndf &lt;- assay\ndf[[\"diagnosis\"]] &lt;- labels\n\n# Run random forest\nresults &lt;- run_ml(\n    df, \"rf\", outcome_colname = \"diagnosis\",\n    kfold = 2, cv_times = 5, training_frac = 0.8)\n\n# Get the final model\nres &lt;- results[[\"trained_model\"]][[\"finalModel\"]]\n# Print result\nconfusionMatrix(data = res[[\"predicted\"]], reference = res[[\"y\"]])\n##  Confusion Matrix and Statistics\n##  \n##            Reference\n##  Prediction T2D healthy\n##     T2D      80      46\n##     healthy  56     109\n##                                          \n##                 Accuracy : 0.649         \n##                   95% CI : (0.592, 0.704)\n##      No Information Rate : 0.533         \n##      P-Value [Acc &gt; NIR] : 3.56e-05      \n##                                          \n##                    Kappa : 0.293         \n##                                          \n##   Mcnemar's Test P-Value : 0.373         \n##                                          \n##              Sensitivity : 0.588         \n##              Specificity : 0.703         \n##           Pos Pred Value : 0.635         \n##           Neg Pred Value : 0.661         \n##               Prevalence : 0.467         \n##           Detection Rate : 0.275         \n##     Detection Prevalence : 0.433         \n##        Balanced Accuracy : 0.646         \n##                                          \n##         'Positive' Class : T2D           \n##  \n\nThe model performs relatively well considering the data type as predicting outcomes based on complex microbiome data is typically challenging.\nIn this second model, we try to improve the prediction accuracy. We address the imbalanced data by applying class weights. Moreover, we utilize a more complex model, XGBoost, which is another commonly used algorithm in bioinformatics, usually one of the best performing models for tabular data (Shwartz-Ziv and Armon 2022). We use caret package which offers a R framework for machine learning.\n\nShwartz-Ziv, Ravid, and Amitai Armon. 2022. “Tabular Data: Deep Learning Is Not All You Need.” Information Fusion 81: 84–90. https://doi.org/https://doi.org/10.1016/j.inffus.2021.11.011.\n\nlibrary(caret)\nlibrary(xgboost)\n\n# Set seed for reproducibility\nset.seed(6358)\n\n# Calculate class weights\nweights &lt;- 1 / (table(tse[[\"disease\"]]) / ncol(tse))\nclass_weights &lt;- weights[ match(labels, names(weights)) ]\n\n# Specify train control\ntrain_control &lt;- trainControl(\n    method = \"cv\", number = 5,\n    classProbs = TRUE,\n    savePredictions = \"final\",\n    allowParallel = TRUE,\n    summaryFunction = twoClassSummary\n    )\n\n# Specify hyperparameter tuning grid. Adjust the values for your own purpose.\n# We have here less values to make the computation faster for this example.\ntune_grid &lt;- expand.grid(\n    nrounds = c(100, 250),\n    max_depth = c(10),\n    colsample_bytree = c(0.4, 0.6),\n    eta = c(0.1, 0.3),\n    gamma = c(0),\n    min_child_weight = c(3, 4),\n    subsample = c(0.6, 0.8)\n)\n\n# Train the model\nmodel &lt;- train(\n    x = assay,\n    y = labels,\n    preProcess = c(\"center\", \"scale\"),\n    method = \"xgbTree\",\n    objective = \"binary:logistic\",\n    eval_metric = \"auc\",\n    metric = \"ROC\",\n    tuneGrid = tune_grid,\n    trControl = train_control,\n    weights = class_weights,\n    max_delta_step = 1\n)\n##  [07:42:57] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:42:57] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:42:58] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:42:58] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:42:59] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:42:59] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:00] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:00] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:02] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:02] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:03] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:03] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:04] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:04] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:05] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:05] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:06] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:06] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:06] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:06] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:07] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:07] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:08] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:08] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:08] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:09] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:09] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:09] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:10] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:10] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:11] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:11] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:12] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:12] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:13] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:13] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:14] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:14] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:14] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:15] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:16] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:16] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:17] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:17] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:18] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:18] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:19] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:19] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:19] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:20] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:20] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:20] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:21] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:21] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:22] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:22] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:22] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:22] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:23] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:23] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:24] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:24] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:25] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:25] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:26] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:26] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:27] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:27] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:27] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:27] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:28] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:28] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:29] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:29] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:31] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:31] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:32] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:32] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:33] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:33] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:33] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:33] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:34] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:34] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:35] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:35] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:35] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:36] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:36] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:36] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:37] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:37] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:38] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:38] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:39] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:39] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:40] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:40] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:40] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:41] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:41] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:41] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:42] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:42] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:43] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:43] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:44] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:44] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:45] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:45] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:47] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:47] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:47] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:47] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:48] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:48] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:49] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:49] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:49] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:49] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:50] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:50] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:51] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:51] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:52] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:52] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:52] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:52] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:53] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:53] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:54] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:54] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:56] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:56] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:57] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:57] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:58] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:58] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:59] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:43:59] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:44:00] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:44:00] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:44:01] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:44:01] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:44:02] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:44:02] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:44:02] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:44:02] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:44:03] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:44:03] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:44:04] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:44:04] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:44:04] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:44:04] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:44:05] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:44:05] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:44:06] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:44:06] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:44:07] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n##  [07:44:07] WARNING: src/c_api/c_api.cc:935: `ntree_limit` is deprecated, use `iteration_range` instead.\n\n# Get predictions\nres &lt;- model[[\"pred\"]]\n# Print result\nconfusionMatrix(data = res[[\"pred\"]], reference = res[[\"obs\"]])\n##  Confusion Matrix and Statistics\n##  \n##            Reference\n##  Prediction T2D healthy\n##     T2D     109      57\n##     healthy  61     136\n##                                          \n##                 Accuracy : 0.675         \n##                   95% CI : (0.624, 0.723)\n##      No Information Rate : 0.532         \n##      P-Value [Acc &gt; NIR] : 2.05e-08      \n##                                          \n##                    Kappa : 0.346         \n##                                          \n##   Mcnemar's Test P-Value : 0.782         \n##                                          \n##              Sensitivity : 0.641         \n##              Specificity : 0.705         \n##           Pos Pred Value : 0.657         \n##           Neg Pred Value : 0.690         \n##               Prevalence : 0.468         \n##           Detection Rate : 0.300         \n##     Detection Prevalence : 0.457         \n##        Balanced Accuracy : 0.673         \n##                                          \n##         'Positive' Class : T2D           \n##  \n\nA receiver operating characteristic curve (ROC) is a common visualization technique for binary classification problems.\n\nlibrary(ROCR)\n\n# Get positive class\npos_class &lt;-levels(res[[\"obs\"]])[[1]]\n# Create ROC plot\npred &lt;- prediction(res[[pos_class]], ifelse(res[[\"obs\"]] == pos_class, 1, 0))\nperf &lt;- performance(pred, measure = \"tpr\", x.measure = \"fpr\")\np &lt;- plot(perf)\n\n\n\n\n\n\np\n##  NULL\n\nXGBoost model returns also feature importances that can be visualized with bar plot.\n\nlibrary(xgboost)\n\n# Get feature importance\ndf &lt;- xgb.importance(model = model$finalModel)\n# Take top 20 features\ndf &lt;- df[seq_len(20), ]\n# Factorize to preserve order\ndf[[\"Feature\"]] &lt;- factor(df[[\"Feature\"]], levels = df[[\"Feature\"]])\n# Round values, add percentage symbol\ndf[[\"Percentage\"]] &lt;- paste0(round(df[[\"Gain\"]], 3)*100, \"%\")\n\n# Create a plot\np &lt;- ggplot(df, aes(x = Feature, y = Gain)) +\n    geom_bar(stat = \"identity\") +\n    geom_text(aes(label = Percentage), hjust = -0.1, size = 2.5) +\n    expand_limits(y = max(df[[\"Gain\"]]) + 0.01) +\n    scale_y_continuous(labels = scales::percent) +\n    coord_flip()\np\n\n\n\n\n\n\n\nThese importances show which features have most of the information for predicting the outcome.\nOur model shows a slight improvement over previous versions, but its performance remains average. The key to better performance lies in the quality of the data; even the most advanced models cannot compensate for data that lacks essential information. The dataset do not have sufficient amount of data on carcinoma to build an accurate predictive model.",
    "crumbs": [
      "Machine learning & statistical modeling",
      "<span class='chapter-number'>23</span>  <span class='chapter-title'>Machine learning</span>"
    ]
  },
  {
    "objectID": "pages/statistical_modeling.html",
    "href": "pages/statistical_modeling.html",
    "title": "24  Statistical modeling",
    "section": "",
    "text": "This chapter will include introduction to statistical modeling in a future version.\n\n\n\n Back to top",
    "crumbs": [
      "Machine learning & statistical modeling",
      "<span class='chapter-number'>24</span>  <span class='chapter-title'>Statistical modeling</span>"
    ]
  },
  {
    "objectID": "pages/introductory_workflow.html",
    "href": "pages/introductory_workflow.html",
    "title": "\n25  Introductory\n",
    "section": "",
    "text": "25.1 Introduction\nHello and welcome to a comprehensive workflow using the latest R/Bioconductor tools for microbiome data science. In this tutorial, we’ll guide you through the foundational steps of microbiome analysis using miaverse. These steps are applicable to almost any of your projects and will help you understand the fundamental concepts that will skyrocket 🚀 your future microbiome analyses.\nIn this workflow, we cover basics of:",
    "crumbs": [
      "Workflows",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Introductory</span>"
    ]
  },
  {
    "objectID": "pages/introductory_workflow.html#introduction",
    "href": "pages/introductory_workflow.html#introduction",
    "title": "\n25  Introductory\n",
    "section": "",
    "text": "- Data wrangling and transformations\n- Exploration\n- Alpha and beta diversity",
    "crumbs": [
      "Workflows",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Introductory</span>"
    ]
  },
  {
    "objectID": "pages/introductory_workflow.html#load-packages",
    "href": "pages/introductory_workflow.html#load-packages",
    "title": "\n25  Introductory\n",
    "section": "\n25.2 Load packages",
    "text": "25.2 Load packages\nTo begin, we need to load the necessary packages. The following script ensures that all required packages are loaded and installed if they aren’t already.\n\n# List of packages that we need\npackages &lt;- c(\"mia\",  \"miaViz\", \"scater\")\n\n# Get packages that are already installed\npackages_already_installed &lt;- packages[ packages %in% installed.packages() ]\n\n# Get packages that need to be installed\npackages_need_to_install &lt;- setdiff( packages, packages_already_installed )\n\n# Loads BiocManager into the session. Install it if it is not already installed.\nif( !require(\"BiocManager\") ){\n    install.packages(\"BiocManager\")\n    library(\"BiocManager\")\n}\n\n# If there are packages that need to be installed, installs them with BiocManager\n# Updates old packages.\nif( length(packages_need_to_install) &gt; 0 ) {\n   install(packages_need_to_install, ask = FALSE)\n}\n\n# Load all packages into session. Stop if there are packages that were not\n# successfully loaded\npkgs_not_loaded &lt;- !sapply(packages, require, character.only = TRUE)\npkgs_not_loaded &lt;- names(pkgs_not_loaded)[ pkgs_not_loaded ]\nif( length(pkgs_not_loaded) &gt; 0 ){\n    stop(\n        \"Error in loading the following packages into the session: '\",\n        paste0(pkgs_not_loaded, collapse = \"', '\"), \"'\")\n}",
    "crumbs": [
      "Workflows",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Introductory</span>"
    ]
  },
  {
    "objectID": "pages/introductory_workflow.html#importing-data",
    "href": "pages/introductory_workflow.html#importing-data",
    "title": "\n25  Introductory\n",
    "section": "\n25.3 Importing data",
    "text": "25.3 Importing data\nThe next step involves importing your data into the R environment. Depending on the bioinformatics tools used in the upstream section of the workflow, importing the data may vary slightly. We cover the most widely used formats, with importers available for convenience. You can also build a TreeSummarizedExperiment (TreeSE) from scratch from basic text files. For more information, see Section 4.1.\nFor this demonstration, you can either use your own data or one of the built-in datasets provided by mia, which you can find here: Section 4.2.\nIn this tutorial, we’ll be using the C Tengeler et al. (2020) dataset. In the study, they explored the impact of altered microbiomes on brain structure, specifically comparing patients with ADHD (Attention Deficit Hyperactivity Disorder) to controls (see more information on this dataset from here). Let’s load this dataset into our R environment:\n\nC Tengeler, Anouk, Sarita A Dam, Maximilian Wiesmann, Jilly Naaijen, Miranda van Bodegom, Clara Belzer, Pieter J Dederen, et al. 2020. “Gut Microbiota from Persons with Attention-Deficit/Hyperactivity Disorder Affects the Brain in Mice.” Microbiome 8: 1–14. https://doi.org/10.1186/s40168-020-00816-x.\n\ndata(\"Tengeler2020\", package = \"mia\")\ntse &lt;- Tengeler2020",
    "crumbs": [
      "Workflows",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Introductory</span>"
    ]
  },
  {
    "objectID": "pages/introductory_workflow.html#subsetting-and-accessing-the-data",
    "href": "pages/introductory_workflow.html#subsetting-and-accessing-the-data",
    "title": "\n25  Introductory\n",
    "section": "\n25.4 Subsetting and accessing the data",
    "text": "25.4 Subsetting and accessing the data\nOnce loaded, we often need to wrangle and preprocess the data. The TreeSE object, a primary data container in the miaverse framework, is designed to handle complex microbiome data effectively. For more details about the TreeSE and other data containers, see Chapter 3.\n\n25.4.1 Subsetting\nIn many cases, you may need to work with only a portion of your original TreeSE for various reasons. Subsetting the TreeSE object is as straightforward as manipulating a basic matrix in R, utilizing rows and columns. For example, using the Tengeler2020 dataset, we can focus on a specific cohort. Here’s how:\n\ndim(tse)\n##  [1] 151  27\n# Subset based on sample metadata\ntse &lt;- tse[ , tse$cohort == \"Cohort_2\" ]\ndim(tse)\n##  [1] 151  10\n\nThis will create a TreeSE object only containing samples of the second cohort. You can find more information on subsetting from here Section 3.1.\n\n25.4.2 Accessing data\nYou can also access different types of data stored within the TreeSE object. Here’s a quick reminder on how to access certain types of data:\nYou can access the abundance table, or assays, as follows. In this example, we specify that we want to fetch an abundance table named “counts”. For more details, see Section 3.2.\n\nassay(tse, \"counts\") |&gt; head()\n##                   A21  A23  A25  A28 A29 A210  A22  A24  A26  A27\n##  Bacteroides     1740 1791 2368 1316 252 4052 1838 3085 1570 3621\n##  Bacteroides_1    540  229    0    0   0 1762    0 2190    0 1480\n##  Parabacteroides  145    0  109  119  31    0 5415    0 3531    0\n##  Bacteroides_2    659    0  588  542 141    0  796   84  135  293\n##  Akkermansia       84  700  440  244  25 2456  976  316 2420 1129\n##  Bacteroides_3    610    0  522  511 352    0    0   70    0  322\n\nSample (or column) metadata is stored in colData. In this example, it includes the diagnoses of the patients from whom the samples were drawn. See for more info on colData from Section 7.2.\n\ncolData(tse)\n##  DataFrame with 10 rows and 4 columns\n##       patient_status      cohort patient_status_vs_cohort sample_name\n##          &lt;character&gt; &lt;character&gt;              &lt;character&gt; &lt;character&gt;\n##  A21            ADHD    Cohort_2            ADHD_Cohort_2         A21\n##  A23            ADHD    Cohort_2            ADHD_Cohort_2         A23\n##  A25            ADHD    Cohort_2            ADHD_Cohort_2         A25\n##  A28            ADHD    Cohort_2            ADHD_Cohort_2         A28\n##  A29            ADHD    Cohort_2            ADHD_Cohort_2         A29\n##  A210        Control    Cohort_2         Control_Cohort_2        A210\n##  A22         Control    Cohort_2         Control_Cohort_2         A22\n##  A24         Control    Cohort_2         Control_Cohort_2         A24\n##  A26         Control    Cohort_2         Control_Cohort_2         A26\n##  A27         Control    Cohort_2         Control_Cohort_2         A27\n\nrowData contains data on feature characteristics, particularly taxonomic information (see Section 3.4).\n\nrd &lt;- rowData(tse)\nrd\n##  DataFrame with 151 rows and 6 columns\n##                                       Kingdom          Phylum\n##                                   &lt;character&gt;     &lt;character&gt;\n##  Bacteroides                         Bacteria   Bacteroidetes\n##  Bacteroides_1                       Bacteria   Bacteroidetes\n##  Parabacteroides                     Bacteria   Bacteroidetes\n##  Bacteroides_2                       Bacteria   Bacteroidetes\n##  Akkermansia                         Bacteria Verrucomicrobia\n##  ...                                      ...             ...\n##  Unidentified_Gastranaerophilales    Bacteria   Cyanobacteria\n##  Halomonas                           Bacteria  Proteobacteria\n##  Lachnoclostridium_4                 Bacteria      Firmicutes\n##  Parabacteroides_8                   Bacteria   Bacteroidetes\n##  Unidentified_Lachnospiraceae_14     Bacteria      Firmicutes\n##                                                 Class               Order\n##                                           &lt;character&gt;         &lt;character&gt;\n##  Bacteroides                              Bacteroidia       Bacteroidales\n##  Bacteroides_1                            Bacteroidia       Bacteroidales\n##  Parabacteroides                          Bacteroidia       Bacteroidales\n##  Bacteroides_2                            Bacteroidia       Bacteroidales\n##  Akkermansia                         Verrucomicrobiae  Verrucomicrobiales\n##  ...                                              ...                 ...\n##  Unidentified_Gastranaerophilales     Melainabacteria Gastranaerophilales\n##  Halomonas                        Gammaproteobacteria   Oceanospirillales\n##  Lachnoclostridium_4                       Clostridia       Clostridiales\n##  Parabacteroides_8                        Bacteroidia       Bacteroidales\n##  Unidentified_Lachnospiraceae_14           Clostridia       Clostridiales\n##                                                Family             Genus\n##                                           &lt;character&gt;       &lt;character&gt;\n##  Bacteroides                           Bacteroidaceae       Bacteroides\n##  Bacteroides_1                         Bacteroidaceae       Bacteroides\n##  Parabacteroides                   Porphyromonadaceae   Parabacteroides\n##  Bacteroides_2                         Bacteroidaceae       Bacteroides\n##  Akkermansia                      Verrucomicrobiaceae       Akkermansia\n##  ...                                              ...               ...\n##  Unidentified_Gastranaerophilales                                      \n##  Halomonas                             Halomonadaceae         Halomonas\n##  Lachnoclostridium_4                  Lachnospiraceae Lachnoclostridium\n##  Parabacteroides_8                 Porphyromonadaceae   Parabacteroides\n##  Unidentified_Lachnospiraceae_14      Lachnospiraceae        uncultured\n\nHere rowData(tse) returns a DataFrame with 151 rows and 7 columns. Each row represents an organism and each column a taxonomic level.",
    "crumbs": [
      "Workflows",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Introductory</span>"
    ]
  },
  {
    "objectID": "pages/introductory_workflow.html#data-wrangling",
    "href": "pages/introductory_workflow.html#data-wrangling",
    "title": "\n25  Introductory\n",
    "section": "\n25.5 Data wrangling",
    "text": "25.5 Data wrangling\n\n25.5.1 Agglomerating data\nAgglomerating your data to a specific taxonomic rank helps simplify the analysis and reveal broader patterns. By grouping taxa at a chosen level, such as Phylum, you can better understand general trends and distributions. The agglomerateByRank() function streamlines this process, making it easier to analyze and visualize data at a higher level of aggregation.\n\ntse_phylum &lt;- agglomerateByRank(tse, rank = \"Phylum\")\n\n# Check\ntse_phylum\n##  class: TreeSummarizedExperiment \n##  dim: 5 10 \n##  metadata(1): agglomerated_by_rank\n##  assays(1): counts\n##  rownames(5): Bacteroidetes Cyanobacteria Firmicutes Proteobacteria\n##    Verrucomicrobia\n##  rowData names(6): Kingdom Phylum ... Family Genus\n##  colnames(10): A21 A23 ... A26 A27\n##  colData names(4): patient_status cohort patient_status_vs_cohort\n##    sample_name\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (5 rows)\n##  rowTree: 1 phylo tree(s) (151 leaves)\n##  colLinks: NULL\n##  colTree: NULL\n\nGreat! Now, our data is aggregated to the taxonomic information up to the Phylum level, allowing the analysis to be focused on this specific rank.\n\n25.5.2 Transformation\nThe mia package provides an easy way to calculate the relative abundances for our TreeSE using the transformAssay() method.\n\ntse &lt;- transformAssay(tse, method = \"relabundance\")\ntse_phylum &lt;- transformAssay(tse_phylum, method = \"relabundance\")\n\nThis function takes the original counts assay and calculates the relative abundances, storing the newly computed matrix back into the TreeSE. You can access it in the assays of the TreeSE by specifying the name of the relative abundance assay (e.g., “relabundance”):\n\nassay(tse, \"relabundance\") |&gt; head()\n##                      A21     A23     A25     A28     A29    A210     A22\n##  Bacteroides     0.27397 0.32796 0.21594 0.19379 0.14221 0.22023 0.09614\n##  Bacteroides_1   0.08503 0.04193 0.00000 0.00000 0.00000 0.09577 0.00000\n##  Parabacteroides 0.02283 0.00000 0.00994 0.01752 0.01749 0.00000 0.28324\n##  Bacteroides_2   0.10376 0.00000 0.05362 0.07981 0.07957 0.00000 0.04164\n##  Akkermansia     0.01323 0.12818 0.04012 0.03593 0.01411 0.13349 0.05105\n##  Bacteroides_3   0.09605 0.00000 0.04760 0.07525 0.19865 0.00000 0.00000\n##                       A24      A26     A27\n##  Bacteroides     0.375716 0.076844 0.24740\n##  Bacteroides_1   0.266715 0.000000 0.10112\n##  Parabacteroides 0.000000 0.172826 0.00000\n##  Bacteroides_2   0.010230 0.006608 0.02002\n##  Akkermansia     0.038485 0.118447 0.07714\n##  Bacteroides_3   0.008525 0.000000 0.02200\n\nFor more information on the capabilities and transformation options of mia::transformAssay(), see Chapter 10.",
    "crumbs": [
      "Workflows",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Introductory</span>"
    ]
  },
  {
    "objectID": "pages/introductory_workflow.html#community-composition",
    "href": "pages/introductory_workflow.html#community-composition",
    "title": "\n25  Introductory\n",
    "section": "\n25.6 Community composition",
    "text": "25.6 Community composition\nA common way to summarize composition is to use a bar plot to display relative abundances. See Chapter 12 for more details on composition summaries. This approach visualizes the relative abundances of selected taxa in each sample, providing a quick overview of common compositions and major changes across samples. Here, we choose to plot all the phyla found in the samples.\n\np &lt;- plotAbundance(tse_phylum, assay.type = \"relabundance\")\np\n\n\n\n\n\n\n\nAs we can see, Bacteroidetes is a common phylum in all samples. When its abundance drops below 50%, Firmicutes notably increases to fill the space.",
    "crumbs": [
      "Workflows",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Introductory</span>"
    ]
  },
  {
    "objectID": "pages/introductory_workflow.html#community-diversity",
    "href": "pages/introductory_workflow.html#community-diversity",
    "title": "\n25  Introductory\n",
    "section": "\n25.7 Community diversity",
    "text": "25.7 Community diversity\nCommunity diversity measures in microbiology can be categorized into three groups:\n- Richness: The total number of taxa.\n- Equitability: How evenly the abundances of taxa are distributed.\n- Diversity: A combination of taxa richness and equitability.\nDiversity can vary in association with different phenotypes. Next, we will calculate Faith’s phylogenetic diversity index. What sets this index apart is its incorporation of phylogeny into the diversity calculation. This index considers both the number and the relatedness of different taxa, using branch lengths on a phylogenetic tree. For more information on diversity, see Chapter 13.\n\n# Estimate Faith's index\ntse &lt;- addAlpha(tse, index = \"faith\")\n\nThe results are stored to colData. The calculated index shows how diverse each sample is in terms of the number of different microbes present. We can then create a graph to visualize this.\n\np &lt;- plotColData(tse, x = \"patient_status\", y = \"faith\")\np\n\n\n\n\n\n\n\nThe graph shows that there is no significant difference in microbial diversity between the ADHD and control groups. However, alpha diversity metrics like Faith’s index only tell us about the diversity within individual samples and do not account for the differences between samples or groups. To understand how microbial communities vary between different samples — for instance, between ADHD patients and controls — we need to examine beta diversity.",
    "crumbs": [
      "Workflows",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Introductory</span>"
    ]
  },
  {
    "objectID": "pages/introductory_workflow.html#community-dissimilarity",
    "href": "pages/introductory_workflow.html#community-dissimilarity",
    "title": "\n25  Introductory\n",
    "section": "\n25.8 Community dissimilarity",
    "text": "25.8 Community dissimilarity\nTo gain a more comprehensive understanding of microbial variation across different samples, we assess beta diversity by measuring the dissimilarities in microbial compositions between samples. Beta diversity helps us determine how distinct or similar the microbiomes are among groups, allowing us to identify patterns or differences in microbial communities that may not be apparent from alpha diversity alone.\nTo explore these dissimilarities, we use Principal Coordinate Analysis (PCoA), a technique that reduces the complexity of high-dimensional data by projecting it into a lower-dimensional space while preserving the dissimilarities (or distances) between samples. This enables us to visualize the relationships and differences between samples in a simplified manner. For more information, refer to Chapter 14.\nIn this analysis, we use UniFrac dissimilarity, which takes into account the phylogenetic relationships among taxa. UniFrac measures the phylogenetic distance between microbial communities by comparing the branch lengths shared by the communities on a phylogenetic tree. This provides a more nuanced understanding of community differences by incorporating evolutionary relationships.\n\n# Run PCoA\ntse &lt;- runMDS(\n    tse,\n    FUN = getDissimilarity,\n    tree = rowTree(tse),\n    method = \"unifrac\",\n    assay.type = \"counts\",\n    niter = 100\n    )\n\nThe results are stored in reducedDim slot. In order to visualize this newly generated projection, we can apply scater::plotReducedDim().\n\n# Create a ggplot object\np &lt;- plotReducedDim(\n    tse, \"MDS\",\n    colour_by = \"patient_status\",\n    point_size = 3\n    )\np &lt;- p + labs(title = \"Principal Coordinate Analysis\")\np\n\n\n\n\n\n\n\nThe plot shows that the data clusters into three groups, with two of them consisting solely of one diagnosis or another. This suggests that the microbial profiles differ between ADHD patients and controls.\nTo further explore the factors driving these differences in microbial profiles, we can perform a differential abundance analysis, for instance (see Chapter 16).",
    "crumbs": [
      "Workflows",
      "<span class='chapter-number'>25</span>  <span class='chapter-title'>Introductory</span>"
    ]
  },
  {
    "objectID": "pages/introductory_workflow_french_version.html#introduction",
    "href": "pages/introductory_workflow_french_version.html#introduction",
    "title": "\n26  Introductory (French)\n",
    "section": "\n26.1 Introduction",
    "text": "26.1 Introduction\nBonjour et bienvenue dans un workflow complet utilisant les derniers outils R/Bioconductor pour la science des données du microbiome. Dans ce tutoriel, nous vous guiderons à travers quelques étapes de base d’une étude d’analyse de composition utilisant OMA. Celles-ci seront applicables à presque tous vos projets et vous aideront à comprendre les concepts fondamentaux qui propulseront 🚀 vos futures analyses du microbiome.",
    "crumbs": [
      "Workflows",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Introductory (French)</span>"
    ]
  },
  {
    "objectID": "pages/introductory_workflow_french_version.html#importation-des-données",
    "href": "pages/introductory_workflow_french_version.html#importation-des-données",
    "title": "\n26  Introductory (French)\n",
    "section": "\n26.2 Importation des données",
    "text": "26.2 Importation des données\nLors de l’utilisation de packages pour le microbiome, il existe de nombreuses façons différentes d’importer vos données. Commençons par charger les packages requis:\n\n# List of packages that we need\npackages &lt;- c(\n    \"ggplot2\", \"knitr\", \"mia\", \"dplyr\", \"miaViz\", \"vegan\", \"DT\",\n    \"scater\", \"patchwork\", \"sechm\", \"plotly\"\n    )\n\n# Get packages that are already installed installed\npackages_already_installed &lt;- packages[ packages %in% installed.packages() ]\n\n# Get packages that need to be installed\npackages_need_to_install &lt;- setdiff( packages, packages_already_installed )\n\n# Loads BiocManager into the session. Install it if it not already installed.\nif( !require(\"BiocManager\") ){\n    install.packages(\"BiocManager\")\n    library(\"BiocManager\")\n}\n\n# If there are packages that need to be installed, installs them with BiocManager\n# Updates old packages.\nif( length(packages_need_to_install) &gt; 0 ) {\n   install(packages_need_to_install, ask = FALSE)\n}\n\n# Load all packages into session. Stop if there are packages that were not\n# successfully loaded\npkgs_not_loaded &lt;- !sapply(packages, require, character.only = TRUE)\npkgs_not_loaded &lt;- names(pkgs_not_loaded)[ pkgs_not_loaded ]\nif( length(pkgs_not_loaded) &gt; 0 ){\n    stop(\n        \"Error in loading the following packages into the session: '\",\n        paste0(pkgs_not_loaded, collapse = \"', '\"), \"'\")\n}\n\nVous pouvez choisir d’utiliser vos propres données ou l’un des ensembles de données intégrés fournis par mia que vous trouverez ici Section 4.2:\nDans ce tutoriel, nous utiliserons l’ensemble de données C Tengeler et al. (2020). Cet ensemble de données a été créé par A.C. Tengeler pour essayer de démontrer l’impact des microbiomes altérés sur la structure du cerveau. Voici comment nous pouvons charger les données dans notre environnement R :\n\nC Tengeler, Anouk, Sarita A Dam, Maximilian Wiesmann, Jilly Naaijen, Miranda van Bodegom, Clara Belzer, Pieter J Dederen, et al. 2020. “Gut Microbiota from Persons with Attention-Deficit/Hyperactivity Disorder Affects the Brain in Mice.” Microbiome 8: 1–14. https://doi.org/10.1186/s40168-020-00816-x.\n\ndata(\"Tengeler2020\", package=\"mia\")\ntse &lt;- Tengeler2020\n\nBien sûr, il existe d’autres moyens d’importer vos données en utilisant le package mia. Ceux-ci incluent : utiliser vos propres données (Section 4.1.2) ou convertir un objet existant en un objet TreeSummarizedExperiment comme indiqué dans cette section : Section 5.1.",
    "crumbs": [
      "Workflows",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Introductory (French)</span>"
    ]
  },
  {
    "objectID": "pages/introductory_workflow_french_version.html#stockage-des-données-du-microbiome",
    "href": "pages/introductory_workflow_french_version.html#stockage-des-données-du-microbiome",
    "title": "\n26  Introductory (French)\n",
    "section": "\n26.3 Stockage des données du microbiome",
    "text": "26.3 Stockage des données du microbiome\nTreeSummarizedExperiment ou objet TreeSE est le type d’objet utilisé dans le package mia pour stocker vos données. C’est un type de données polyvalent et multi-usages qui permet de stocker et d’accéder aux données de manière efficace.\nVoici un rappel rapide sur la façon d’accéder à certains types de données :\nVous pouvez accéder aux assays assays (Section 3.2) de cette manière :\n\nassay(tse)[1:5,1:10]\n##                   A110   A12  A15  A19  A21  A23  A25  A28 A29  A34\n##  Bacteroides     17722 11630    0 8806 1740 1791 2368 1316 252 5702\n##  Bacteroides_1   12052     0 2679 2776  540  229    0    0   0 6347\n##  Parabacteroides     0   970    0  549  145    0  109  119  31    0\n##  Bacteroides_2       0  1911    0 5497  659    0  588  542 141    0\n##  Akkermansia      1143  1891 1212  584   84  700  440  244  25 1611\n\nAlors que colData (Section 7.2) est accessible via :\n\n# Transform the colData to a dataframe\ntse_df_colData &lt;- as.data.frame(colData(tse))\n\n# Show as an interactive table\ndatatable(tse_df_colData,options = list(pageLength = 5),rownames = FALSE)\n\n\n\n\n\nrowData (Section 3.4) contient des données sur les caractéristiques des échantillons, notamment des informations taxonomiques.\n\ntse_df_rowData &lt;- as.data.frame(rowData(tse))\ndatatable(tse_df_rowData, options = list(pageLength = 5))  \n\n\n\n\n\nIci rowData(tse) renvoie un DataFrame avec 151 lignes et 7 colonnes. Chaque ligne représente un organisme et chaque colonne un niveau taxonomique.\nPour illustrer la structure d’un TreeSummarizedExperiment, voici un article de Huang et al. (2021) qui utilise ce type d’objet. De plus, veuillez consulter la figure 1 ci-dessous.\n\nHuang, Ruizhu, Charlotte Soneson, Felix G. M. Ernst, et al. 2021. “TreeSummarizedExperiment: A S4 Class for Data with Hierarchical Structure [Version 2; Peer Review: 3 Approved].” F1000Research 9: 1246. https://doi.org/10.12688/f1000research.26669.2.\n\n\n1. Storing microbial data: the structure of a TreeSummarizedExperiment",
    "crumbs": [
      "Workflows",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Introductory (French)</span>"
    ]
  },
  {
    "objectID": "pages/introductory_workflow_french_version.html#manipulation-des-données",
    "href": "pages/introductory_workflow_french_version.html#manipulation-des-données",
    "title": "\n26  Introductory (French)\n",
    "section": "\n26.4 Manipulation des données",
    "text": "26.4 Manipulation des données\nDans certains cas, vous devrez peut-être modifier vos données pour obtenir les résultats souhaités. Dans cette section, nous verrons comment agglomérer les données, les sous-ensembles et plus encore. Un TreeSummarizedExperiment permet une manipulation astucieuse des données en utilisant le package dplyr.\n\n26.4.1 Sous-ensembles\nDans certains cas, vous n’aurez peut-être besoin d’utiliser qu’une partie de votre TreeSummarizedExperiment d’origine.\nEn utilisant l’ensemble de données Tengeler2020, nous pouvons nous concentrer sur une certaine cohorte par exemple. Cela est assez simple :\n\ntse_subset_by_sample &lt;- tse[ , tse$cohort ==\"Cohort_1\"]\n\nCela créera un objet TreeSummarizedExperiment ne contenant que les échantillons de la première cohorte.\n\n26.4.2 Agglomération des données\nPour pousser davantage votre analyse de données et vous concentrer sur sa distribution à un rang taxonomique spécifique, il peut être bénéfique d’agglomérer vos données à ce niveau particulier. La fonction agglomerateByRank() simplifie ce processus, permettant des analyses plus fluides et efficaces. Voici un exemple :\n\ntse.agglomerated &lt;- agglomerateByRank(tse, rank='Phylum')\n\n# Check\ndatatable(\n    data.frame(rowData(tse.agglomerated)),\n    options = list(pageLength = 5),rownames = FALSE)\n\n\n\n\n\nGénial ! Maintenant, nos données sont confinées aux informations taxonomiques jusqu’au niveau du Phylum, permettant à l’analyse de se concentrer sur ce rang spécifique. Dans le reste du workflow, nous n’utiliserons pas les données agglomérées, mais tout le code ci-dessous peut être utilisé sur celles-ci.",
    "crumbs": [
      "Workflows",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Introductory (French)</span>"
    ]
  },
  {
    "objectID": "pages/introductory_workflow_french_version.html#indicateurs",
    "href": "pages/introductory_workflow_french_version.html#indicateurs",
    "title": "\n26  Introductory (French)\n",
    "section": "\n26.5 Indicateurs",
    "text": "26.5 Indicateurs\n\n26.5.1 Diversité de la communauté\nLa diversité de la communauté en microbiologie est mesurée par plusieurs indices : - la richesse en espèces (nombre total d’espèces) - l’équitabilité (répartition des espèces au sein d’un microbiome) - la diversité (combinaison des deux)\nLe coefficient de Hill (1910) combine ces mesures en une seule équation. Toutes ces variations sont appelées diversité alpha.\nHill, Archibald V. 1910. “The Possible Effects of the Aggregation of the Molecules of Hæmoglobin on Its Dissociation Curves.” Journal of Physiology 40: iv–vii. https://en.wikipedia.org/wiki/Hill_equation_(biochemistry).\n\n\n# Estimate (observed) richness\ntse_alpha &lt;- addAlpha(\n    tse,\n    assay.type = \"counts\",\n    index = \"observed\",\n    name=\"observed\")\n\n# Check some of the first values in colData\ntse_alpha$observed |&gt; head()\n##  [1] 68 51 68 62 58 61\n\nLe résultat montre les valeurs de richesse estimées pour différents échantillons ou emplacements au sein de l’ensemble de données. Il donne une idée de la diversité de chaque échantillon en termes de nombre d’espèces différentes présentes. Nous pouvons ensuite créer un graphique pour visualiser cela.\n\nplotColData(\n    tse_alpha,\n    \"observed\",\n    \"cohort\",\n    colour_by = \"patient_status\") +\n\n    theme(axis.text.x = element_text(angle=45,hjust=1)) +\n    labs(y=expression(Richness[Observed]))\n\n\n\n\n\n\n\nPour aller encore plus loin, nous pouvons également comparer l’indice de Shannon estimé à la richesse observée. Shannon quantifie la diversité en termes à la fois du nombre d’espèces différentes (richesse) et de l’uniformité de leur répartition (abondance) et est calculé comme suit :\n\\[\nH' = -\\sum_{i=1}^{R} p_i \\ln(p_i)\n\\] pi étant la proportion d’un certain microorganisme.\n\nD’abord, nous pouvons facilement calculer cette mesure et l’ajouter à notre TreeSE.\n\ntse_alpha &lt;- addAlpha(\n    tse_alpha,\n    assay.type = \"counts\",\n    index = c(\"shannon\"),\n    name = c(\"shannon\"))\n\nNous pouvons également comparer les deux mesures de diversité en produisant les graphiques suivants.\n\n# Create the plots\nplots &lt;- lapply(\n    c(\"observed\", \"shannon\"),\n    plotColData,\n    object = tse_alpha,\n    x = \"patient_status\",\n    colour_by = \"patient_status\")\n\n# Fine-tune visual appearance\nplots &lt;- lapply(plots, \"+\",\n    theme(\n        axis.text.x = element_blank(),\n        axis.title.x = element_blank(),\n        axis.ticks.x = element_blank()))\n\n# Plot the figures\n(plots[[1]] | plots[[2]]) +\n  plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\nIl est très important de faire toutes ces comparaisons afin de quantifier la diversité et de comparer les échantillons dans nos données en utilisant différentes mesures. - Vous pouvez trouver d’autres types de comparaisons directement dans le livre Chapter 13.\n\n26.5.2 Similarité de la communauté\nLa similarité de la communauté fait référence à la manière dont les microorganismes se ressemblent en termes de composition et d’abondance des différents taxons microbiens. Cela peut nous aider à comprendre dans quelle mesure différents échantillons se ressemblent et à trouver des informations clés. Cependant, en analyse de microbiome, il est plus courant de mesurer la dissimilarité/diversité bêta entre deux échantillons A et B en utilisant la mesure de Bray-Curtis qui est définie comme suit :\n\\[\nBC_{ij} = \\frac{\\sum_{k} |A_{k} - B_{k}|}{\\sum_{k} (A_{k} + B_{k})}\n\\]\nHeureusement pour nous, le package mia fournit un moyen facile de calculer l’abondance relative pour notre TreeSE en utilisant la méthode transformAssay.\n\ntse &lt;- transformAssay(\n    tse,\n    assay.type = \"counts\",\n    method = \"relabundance\")\n\nCela prendra l’assay des comptes d’origine et appliquera le calcul des abondances relatives. Le résultat est une matrice avec les identifiants des échantillons en lignes et les abondances relatives pour chaque taxon dans ces échantillons en colonnes. Il peut être consulté dans les assays du tse :\n\nassay(tse, \"relabundance\")[5:10,1:10]\n##                       A110      A12     A15      A19      A21    A23      A25\n##  Akkermansia       0.03057 0.046595 0.07539 0.014894 0.013226 0.1282 0.040124\n##  Bacteroides_3     0.00000 0.160112 0.00000 0.113619 0.096048 0.0000 0.047602\n##  Parabacteroides_1 0.00000 0.005470 0.00000 0.003290 0.004409 0.0000 0.002280\n##  Bacteroides_4     0.00000 0.089370 0.00000 0.019663 0.004566 0.0000 0.064654\n##  Bacteroides_5     0.00000 0.066061 0.00000 0.013542 0.006928 0.0000 0.055079\n##  Parabacteroides_2 0.00000 0.004632 0.00000 0.002907 0.005196 0.0000 0.002189\n##                         A28      A29     A34\n##  Akkermansia       0.035930 0.014108 0.07693\n##  Bacteroides_3     0.075247 0.198646 0.00000\n##  Parabacteroides_1 0.003240 0.004515 0.00000\n##  Bacteroides_4     0.033574 0.134312 0.00000\n##  Bacteroides_5     0.064792 0.132054 0.00000\n##  Parabacteroides_2 0.002798 0.003386 0.00000\n\nEnsuite, nous pouvons ajouter la dissimilarité de Bray-Curtis :\n\n# Run PCoA on relabundance assay with Bray-Curtis distances\ntse &lt;- runMDS(\n    tse,\n    FUN = vegdist,\n    method = \"bray\",\n    assay.type = \"relabundance\",\n    name = \"MDS_bray\")\n\nDans notre cas, l’assay contient 151 lignes et 27 colonnes. Avoir autant de colonnes et donc de dimensions peut être problématique pour visualiser la dissimilarité.\nPour visualiser la dissimilarité entre les différents échantillons, nous pouvons effectuer une analyse en coordonnées principales sur l’assay nouvellement créé. Cela projette essentiellement les dimensions de Bray-Curtis sur un espace inférieur tout en conservant autant de variation que possible, les valeurs projetées étant appelées coordonnées principales. Vous pouvez en lire plus sur “Multidimensional Scaling” (n.d.) ici.\n\n“Multidimensional Scaling.” n.d. https://en.wikipedia.org/wiki/Multidimensional_scaling#Types.\n\nOksanen, Jari, F. Guillaume Blanchet, Michael Friendly, Roeland Kindt, Pierre Legendre, Dan McGlinn, Peter R. Minchin, et al. 2020. Vegan: Community Ecology Package. https://CRAN.R-project.org/package=vegan.\nmia fournit certaines techniques de réduction de dimension, telles que dbRDA. De plus, nous pouvons utiliser le package scater de Bioconductor et le package vegan, créé par Oksanen et al. (2020) pour transformer la dissimilarité en distances réelles pouvant être visualisées :\n\n# Create ggplot object\np &lt;- plotReducedDim(tse, \"MDS_bray\",colour_by = \"cohort\")\n\n# Convert to an interactive plot with ggplotly\nggplotly(p)\n\n\n\n\n\nCependant, les axes ne sont pas très informatifs et la quantité de variance capturée par l’algorithme n’est nulle part indiquée. Nous pouvons ajuster le graphique pour montrer plus d’informations comme suit :\n\n# Calculate explained variance\ne &lt;- attr(reducedDim(tse, \"MDS_bray\"), \"eig\")\nrel_eig &lt;- e / sum(e[e &gt; 0])\n\n# Add explained variance for each axis on the plot\np &lt;- p + labs(\n    x = paste(\"PCoA 1 (\", round(100 * rel_eig[[1]], 1), \"%\", \")\", sep = \"\"),\n    y = paste(\"PCoA 2 (\", round(100 * rel_eig[[2]], 1), \"%\", \")\", sep = \"\"))\n\n# Reonvert to an interactive plot with ggplotly\nggplotly(p)\n\n\n\n\n\nEt voilà ! Chaque axe montre la quantité de variance ou dans notre cas de dissimilarité retenue par chaque coordonnée principale. Vous pouvez également ajouter d’autres options pour colorier par une certaine caractéristique par exemple. Vous pouvez en savoir plus dans Chapter 14.",
    "crumbs": [
      "Workflows",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Introductory (French)</span>"
    ]
  },
  {
    "objectID": "pages/introductory_workflow_french_version.html#visualisation-des-données",
    "href": "pages/introductory_workflow_french_version.html#visualisation-des-données",
    "title": "\n26  Introductory (French)\n",
    "section": "\n26.6 Visualisation des données",
    "text": "26.6 Visualisation des données\nLes cartes de chaleurs sont l’un des moyens les plus polyvalents de visualiser vos données. Dans cette section, nous verrons comment créer une heatmap de base pour visualiser les caractéristiques les plus répandues en utilisant la bibliothèque sechm. Pour une carte de chaleur plus détaillée, veuillez vous reporter à cette section Section 20.1.\nEnsuite, nous allons créer un sous-ensemble de TreeSE pour les taxons les plus répandus en utilisant une expérience alternative :\n\naltExp(tse, \"prevalence-subset\") &lt;- subsetByPrevalent(tse,prevalence=0.5)[1:5,]\n\nLors de la création de sous-ensembles avec cette fonction, l’objet résultant ne contient plus les abondances relatives correctes car ces abondances ont été calculées à l’origine sur la basees données complètes. Par conséquent, il est essentiel de recalculer les abondances relatives pour notre sous-ensemble :\n\naltExp(tse, \"prevalence-subset\") &lt;- transformAssay(\n    altExp(tse, \"prevalence-subset\"),\n    assay.type = \"counts\",\n    method = \"relabundance\")\n\nMaintenant que nous avons préparé les données, nous pouvons utiliser la bibliothèque sechm précédemment chargée pour visualiser la carte de chaleur :\n\n# Sets the colors\nsetSechmOption(\"hmcols\", value=c(\"#F0F0FF\",\"#007562\"))\n\n# Plots the actual heatmap.\nsechm(\n    altExp(tse, \"prevalence-subset\"), features =\n    rownames(rowData(altExp(tse, \"prevalence-subset\"))),\n    assayName=\"relabundance\",show_colnames=TRUE)\n\n\n\n\n\n\n\nSur la carte de chaleur ci-dessus, il est évident que les Parabacteroides sont relativement fréquents dans certains échantillons, tandis que les Akkermansia sont détectés très rarement.",
    "crumbs": [
      "Workflows",
      "<span class='chapter-number'>26</span>  <span class='chapter-title'>Introductory (French)</span>"
    ]
  },
  {
    "objectID": "pages/introductory_workflow_dutch_version.html#introductie",
    "href": "pages/introductory_workflow_dutch_version.html#introductie",
    "title": "\n27  Introductory (Dutch)\n",
    "section": "\n27.1 Introductie",
    "text": "27.1 Introductie\nHallo en welkom bij een complete workflow met de nieuwste R/Bioconductor-tools voor microbiome data science. In deze tutorial leiden we je door enkele basisstappen van een compositieanalyse-studie met behulp van OMA. Deze stappen zijn toepasbaar op vrijwel al je projecten en zullen je helpen de fundamentele concepten te begrijpen die je toekomstige microbiome-analyses naar een hoger niveau zullen tillen 🚀.",
    "crumbs": [
      "Workflows",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Introductory (Dutch)</span>"
    ]
  },
  {
    "objectID": "pages/introductory_workflow_dutch_version.html#data-importeren",
    "href": "pages/introductory_workflow_dutch_version.html#data-importeren",
    "title": "\n27  Introductory (Dutch)\n",
    "section": "\n27.2 Data importeren",
    "text": "27.2 Data importeren\nBij het gebruik van microbiome-pakketten zijn er veel verschillende manieren om je data te importeren. Laten we eerst alle paketten laden:\n\n# List of packages that we need\npackages &lt;- c(\n    \"ggplot2\", \"knitr\", \"mia\", \"dplyr\", \"miaViz\", \"vegan\", \"DT\",\n    \"scater\", \"patchwork\", \"sechm\", \"plotly\"\n    )\n\n# Get packages that are already installed installed\npackages_already_installed &lt;- packages[ packages %in% installed.packages() ]\n\n# Get packages that need to be installed\npackages_need_to_install &lt;- setdiff( packages, packages_already_installed )\n\n# Loads BiocManager into the session. Install it if it not already installed.\nif( !require(\"BiocManager\") ){\n    install.packages(\"BiocManager\")\n    library(\"BiocManager\")\n}\n\n# If there are packages that need to be installed, installs them with BiocManager\n# Updates old packages.\nif( length(packages_need_to_install) &gt; 0 ) {\n   install(packages_need_to_install, ask = FALSE)\n}\n\n# Load all packages into session. Stop if there are packages that were not\n# successfully loaded\npkgs_not_loaded &lt;- !sapply(packages, require, character.only = TRUE)\npkgs_not_loaded &lt;- names(pkgs_not_loaded)[ pkgs_not_loaded ]\nif( length(pkgs_not_loaded) &gt; 0 ){\n    stop(\n        \"Error in loading the following packages into the session: '\",\n        paste0(pkgs_not_loaded, collapse = \"', '\"), \"'\")\n}\n\nJe kunt er zowel voor kiezen om je eigen data te gebruiken als een van de ingebouwde datasets die door mia worden aangeboden, welke je kunt vinden in het OMA boek@sec-example-data :\nIn deze tutorial gebruiken we de C Tengeler et al. (2020) dataset. Deze dataset is gemaakt door A.C. Tengeler om de impact van aangetaste microbiomen op de hersenstructuur aan te tonen. Hier is hoe we de data in onze R-omgeving kunnen laden:\n\nC Tengeler, Anouk, Sarita A Dam, Maximilian Wiesmann, Jilly Naaijen, Miranda van Bodegom, Clara Belzer, Pieter J Dederen, et al. 2020. “Gut Microbiota from Persons with Attention-Deficit/Hyperactivity Disorder Affects the Brain in Mice.” Microbiome 8: 1–14. https://doi.org/10.1186/s40168-020-00816-x.\n\ndata(\"Tengeler2020\", pakket=\"mia\")\ntse &lt;- Tengeler2020\n\nEr zijn verschillende andere manieren om je data te importeren via het mia pakket. Deze omvatten het gebruik van zowel je eigen data(Section 4.1.2) of door een bestaand object om te zetten naar een TreeSummarizedExperiment object zoals vermeld in dit gedeelte van het OMA boek: Section 5.1",
    "crumbs": [
      "Workflows",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Introductory (Dutch)</span>"
    ]
  },
  {
    "objectID": "pages/introductory_workflow_dutch_version.html#microbiële-data-opslaan",
    "href": "pages/introductory_workflow_dutch_version.html#microbiële-data-opslaan",
    "title": "\n27  Introductory (Dutch)\n",
    "section": "\n27.3 Microbiële data opslaan",
    "text": "27.3 Microbiële data opslaan\nTreeSummarizedExperiment of TSE objecten zijn het type object dat wordt gebruikt binnen mia om data op te slaan. Een TreeSummarizedExperiment is een veelzijdig en multifunctioneel datatype dat een efficiënte manier biedt om data op te slaan en te benaderen.\n\n27.3.1 Assays\nEen assay(Section 3.2) is een methode om de aanwezigheid en hoeveelheid van verschillende soorten microben in een monster te detecteren en te meten. Als je bijvoorbeeld wilt weten hoeveel bacteriën van een bepaald type in je darmen aanwezig zijn, kun je een assay gebruiken om dit te bepalen. In het volgende voorbeeld selecteren we een subset van een assay door alleen de eerste 5 rijen en de eerste 10 kolommen te tonen. Dit maakt het eenvoudiger om te begrijpen en te lezen. Later in de worklow zal er meer uitleg worden gegeven over het maken van subsets.\n\nassay(tse)[1:5,1:10]\n##                   A110   A12  A15  A19  A21  A23  A25  A28 A29  A34\n##  Bacteroides     17722 11630    0 8806 1740 1791 2368 1316 252 5702\n##  Bacteroides_1   12052     0 2679 2776  540  229    0    0   0 6347\n##  Parabacteroides     0   970    0  549  145    0  109  119  31    0\n##  Bacteroides_2       0  1911    0 5497  659    0  588  542 141    0\n##  Akkermansia      1143  1891 1212  584   84  700  440  244  25 1611\n\n\n27.3.2 colData\nEen ander belangrijk aspect van microbiome-analyse is monsterdata(Section 7.2).\n\n# verandert de colData in een dataframe\ntse_df_colData &lt;- as.data.frame(colData(tse))\n\n# laat een interactieve tabel zien\ndatatable(tse_df_colData,options = list(pageLength = 5),rownames = FALSE)\n\n\n\n\n\nn het bovenstaande voorbeeld retourneert colData(tse) een DataFrame met 26 rijen en 10 kolommen. Elke rij correspondeert met een specifiek monster en elke kolom bevat gegevens over dat monster.\n\n27.3.3 rowData\nrowData(Section 3.4) bevat gegevens van een type microbe, voornamelijk taxonomische informatie.\n\ntse_df_rowData &lt;- as.data.frame(rowData(tse))\ndatatable(tse_df_rowData, options = list(pageLength = 5))\n\n\n\n\n\nHierboven retourneert rowData(tse) een DataFrame met 151 rijen en 7 colommen. Iedere rij verwijst naar een organisme terwijl iedere kolom naar een taxonomische rang verwijst.\nIn dit voorbeeld geeft de kolom genaamd Kingdom aan of het organisme behoort tot het rijk van bacteriën of archaea. Phylum geeft aan tot welke stam een micro-organisme behoort, en zo verder tot het niveau van de soort micro-organisme.\nOm de structuur van een TreeSummarizedExperiment te verduidelijken is hier een artikel van Huang et al. (2021) dat gebruik maakt van dit soort type object. Bekijk ook figuur 1 hieronder.\n\nHuang, Ruizhu, Charlotte Soneson, Felix G. M. Ernst, et al. 2021. “TreeSummarizedExperiment: A S4 Class for Data with Hierarchical Structure [Version 2; Peer Review: 3 Approved].” F1000Research 9: 1246. https://doi.org/10.12688/f1000research.26669.2.\n\n\n1. microbiële data opslaan : de structuur van een TreeSummarizedExperiment",
    "crumbs": [
      "Workflows",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Introductory (Dutch)</span>"
    ]
  },
  {
    "objectID": "pages/introductory_workflow_dutch_version.html#data-verwerking",
    "href": "pages/introductory_workflow_dutch_version.html#data-verwerking",
    "title": "\n27  Introductory (Dutch)\n",
    "section": "\n27.4 Data verwerking",
    "text": "27.4 Data verwerking\nIn sommige gevallen is het nodig om je data te transformeren om een bepaald soort resultaat te behalen. In de volgende rubriek zullen we bespreken hoe je gegevens kunt samenvoegen, je gegevens kunt subsetten en meer. Een TreeSummarizedExperiment maakt het mogelijk om gegevens op een handige manier te manipuleren met dplyr.\n\n27.4.1 Subsetten\nIn sommige gevallen hoeft u slechts een deel van uw originele TreeSummarizedExperiment te behouden.\nMet de Tengeler2020 dataset, kunnen we de focus leggen op een bepaald cohort bijvoorbeeld. Dit resultaat kan op de volgende manier behaald worden:\n\ntse_subset_by_sample &lt;- tse[ , tse$cohort ==\"Cohort_1\"]\n\nDit creëert een TreeSummarizedExperiment object dat alleen bestaat uit monsters van het eerste cohort. Om het resulterende object beter te visualiseren, kunnen we de meltAssay()-methode gebruiken en specificeren welk type kolom behouden moet blijven:\n\nmolten_tse &lt;- meltAssay(\n    tse_subset_by_sample,\n    add_row_data = TRUE,\n    add_col_data = TRUE,\n    assay.type = \"counts\")\n\ndatatable(molten_tse,options = list(pageLength = 5),rownames = FALSE)\n\n\n\n\n\n\n27.4.2 Data samenvoegen\nOm de analyse verder te verdiepen en de focus te leggen op de verdeling van de microbiële data op een specifieke taxonomische rang, kan het nuttig zijn om de gegevens samen te voegen tot dat specifieke niveau. De functie agglomerateByRank vereenvoudigt dit proces en maakt meer geraffineerde en effectieve analyses mogelijk. Hier volgt een voorbeeld:\n\ntse.agglomerated &lt;- agglomerateByRank(tse, rank='Phylum')\n\n# Check\ndatatable(\n    data.frame(rowData(tse.agglomerated)),\n    options = list(pageLength = 5),rownames = FALSE)\n\n\n\n\n\nPerfect! Nu bevatten onze gegevens alleen nog maar taxonomische informatie tot op het niveau van het phylum, waardoor het gemakkelijker is om de nadruk te leggen op deze specifieke rang bij het analyseren van de data.",
    "crumbs": [
      "Workflows",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Introductory (Dutch)</span>"
    ]
  },
  {
    "objectID": "pages/introductory_workflow_dutch_version.html#metingen",
    "href": "pages/introductory_workflow_dutch_version.html#metingen",
    "title": "\n27  Introductory (Dutch)\n",
    "section": "\n27.5 Metingen",
    "text": "27.5 Metingen\n\n27.5.1 Microbiële diversititeit\nMicrobiële diversititeit in microbiologie wordt gemeten op vershillende manieren:\n\nSoortenrijkdom: Het totale aantal soorten micro-organismen.\nEvenwichtigheid: De verdeling van soorten binnen een microbioom.\nDiversiteit: De combinatie van beide (soortenrijkdom en evenwichtigheid).\n\nHill (1910)’s coefficiënt combineert deze soorten metingen tot een formule. De drie vorige maatstaven worden ook wel Alfabetische diversiteit (alpha-diversiteit) genoemd.\n\n# Schatting (waargenomen) rijkdom\ntse_alpha &lt;- addAlpha(\n    tse,\n    assay.type = \"counts\",\n    index = \"observed\",\n    name=\"observed\")\n\n# Controleer enkele van de eerste waarden in colData\ntse_alpha$observed |&gt; head()\n##  [1] 68 51 68 62 58 61\n\nHet resultaat toont de geschatte rijkdomwaarden voor verschillende monsters of locaties binnen de dataset. Het geeft een idee van hoe divers elk monster is in verhouding tot het aantal verschillende soorten dat aanwezig is. We kunnen dan vervolgens een figuur tekenen om dit te visualiseren.\n\nplotColData(\n    tse_alpha,\n    \"observed\",\n    \"cohort\",\n    colour_by = \"patient_status\") +\n\n    theme(axis.text.x = element_text(angle=45,hjust=1)) +\n    labs(y=expression(Richness[Observed]))\n\n\n\n\n\n\n\nOm nog een stap verder te gaan, kunnen we ook de geschatte Shannon-index vergelijken met de waargenomen soortenrijkdom. De Shannon-index kwantificeert de diversiteit in relatie tot zowel het aantal verschillende soorten (rijkdom) als de gelijkheid van hun verspreiding (evenwichtigheid) en wordt als volgt berekend:\n\\[\nH' = -\\sum_{i=1}^{R} p_i \\ln(p_i)\n\\]\nis het aandeel dat bestaat uit een bepaald micro-organisme binnen een microbioom.\n\nEerst kunnen we deze maatstaf eenvoudig berekenen en toevoegen aan onze TSE.\n\ntse_alpha &lt;- addAlpha(\n    tse_alpha,\n    assay.type = \"counts\",\n    index = c(\"shannon\"),\n    name = c(\"shannon\"))\n\nEn daarna kunnen we de twee maten van diversiteit vergelijken door de volgende grafieken te maken.\n\n# Initialisatie van het grafiek object\nplots &lt;- lapply(\n    c(\"observed\", \"shannon\"),\n    plotColData,\n    object = tse_alpha,\n    x = \"patient_status\",\n    colour_by = \"patient_status\")\n\n# Weergave verbeteren\nplots &lt;- lapply(plots, \"+\",\n    theme(\n        axis.text.x = element_blank(),\n        axis.title.x = element_blank(),\n        axis.ticks.x = element_blank()))\n\n# Grafieken vertonen\n(plots[[1]] | plots[[2]]) +\n    plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\nHet is erg belangrijk om al deze vergelijkingen te maken om diversiteit te kwantificeren en monsters in onze gegevens te vergelijken met behulp van verschillende maatstaven. - Je kunt andere soorten vergelijkingen direct in het boek vinden.\n\n27.5.2 Community similarity (Gemeenschapsovereenkomst)\nCommunity similarity of Gemeenschapsovereenkomst verwijst naar de mate waarin micro-organismen op elkaar lijken qua samenstelling en overvloed van verschillende microbiële taxa. Dit kan ons helpen begrijpen in hoeverre verschillende monsters op elkaar lijken en faciliteert het helpen van belangrijke informatie. In microbiële analyse is het echter gebruikelijker om de ongelijkheid (Beta diversiteit) tussen twee monsters A en B te meten met behulp van de Bray-Curtis-formule, die als volgt wordt gedefinieerd:\n\\[\nBC_{ij} = \\frac{\\sum_{k} |A_{k} - B_{k}|}{\\sum_{k} (A_{k} + B_{k})}\n\\]\nGelukkig biedt de mia pakket ons een eenvoudige manier om ten eerste de relatieve overvloed te berekenen en daarna de Bray-Curtis ongelijkheid. de relatieve overvloed kan worden toegevoegd aan onze TSE met behulp van de transformAssay() methode:\n\ntse &lt;- transformAssay(tse, assay.type = \"counts\", method = \"relabundance\")\n\nDit resulteert in een matrix waarbij de verschillende monsters als rijen worden weergegeven en de overvloed ten opzichte van de monsters als kolommen. Deze nieuwe maatstaaf is makkelijk toegankelijk via de assays van de tse:\n\nassay(tse, \"relabundance\")[5:10,1:10]\n##                       A110      A12     A15      A19      A21    A23      A25\n##  Akkermansia       0.03057 0.046595 0.07539 0.014894 0.013226 0.1282 0.040124\n##  Bacteroides_3     0.00000 0.160112 0.00000 0.113619 0.096048 0.0000 0.047602\n##  Parabacteroides_1 0.00000 0.005470 0.00000 0.003290 0.004409 0.0000 0.002280\n##  Bacteroides_4     0.00000 0.089370 0.00000 0.019663 0.004566 0.0000 0.064654\n##  Bacteroides_5     0.00000 0.066061 0.00000 0.013542 0.006928 0.0000 0.055079\n##  Parabacteroides_2 0.00000 0.004632 0.00000 0.002907 0.005196 0.0000 0.002189\n##                         A28      A29     A34\n##  Akkermansia       0.035930 0.014108 0.07693\n##  Bacteroides_3     0.075247 0.198646 0.00000\n##  Parabacteroides_1 0.003240 0.004515 0.00000\n##  Bacteroides_4     0.033574 0.134312 0.00000\n##  Bacteroides_5     0.064792 0.132054 0.00000\n##  Parabacteroides_2 0.002798 0.003386 0.00000\n\nIn ons geval bevat de assay 151 rijen en 27 kolommen. Zoveel kolommen en dus dimensies kunnen datavisualisatie belemmeren.\nOm het verschil tussen de verschillende monsters te visualiseren, kunnen we een hoofdcomponentenanalyse uitvoeren op de nieuwe assay. Dit projecteert de Bray-curtis dimensies op een lagere ruimte met behoud van zoveel mogelijk variatie. De geprojecteerde waarden worden principale coördinaten genoemd. U kunt hier “Multidimensional Scaling” (n.d.) meer lezen over dit type analyse.\n\n“Multidimensional Scaling.” n.d. https://en.wikipedia.org/wiki/Multidimensional_scaling#Types.\n\nOksanen, Jari, F. Guillaume Blanchet, Michael Friendly, Roeland Kindt, Pierre Legendre, Dan McGlinn, Peter R. Minchin, et al. 2020. Vegan: Community Ecology Package. https://CRAN.R-project.org/package=vegan.\nMIA biedt geen directe manier om de dimensionaliteit te reduceren, maar we kunnen wel gebruik maken van Bioconductor’s scater pakket en het vegan pakket, dat Oksanen et al. (2020) hier kan worden gevonden om de ongelijkheid om te zetten in werkelijke afstanden die gevisualiseerd kunnen worden:\n\n# Voer een Hoofdcomponentenanalyse uit  op de relabundance assay en behoudt de Bray-Curtis afstanden.\ntse &lt;- runMDS(\n    tse,\n    FUN = vegdist,\n    method = \"bray\",\n    assay.type = \"relabundance\",\n    name = \"MDS_bray\")\n\nNu we de hoofdcoördinaten hebben berekend, kunnen we ze als volgt weergeven in een tweedimensionale ruimte:\n\n# Maak een ggplot object\np &lt;- plotReducedDim(tse, \"MDS_bray\",colour_by = \"cohort\")\n\n# Converteren naar een interactief plot met ggplotly\nggplotly(p)\n\n\n\n\n\nDe assen zijn echter niet erg informatief en de hoeveelheid behouden variantie door het algoritme is nergens te vinden. We kunnen de grafiek op de volgende manier aanpassen om meer informatie weer te geven :\n\n# Berekent de behouden variantie\ne &lt;- attr(reducedDim(tse, \"MDS_bray\"), \"eig\")\nrel_eig &lt;- e / sum(e[e &gt; 0])\n\n# voegt de variantie toe aan de assen van de grafiek\np &lt;- p + labs(\n    x = paste(\"Component 1 (\", round(100 * rel_eig[[1]], 1), \"%\", \")\", sep = \"\"),\n    y = paste(\"Component 2 (\", round(100 * rel_eig[[2]], 1), \"%\", \")\", sep = \"\"))\n\n# Reonvert to an interactive plot with ggplotly\nggplotly(p)\n\n\n\n\n\nElke as toont nu de hoeveelheid variantie, in ons geval ongelijkheid, van elk hoofdcoördinaat. Je kunt meer opties toevoegen om bijvoorbeeld een bepaald kenmerk in te kleuren. Meer hierover vindt u in deze sectie Chapter 14 van het OMA boek.",
    "crumbs": [
      "Workflows",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Introductory (Dutch)</span>"
    ]
  },
  {
    "objectID": "pages/introductory_workflow_dutch_version.html#datavisualisatie-met-heatmaps",
    "href": "pages/introductory_workflow_dutch_version.html#datavisualisatie-met-heatmaps",
    "title": "\n27  Introductory (Dutch)\n",
    "section": "\n27.6 Datavisualisatie met heatmaps",
    "text": "27.6 Datavisualisatie met heatmaps\nHeatmaps zijn een van de meest veelzijdige manieren om je gegevens te visualiseren. In dit gedeelte behandelen we hoe je een eenvoudige heatmap maakt om de meest voorkomende taxa te visualiseren met behulp van het sechm pakket. Ga voor een meer gedetailleerde heatmap naar dit gedeelteSection 20.1.\nLaten we de TreeSE subsetten naar de meest voorkomende taxa met behulp van een alternatief experiment:\n\naltExp(tse, \"prevalence-subset\") &lt;- subsetByPrevalent(tse,prevalence=0.5)[1:5,]\n\nBij het subsetten met deze functie bevat het resulterende object niet langer de juiste relatieve abundanties, omdat deze abundanties oorspronkelijk werden berekend op basis van de volledige dataset en niet op basis van de subset. Daardoor moeten we de waarden opnieuw berekenen om de subset accuraat te kunnen weergeven door middel van een heatmap. Omwille van de leesbaarheid subsetten we ook de eerste vijf taxa na de eerste subset.\n\naltExp(tse, \"prevalence-subset\") &lt;- transformAssay(\n    altExp(tse, \"prevalence-subset\"),\n    assay.type = \"counts\",\n    method = \"relabundance\")\n\nNu we de gegevens hebben voorbereid, kunnen we de eerder geladen sechm-bibliotheek gebruiken om de heatmap weer te geven:\n\n# Definieert de kleuren.\nsetSechmOption(\"hmcols\", value=c(\"#F0F0FF\",\"#007562\"))\n\n# Geeft de daadwerkelijke heatmap weer.\nsechm(\n    altExp(tse, \"prevalence-subset\"), features =\n    rownames(rowData(altExp(tse, \"prevalence-subset\"))),\n    assayName=\"relabundance\",show_colnames=TRUE)\n\n\n\n\n\n\n\nIn de heatmap hierboven valt op dat Parabacteroides relatief vaak voorkomen in sommige monsters terwijl Akkermansia zeer weinig wordt gedetecteerd.",
    "crumbs": [
      "Workflows",
      "<span class='chapter-number'>27</span>  <span class='chapter-title'>Introductory (Dutch)</span>"
    ]
  },
  {
    "objectID": "pages/training.html",
    "href": "pages/training.html",
    "title": "28  Training",
    "section": "",
    "text": "28.1 Checklist\nBrief checklist to prepare for training (see below for links).",
    "crumbs": [
      "Training",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Training</span>"
    ]
  },
  {
    "objectID": "pages/training.html#sec-checklist",
    "href": "pages/training.html#sec-checklist",
    "title": "28  Training",
    "section": "",
    "text": "Install the recommended software\nIf the time allows, watch the short online videos and familiarize yourself with the other available material\nJoin Gitter online chat for support",
    "crumbs": [
      "Training",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Training</span>"
    ]
  },
  {
    "objectID": "pages/training.html#sec-software",
    "href": "pages/training.html#sec-software",
    "title": "28  Training",
    "section": "\n28.2 Recommended software",
    "text": "28.2 Recommended software\nWe recommend installing and setting up the relevant software packages on your own computer as this will support later use. The essential components to install include:\n\nR (the latest official release)\nRStudio; choose “Rstudio Desktop” to download the latest version. Check the Rstudio home page for more information. RStudio is optional.\nInstall key R packages (Section Chapter 2 provides an installation script)\nAfter a successful installation you can consider trying out examples from Section Chapter 29 already before training. You can run the workflows by simply copy-pasting examples. You can then test further examples from this tutorial, modifying and applying these techniques to your own data. Plain source code for the individual chapters of this book are available via Github\nIf you have access to CSC notebook you can find instructions from here.",
    "crumbs": [
      "Training",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Training</span>"
    ]
  },
  {
    "objectID": "pages/training.html#sec-material",
    "href": "pages/training.html#sec-material",
    "title": "28  Training",
    "section": "\n28.3 Study material",
    "text": "28.3 Study material\nWe encourage you to familiarize yourself with the material and test examples in advance but this is optional:\n\nIntroduction to data analysis with R and Bioconductor (for beginners with R)\nShort online videos on microbiome data science with R/Bioconductor\nQuarto presentations\nOrchestrating Microbiome Analysis with Bioconductor (OMA) (this book)\nOther outreach material\nChapter 29 for self-study\nChapter 31 and links to complementary external material",
    "crumbs": [
      "Training",
      "<span class='chapter-number'>28</span>  <span class='chapter-title'>Training</span>"
    ]
  },
  {
    "objectID": "pages/exercises.html",
    "href": "pages/exercises.html",
    "title": "29  Exercises",
    "section": "",
    "text": "29.1 Basics of R/Bioconductor\nBioconductor training material has been contributed to Carpentries. You can check the following lessons for basic background of R and Bioconductor.",
    "crumbs": [
      "Training",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "pages/exercises.html#basics-of-rbioconductor",
    "href": "pages/exercises.html#basics-of-rbioconductor",
    "title": "29  Exercises",
    "section": "",
    "text": "Introduction to data analysis with R and Bioconductor\nIntroduction to the Bioconductor project",
    "crumbs": [
      "Training",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "pages/exercises.html#workflows",
    "href": "pages/exercises.html#workflows",
    "title": "29  Exercises",
    "section": "\n29.2 Workflows",
    "text": "29.2 Workflows\n\n29.2.1 Reproducible reporting with Quarto\nThe following batch of exercises walks you through typical use cases of Quarto in RStudio. Before heading to the exercises, it is recommended to read the Quarto guidelines for RStudio\n\n29.2.1.1 New document\nThis exercise gets you started with creating a Quarto document and adding text to it with typing conventions borrowed from the markdown syntax. Feel free to render the document with the Render button after each step to see the changes in the final report.\n\nOpen RStudio and create a new Quarto file named My first Quarto.\nAdd the subtitle My first section and write some text of your choice underneath. You can choose the level of headings by the number of preceding hashes (#).\nAdd a subsection named List of items and list three items underneath, both ordered and unordered. You can initialize items with numbers (1., 2., 3., …) or stars (*) for the ordered and unordered case, respectively.\nAdd another subsection named Link to web and add a clickable link to the OMA book, using the pattern [text](url).\nRender the document and check its appearance\n\nNice start! You are now able to create a Quarto document, understand its syntax and can render it into a reproducible report. If you got stuck, you can look up the docs on creating and rendering Quarto documents.\n\n29.2.1.2 Code chunks\nWhile customizable text is nothing new by itself, the advantage of Quarto (and previously Rmarkdown) is to combine text with code in R or other programming languages, so that both the analytical pipeline and verbal description can be put in one place. In this exercise, we learn how to write and run code in Quarto.\n\nOpen RStudio and create a new Quarto file (click on File tab - New File - Quarto document).\nInitialize a code chunk by pressing alt + cmd + i and define the variables A &lt;- \"my name\" and B &lt;- 0 in it.\nWrite the text Below is my first code chunk just above the code chunk.\nInitialize one more code chunk and add 100 to the variable B in it.\nWrite the text Below I change variable B just above the second chunk.\n\nExtra: Write the following line of text: my name is A and I am B years old, where A and B are variables defined in the code chunks upstream and change if those variables are modified. Be aware that inline code can be added as &gt; r my_inline_command (without &gt;).\n\nGood job. You are now able to combine text and code in a Quarto document. If you got stuck, you can refer to the Quarto docs on using code chunks.\n\n29.2.1.3 Knitr options\nCode chunks can be greatly customized in terms of visibility and execution, output size and location and much more. This is possible with the knitr chunk options, which usually appear at the beginning of the target chunk with the syntax #| option-name: value, also described here. In this exercise, we explore part of the knitr potential.\n\nOpen RStudio and create a new Quarto file.\nInitialize three code chunks and label them as setup, fig-box and tbl-coldata, respectively. Remember that the name of a chunk can be specified with the label option.\nWrite the following code in the corresponding chunk and render the document.\n\n\n# setup\nlibrary(mia)\ndata(\"GlobalPatterns\", package = \"mia\")\ntse &lt;- GlobalPatterns\n\n# this line sets some options for all the chunks (global chunk options)\nknitr::opts_chunk$set(message = FALSE, warning = FALSE)\n\n\n# fig-box\nboxplot(colSums(assay(tse)) ~ tse$SampleType)\n\n\nlibrary(knitr)\n\n# tbl-coldata\ncolData(tse) |&gt; head() |&gt;\nkable()\n\n\nSet include: false in the setup chunk, fig-width: 10 in the fig-box chunk and echo: false in the tbl-coldata chunk. Render the document again and find the differences from before.\n\nThe setup code and output are no longer visible, resulting in a cleaner document without initialization details. Figures in the fig-box chunk are now wider, providing better visibility and detail in the graphics. The code in the tbl-coldata chunk is hidden, making the document more concise and focused on the results rather than the code implementation.\n\nAdd the options fig-cap and tab-cap to the fig-box and tbl-coldata chunks, respectively. They require some text input, which makes for the caption of the figures or tables.\n\nExtra: Create a cross-reference to fig-box and tbl-coldata in the text above the respective code chunk. You can do that with the syntax @chunk-name.\n\nExtra: Define a custom folder for storing figures with fig-path. Insert it in knitr::opts_chunk$set, so that it applies globally to all the figures generated in the document.\n\nCongratulations! You are now familiar with the great potential and flexibility of knitr chunk options. An exhaustive list of available options can be found in the knitr documentation.\n\n29.2.1.4 YAML instructions\nThe box at the beginning of every Quarto document contains yaml options that let you define the metadata of the document. They will affect the appearance of the document when it is rendered. By default, the box includes yaml options for the title, format and editor to be used, but much more information on layout, code execution and figures can be specified. A comprehensive list of yaml options is available here. In this exercise, we will get a tiny taste of such functionality.\n\nOpen RStudio and create a new Quarto file.\nIn the yaml box at the beginning of the document, change the title from Untitled to My first Quarto.\nIn the same box, add the two lines author and date followed by your name and today’s date, respectively.\nRender the document and check its appearance.\n\nExtra: Set toc: true to produce a table of contents. This line should follow format and html at the second level of indentation.\n\nWell done! Now you are able to specify yaml options and understand how they affect your Quarto document. If you got stuck, you can check this section of the Quarto documentation.\n\n29.2.1.5 Quarto parameters\nAn advanced feature of Quarto consists of execution parameters, which are externally pre-defined variables that are also accessible in the Quarto document. They can be specified in the yaml box as params. Here we learn how to use them.\n\nOpen RStudio and create a new Quarto file.\nIn the yaml box at the beginning of the document, add a line named params followed by an indented line with gamma: 10\n\nInitialize a code chunk and type str(params$gamma) in it.\nRender the document and check what happened.\nDefine one more parameter beta: 3 and multiply gamma by beta in a code chunk below.\nRender the document again and check what happened.\n\nWell done! You can now use an advanced feature of Quarto such as parameters. If you got stuck, here you can find more information about parameter definition and usage.",
    "crumbs": [
      "Training",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "pages/exercises.html#data-containers-treese",
    "href": "pages/exercises.html#data-containers-treese",
    "title": "29  Exercises",
    "section": "\n29.3 Data containers: TreeSE",
    "text": "29.3 Data containers: TreeSE\nTreeSE containers represent the working unit of the mia package. In the following exercises we learn how to construct, explore and work with them. A few demo datasets can be imported with mia and can be accessed as explained in Section 4.2.\n\n29.3.1 Constructing a data object\nHere we cover how to construct a TreeSE from CSV files, using the components of OKeefeDSData from the microbiomeDataSets package as an example dataset.\n\nFetch or download the files in this directory.\n\n\nShow solutionurl_to_assay &lt;- url(\"https://github.com/microbiome/data/raw/main/OKeefeDSData/okeefe_assay.csv\")\nurl_to_coldata &lt;- url(\"https://github.com/microbiome/data/raw/main/OKeefeDSData/okeefe_coldata.csv\")\nurl_to_rowdata &lt;- url(\"https://github.com/microbiome/data/raw/main/OKeefeDSData/okeefe_rowdata.csv\")\n\n\n\nRead in the csv files with read.csv and store them into the variables assays, rowdata and coldata, respectively.\n\n\nShow solutionokeefe_assay &lt;- read.csv(url_to_assay, row.names = 1)\nokeefe_coldata &lt;- read.csv(url_to_coldata, row.names = 1)\nokeefe_rowdata &lt;- read.csv(url_to_rowdata, row.names = 1)\n\n\n\nCreate a TreeSE from the individual components with TreeSummarizedExperiment. Note that the function requires three arguments: assays, rowData and colData, to which you can give the appropriate item.\n\n\nShow solutiontse &lt;- TreeSummarizedExperiment(assays = list(counts = okeefe_assay),\n                                colData = okeefe_coldata,\n                                rowData = okeefe_rowdata)\n\n\n\nCheck that importing is done correctly. E.g., choose random samples and features, and check that their values equal between raw files and TreeSE.\n\n\nShow solutionokeefe_assay[1:5, 1:7]\nassay(tse, \"counts\")[1:5,1:7]\n\n\nUseful functions: DataFrame, TreeSummarizedExperiment, matrix, rownames, colnames, SimpleList\n\n29.3.2 Importing data\nRaw data of different types can be imported as a TreeSE with a number of functions explained in chapter Section 4.1.2. You can also check the function reference in the mia package.\n\nGet familiar with the microbiome data repository and read the instructions in its README to import and construct datasets from there.\nImport data by using mia. (functions: importMetaPhlAn | importMothur | importQIIME2 | convertFromBIOM | convertFromDADA2 …)\nTry out conversions between TreeSE and phyloseq data containers (convertFromPhyloseq; convertToPhyloseq)\n\n29.3.3 Preliminary exploration\n\nImport the mia package, load any of the example data sets mentioned in Section 4.2 with data and store it into a variable named tse.\n\n\nShow solutionlibrary(mia)\ndata(GlobalPatterns, package=\"mia\")\ntse &lt;- GlobalPatterns\n\n\n\nGet a summary about the TreeSE with summary. What is the mean count across samples? How many features recur only once (singletons)?\n\n\nShow solutionsummary(tse)\n\n\n\nCheck the dimensions of the TreeSE with dim or alternatively with nrow and ncol. How many samples and features are present?\n\n\nShow solutiondim(tse)\n\n\n\nList sample and features names with rownames and colnames.\n\n\nShow solutionrownames(tse)\ncolnames(tse)\n\n\n\nCheck what information about samples and features is contained by the colData and rowData of the TreeSE with names.\n\n\nShow solutionnames(colData(tse))\nnames(rowData(tse))\n\n\n\n\nExtra: Calculate the number of unique taxa for each taxonomic rank. You can use apply to count unique elements for each column of rowData.\n\n29.3.4 Assay retrieval\n\nImport the mia package, load any of the example data sets mentioned in Section 4.2 with data and store it into a variable named tse.\n\n\nShow solutionlibrary(mia)\ndata(GlobalPatterns, package=\"mia\")\ntse &lt;- GlobalPatterns\n\n\n\nList the names of all available assays with assayNames.\n\n\nShow solutionassayNames(tse)\n\n\n\nFetch the list of assays with assays.\n\n\nShow solutionassays(tse)\n\n\n\nRetrieve the first assay of the TreeSE with assay, where the second argument can be either the name or the index of the desired assay.\n\n\nShow solutionassay(tse, \"counts\")[1:5,1:7]\n\n\nWell done! You can now locate and retrieve individual assays of a TreeSE. If you got stuck, you can refer to chapter Section 3.2 of this book.\n\n29.3.5 Sample information\n\nImport the mia package, load any of the example data sets mentioned in Section 4.2 with data and store it into a variable named tse.\n\n\nShow solutionlibrary(mia)\ndata(\"GlobalPatterns\", package = \"mia\")\ntse &lt;- GlobalPatterns\n\n\n\nCheck the names of the samples with colnames.\n\n\nShow solutioncolnames(tse)\n\n\n\nList the information on samples available in colData with names.\n\n\nShow solutionnames(colData(tse))\n\n\n\nVisualize the colData with View and briefly look at the information stored in the different columns.\n\n\nShow solutionView(colData(tse))\n\n\n\nGet the abundances of all features for a specific sample, such as ID34, for an assay of your choice.\n\n29.3.6 Feature information\n\nImport the mia package, load any of the example data sets mentioned in Section 4.2 with data and store it into a variable named tse.\n\n\nShow solutionlibrary(mia)\ndata(\"GlobalPatterns\", package = \"mia\")\ntse &lt;- GlobalPatterns\n\n\n\nCheck the names of the features with rownames.\n\n\nShow solutionrownames(tse)\n\n\n\nList the information on features available in rowData with names.\n\n\nShow solutionnames(rowData(tse))\n\n\n\nVisualize the rowData with View and briefly look at the information stored in the different columns.\n\n\nShow solutionView(rowData(tse))\n\n\n\nGet the abundances for a specific feature, such as OTU1810, in all the samples. You can access feature-specific abundances for an assay of your choice.\n\nIf you got stuck, you can look up chapters Chapter 6 and Section 6.3 on how to pick specific abundances and generate row trees, respectively.\n\n29.3.7 Other elements\nExtract some of the other TreeSE elements listed in chapter Chapter 3. However, such data are not always included.\n\nImport the mia package, load any of the example data sets mentioned in Section 4.2 and store it into a variable named tse.\n\n\nShow solutionlibrary(mia)\ndata(\"GlobalPatterns\", package = \"mia\")\ntse &lt;- GlobalPatterns\n\n\n\nFetch the metadata of the TreeSE. Is there any information available?\n\n\nShow solutionnames(metadata(tse))\n\n\n\nAccess the phylogenetic tree with rowTree. How big is it in terms of tips and nodes. If you like you can visualize it with ggtree.\n\n\nShow solutionrowTree(tse)\n\n\n\nCheck if a sample tree is available with colTree, which is suitable for hierarchical or nested study designs.\n\n\nShow solutioncolTree(tse)\n\n\n\nIf present, obtain the information on feature DNA sequences from the DNA sequence slot.\n\n\nShow solutioncolData(tse)$Barcode_full_length",
    "crumbs": [
      "Training",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "pages/exercises.html#data-manipulation",
    "href": "pages/exercises.html#data-manipulation",
    "title": "29  Exercises",
    "section": "\n29.4 Data manipulation",
    "text": "29.4 Data manipulation\n\n29.4.1 Subsetting\nIn this exercise, we’ll go over the basics of subsetting a TreeSE object. Keep in mind that it’s good practice to always keep the original data intact. Therefore, we suggest creating a new TreeSE object whenever you subset.\nPlease have a try at the following exercises.\n\nSubset the TreeSE object to specific samples and features.\n\n1.1. Find some samples and features to subset with.\n\nShow solutionlibrary(mia)\ndata(\"GlobalPatterns\", package = \"mia\")\ntse &lt;- GlobalPatterns\n\nrowData(tse)$Phylum |&gt; unique() |&gt; head() # Features\n\ntse$SampleType |&gt; unique() # Samples\n\n\n1.2. Subset the TreeSE with your found samples and features.\n\nShow solutionfeatures &lt;- c(\"Crenarchaeota\", \"Euryarchaeota\", \"Actinobacteria\")\nsamples &lt;- c(\"Feces\", \"Skin\", \"Tongue\")\n\nrows &lt;- rowData(tse)$Phylum %in% features\ncols &lt;- tse$SampleType %in% samples\ntse_subset_by_feature &lt;- tse[rows, cols]\n\nunique(rowData(tse_subset_by_feature)$Phylum)\n\n\n\n29.4.2 Library sizes\n\nCalculate library sizes\nSubsample / rarify the counts (see: rarefyAssay)\n\nUseful functions: nrow, ncol, dim, summary, table, quantile, unique, scater::addPerCellQC, mia::agglomerateByRank\n\n29.4.3 Prevalent and core taxonomic features\n\nEstimate prevalence for your chosen feature (specific row and taxonomic group)\n\n\nShow solutionlibrary(mia)\ndata(\"GlobalPatterns\", package = \"mia\")\ntse &lt;- GlobalPatterns\n\n# First, merge the features by rank and add it as an alternative experiment.\ntse_phylum &lt;- agglomerateByRank(tse, \"Phylum\")\n\n# Calculate relative abundance\ntse_phylum &lt;- transformAssay(tse_phylum, method = \"relabundance\")\n\n# Then get the prevalence for a specific feature\nres &lt;- getPrevalence(\n     tse_phylum, detection = 1/100,  sort = TRUE, assay.type = \"relabundance\")\nres[\"Proteobacteria\"]\n\n\n\nIdentify all prevalent features and subset the data accordingly.\n\n\nShow solution# Get the prevalent features\nprevalent &lt;- getPrevalent(\n     tse, assay.type = \"counts\", detection = 1, prevalence = 0.1)\n# Subset the data to the prevalent features\ntse_prevalent1 &lt;- tse[rownames(tse) %in% prevalent, ]\n\n# Alternatively subsetByPrevalentFeatures can be used to subset directly\ntse_prevalent2 &lt;- subsetByPrevalent(\n     tse, assay.type = \"counts\", detection = 1, prevalence = 0.1)\n\nidentical(tse_prevalent1, tse_prevalent2)\n\n\n\nHow many features are left ?\n\n\nShow solutionnrow(tse_prevalent1)\n\n\n\nRecalculate the most prevalent features based on relative abundance. How many are left?\n\n\nShow solutiontse &lt;- transformAssay(tse, MARGIN = \"cols\", method=\"relabundance\")\n\ntse_prevalent &lt;- subsetByPrevalent(\n     tse, assay.type = \"relabundance\",\n     detection = 0.01/100, prevalence = 50/100)\n\nnrow(tse_prevalent)\n\n\n\nVisualize prevalence of most prevalent Phyla using a violin/bean plot.\n\n\nShow solution# Import the scater library\nlibrary(scater)\n\n# Agglomerate based on prevalence. Agglomerate to Phylum level.\ntse_phylum &lt;- subsetByPrevalent(\n     tse, rank = \"Phylum\", assay.type = \"relabundance\",\n     detection = 0.001, prevalence = 0.2)\n# Store the prevalence of each taxon\nres &lt;- getPrevalence(\n     tse_phylum, detection = 0.001, sort = FALSE, assay.type = \"relabundance\")\nrowData(tse_phylum)$prevalence &lt;- res\n\n# Then plot the row data\nplotRowData(tse_phylum, \"prevalence\", colour_by = \"Phylum\")\n\n\nUseful functions: getPrevalence, getPrevalent, subsetByPrevalent\n\n29.4.4 Data exploration\n\nSummarize sample metadata variables. (How many age groups, how they are distributed? 0%, 25%, 50%, 75%, and 100% quantiles of library size?)\nCreate two histograms. Another shows the distribution of absolute counts, another shows how CLR transformed values are distributed.\nVisualize how relative abundances are distributed between taxa in samples.\n\nUseful functions: nrow, ncol, dim, summary, table, quantile, unique, transformAssay, ggplot, wilcox.test, agglomerateByRank, miaViz::plotAbundance\n\n29.4.5 Other functions\n\nMerge data objects (merge, mergeSEs)\nMelt the data for visualization purposes (meltSE)\n\n29.4.6 Assay transformation\n\nImport the mia package, load any of the example data sets mentioned in Section 4.2 with data and store it into a variable named tse.\nTransform the counts assay into relative abundances with transformAssay and store it into the TreeSE as an assay named relabund (see chapter Chapter 10).\nSimilarly, perform a clr transformation on the counts assay with a pseudocount of 1 and add it to the TreeSE as a new assay.\nList the available assays by name with assays.\nAccess the clr assay and select a subset of its first 100 features and 10 samples. Remember that assays are subsettable with assay[row_idx, col_idx].\nTake the same subset from the TreeSE, and check how this affects the individual transformed assays. TreeSE can also be subsetted with tse[row_idx, col_idx].\n\nExtra: If the data has phylogenetic tree, perform the phILR transformation.",
    "crumbs": [
      "Training",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "pages/exercises.html#abundance-tables",
    "href": "pages/exercises.html#abundance-tables",
    "title": "29  Exercises",
    "section": "\n29.5 Abundance tables",
    "text": "29.5 Abundance tables\n\n29.5.1 Taxonomic levels\n\nImport the mia package, load one of the example data sets mentioned in Section 4.2 with data (you need one with taxonomic information at Phylum level) and store it into a variable named tse.\nList the available taxonomic ranks in the data with taxonomyRanks.\nAgglomerate the data to Phylum level with agglomerateByRank and the appropriate value for Rank.\nReport the dimensions of the TreeSE before and after agglomerating. You can use dim for that.\n\nExtra: Perform CLR transformation on the data. Does this affect agglomeration?\n\nExtra: List full taxonomic information for a few selected taxa, such as OTU1 and OTU1368. For that you can use mapTaxonomy on a specific subset of the TreeSE.\n\n29.5.2 Alternative experiments\n\nImport the mia package, load one of the example data sets mentioned in Section 4.2 with data (you need one with taxonomic information) and store it into a variable named tse. Can you find the same taxonomyRanks from rowData?\nCheck the taxonomic ranks of the features with taxonomyRanks. What is the deepest taxonomic rank available?\nAgglomerate the TreeSE to each taxonomic rank and store the resulting experiments as altExps. This can be performed automatically with agglomerateByRanks.\nCheck the names of the generated altExps with altExpNames and retrieve a complete list with altExps.\nRetrieve the data agglomerated by genus from the corresponding altExp. As for assays, you can access the desired altExp by name or index.\n\nExtra: Split the data based on other features with splitOn.\n\n29.5.3 Beta Diversity\nThis Exercise will focus on calculating dissimilarities or beta diversity.\n\nImport the mia and vegan packages and load a dataset. This can be your own or one of the packages built in to mia.\n\n\nShow solutionlibrary(mia)\nlibrary(vegan)\n\ndata(\"Tengeler2020\", package = \"mia\")\ntse &lt;- Tengeler2020\n\n\n\nAgglomerate data to all available taxonomy ranks by using agglomerateByRanks()\n\n\n\nShow solutiontse &lt;- agglomerateByRanks(tse)\naltExpNames(tse)\n\n\n\nImport the scater library and run PCoA on on one of the created alternative experiments using Bray-Curtis dissimilarity.\n\n\nShow solution# We use scater library for calculating ordination\nlibrary(scater)\n\n# Choose rank\nrank &lt;- \"Genus\"\n# Calculate relative abundance\naltExp(tse, rank) &lt;- transformAssay(\n   altExp(tse, rank), MARGIN = \"cols\", method=\"relabundance\")\n\n# Calculate ordination\naltExp(tse, rank) &lt;- runMDS(\n    altExp(tse, rank),\n    FUN = vegan::vegdist,\n    method = \"bray\",\n    assay.type = \"relabundance\",\n    name = \"MDS_bray\")\n\n\n\nPlot the first two coordinates using the reducedDim function and plot the coordinates.\n\n\nShow solutionp &lt;- plotReducedDim(altExp(tse, rank), \"MDS_bray\")\np\n\n\n\nAdd the explained variance ratios for each coordinate on the axes labels and plot the PCoA again.\n\n\nShow solution# Calculate explained variance\ne &lt;- attr(reducedDim(altExp(tse, rank), \"MDS_bray\"), \"eig\")\nrel_eig &lt;- e / sum(e[e &gt; 0])\n\n# Add explained variance for each axis\np &lt;- p +\n   labs(\n      x = paste(\"PCoA 1 (\", round(100 * rel_eig[[1]], 1), \"%\", \")\", sep = \"\"),\n      y = paste(\"PCoA 2 (\", round(100 * rel_eig[[2]], 1), \"%\", \")\", sep = \"\"))\n\np",
    "crumbs": [
      "Training",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "pages/exercises.html#community-alpha-diversity",
    "href": "pages/exercises.html#community-alpha-diversity",
    "title": "29  Exercises",
    "section": "\n29.6 Community (alpha) diversity",
    "text": "29.6 Community (alpha) diversity\n\n29.6.1 Estimation\n\nImport the mia package, load any of the example data sets mentioned in Section 4.2 with data and store it into a variable named tse.\nCalculate multiple alpha diversity indices with estimateDiversity without any additional arguments.\nCheck the names of colData with names. Can you identify which columns contain the alpha diversity indices?\n\nExtra: Agglomerate the TreeSE by phylum and compare the mean Shannon diversity of the original experiment with its agglomerated version. You can use agglomerateByRank to perform agglomeration and mean to calculate the mean values of the respective columns in colData.\n\n29.6.2 Visualization\n\nImport the mia and scater packages, load any of the example data sets mentioned in Section 4.2 with data and store it into a variable named tse.\nCalculate Shannon diversity index and Faith’s phylogenetic diversity with estimateDiversity and the appropriate arguments for index.\nMake a boxplot of Shannon diversity on the y axis and sample type on the x axis using scater::plotColData.\nRepeat the previous point with Faith’s phylogenetic diversity and compare the sample distributions of the two alpha diversity indices. How greatly do they differ?\n\nExtra: Make a scatterplot of Shannon diversity on the y axis and Faith’s phylogenetic diversity on the x axis with plotColData. Colour the points by sample type with the appropriate optional argument.\n\n29.6.3 Correlation\n\nImport the mia and scater packages, load any of the example data sets mentioned in Section 4.2 with data and store it into a variable named tse.\nCalculate coverage and Shannon diversity index with addAlpha and the appropriate arguments for index.\nTest the correlation between the two indices with cor.test. Remember that colData parameters are accessible with tse$param_name. Use Kendall tau coefficients as method to measure correlation. Is the correlation weak or strong, significant or not?\nMake a scatterplot of Shannon diversity index on the y axis and coverage on the x axis. You can do that with plotColData. How do the two indices relate to one another?\n\nExtra: Compute the library size of the samples by applying colSums to the counts assay of the TreeSE, and test the correlation of library size with Shannon diversity or coverage. Which index is more correlated with library size?\n\nIn this example, we inspected the correlation between two related variables, also known as multicollinearity, and checked the correlation to library size, which is part of quality control. However, the correlation between alpha diversity and other numerical data about samples, such as participant’s age and weight, also represent an important analysis in several studies.\n\n29.6.4 Differences between groups\n\nImport the mia package, load any of the example data sets mentioned in Section 4.2 with data and store it into a variable named tse.\nCalculate the Gini-Simpson diversity with estimateDiversity and the appropriate argument for index. Set name to simpson. You will use this name to access the diversity index from colData.\nInspect the Diet column in the colData. Determine how the samples are grouped in terms of diet. You can see the number of unique elements in a column with unique.\nTest differences in Gini-Simpson diversity between different diets with kruskal.test. Remember that colData parameters are accessible with tse$param_name.\nIs diversity significantly different between vegan and mixed diet? To visualize that, make a boxplot of Gini-Simpson diversity on the y axis and diet on the x axis with plotColData.\n\nExtra: Repeat points 3 through 5, this time for age groups. Make sure that you are using an appropriate statistical test for the number of groups and distribution.",
    "crumbs": [
      "Training",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "pages/exercises.html#community-similarity",
    "href": "pages/exercises.html#community-similarity",
    "title": "29  Exercises",
    "section": "\n29.7 Community similarity",
    "text": "29.7 Community similarity\n\n29.7.1 Reduced dimensions retrieval\n\nImport the mia package, load enterotype with data and store it into a variable named tse.\nList all available reduced dimensions with reducedDims. At this point, no reducedDims are likely found, because we haven’t created any yet.\nPerform PCA using the scater library and store its output in the TreeSE by running tse &lt;- runPCA(tse, assay.type = \"counts\"). Note that it is required to specify the assay on which dimensionality reduction should be conducted.\nView the names of all available reduced dimensions with reducedDimNames. Has something new appeared?\n\nExtra: Access the scater::PCA reducedDim object with reducedDim and explore its content. How are the different dimensions stored? Extract an array with only the values from the second dimension by indexing the object with [ , 2].\n\n29.7.2 Visualization basics with PCA\n\nImport the mia and scater packages, load enterotype with data and store it into a variable named tse.\nPerform a 3-component PCA based on the counts assay. You can use runPCA and set the optional arguments ncomponents and assay.type to the appropriate values.\nPlot the first two dimensions of PCA with scater::plotReducedDim, to which you should give the appropriate reducedDim name as the second argument. Note that by default only the first two dimensions are shown.\nCheck which information is stored in the ColData of the TreeSE. What would be worth visualizing in our coordination plot?\nMake the same plot again, but this time colour the observations by Enterotype. You can do that by setting colour.by to the appropriate colname in the colData of the TreeSE.\n\nExtra: Plot all three dimensions of PCA with scater::plotReducedDim and the optional argument ncomponents. Colour observations by Enterotype. Which pair of dimensions best explains the variance between Enterotypes?\n\n29.7.3 Principal Coordinate Analysis (PCoA)\nPCoA turns out to be particularly relevant for microbiome analysis, because unlike PCA it can generate reduced dimensions from distances other than Euclidean. There are several ecological distances to choose from and you can find many of them under methods in the vignettes of vegan::vegdist.\n\nImport the mia and scater packages, load enterotype with data and store it into a variable named tse.\nTransform the counts assay to relative abundances with transformAssay.\nPerform a Multi-Dimensional Scaling (MDS) based on the relative abundance assay in terms of Bray-Curtis dissimilarity. You can use scater::runMDS with the compulsory argument FUN = vegan::vegdist.\nPlot the first two dimensions of PCA with plotReducedDim, to which you should give the appropriate reducedDim name as the second argument. Colour the observations by Enterotype with colour.by.\n\nExtra: Perform MDS again with scater::runMDS, but this time use Jaccard dissimilarity. The distance metric to use can be defined with the optional argument method, choosing from the methods in ?vegan::vegdist. If you don’t want to overwrite the reducedDim object made in point 3, set name to a name of your choice. Visualize and compare it to the plot from point 4.\n\nGood job! You are now able to produce and visualize reduced dimensions of a TreeSE. runMDS is actually one of several algorithms for PCoA and dimensionality reduction, which you can find in Section 14.2.3.\n\n29.7.4 PERMANOVA analysis\nIn this exercise we focus on studying the weight of variables on the microbiome composition. Significance of each variable on beta diversity is tested with PERMANOVA (point 4) and the homogeneity assumption is also be controlled with a PERMDISP2 analysis (point 5).\n\nImport the mia and vegan packages, load any of the example data sets mentioned in Section 4.2 with data and store it into a variable named tse.\nTransform the counts assay into relative abundances with transformAssay.\nExtract the relative abundance assay, transpose it and save it into a variable named relabund_assay.\nPerform PERMANOVA with vegan::adonis2 to see how much Diet can explain the relative abundance assay (formula = relabund_assay ~ Diet) in terms of Bray-Curtis dissimilarity (method = \"bray\"). Also set data = colData(tse) by = \"margin\" and permutations = 99. What do the results tell you about Diet with respect to beta diversity?\n\nExtra: Test homogeneity of distribution across Diet groups with anova(betadisper(my_mat), my_groups, where my_mat is the Bray-Curtis dissimilarity matrix of relabund_assay calculated with vegdist(relabund_assay, \"bray\") and my_groups is the vector of Diet values obtained from the colData of the TreeSE.\n\nWell done! You went through testing the effect and significance of Diet on beta diversity. Keep in mind that the formula fed to adonis2 can take more than one independent variable, so that you can also (and very often should) include covariates of your studies.\n\n29.7.5 Redundancy analysis (RDA)\nHere we apply RDA, an ordination method that provides dimensions with the largest variation between the data based in the light of the specified variables (point 3). The results of RDA are usually assessed with PERMANOVA (point 5) and the homogeneity assumption should be checked as in the previous exercise. This is a relatively complex procedure, but the way this is broken down into steps below will hopefully make more sense.\n\nImport the mia package, load any of the example data sets mentioned in Section 4.2 with data and store it into a variable named tse.\nTransform the counts assay into relative abundances with transformAssay.\nPerform RDA with addRDA to see how much Diet can explain the relative abundance assay (formula = assay ~ Diet and assay.type = relabundance) in terms of Bray-Curtis dissimilarity (method = \"bray\").\nExtract the RDA dimensions from the appropriate reducedDim slot with attr(reducedDim(tse, \"RDA\"), \"rda) and store it into a variable named rda.\nExtract the effect and significance of Diet on beta diversity with attr(reducedDim(tse, “RDA”), “significance”). What do the results tell you about Diet?\n\nExtra: Check what other parameters are stored in the colData of peerj13075, add them to the formula (formula = assay ~ Diet + ...) of getRDA and proceed to see how that changes the results of PERMANOVA.\n\nWell done! You went through an RDA analysis followed by significance testing with PERMANOVA and BETADISPER2. In the next exercise we’ll go deeper quantify the contributions to beta diversity.\n\n29.7.6 Beta diversity analysis\nIn this exercise, we’ll ask you to implement a distance-based Redundancy Analysis (dbRDA) to understand the relationships between microbial community composition and various environmental or experimental factors within your dataset. You can refer to chapter Section 14.3.2 for a step-by-step walkthrough, which may be simplified in the future.\n\nImport the mia package, load any of the example data sets mentioned in Section 4.2 with data and store it into a variable named tse.\n\n\nShow solutionlibrary(mia)\n\ndata(\"GlobalPatterns\", package = \"mia\") # Feel free to use any dataset\ntse &lt;- GlobalPatterns\n\n\n\nCreate a new assay with the relative abundance for your dataset and merge the features by a rank of your choice.\n\n\nShow solutiontse &lt;- transformAssay(tse, MARGIN = \"cols\", method=\"relabundance\")\n\n\n\nSelect a group of samples and perform a permutational analysis on the calculated relative abundance using Bray-Curtis dissimilarities\n\n\nShow solutiontse$Group &lt;- tse$SampleType == \"Feces\"\n\n\n\nImplement dbRDA on relative abundances and perform another permutational analysis on the redundancy analysis.\n\n\nShow solutiontse &lt;- runRDA(\n    tse,\n    assay.type = \"relabundance\",\n    formula = assay ~ Group,\n    distance = \"bray\",\n    na.action = na.exclude)\n\nrda_info &lt;- attr(reducedDim(tse, \"RDA\"), \"significance\")\n\nrda_info\n\n\nrda_info now holds information on the variation differences between the chosen groups, in our case, the homogeneity test has a p-value of 0.01, indicating that the groups have different variances, making it so that the permanova results are compromised and do not correctly explain whether there are significant differences between groups.\n\nNevertheless, extract the p-values. Can the differences between samples be explained with variables from their metadata?\n\n\nShow solutionrda_info[[\"permanova\"]][[\"Pr(&gt;F)\"]]\n\n\nUseful functions: scater::runMDS, runRDA, transformAssay, agglomerateByRank",
    "crumbs": [
      "Training",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "pages/exercises.html#differential-abundance",
    "href": "pages/exercises.html#differential-abundance",
    "title": "29  Exercises",
    "section": "\n29.8 Differential abundance",
    "text": "29.8 Differential abundance\n\n29.8.1 Standard analysis with ALDEx2\n\nImport the mia and ALDEx2 packages, load any of the example data sets mentioned in Section 4.2 with data and store it into a variable named tse.\n\n\nShow solutionlibrary(mia)\nlibrary(ALDEx2)\n\ndata(\"peerj13075\", package = \"mia\")\ntse &lt;- peerj13075\n\n\n\nAgglomerate the TreeSE by genus and filter by a prevalence of 10%. You can perform both operations in one go with subsetByPrevalent by specifying the rank and prevalence arguments.\n\n\nShow solutiontse &lt;- subsetByPrevalent(tse, rank = \"genus\", prevalence = 0.1)\n\n\n\nModel the counts assay of the TreeSE with aldex.clr and store it into the variable x. As a second argument, provide the grouping variable Diet, which is contained in a column of the colData.\n\n\nShow solutionx &lt;- aldex.clr(assay(tse), tse$Gender)\n\n\n\nFeed x to the functions aldex.ttest to perform t-test and to aldex.effect to estimate effect sizes. Store the output into x_tt and x_effect, respectively.\n\n\nShow solutionx_tt &lt;- aldex.ttest(x)\nx_effect &lt;- aldex.effect(x, CI = TRUE)\n\n\n\nCreate a data.frame named aldex_out which includes both x_tt and x_effect and filter for the features with wi.eBH &lt; 0.05. Are there any significantly differential abundance taxa?\n\n\nShow solutionaldex_out &lt;- data.frame(x_tt, x_effect)\n\naldex_out |&gt;\n     rownames_to_column(var = \"Genus\") |&gt;\n     filter(wi.eBH &lt;= 0.05)  |&gt;\n     dplyr::select(Genus, we.eBH, wi.eBH, effect, overlap)\n\n\n\n\nExtra: If these results appear boring, repeat steps 1 - 5, but use Gender or Age as the grouping variable. Do we have any better luck with Gender? What is the problem with Age?\n\n29.8.2 Controlling for confounders\n\nImport the mia and MicrobiomeStat packages, load any of the example data sets mentioned in Section 4.2 with data and store it into a variable named tse.\n\n\nShow solutionlibrary(mia)\nlibrary(MicrobiomeStat)\n\ndata(\"peerj13075\", package = \"mia\")\ntse &lt;- peerj13075\n\n\n\nAgglomerate the TreeSE by genus and filter by a prevalence of 10%. You can perform both operations in one go with subsetByPrevalent by specifying the rank and prevalence arguments.\n\n\nShow solutiontse &lt;- subsetByPrevalent(tse, rank = \"genus\", prevalence = 0.1)\n\n\n\nModel the counts assay of the TreeSE with linda and store the output into a variable named linda_out. Provide the colData converted into a data.frame (with as.data.frame) as the second argument, and a formula with the Age, Gender and Diet as variables. For example, formula = \"~ A + B\" represents a formula with variables A and B.\n\n\nShow solutionlinda_out &lt;- linda(\n    as.data.frame(assay(tse, \"counts\")),\n    as.data.frame(colData(tse)),\n    formula = \"~ Diet + Gender + Age\")\n\n\n\nExtract the output$AgeElderly object from linda_out with $ and store it into a variable named linda_res.\n\n\nShow solutionlinda_res &lt;- linda_out$output$AgeElderly\n\n\n\nFilter linda_res for features with reject == TRUE. How many differentially abundant taxa were found? What are their names and how significant are they in terms of log-fold change and adjusted p-value?\n\n\nShow solutionlibrary(tidyverse)\n\nlinda_res |&gt;\n    filter(reject) |&gt;\n    select(log2FoldChange, stat, padj) |&gt;\n    rownames_to_column(var = \"feature\")\n\nnrow(linda_res)\n\n\n\n29.8.3 Comparing methods\nHere, we conduct DAA with identical parameters as in the previous exercise, but with a different method, namely ZicoSeq. We aim to compare the results between these two methods and draw better informed conclusions from such comparative approach.\n\nImport the mia and GUniFrac packages, load any of the example data sets mentioned in Section 4.2 with data and store it into a variable named tse.\n\n\nShow solutionlibrary(mia)\nlibrary(tidyverse)\n\ndata(\"peerj13075\", package = \"mia\")\ntse &lt;- peerj13075\n\n\n\nAgglomerate the TreeSE by genus and filter by a prevalence of 10%. You can perform both operations in one go with subsetByPrevalent by specifying the rank and prevalence arguments.\n\n\nShow solutiontse &lt;- subsetByPrevalent(tse,  rank = \"genus\", prevalence = 0.1)\n\n\n\nModel the counts assay of the TreeSE with ZicoSeq as the feature.dat argument and store the output into a variable named zicoseq_out. Provide also the colData converted to a data.frame (with as.data.frame) as meta.dat. In addition, set grp.name to \"Age\", adj.name to c(\"Diet\", \"Gender\"), feature.dat.type to \"count\", return.feature.dat to TRUE and perm.no to 999.\n\n\nShow solutionzicoseq_out &lt;- ZicoSeq(\n    feature.dat = as.matrix(assay(tse)),\n    meta.dat = as.data.frame(colData(tse)),\n    grp.name = \"Age\",\n    adj.name = c(\"Diet\", \"Gender\"),\n    feature.dat.type = \"count\",\n    return.feature.dat = TRUE,\n    perm.no = 999)\n\n\n\nView the top six differentially abundant taxa and their adjusted p-values with head(sort(zicoseq_out$p.adj.fdr)). Is there any significant taxon according to ZicoSeq? Compared to the output of linda, do we see the same taxa at the top in terms of significance? Overall, to what extent do the two methods agree with one another?\n\n\nShow solutionzicoseq_res &lt;- cbind.data.frame(\n    p.raw = zicoseq_out$p.raw, p.adj.fdr = zicoseq_out$p.adj.fdr)\n\nzicoseq_res |&gt;\n    arrange(p.raw) |&gt;\n    head() |&gt;\n    kable()\n\n\n\n29.8.4 Workflow 1\n\nGet the abundances for an individual feature (taxonomic group / row).\nVisualize the abundances per group with boxplot / jitterplot.\nIs the difference significant (Wilcoxon test)?\nIs the difference significant (linear model with covariates)?\nHow do transformations affect the outcome (log10, clr..)?\nGet p-values for all features (taxa), for instance with a for loop.\nDo multiple testing correction.\nCompare the results from different tests with a scatterplot.\n\nUseful functions: [], ggplot2::geom_boxplot, ggplot2::geom_jitter, wilcox.test, lm.test, transformAssay, p.adjust\n\n29.8.5 Workflow 2\n\nInstall the latest development version of mia from GitHub.\nLoad experimental dataset from mia.\nCompare abundances of each taxa between groups. First, use Wilcoxon or Kruskall-Wallis test. Then use some other method dedicated to microbiome data.\nSummarize findings by plotting a taxa vs samples heatmap. Add column annotation that tells the group of each sample, and row annotation that tells whether the difference of certain taxa was statistically significant.\nChoose statistically significant taxa and visualize their abundances with boxplot & jitterplot.\n\nUseful functions: wilcox.test, kruskal.test, ggplot2::ggplot, ComplexHeatmap::pheatmap, ComplexHeatMap::Heatmap, ANCOMBC::ancombc2, ALDEx2::aldex, Maaslin2::Maaslin2, agglomerateByRank, transformAssay, subsetByPrevalent",
    "crumbs": [
      "Training",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "pages/exercises.html#visualization-1",
    "href": "pages/exercises.html#visualization-1",
    "title": "29  Exercises",
    "section": "\n29.9 Visualization",
    "text": "29.9 Visualization\n\n29.9.1 Multivariate ordination\n\nLoad experimental dataset from mia.\nCreate PCoA with Bray-Curtis dissimilarities.\nCreate PCA with Aitchison dissimilarities.\nVisualize and compare both.\nTest other transformations, dissimilarities, and ordination methods.\n\nUseful functions: scater::runMDS, runNMDS, transformAssay, ggplot, scater::plotReducedDim\n\n29.9.2 Heatmap visualization\n\nLoad one of the datasets from mia and the miaViz and sechm packages.\n\n\nShow solutionlibrary(mia)\nlibrary(miaViz)\nlibrary(sechm)\n\ndata(\"GlobalPatterns\", package = \"mia\")\ntse &lt;- GlobalPatterns\n\n\n\nAgglomerate your TreeSE to include the most prevalent Phyla.\n\n\nShow solutiontse &lt;- agglomerateByPrevalence(tse, rank = \"Phylum\", prevalence = 0.9)\n\n\n\nAdd a relative abundance assay to the TreeSE.\n\n\nShow solutiontse &lt;- transformAssay(tse, assay.type = \"counts\", method = \"relabundance\")\n\n\n\nVisualize the relative abundances with a heatmap using the sechm package.\n\n\nShow solutionsetSechmOption(\"hmcols\", value=c(\"#F0F0FF\",\"#007562\"))\nsechm(\n    tse, features = rownames(tse), assayName=\"relabundance\",\n    show_colnames=TRUE)\n\n\n\nCreate a similar heatmap but now using the ComplexHeatmap package directly.\n\n\nShow solutionlibrary(mia)\nlibrary(ComplexHeatmap)\n\nHeatmap(assay(tse, \"relabundance\"))\n\n\n\n29.9.3 Advanced Heatmaps\n\nImport mia, miaviz, complexHeatmap, shadowtext as well as a dataset of your choice\n\n\nShow solutionlibrary(mia)\nlibrary(miaViz)\nlibrary(shadowtext)\nlibrary(ComplexHeatmap)\n\ndata(\"Tengeler2020\", package = \"mia\")\ntse &lt;- Tengeler2020\n\n\n\nAgglomerate the data by prevalence to a rank of your choice, apply log10 transformation and assure unique rownames for when we plot the heatmap.\n\n\nShow solutiontse &lt;- agglomerateByPrevalence(tse, rank = \"Family\")\n\ntse &lt;- transformAssay(tse, method = \"log10\", pseudocount = TRUE)\n\nrownames(tse) &lt;- getTaxonomyLabels(tse)\n\n\n\nCalculate the correlations and their respective p-values between the log10 and count assays.\n\n\nShow solutioncorrelations &lt;- getCrossAssociation(\n    tse,\n    test.signif=TRUE,\n    assay.type1 = \"log10\",\n    assay.type2 = \"counts\",\n    method = \"spearman\",\n    p.adj.threshold = NULL,\n    cor.threshold = NULL,\n    # Remove when mia is fixed\n    mode = \"matrix\",\n    sort = TRUE,\n    show.warnings = FALSE)\n\n\n\nPlot a heatmap using the correlations and mark significant correlations (p&lt;0.05) with a cross.\n\n\nShow solution# Create a heatmap and store it\np &lt;- Heatmap(\n    correlations$cor,\n    # Print values to cells\n    cell_fun = function(j, i, x, y, width, height, fill) {\n        # If the p-value is under threshold\n        if( !is.na(correlations$pval[i, j]) & correlations$pval[i, j] &lt; 0.05 ){\n            # Print \"X\"\n            grid.shadowtext(\n                sprintf(\"%s\", \"X\"), x, y,\n                gp = gpar(fontsize = 8, col = \"#f5f5f5\"))\n        }\n    },\n    heatmap_legend_param = list(title = \"\", legend_height = unit(5, \"cm\"))\n)\np\n\n\n\nPlot similar heatmap but adjust color scale to ensure that 0 is in the middle\n\nHint: utilize circlize::colorRamp2()\n\nShow solutionlibrary(circlize)\n# Update color scale to ensure 0 is in the middle\ncol_fun &lt;- colorRamp2(\n    c(-1, -0.5, 0, 0.5, 1),\n    c(\"darkblue\",\"skyblue\",\"white\", \"brown1\", \"darkred\"))\n\n# Create a heatmap and store it\np &lt;- Heatmap(\n    correlations$cor,\n    # Print values to cells\n    cell_fun = function(j, i, x, y, width, height, fill) {\n        # If the p-value is under threshold\n        if( !is.na(correlations$pval[i, j]) & correlations$pval[i, j] &lt; 0.05 ){\n            # Print \"X\"\n            grid.shadowtext(\n                sprintf(\"%s\", \"X\"), x, y,\n                gp = gpar(fontsize = 8, col = \"#f5f5f5\"))\n        }\n    },\n    heatmap_legend_param = list(title = \"\", legend_height = unit(5, \"cm\")),\n    col = col_fun\n)\np\n\n\nExtra Cool exercises:\n\nCreate an interactive heatmap in Phylum level. Visualize standardized (Z-scored) relative abundances.\n\n\nShow solutionlibrary(mia)\nlibrary(heatmaply)\n\ndata(\"GlobalPatterns\", package = \"mia\")\ntse &lt;- GlobalPatterns\n# Agglomerate\ntse_phylum &lt;- agglomerateByRank(GlobalPatterns, rank = \"Phylum\")\n# Transform\ntse_phylum &lt;- transformAssay(tse_phylum, method = \"relabundance\")\ntse_phylum &lt;- transformAssay(\n   tse_phylum, assay.type = \"relabundance\", method = \"standardize\",\n   MARGIN = \"rows\")\n\n# Create the interactive heatmap using aggregated data\nheatmaply(assay(tse_phylum, \"standardize\"), xlab = \"Samples\", ylab = \"Phyla\")\n\n\n\nk-means clustering on reduced dimensions and visualization\n\n\nPerforms k-means clustering on reduced dimensional data obtained from PCoA.\nVisualizes the clusters in a scatter plot of the reduced dimensions.\n\n\nShow solutionlibrary(mia)\nlibrary(SummarizedExperiment)\nlibrary(scater)\nlibrary(bluster)\n\ndata(GlobalPatterns)\ntse &lt;- GlobalPatterns\n\n# Perform MDS on the abundance data using scater::runMDS\ntse &lt;- runMDS(tse, FUN = getDissimilarity, method = \"bray\", assay.type = \"counts\")\n\n# Perform k-means clustering using mia's addCluster()\nkmeans_param &lt;- KmeansParam(centers = 3)\ntse &lt;- addCluster(\n   tse, clust.col = \"kmeans_clusters\", by = \"columns\", BLUSPARAM = kmeans_param)\n\n# Visualize MDS with clusters\nplotReducedDim(tse, dimred = \"MDS\", colour_by = \"kmeans_clusters\") +\n  labs(title = \"MDS with k-means Clustering\") +\n  theme_minimal()\n\n\n\nHierarchical Clustering\n\n\nAgglomerate to Family level\nHierarchical clustering of samples based on abundance data.\nVisualizes the clustered data using a heatmap, with cluster information added to metadata.\n\n\nShow solutionlibrary(mia)\nlibrary(bluster)\nlibrary(ComplexHeatmap)\n\ndata(\"GlobalPatterns\", package = \"mia\")\ntse &lt;- GlobalPatterns\n\n# Agglomerate data\ntse &lt;- agglomerateByRank(tse, rank = \"Phylum\")\n# Transform adata\ntse &lt;- transformAssay(tse, method = \"clr\", pseudocount = TRUE)\ntse &lt;- transformAssay(tse, assay.type = \"clr\", method = \"standardize\", MARGIN = \"rows\")\n# Perform hierarchical clustering\nhclust_param &lt;- HclustParam(method = \"complete\", cut.params = list(k = 3))\ntse &lt;- addCluster(\n   tse, clust.col = \"Cluster\", MARGIN = \"columns\", BLUSPARAM = hclust_param)\n\n# Create column annotation\ncolumn_ha = HeatmapAnnotation(cluster = colData(tse)$Cluster)\n# Visualization using sechm heatmap\nmat &lt;- assay(tse, \"standardize\")\nHeatmap(mat, name = \"mat\", top_annotation = column_ha)\n\n\n\nIn the previous heatmap, order the columns based on clusters.\n\n\nShow solution# Order\ntse &lt;- tse[, order(colData(tse)$Cluster)]\n# Create column annotation\ncolumn_ha = HeatmapAnnotation(cluster = colData(tse)$Cluster)\n# Visualization using sechm heatmap\nmat &lt;- assay(tse, \"standardize\")\nHeatmap(mat, name = \"mat\", top_annotation = column_ha, cluster_columns = FALSE)",
    "crumbs": [
      "Training",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "pages/exercises.html#multiomics",
    "href": "pages/exercises.html#multiomics",
    "title": "29  Exercises",
    "section": "\n29.10 Multiomics",
    "text": "29.10 Multiomics\n\n29.10.1 Basic exploration\nHere we learn how to conduct preliminary exploration on a MAE, using HintikkaXOData as an example dataset.\n\nImport the mia package, load HintikkaXOData with data and store it into a variable named mae.\nWhich experiments make up the MAE? How many samples and features are contained by each experiment? You can get a summary for all experiments with experiments, and check for each individual experiment with dim, nrow and ncol.\nWhat are the names of the features and samples of the different experiments? You can see that with rownames and colnames, respectively.\nWhat information is known about the samples? Remember that information about samples is stored in the colData of the MAE.\n\nExtra: How do the samples of the individual experiments map to the columns of the MAE? You can find the sample mapping in the sampleMap of the MAE.\n\nSo far so good. You explored a MAE and its experiments, getting a taste of how information is organized in its internal structure.\n\n29.10.2 Experiment agglomeration\nHere we learn how to manipulate an experiment contained by a MAE and save the new modified version of the experiment in a suitable place (the altExp slot).\n\nImport the mia package, load HintikkaXOData with data and store it into a variable named mae.\nAgglomerate the microbiota experiment by Genus and store the output into the altExp slot of the microbiota experiment, with the custom name microbiota_genus.\nHow many features remain after agglomerating? What are their names?\n\nExtra: create one more alternative experiment named prevalent_microbiota_family, which contains the microbiota experiment agglomerated by Family with a prevalence threshold of 10%. You can agglomerate and in parallel select by prevalence with agglomerateByPrevalence.\n\nGood job! You agglomerated one of the experiments in the MAE and stored it as an alternative experiment.\n\n29.10.3 Experiment transformation\nWe proceed with an exercise on a different type of data manipulation, that is, transformation of assays of individual experiments in the MAE.\n\nImport the mia package, load HintikkaXOData with data and store it into a variable named mae.\nWhat assays are contained by each individual experiment? You can check their names with assays.\nApply a log10 transformation to the assay of the metabolite experiment. For that you can use transformAssay and don’t forget to specify the assay to be transformed with the argument assay.type.\nApply a CLR transformation to the counts assay of the microbiota experiment. To ensure non-null values in the assay, set pseudocount equal to 1.\n\nYou made it! You learnt how to apply different transformations to the assays of individual experiments in a MAE with transformAssay, specifying optional arguments based on the used method.\n\n29.10.4 Assay extraction\nThe following exercise walks you through disassembling a MAE object in order to retrieve a specific assay, or to store its components as multiple separate csv files.\n\nImport the mia package, load HintikkaXOData with data and store it into a variable named mae.\nExtract the individual metabolite experiment from the MAE into a distinct TreeSE object named metabolites.\nWhich and how many assays are contained by metabolites? You can check that with assays or assayNames.\nWrite a csv file for the nmr assay with write.csv. You can access an individual assay of a TreeSE with assay by specifying the name of the desired assay.\n\nExtra: Repeat step 1 thorugh 4 also for the microbiota and biomarkers experiments, so that a completely disassembled version of the MAE is available.\n\nExtra: Besides experiments, MAEs also include a sampleData and a sampleMap, which are accessible with colData(mae) and sampleMap(mae), respectively. Save also each of these two elements into a csv file.\n\nWell done! You just splitted a MAE into its components and stored them as csv files. This script shows a possible approach.\n\n29.10.5 MAE reconstruction\nNext, we will try to reconstruct the same MAE from the files you created. Make sure you know their names and location! Alternatively, you can fetch or download the CSV files in this directory with the readily disassembled components of HintikkaXOData.\n\nRead in the csv files containing assays with read.csv and save each of them into a variable named &lt;assay name&gt;_assays.\nCreate one TreeSE from each assays object with the TreeSummarizedExperiment function, as explained in this exercise.\nRead in the sampleData and the sampleMap and store them into the variables sample_data and sample_map, respectively.\nCombine the components with MultiAssayExperiment, where the first argument is an ExperimentList (for now include only the microbiota and metabolites TreeSEs), the second is colData and the third is sampleMap.\nMake sure that the MAE experiments are identical to the original TreeSEs. You can do that qualitatively by checking their head and quantitatively by looking at their dim.\n\nExtra: Add the biomarkers TreeSE as a new experiment to the MAE. Note that new experiments can be added to a MAE through simple concatenation with c(mae, experiment).\n\nGood job! Now you are aware of how MAEs are built and we can proceed to some analytical exercises.\n\n29.10.6 Cross-association analysis\nNow we will perform a cross-association analysis between two of the experiments in the MAE.\n\nImport the mia package, load HintikkaXOData with data and store it into a variable named mae.\nAnalyze correlations between the microbiota and the biomarkers experiments with getCrossAssociation. Don’t forget to specify the experiments you want to compare with the arguments experiment1 and experiment2, and which of their assays with assay.type1 and assay.type2.\nWhat does the output look like? By default, correlation is measured in terms of Kendall tau coefficients. Repeat point 2, but this time change method to Spearman coefficients.\nAre you able to infer significance from the output?\nVisualize results with a heatmap similarly to the example in section Section 20.1. Do you see any significant correlations? Interpret your results.\n\nExtra: Perform Cross-association analysis between the remaining experiments (microbiota vs metabolites and metabolites vs biomarkers) and visualize results with heatmaps.\n\nGreat job! You performed a Cross-association analysis between two experiments of a MAE and visualized the results with a heatmap. You are also able to customise the correlation method and significance testing used for the analysis.",
    "crumbs": [
      "Training",
      "<span class='chapter-number'>29</span>  <span class='chapter-title'>Exercises</span>"
    ]
  },
  {
    "objectID": "pages/support.html",
    "href": "pages/support.html",
    "title": "30  Support",
    "section": "",
    "text": "30.1 Online support\nFor online support on installation and other matters, join us on:\nYou are also welcome to connect through various channels with our broader developer and user community.",
    "crumbs": [
      "Support & resources",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Support</span>"
    ]
  },
  {
    "objectID": "pages/support.html#online-support",
    "href": "pages/support.html#online-support",
    "title": "30  Support",
    "section": "",
    "text": "Gitter\nSlack\nGitHub",
    "crumbs": [
      "Support & resources",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Support</span>"
    ]
  },
  {
    "objectID": "pages/support.html#sec-coc",
    "href": "pages/support.html#sec-coc",
    "title": "30  Support",
    "section": "30.2 Code of Conduct",
    "text": "30.2 Code of Conduct\nWe support the Bioconductor Code of Conduct. The community values an open approach to science that promotes:\n\nsharing of ideas, code, software and expertise\na kind and welcoming environment, diversity and inclusivity\ncommunity contributions and collaboration",
    "crumbs": [
      "Support & resources",
      "<span class='chapter-number'>30</span>  <span class='chapter-title'>Support</span>"
    ]
  },
  {
    "objectID": "pages/resources.html",
    "href": "pages/resources.html",
    "title": "31  Resources",
    "section": "",
    "text": "31.1 Data containers",
    "crumbs": [
      "Support & resources",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "pages/resources.html#data-containers",
    "href": "pages/resources.html#data-containers",
    "title": "31  Resources",
    "section": "",
    "text": "31.1.1 Data container documentation\n\nSingleCellExperiment (Lun and Risso 2020)\n\nOnline tutorial\nProject page\nPublication\n\nSummarizedExperiment (Morgan et al. 2020)\n\nOnline tutorial\nProject page\n\nTreeSummarizedExperiment (Huang 2020)\n\nOnline tutorial\nProject page\nPublication\n\nMultiAssayExperiment (Ramos et al. 2017)\n\nOnline tutorial\nProject page\nPublication\n\n\n\nLun, Aaron, and Davide Risso. 2020. SingleCellExperiment: S4 Classes for Single Cell Data.\n\nMorgan, Martin, Valerie Obenchain, Jim Hester, and Hervé Pagès. 2020. SummarizedExperiment: SummarizedExperiment Container. https://bioconductor.org/packages/SummarizedExperiment.\n\nHuang, Ruizhu. 2020. TreeSummarizedExperiment: A S4 Class for Data with Tree Structures.\n\n\n31.1.2 Other relevant containers\n\nDataFrame which behaves similarly to data.frame, yet efficient and fast when used with large datasets.\nDNAString along with DNAStringSet,RNAString and RNAStringSet efficient storage and handling of long biological sequences are offered within the Biostrings package (Pagès et al. 2020).\nGenomicRanges ((Lawrence et al. 2013)) offers an efficient representation and manipulation of genomic annotations and alignments, see e.g. GRanges and GRangesList at An Introduction to the GenomicRangesPackage.\n\n\nPagès, H., P. Aboyoun, R. Gentleman, and S. DebRoy. 2020. Biostrings: Efficient Manipulation of Biological Strings. https://bioconductor.org/packages/Biostrings.\n\nLawrence, Michael, Wolfgang Huber, Hervé Pagès, Patrick Aboyoun, Marc Carlson, Robert Gentleman, Martin Morgan, and Vincent Carey. 2013. “Software for Computing and Annotating Genomic Ranges.” PLoS Computational Biology 9. https://doi.org/10.1371/journal.pcbi.1003118.\nNGS Analysis Basics provides a walk-through of the above-mentioned features with detailed examples.\n\n\n31.1.3 phyloseq: an alternative container for microbiome data\nThe phyloseq package and class became the first widely used data container for microbiome data science in R. Many methods for taxonomic profiling data are readily available for this class. We provide here a short description how phyloseq and Experiment classes relate to each other.\nassays : This slot is similar to otu_table in phyloseq. In a SummarizedExperiment object multiple assays, raw counts, transformed counts can be stored. See also (2017) for storing data from multiple experiments such as RNASeq, Proteomics, etc. rowData : This slot is similar to tax_table in phyloseq to store taxonomic information. colData : This slot is similar to sample_data in phyloseq to store information related to samples. rowTree : This slot is similar to tree.file in phyloseq to store phylogenetic tree.\n\nRamos, Marcel, Lucas Schiffer, Angela Re, Rimsha Azhar, Azfar Basunia, Carmen Rodriguez Cabrera, Tiffany Chan, et al. 2017. “Software for the Integration of Multiomics Experiments in Bioconductor.” Cancer Research. https://doi.org/10.1158/0008-5472.CAN-17-0344.\nIn this book, you will encounter terms such as FeatureIDs and SampleIDs. FeatureIDs : These are basically OTU/ASV ids which are row names in assays and rowData. SampleIDs : As the name suggests, these are sample ids which are column names in assays and row names in colData. FeatureIDs and SampleIDs are used but the technical terms rownames and colnames are encouraged to be used, since they relate to actual objects we work with.\n\n\n31.1.3.1 Benchmarking TreeSE with phyloseq\nTreeSE objects can be converted into phyloseq objects and vice versa, therefore it is possible to compare the two containers in terms of computational efficiency. Remarkably, TreeSE and phyloseq were benchmarked against one another in mia v1.2.3 and phyloseq v1.38.0, respectively. 5 standard microbiome analysis operationswere applied to 4 datasets of varying size with both containers. In a nutshell, TreeSE and phyloseq showed a similar performance for datasets of small and medium size for most of the operations. However, TreeSE performed more efficiently as the size of the datasets increased. Further details on such results can be found in the benchmarking repository.\n\n\n31.1.3.2 Resources on phyloseq\nThe phyloseq container provides analogous methods to TreeSE. The following material can be used to familiarize with such alternative methods:\n\nList of R tools for microbiome analysis\nphyloseq (McMurdie and Holmes 2013)\nmicrobiome tutorial\nmicrobiomeutilities\nphyloseq/TreeSE cheatsheet\nBioconductor Workflow for Microbiome Data Analysis: from raw reads to community analyses (Callahan et al. 2016).\n\n\nMcMurdie, PJ, and S Holmes. 2013. “Phyloseq: An r Package for Reproducible Interactive Analysis and Graphics of Microbiome Census Data.” PLoS ONE 8: e61217. https://doi.org/10.1371/journal.pone.0061217.\n\nCallahan, Ben J., Kris Sankaran, Julia A. Fukuyama, Paul J. McMurdie, and Susan P. Holmes. 2016. “Bioconductor Workflow for Microbiome Data Analysis: From Raw Reads to Community Analyses [Version 2; Peer Review: 3 Approved].” F1000Research 5: 1492. https://doi.org/10.12688/f1000research.8986.2.",
    "crumbs": [
      "Support & resources",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "pages/resources.html#r-programming-resources",
    "href": "pages/resources.html#r-programming-resources",
    "title": "31  Resources",
    "section": "31.2 R programming resources",
    "text": "31.2 R programming resources\n\n31.2.1 Base R and RStudio\nIf you are new to R, you could try swirl for a kickstart to R programming. Further support resources are available through the Bioconductor project (Huber et al. 2015).\n\nBase R and RStudio cheatsheets\nPackage-specific cheatsheets\nVisualization with ggplot2\nR graphics cookbook\n\n\n\n31.2.2 Bioconductor Classes\nIntroduction to data analysis with R and Bioconductor; Carpentries introduction, including R & RStudio installation instructions\nS4 system\nS4 class system has brought several useful features to the object-oriented programming paradigm within R, and it is constantly deployed in R/Bioconductor packages (Huber et al. 2015).\n\nHuber, W., V. J. Carey, R. Gentleman, S. Anders, M. Carlson, B. S. Carvalho, H. C. Bravo, et al. 2015. “Orchestrating High-Throughput Genomic Analysis with Bioconductor.” Nature Methods 12 (2): 115–21. http://www.nature.com/nmeth/journal/v12/n2/full/nmeth.3252.html.\n  Online Document:\n\nHervé Pagès, A quick overview of the S4 class system.\nLaurent Gatto, A practical tutorial on S4 programming\nHow S4 Methods Work (J. Chambers 2006)\n\n\nChambers, JM. 2006. “How S4 Methods Work.” Technical report.\n  Books:\n\nJohn M. Chambers. Software for Data Analysis: Programming with R. Springer, New York, 2008. ISBN-13 978-0387759357 (J. M. Chambers 2008)\nI Robert Gentleman. R Programming for Bioinformatics. Chapman & Hall/CRC, New York, 2008. ISBN-13 978-1420063677 (Gentleman 2008)\n\n\nChambers, John M. 2008. Software for Data Analysis: Programming with r. Vol. 2. Springer.\n\nGentleman, Robert. 2008. R Programming for Bioinformatics. CRC Press.",
    "crumbs": [
      "Support & resources",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "pages/resources.html#sec-quarto",
    "href": "pages/resources.html#sec-quarto",
    "title": "31  Resources",
    "section": "31.3 Reproducible reporting with Quarto",
    "text": "31.3 Reproducible reporting with Quarto\n\n31.3.1 Learn Quarto\nReproducible reporting is the starting point for robust interactive data science. Perform the following tasks:\n\nIf you are entirely new to Quarto, take this short tutorial to get introduced to the most important functions within Quarto. Then experiment with different options from the Quarto cheatsheet.\nCreate a Quarto template in RStudio, and render it into a document (markdown, PDF, docx or other format). In case you are new to Quarto, its documentation provides guidelines to use Quarto with the R language (here) and the RStudio IDE (here).\nFurther examples are tips for Quarto are available in this online tutorial to interactive reproducible reporting.\n\n\n\n31.3.2 Additional material on Rmarkdown\nBeing able to use Quarto in R partly relies on your previous knowledge of Rmarkdown. The following resources can help you get familiar with Rmarkdown:\n\nOnline tutorial\nCheatsheet\nDocumentation\nDr. C Titus Brown’s tutorial\n\nFigure sources:\nOriginal article\n\nHuang R et al. (2021) TreeSummarizedExperiment: a S4 class for data with hierarchical structure. F1000Research 9:1246. (Huang et al. 2021)\n\n\nHuang, Ruizhu, Charlotte Soneson, Felix G. M. Ernst, et al. 2021. “TreeSummarizedExperiment: A S4 Class for Data with Hierarchical Structure [Version 2; Peer Review: 3 Approved].” F1000Research 9: 1246. https://doi.org/10.12688/f1000research.26669.2.\nReference Sequence slot extension\n\nLahti L et al. (2020) Upgrading the R/Bioconductor ecosystem for microbiome research F1000Research 9:1464 (slides).\n\n\n\n31.3.3 Further reading\nThe following online books provide good general data science background:\n\n(Data science basics in R](https://r4ds.had.co.nz)\n(Modern Statistics for Modern Biology)[https://www.huber.embl.de/msmb/] open access book (Holmes S, Huber W)\nThe Bioconductor project (background on the Bioconductor project; Carpentries workshop)",
    "crumbs": [
      "Support & resources",
      "<span class='chapter-number'>31</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "pages/acknowledgments.html",
    "href": "pages/acknowledgments.html",
    "title": "\n32  Contributions\n",
    "section": "",
    "text": "Core team\nContributions to this Gitbook from the various developers are coordinated by:\n\nLeo Lahti, DSc, professor in Data Science in the Department of Computing, University of Turku, Finland, with a focus on computational microbiome analysis. Lahti obtained a doctoral degree (DSc) from Aalto University in Finland (2010), developing probabilistic machine learning with applications to high-throughput life science data integration. Since then, he has focused on microbiome research and developed, for instance, the phyloseq-based microbiome R package before starting to develop the TreeSummarizedExperiment / MultiAssayExperiment framework and the mia family of Bioconductor packages for microbiome data science introduced in this Gitbook. Lahti led the development of national policy on open access to research methods in Finland. He is a current member in the [Bioconductor Community Advisory] (https://bioconductor.org/about/community-advisory-board/) and runs regular training workshops in microbiome data science.\nTuomas Borman, PhD researcher and the lead developer of OMA/mia at the Department of Computing, University of Turku.\nContributors\nThis work is a remarkably collaborative effort. The full list of contributors is available via Github. Some key authors/contributors include:\n\nFelix Ernst, PhD, among the first developers of R/Bioc methods for microbiome research based on the SummarizedExperiment class and its derivatives.\nGiulio Benedetti, scientific programmer at the Department of Computing, University of Turku. His research interest is mostly related to Data Science. He has also helped to expand the SummarizedExperiment-based microbiome analysis framework to the Julia language, implementing Board](https://bioconductor.org/about/community-advisory-board/) MicrobiomeAnalysis.jl.\nSudarshan Shetty, PhD has supported the establishment of the framework and associated tools. He also maintains a list of microbiome R packages.\nHenrik Eckermann contributed in particular to the development of differential abundance analyses\nChouaib Benchraka provided various contributions to the package ecosystem and the OMA book\nYağmur Şimşek converted the miaSim R package to support the Bioconductor framework\nBasil Courbayre provided various contributions to the package ecosystem and the OMA book, in particular on unsupervised machine learning\nMatti Ruuskanen, PhD, added machine learning techniques for microbiome analysis\nStefanie Peschel has contributed chapters on the construction, analysis, and comparison of microbial association networks.\nChristian L. Müller, group leader at the Computational Health Center, Helmholtz Zentrum München, Germany and a Professor for Biomedical Statistics and Data Science at LMU Munich. He assisted in writing the chapters on network learning and comparison.\nShigdel Rajesh, PhD\nArtur Sannikov\nAkewak Jeba\nHimmi Lindgren\nLu Yang\nKatariina Pärnänen\nNoah de Gunst\nAxel Dagnaud\nEly Seraidarian\nThéotime Pralas\nGeraldson Muluh\nJiya Chaudhary\nElina Chiesa\nPande Erawijantari\nShadman Ishraq\nSam Hillman\nMatteo Calgaro\nBasil Courbayre Dussau\nYang Cao\nEineje Ameh\nDomenick J. Braccia\nRenuka Potbhare\nHervé Pagès\nMoritz E. Beber\nNitesh Turaga\nVivian Ikeh\nYu Gao\nDaniel Garza\nKaroline Faust\nJacques Serizay converted the OMA book to the BiocBook format. This allows the OMA book to be built and distributed by Bioconductor.\nHimel Mallick, PhD, FASA, principal investigator and tenure-track faculty at Cornell University’s Department of Population Health Sciences and an adjunct faculty of Statistics and Data Science at Bowers College of Computing and Information Science. He contributed to the chapters on meta-analyses, microbe set enrichment analysis (MSEA) and multi-omics prediction and classification.\nYihan Liu, assisted Dr. Mallick in writing the chapters on meta-anlayses, MSEA and multi-omics prediction and classification.\nJennifer Wokaty\nDanielle Callan\nKatariina Pärnänen\nYu Gao 高煜\nBen Allen\nTeo Dallier\nElliot Gaudron-Parry\nInès Benseddik\nJesse Pasanen\nAcknowledgments\nThis work would not have been possible without the countless contributions and interactions with other researchers, developers, and users. We express our gratitude to the entire Bioconductor community for developing this high-quality open research software repository for life science analytics, continuously pushing the limits in emerging fields (Gentleman et al. 2004), (Huber et al. 2015).\n\nGentleman, Robert C, Vincent J Carey, Douglas M Bates, Ben Bolstad, Marcel Dettling, Sandrine Dudoit, Byron Ellis, et al. 2004. “Bioconductor: Open Software Development for Computational Biology and Bioinformatics.” Genome Biology 5: R80.\n\nHuber, W., V. J. Carey, R. Gentleman, S. Anders, M. Carlson, B. S. Carvalho, H. C. Bravo, et al. 2015. “Orchestrating High-Throughput Genomic Analysis with Bioconductor.” Nature Methods 12 (2): 115–21. http://www.nature.com/nmeth/journal/v12/n2/full/nmeth.3252.html.\n\nHuang, Ruizhu. 2020. TreeSummarizedExperiment: A S4 Class for Data with Tree Structures.\n\nErnst, F. G. M., S. A. Shetty, R. Huang, Braccia D. J., Bravo H. C., and L. Lahti. 2020. “The Emerging r Ecosystem for Microbiome Research.” F1000Research 9. https://doi.org/10.7490/f1000research.1118445.1.\n\nRamos, Marcel, Lucas Schiffer, Angela Re, Rimsha Azhar, Azfar Basunia, Carmen Rodriguez Cabrera, Tiffany Chan, et al. 2017. “Software for the Integration of Multiomics Experiments in Bioconductor.” Cancer Research. https://doi.org/10.1158/0008-5472.CAN-17-0344.\n\nShetty, Sudarshan, and Leo Lahti. 2019. “Microbiome Data Science.” Journal of Biosciences 44: 115. https://doi.org/10.1007/s12038-019-9930-2.\nThe presented framework for microbiome data science is based on the TreeSummarizedExperiment data container created by Ruizhu Huang and others (Huang 2020), (Ernst et al. 2020), and on the MultiAssayExperiment by Marcel Ramos et al. (Ramos et al. 2017). The idea of using these containers as a basis for microbiome data science was initially advanced by the groundwork of Domenick Braccia, Héctor Corrada Bravo and others and brought together with other microbiome data science developers (Shetty and Lahti 2019). Setting up the base ecosystem of packages and tutorials was then subsequently led by Tuomas Borman, Felix Ernst, and Leo Lahti. We would specifically like to thank everyone who contributed to the work supporting the TreeSummarizedExperiment ecosystem for microbiome research, including but not limited to the R packages mia, miaViz, miaTime, miaSim, philr, ANCOMBC, curatedMetagenomicData, scater, scuttle, and other packages, some of which are listed in Section Chapter 2. A number of other contributors have advanced the ecosystem further, and will be acknowledged in the individual packages, pull requests, issues, and other work.\nAmple demonstration data resources supporting this framework have been made available through the curatedMetagenomicData project by Edoardo Pasolli, Lucas Schiffer, Levi Waldron and others (Pasolli et al. 2017).\n\nPasolli, Edoardo, Lucas Schiffer, Paolo Manghi, Audrey Renson, Valerie Obenchain, Duy Tin Truong, Francesco Beghini, et al. 2017. “Accessible, Curated Metagenomic Data Through ExperimentHub.” Nature Methods 14 (11): 1023–24. https://doi.org/https://doi.org/10.1038/nmeth.4468.\n\nMcMurdie, PJ, and S Holmes. 2013. “Phyloseq: An r Package for Reproducible Interactive Analysis and Graphics of Microbiome Census Data.” PLoS ONE 8: e61217. https://doi.org/10.1371/journal.pone.0061217.\n\nAmezquita, Robert A., Aaron T. L. Lun, Etienne Becht, Vince J. Carey, Lindsay N. Carpp, Ludwig Geistlinger, Federico Marini, et al. 2020. “Orchestrating Single-Cell Analysis with Bioconductor.” Nature Methods 17: 137–45. https://doi.org/10.1038/s41592-019-0654-x.\nThe work has drawn initial inspiration from many sources, most notably from the work on phyloseq by Paul McMurdie and Susan Holmes (McMurdie and Holmes 2013) who pioneered the work on rigorous and reproducible microbiome data science ecosystems in R/Bioconductor. The phyloseq framework continues to provide a vast array of complementary packages and methods for microbiome studies. The Orchestrating Single-Cell Analysis with Bioconductor, or OSCA book by Robert Amezquita, Aaron Lun, Stephanie Hicks, and Raphael Gottardo (Amezquita et al. 2020) has implemented closely related work on the SummarizedExperiment data container and its derivatives in the field of single cell sequencing studies that have inspired this work.\nIn the background, the open source books by Susan Holmes and Wolfgang Huber, Modern Statistics for Modern Biology (Holmes and Huber 2019) and by Garret Grolemund and Hadley Wickham, the R for Data Science (Grolemund and Wickham 2017), and Richard McElreath’s Statistical Rethinking and the associated online resources by Solomon Kurz (McElreath 2020) are key references that have advanced reproducible data science training and dissemination.\n\nHolmes, Susan, and Wolfgang Huber. 2019. Modern Statistics for Modern Biology. New York, NY: Cambridge University Press. https://www.huber.embl.de/msmb/.\n\nGrolemund, Garret, and Hadley Wickham. 2017. R for Data Science. Vol. 77(21); e39–42. O’Reilly.\n\nMcElreath, R. 2020. Statistical Rethinking. Chapman; Hall/CRC.\n\n32.0.1 How to contribute\nTo contribute to the project, please follow the Git flow procedure introduced below. See instructions to get started with Github):\n\n\nFork the project\n\nClone your fork\n\nModify the material\nCheck locally that the changes render successfully\n\nAdd and commit the changes to your fork\n\nCreate a pull request from your fork back to the original repository\nFix and discuss issues in a review process\n\nMore detailed instructions for contributing can be found on OMA README.\nSupport\nThis work has been supported by:\n\nResearch Council of Finland\nFindingPheno European Union’s Horizon 2020 research and innovation programme under grant agreement No 952914\nCOST Action network on Statistical and Machine Learning Techniques for Human Microbiome Studies (ML4microbiome) (Moreno-Indias et al. 2021).\nComputational and Molecular Methodologies for Life Sciences (CompLifeSci) Research Program, Biocity Turku\nTurku University Foundation\n\n\n\n\nMoreno-Indias, Isabel, Leo Lahti, Miroslava Nedyalkova, Ilze Elbere, Gennady V. Roshchupkin, Muhamed Adilovic, Onder Aydemir, et al. 2021. “Statistical and Machine Learning Techniques in Human Microbiome Studies: Contemporary Challenges and Solutions.” Frontiers in Microbiology 12: 277. https://doi.org/10.3389/fmicb.2021.635781.\n\n Back to top",
    "crumbs": [
      "Support & resources",
      "<span class='chapter-number'>32</span>  <span class='chapter-title'>Contributions</span>"
    ]
  },
  {
    "objectID": "pages/msea.html",
    "href": "pages/msea.html",
    "title": "Appendix A — Microbe Set Enrichment Analysis (MSEA)",
    "section": "",
    "text": "A.1 Input data for MSEA using species relative abundance data\nIn this chapter, we will use the publicly available Inflammatory Bowel Diseases (IBD) microbiome data from the integrative Human Microbiome Project (iHMP) available from the curatedMetagenomicData package (Lloyd-Price et al. 2019). We aim to conduct MSEA analysis based on both taxonomic profiles (species relative abundances) and functional profiles (pathway relative abundances).",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Microbe Set Enrichment Analysis (MSEA)</span>"
    ]
  },
  {
    "objectID": "pages/msea.html#input-data-for-msea-using-species-relative-abundance-data",
    "href": "pages/msea.html#input-data-for-msea-using-species-relative-abundance-data",
    "title": "Appendix A — Microbe Set Enrichment Analysis (MSEA)",
    "section": "",
    "text": "Lloyd-Price, Jason, Cesar Arze, Ashwin N. Ananthakrishnan, Melanie Schirmer, Julian Avila-Pacheco, Tiffany W. Poon, Elizabeth Andrews, et al. 2019. “Multi-Omics of the Gut Microbial Ecosystem in Inflammatory Bowel Diseases.” Nature 569 (7758): 655–62. https://doi.org/https://doi.org/10.1038/s41586-019-1237-9.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Microbe Set Enrichment Analysis (MSEA)</span>"
    ]
  },
  {
    "objectID": "pages/msea.html#performing-the-msea-analysis-with-species-relative-abundance-data",
    "href": "pages/msea.html#performing-the-msea-analysis-with-species-relative-abundance-data",
    "title": "Appendix A — Microbe Set Enrichment Analysis (MSEA)",
    "section": "\nA.2 Performing the MSEA analysis with species relative abundance data",
    "text": "A.2 Performing the MSEA analysis with species relative abundance data\nWe will first prepare the input feature table and sample metadata for differential abundance analysis using MaAsLin2 (Mallick et al. 2021). The ranked feature list from the differential abundance analysis serves as an input for the MSEA.\n\nMallick, Himel, Ali Rahnavard, Lauren J. McIver, Siyuan Ma, Yancong Zhang, Long H. Nguyen, Timothy L. Tickle, et al. 2021. “Multivariable Association Discovery in Population-Scale Meta-Omics Studies.” PLOS Computational Biology 17 (11): e1009442. https://doi.org/https://doi.org/10.1371/journal.pcbi.1009442.\n\n\n##################\n# Load iHMP data #\n##################\n\nlibrary(curatedMetagenomicData)\nlibrary(dplyr)\n\nse_relative &lt;- sampleMetadata |&gt;\n    filter(study_name == \"HMP_2019_ibdmdb\") |&gt;\n    returnSamples(\"relative_abundance\", rownames = \"short\")\n\n##########################\n# Create sample metadata #\n##########################\n\nsample_metadata &lt;-\n    colData(se_relative) |&gt;\n    as.data.frame() |&gt; filter(visit_number == 1) |&gt;\n    dplyr::select(c(\"age\", \"disease\", \"antibiotics_current_use\"))\n\n#################\n# Set reference #\n#################\n\nsample_metadata$disease &lt;- as.factor(sample_metadata$disease)\nsample_metadata$disease &lt;- relevel(sample_metadata$disease, 'healthy')\n\n###########################\n# Create species features #\n###########################\n\nfeature_species_t &lt;- as.data.frame(assay(se_relative))\nrownames(feature_species_t) &lt;- sub('.*s__', '', rownames(feature_species_t))\n\n##############################\n# Subset to baseline samples #\n##############################\n\nfeature_species &lt;- as.data.frame(t(feature_species_t))\nfeature_species &lt;- feature_species[rownames(sample_metadata),]\nfeature_species &lt;- feature_species / 100\nrm(feature_species_t); rm(se_relative)\n\nIn the next step, we will use MaAsLin2 to fit a multivariable regression model for testing the association between microbial species abundance versus IBD diagnosis. The analysis method we use here is “LM”, which is the default setting. We also adjust for age and antibiotic usage, following the original study.\n\nlibrary(Maaslin2)\n\nfit_data = Maaslin2(\n    input_data = feature_species,\n    input_metadata = sample_metadata,\n    normalization = \"NONE\",\n    output = \"output_species\",\n    fixed_effects = c(\"disease\", \"age\", \"antibiotics_current_use\"))\n##  [1] \"Creating output folder\"\n##  [1] \"Creating output feature tables folder\"\n##  [1] \"Creating output fits folder\"\n##  [1] \"Creating output figures folder\"\n##  2024-10-06 07:46:11.198281 INFO::Writing function arguments to log file\n##  2024-10-06 07:46:11.213227 INFO::Verifying options selected are valid\n##  2024-10-06 07:46:11.240424 INFO::Determining format of input files\n##  2024-10-06 07:46:11.241069 INFO::Input format is data samples as rows and metadata samples as rows\n##  2024-10-06 07:46:11.246745 INFO::Formula for fixed effects: expr ~  disease + age + antibiotics_current_use\n##  2024-10-06 07:46:11.247425 INFO::Factor detected for categorial metadata 'disease'. Provide a reference argument or manually set factor ordering to change reference level.\n##  2024-10-06 07:46:11.248053 INFO::Filter data based on min abundance and min prevalence\n##  2024-10-06 07:46:11.248494 INFO::Total samples in data: 136\n##  2024-10-06 07:46:11.248938 INFO::Min samples required with min abundance for a feature not to be filtered: 13.600000\n##  2024-10-06 07:46:11.254949 INFO::Total filtered features: 452\n##  2024-10-06 07:46:11.255651 INFO::Filtered feature names from abundance and prevalence filtering: Abiotrophia.sp..HMSC24B09, Acidaminococcus.sp..CAG.542, Acinetobacter.lwoffii, Acinetobacter.ursingii, Actinobaculum.sp..oral.taxon.183, Actinomyces.graevenitzii, Actinomyces.sp..HMSC035G02, Actinomyces.sp..HPA0247, Actinomyces.sp..ICM47, Actinomyces.sp..oral.taxon.180, Actinomyces.sp..oral.taxon.181, Actinomyces.urogenitalis, Actinotignum.timonense, Adlercreutzia.caecimuris, Adlercreutzia.equolifaciens, Aeriscardovia.aeriphila, Aerococcus.urinaeequi, Aeromonas.dhakensis, Aeromonas.hydrophila, Aggregatibacter.aphrophilus, Aggregatibacter.segnis, Aggregatibacter.sp..oral.taxon.458, Alistipes.inops, Alistipes.onderdonkii, Alistipes.timonensis, Allisonella.histaminiformans, Alloprevotella.tannerae, Alloscardovia.omnicolens, Amedibacillus.dolichus, Anaerococcus.lactolyticus, Anaerococcus.vaginalis, Anaerocolumna.aminovalerica, Anaerofilum.sp..An201, Anaerofustis.stercorihominis, Anaeroglobus.geminatus, Anaeromassilibacillus.sp..An172, Anaerosporobacter.mobilis, Anaerostipes.caccae, Anaerostipes.sp..494a, Anaerostipes.sp..992a, Anaerotruncus.sp..CAG.528, Arthrospira.platensis, Atopobium.deltae, Atopobium.minutum, Bacteroidales.bacterium.KA00251, Bacteroides.clarus, Bacteroides.fluxus, Bacteroides.nordii, Bacteroides.oleiciplenus, Bacteroides.sp..43_108, Bacteroides.sp..CAG.144, Bacteroides.sp..CAG.530, Bacteroides.sp..CAG.598, Bacteroides.sp..CAG.633, Bacteroides.sp..CAG.661, Bacteroides.sp..D2, Bacteroides.sp..OM08.11, Bacteroides.stercorirosoris, Bacteroidetes.oral.taxon.274, Bavariicoccus.seileri, Bifidobacterium.angulatum, Bifidobacterium.animalis, Bifidobacterium.asteroides, Bifidobacterium.breve, Bifidobacterium.catenulatum, Bifidobacterium.dentium, Bifidobacterium.pseudolongum, Bifidobacterium.pullorum, Blastocystis.sp..subtype.1, Blautia.argi, Blautia.coccoides, Blautia.hansenii, Blautia.hydrogenotrophica, Blautia.producta, Brachyspira.pilosicoli, Butyricicoccus.pullicaecorum, Butyrivibrio.crossotus, Butyrivibrio.sp..CAG.318, Campylobacter.concisus, Campylobacter.gracilis, Campylobacter.hominis, Campylobacter.showae, Campylobacter.upsaliensis, Campylobacter.ureolyticus, Candidatus.Gastranaerophilales.bacterium, Candidatus.Methanomassiliicoccus.intestinalis, Candidatus.Stoquefichus.sp..KLE1796, Catenibacterium.mitsuokai, Cellulosilyticum.lentocellum, Chlamydia.ibidis, Christensenella.hongkongensis, Christensenella.minuta, Citrobacter.amalonaticus, Citrobacter.braakii, Citrobacter.europaeus, Citrobacter.farmeri, Citrobacter.freundii, Citrobacter.pasteurii, Citrobacter.portucalensis, Citrobacter.werkmanii, Citrobacter.youngae, Cloacibacillus.porcorum, Clostridiales.bacterium.1_7_47FAA, Clostridiales.bacterium.CHKCI006, Clostridioides.difficile, Clostridium.baratii, Clostridium.botulinum, Clostridium.butyricum, Clostridium.cadaveris, Clostridium.celatum, Clostridium.disporicum, Clostridium.neonatale, Clostridium.paraputrificum, Clostridium.perfringens, Clostridium.sp..7_2_43FAA, Clostridium.sp..CAG.167, Clostridium.sp..CAG.242, Clostridium.sp..CAG.253, Clostridium.sp..CAG.411, Clostridium.sp..CAG.413, Clostridium.sp..CAG.590, Clostridium.sp..CAG.678, Clostridium.sp..CAG.964, Clostridium.sp..D5, Clostridium.sp..MSTE9, Clostridium.sp..chh4.2, Clostridium.sporogenes, Comamonas.kerstersii, Coprobacillus.cateniformis, Coprobacter.secundus, Coprobacter.sp., Corynebacterium.accolens, Corynebacterium.amycolatum, Corynebacterium.kroppenstedtii, Corynebacterium.matruchotii, Corynebacterium.oculi, Cronobacter.malonaticus, Cronobacter.sakazakii, Cutibacterium.acnes, Cutibacterium.granulosum, Dellaglioa.algida, Desulfovibrio.fairfieldensis, Desulfovibrio.piger, Desulfovibrionaceae.bacterium, Dialister.micraerophilus, Dialister.pneumosintes, Dialister.sp..CAG.357, Dorea.sp..CAG.317, Dysgonomonas.gadei, Dysgonomonas.mossii, Dysgonomonas.sp..37.18, Eikenella.corrodens, Enhydrobacter.aerosaccus, Enorma.massiliensis, Enterobacter.mori, Enterocloster.asparagiformis, Enterococcus.asini, Enterococcus.avium, Enterococcus.casseliflavus, Enterococcus.dispar, Enterococcus.durans, Enterococcus.faecalis, Enterococcus.faecium, Enterococcus.gallinarum, Enterococcus.hirae, Enterococcus.mundtii, Enterococcus.pseudoavium, Enterococcus.raffinosus, Enterococcus.sp..3H8_DIV0648, Enterococcus.thailandicus, Erysipelothrix.larvae, Escherichia.albertii, Escherichia.marmotae, Eubacteriaceae.bacterium.CHKCI005, Eubacterium.coprostanoligenes, Eubacterium.dolichum.CAG.375, Eubacterium.limosum, Eubacterium.sp..An11, Eubacterium.sp..CAG.180, Eubacterium.sp..CAG.274, Eubacterium.sp..OM08.24, Ezakiella.coagulans, Faecalicatena.orotica, Faecalicoccus.pleomorphus, Faecalitalea.cylindroides, Fannyhessea.vaginae, Finegoldia.magna, Firmicutes.bacterium.CAG.110, Firmicutes.bacterium.CAG.145, Firmicutes.bacterium.CAG.170, Firmicutes.bacterium.CAG.238, Firmicutes.bacterium.CAG.424, Firmicutes.bacterium.CAG.534, Firmicutes.bacterium.CAG.646, Firmicutes.bacterium.CAG.95, Flavonifractor.sp..An10, Flavonifractor.sp..An100, Flavonifractor.sp..An306, Fretibacterium.fastidiosum, Frigoribacterium.sp..Leaf8, Fructilactobacillus.sanfranciscensis, Fusobacterium.equinum, Fusobacterium.gonidiaformans, Fusobacterium.mortiferum, Fusobacterium.naviforme, Fusobacterium.nucleatum, Fusobacterium.periodonticum, Fusobacterium.sp..CAG.439, Fusobacterium.sp..oral.taxon.370, Fusobacterium.ulcerans, Gemella.asaccharolytica, Gemella.haemolysans, Gemella.morbillorum, Gemella.sanguinis, Gemmiger.sp..An50, Gemmiger.sp..An87, Gleimia.europaea, Gordonibacter.pamelaeae, Granulicatella.adiacens, Haemophilus.haemolyticus, Haemophilus.influenzae, Haemophilus.parahaemolyticus, Haemophilus.paraphrohaemolyticus, Haemophilus.pittmaniae, Haemophilus.sputorum, Hafnia.alvei, Hafnia.paralvei, Harryflintia.acetispora, Holdemanella.biformis, Klebsiella.aerogenes, Klebsiella.michiganensis, Klebsiella.oxytoca, Klebsiella.quasipneumoniae, Klebsiella.variicola.CAG.634, Kluyvera.ascorbata, Kluyvera.cryocrescens, Kluyvera.georgiana, Kocuria.palustris, Kosakonia.sacchari, Lachnoclostridium.sp..An118, Lachnoclostridium.sp..An131, Lachnoclostridium.sp..An138, Lachnoclostridium.sp..An14, Lachnoclostridium.sp..An181, Lachnoclostridium.sp..An298, Lachnospiraceae.bacterium.2_1_46FAA, Lachnospiraceae.bacterium.oral.taxon.096, Lacrimispora.celerecrescens, Lacticaseibacillus.rhamnosus, Lactiplantibacillus.plantarum, Lactobacillus.acidophilus, Lactobacillus.amylovorus, Lactobacillus.crispatus, Lactobacillus.delbrueckii, Lactobacillus.gasseri, Lactobacillus.jensenii, Lactobacillus.johnsonii, Lactobacillus.paragasseri, Lactococcus.lactis, Lactococcus.petauri, Lactococcus.piscium, Lactonifactor.longoviformis, Lancefieldella.parvula, Lancefieldella.rimae, Latilactobacillus.sakei, Lawsonella.clevelandensis, Leclercia.adecarboxylata, Leuconostoc.garlicum, Leuconostoc.lactis, Ligilactobacillus.animalis, Ligilactobacillus.ruminis, Ligilactobacillus.salivarius, Limosilactobacillus.fermentum, Limosilactobacillus.mucosae, Limosilactobacillus.oris, Limosilactobacillus.reuteri, Limosilactobacillus.vaginalis, Massilimicrobiota.timonensis, Megamonas.funiformis, Megamonas.funiformis.CAG.377, Megamonas.hypermegale, Megasphaera.elsdenii, Megasphaera.micronuciformis, Megasphaera.sp..DISK.18, Megasphaera.sp..MJR8396C, Methanobrevibacter.smithii, Micrococcus.aloeverae, Micrococcus.luteus, Micrococcus.lylae, Microvirgula.aerodenitrificans, Mitsuokella.jalaludinii, Mitsuokella.multacida, Moraxella.osloensis, Morganella.morganii, Murimonas.intestini, Neisseria.cinerea, Neisseria.flavescens, Neisseria.sp..oral.taxon.014, Neisseria.subflava, Obesumbacterium.proteus, Odoribacter.laneus, Oscillibacter.sp..PC13, Oxalobacter.formigenes, Paenibacillus.macerans, Parabacteroides.goldsteinii, Parabacteroides.johnsonii, Parabacteroides.sp..CAG.409, Pararheinheimera.mesophila, Parvimonas.micra, Parvimonas.sp..KA00067, Parvimonas.sp..oral.taxon.110, Parvimonas.sp..oral.taxon.393, Paucilactobacillus.vaccinostercus, Pediococcus.acidilactici, Pediococcus.pentosaceus, Peptococcus.niger, Peptoniphilus.coxii, Peptoniphilus.duerdenii, Peptoniphilus.harei, Peptoniphilus.lacrimalis, Peptoniphilus.sp..BV3C26, Peptoniphilus.sp..HMSC062D09, Peptostreptococcus.anaerobius, Peptostreptococcus.stomatis, Phascolarctobacterium.sp..CAG.266, Phascolarctobacterium.succinatutens, Phocaeicola.sartorii, Phytobacter.palmae, Porphyromonas.asaccharolytica, Porphyromonas.endodontalis, Porphyromonas.somerae, Porphyromonas.sp..HMSC065F10, Porphyromonas.uenonis, Prevotella.amnii, Prevotella.bergensis, Prevotella.bivia, Prevotella.buccae, Prevotella.buccalis, Prevotella.colorans, Prevotella.corporis, Prevotella.dentalis, Prevotella.denticola, Prevotella.disiens, Prevotella.histicola, Prevotella.intermedia, Prevotella.jejuni, Prevotella.melaninogenica, Prevotella.nigrescens, Prevotella.oralis, Prevotella.oris, Prevotella.oulorum, Prevotella.pallens, Prevotella.salivae, Prevotella.sp..885, Prevotella.sp..AM42.24, Prevotella.sp..CAG.1092, Prevotella.sp..CAG.1185, Prevotella.sp..CAG.279, Prevotella.sp..CAG.520, Prevotella.sp..CAG.891, Prevotella.sp..S7.1.8, Prevotella.stercorea, Prevotella.timonensis, Proteus.hauseri, Proteus.mirabilis, Proteus.penneri, Proteus.vulgaris, Providencia.alcalifaciens, Pseudoflavonifractor.capillosus, Pseudoflavonifractor.sp..An184, Pseudoflavonifractor.sp..An85, Pseudomonas.fragi, Pseudomonas.guguanensis, Raoultella.ornithinolytica, Raoultella.planticola, Rikenella.microfusus, Robinsoniella.sp..RHS, Romboutsia.ilealis, Roseburia.sp..CAG.182, Roseburia.sp..CAG.303, Roseburia.sp..CAG.309, Rothia.mucilaginosa, Ruminococcaceae.bacterium.D5, Ruminococcus.callidus, Ruminococcus.obeum.CAG.39, Ruminococcus.sp..CAG.330, Ruminococcus.sp..CAG.403, Ruminococcus.sp..CAG.488, Ruminococcus.sp..CAG.563, Saccharomyces.cerevisiae, Sanguibacteroides.justesenii, Sarcina.ventriculi, Scardovia.wiggsiae, Schaalia.odontolytica, Schaalia.turicensis, Serratia.liquefaciens, Serratia.marcescens, Sharpea.azabuensis, Shuttleworthia.satelles, Slackia.isoflavoniconvertens, Solobacterium.moorei, Staphylococcus.aureus, Staphylococcus.epidermidis, Staphylococcus.hominis, Streptococcus.agalactiae, Streptococcus.australis, Streptococcus.cristatus, Streptococcus.gallolyticus, Streptococcus.gordonii, Streptococcus.infantis, Streptococcus.lutetiensis, Streptococcus.macedonicus, Streptococcus.milleri, Streptococcus.mitis, Streptococcus.mutans, Streptococcus.oralis, Streptococcus.pasteurianus, Streptococcus.peroris, Streptococcus.salivarius.CAG.79, Streptococcus.sanguinis, Streptococcus.sp..A12, Streptococcus.sp..F0442, Streptococcus.sp..HPH0090, Streptococcus.sp..M334, Streptococcus.thermophilus, Streptococcus.vestibularis, Terrisporobacter.othiniensis, Thermoleophilum.album, Tractidigestivibacter.scatoligenes, Treponema.lecithinolyticum, Turicibacter.sanguinis, Tyzzerella.nexilis, Varibaculum.cambriense, Veillonella.rodentium, Veillonella.rogosae, Veillonella.seminalis, Veillonella.sp..CAG.933, Veillonella.tobetsuensis, Victivallis.vadensis, Weissella.cibaria, Weissella.confusa, Weissella.viridescens, Wohlfahrtiimonas.chitiniclastica, Yersinia.frederiksenii, X.Bacteroides..pectinophilus, X.Butyribacterium..methylotrophicum, X.Clostridium..hylemonae, X.Clostridium..methylpentosum, X.Clostridium..scindens, X.Clostridium..spiroforme, X.Eubacterium..brachy, X.Eubacterium..infirmum\n##  2024-10-06 07:46:11.258419 INFO::Total filtered features with variance filtering: 0\n##  2024-10-06 07:46:11.258932 INFO::Filtered feature names from variance filtering:\n##  2024-10-06 07:46:11.259354 INFO::Running selected normalization method: NONE\n##  2024-10-06 07:46:11.259841 INFO::Applying z-score to standardize continuous metadata\n##  2024-10-06 07:46:11.264091 INFO::Running selected transform method: LOG\n##  2024-10-06 07:46:11.267011 INFO::Running selected analysis method: LM\n##  2024-10-06 07:46:11.270578 INFO::Fitting model to feature number 1, Acidaminococcus.intestini\n##  2024-10-06 07:46:11.276934 INFO::Fitting model to feature number 2, Agathobaculum.butyriciproducens\n##  2024-10-06 07:46:11.27928 INFO::Fitting model to feature number 3, Akkermansia.muciniphila\n##  2024-10-06 07:46:11.281599 INFO::Fitting model to feature number 4, Alistipes.finegoldii\n##  2024-10-06 07:46:11.283932 INFO::Fitting model to feature number 5, Alistipes.indistinctus\n##  2024-10-06 07:46:11.286199 INFO::Fitting model to feature number 6, Alistipes.putredinis\n##  2024-10-06 07:46:11.288476 INFO::Fitting model to feature number 7, Alistipes.shahii\n##  2024-10-06 07:46:11.290775 INFO::Fitting model to feature number 8, Anaerobutyricum.hallii\n##  2024-10-06 07:46:11.293049 INFO::Fitting model to feature number 9, Anaeromassilibacillus.sp..An250\n##  2024-10-06 07:46:11.295329 INFO::Fitting model to feature number 10, Anaerostipes.hadrus\n##  2024-10-06 07:46:11.297596 INFO::Fitting model to feature number 11, Anaerotignum.lactatifermentans\n##  2024-10-06 07:46:11.29992 INFO::Fitting model to feature number 12, Anaerotruncus.colihominis\n##  2024-10-06 07:46:11.302174 INFO::Fitting model to feature number 13, Bacteroides.caccae\n##  2024-10-06 07:46:11.304435 INFO::Fitting model to feature number 14, Bacteroides.cellulosilyticus\n##  2024-10-06 07:46:11.306692 INFO::Fitting model to feature number 15, Bacteroides.eggerthii\n##  2024-10-06 07:46:11.308962 INFO::Fitting model to feature number 16, Bacteroides.faecis\n##  2024-10-06 07:46:11.31122 INFO::Fitting model to feature number 17, Bacteroides.faecis.CAG.32\n##  2024-10-06 07:46:11.313475 INFO::Fitting model to feature number 18, Bacteroides.finegoldii\n##  2024-10-06 07:46:11.315713 INFO::Fitting model to feature number 19, Bacteroides.fragilis\n##  2024-10-06 07:46:11.318002 INFO::Fitting model to feature number 20, Bacteroides.galacturonicus\n##  2024-10-06 07:46:11.320244 INFO::Fitting model to feature number 21, Bacteroides.intestinalis\n##  2024-10-06 07:46:11.322502 INFO::Fitting model to feature number 22, Bacteroides.ovatus\n##  2024-10-06 07:46:11.324775 INFO::Fitting model to feature number 23, Bacteroides.salyersiae\n##  2024-10-06 07:46:11.327032 INFO::Fitting model to feature number 24, Bacteroides.stercoris\n##  2024-10-06 07:46:11.329283 INFO::Fitting model to feature number 25, Bacteroides.thetaiotaomicron\n##  2024-10-06 07:46:11.331562 INFO::Fitting model to feature number 26, Bacteroides.uniformis\n##  2024-10-06 07:46:11.333863 INFO::Fitting model to feature number 27, Bacteroides.xylanisolvens\n##  2024-10-06 07:46:11.336139 INFO::Fitting model to feature number 28, Barnesiella.intestinihominis\n##  2024-10-06 07:46:11.338415 INFO::Fitting model to feature number 29, Bifidobacterium.adolescentis\n##  2024-10-06 07:46:11.340762 INFO::Fitting model to feature number 30, Bifidobacterium.bifidum\n##  2024-10-06 07:46:11.343027 INFO::Fitting model to feature number 31, Bifidobacterium.longum\n##  2024-10-06 07:46:11.345278 INFO::Fitting model to feature number 32, Bifidobacterium.pseudocatenulatum\n##  2024-10-06 07:46:11.347525 INFO::Fitting model to feature number 33, Bilophila.wadsworthia\n##  2024-10-06 07:46:11.349824 INFO::Fitting model to feature number 34, Blautia.obeum\n##  2024-10-06 07:46:11.352074 INFO::Fitting model to feature number 35, Blautia.sp..CAG.257\n##  2024-10-06 07:46:11.354317 INFO::Fitting model to feature number 36, Blautia.wexlerae\n##  2024-10-06 07:46:11.356558 INFO::Fitting model to feature number 37, Butyricimonas.synergistica\n##  2024-10-06 07:46:11.358827 INFO::Fitting model to feature number 38, Butyricimonas.virosa\n##  2024-10-06 07:46:11.361101 INFO::Fitting model to feature number 39, Clostridium.bolteae.CAG.59\n##  2024-10-06 07:46:11.363465 INFO::Fitting model to feature number 40, Clostridium.sp..CAG.299\n##  2024-10-06 07:46:11.365838 INFO::Fitting model to feature number 41, Clostridium.sp..CAG.58\n##  2024-10-06 07:46:11.368082 INFO::Fitting model to feature number 42, Collinsella.aerofaciens\n##  2024-10-06 07:46:11.370325 INFO::Fitting model to feature number 43, Collinsella.intestinalis\n##  2024-10-06 07:46:11.372597 INFO::Fitting model to feature number 44, Coprobacter.fastidiosus\n##  2024-10-06 07:46:11.374892 INFO::Fitting model to feature number 45, Coprococcus.catus\n##  2024-10-06 07:46:11.377173 INFO::Fitting model to feature number 46, Coprococcus.comes\n##  2024-10-06 07:46:11.379444 INFO::Fitting model to feature number 47, Coprococcus.eutactus\n##  2024-10-06 07:46:11.381753 INFO::Fitting model to feature number 48, Dialister.invisus\n##  2024-10-06 07:46:11.384038 INFO::Fitting model to feature number 49, Dielma.fastidiosa\n##  2024-10-06 07:46:11.3863 INFO::Fitting model to feature number 50, Dorea.formicigenerans\n##  2024-10-06 07:46:11.38855 INFO::Fitting model to feature number 51, Dorea.longicatena\n##  2024-10-06 07:46:11.390878 INFO::Fitting model to feature number 52, Eggerthella.lenta\n##  2024-10-06 07:46:11.393152 INFO::Fitting model to feature number 53, Eisenbergiella.massiliensis\n##  2024-10-06 07:46:11.395464 INFO::Fitting model to feature number 54, Eisenbergiella.tayi\n##  2024-10-06 07:46:11.397764 INFO::Fitting model to feature number 55, Enterocloster.aldenensis\n##  2024-10-06 07:46:11.40003 INFO::Fitting model to feature number 56, Enterocloster.bolteae\n##  2024-10-06 07:46:11.402328 INFO::Fitting model to feature number 57, Enterocloster.citroniae\n##  2024-10-06 07:46:11.40466 INFO::Fitting model to feature number 58, Enterocloster.clostridioformis\n##  2024-10-06 07:46:11.406934 INFO::Fitting model to feature number 59, Enterocloster.lavalensis\n##  2024-10-06 07:46:11.409195 INFO::Fitting model to feature number 60, Erysipelatoclostridium.ramosum\n##  2024-10-06 07:46:11.411448 INFO::Fitting model to feature number 61, Escherichia.coli\n##  2024-10-06 07:46:11.413761 INFO::Fitting model to feature number 62, Eubacterium.ramulus\n##  2024-10-06 07:46:11.416054 INFO::Fitting model to feature number 63, Eubacterium.sp..CAG.251\n##  2024-10-06 07:46:11.418319 INFO::Fitting model to feature number 64, Eubacterium.sp..CAG.38\n##  2024-10-06 07:46:11.420587 INFO::Fitting model to feature number 65, Eubacterium.ventriosum\n##  2024-10-06 07:46:11.422867 INFO::Fitting model to feature number 66, Faecalibacterium.prausnitzii\n##  2024-10-06 07:46:11.425136 INFO::Fitting model to feature number 67, Firmicutes.bacterium.CAG.83\n##  2024-10-06 07:46:11.427383 INFO::Fitting model to feature number 68, Firmicutes.bacterium.CAG.94\n##  2024-10-06 07:46:11.42963 INFO::Fitting model to feature number 69, Flavonifractor.plautii\n##  2024-10-06 07:46:11.43192 INFO::Fitting model to feature number 70, Fusicatenibacter.saccharivorans\n##  2024-10-06 07:46:11.4342 INFO::Fitting model to feature number 71, Gemmiger.formicilis\n##  2024-10-06 07:46:11.436483 INFO::Fitting model to feature number 72, Haemophilus.parainfluenzae\n##  2024-10-06 07:46:11.438874 INFO::Fitting model to feature number 73, Haemophilus.sp..HMSC71H05\n##  2024-10-06 07:46:11.441214 INFO::Fitting model to feature number 74, Holdemania.filiformis\n##  2024-10-06 07:46:11.443519 INFO::Fitting model to feature number 75, Hungatella.hathewayi\n##  2024-10-06 07:46:11.445857 INFO::Fitting model to feature number 76, Intestinibacter.bartlettii\n##  2024-10-06 07:46:11.448228 INFO::Fitting model to feature number 77, Intestinimonas.butyriciproducens\n##  2024-10-06 07:46:11.450587 INFO::Fitting model to feature number 78, Klebsiella.pneumoniae\n##  2024-10-06 07:46:11.452907 INFO::Fitting model to feature number 79, Klebsiella.variicola\n##  2024-10-06 07:46:11.455209 INFO::Fitting model to feature number 80, Lachnospira.eligens\n##  2024-10-06 07:46:11.457509 INFO::Fitting model to feature number 81, Lachnospira.pectinoschiza\n##  2024-10-06 07:46:11.45988 INFO::Fitting model to feature number 82, Lacrimispora.saccharolytica\n##  2024-10-06 07:46:11.462241 INFO::Fitting model to feature number 83, Lactobacillus.rogosae\n##  2024-10-06 07:46:11.464588 INFO::Fitting model to feature number 84, Lawsonibacter.asaccharolyticus\n##  2024-10-06 07:46:11.466934 INFO::Fitting model to feature number 85, Monoglobus.pectinilyticus\n##  2024-10-06 07:46:11.469245 INFO::Fitting model to feature number 86, Odoribacter.splanchnicus\n##  2024-10-06 07:46:11.471552 INFO::Fitting model to feature number 87, Oscillibacter.sp..57_20\n##  2024-10-06 07:46:11.473867 INFO::Fitting model to feature number 88, Oscillibacter.sp..CAG.241\n##  2024-10-06 07:46:11.476172 INFO::Fitting model to feature number 89, Parabacteroides.distasonis\n##  2024-10-06 07:46:11.478474 INFO::Fitting model to feature number 90, Parabacteroides.merdae\n##  2024-10-06 07:46:11.48079 INFO::Fitting model to feature number 91, Paraprevotella.clara\n##  2024-10-06 07:46:11.483089 INFO::Fitting model to feature number 92, Paraprevotella.xylaniphila\n##  2024-10-06 07:46:11.485373 INFO::Fitting model to feature number 93, Parasutterella.excrementihominis\n##  2024-10-06 07:46:11.48767 INFO::Fitting model to feature number 94, Phascolarctobacterium.faecium\n##  2024-10-06 07:46:11.489995 INFO::Fitting model to feature number 95, Phocaeicola.coprocola\n##  2024-10-06 07:46:11.49229 INFO::Fitting model to feature number 96, Phocaeicola.dorei\n##  2024-10-06 07:46:11.494554 INFO::Fitting model to feature number 97, Phocaeicola.massiliensis\n##  2024-10-06 07:46:11.496866 INFO::Fitting model to feature number 98, Phocaeicola.plebeius\n##  2024-10-06 07:46:11.499184 INFO::Fitting model to feature number 99, Phocaeicola.vulgatus\n##  2024-10-06 07:46:11.501497 INFO::Fitting model to feature number 100, Prevotella.copri\n##  2024-10-06 07:46:11.503815 INFO::Fitting model to feature number 101, Proteobacteria.bacterium.CAG.139\n##  2024-10-06 07:46:11.506105 INFO::Fitting model to feature number 102, Roseburia.faecis\n##  2024-10-06 07:46:11.508387 INFO::Fitting model to feature number 103, Roseburia.hominis\n##  2024-10-06 07:46:11.510755 INFO::Fitting model to feature number 104, Roseburia.intestinalis\n##  2024-10-06 07:46:11.513036 INFO::Fitting model to feature number 105, Roseburia.inulinivorans\n##  2024-10-06 07:46:11.515332 INFO::Fitting model to feature number 106, Roseburia.sp..CAG.471\n##  2024-10-06 07:46:11.517625 INFO::Fitting model to feature number 107, Ruminococcaceae.bacterium.D16\n##  2024-10-06 07:46:11.519934 INFO::Fitting model to feature number 108, Ruminococcus.bicirculans\n##  2024-10-06 07:46:11.522232 INFO::Fitting model to feature number 109, Ruminococcus.bromii\n##  2024-10-06 07:46:11.524525 INFO::Fitting model to feature number 110, Ruthenibacterium.lactatiformans\n##  2024-10-06 07:46:11.526833 INFO::Fitting model to feature number 111, Sellimonas.intestinalis\n##  2024-10-06 07:46:11.529117 INFO::Fitting model to feature number 112, Streptococcus.parasanguinis\n##  2024-10-06 07:46:11.531406 INFO::Fitting model to feature number 113, Streptococcus.salivarius\n##  2024-10-06 07:46:11.533699 INFO::Fitting model to feature number 114, Turicimonas.muris\n##  2024-10-06 07:46:11.536011 INFO::Fitting model to feature number 115, Veillonella.atypica\n##  2024-10-06 07:46:11.538299 INFO::Fitting model to feature number 116, Veillonella.dispar\n##  2024-10-06 07:46:11.54059 INFO::Fitting model to feature number 117, Veillonella.infantium\n##  2024-10-06 07:46:11.542899 INFO::Fitting model to feature number 118, Veillonella.parvula\n##  2024-10-06 07:46:11.545196 INFO::Fitting model to feature number 119, Veillonella.sp..T11011.6\n##  2024-10-06 07:46:11.547525 INFO::Fitting model to feature number 120, X.Clostridium..innocuum\n##  2024-10-06 07:46:11.549819 INFO::Fitting model to feature number 121, X.Clostridium..leptum\n##  2024-10-06 07:46:11.552154 INFO::Fitting model to feature number 122, X.Clostridium..symbiosum\n##  2024-10-06 07:46:11.554541 INFO::Fitting model to feature number 123, X.Eubacterium..rectale\n##  2024-10-06 07:46:11.556859 INFO::Fitting model to feature number 124, X.Eubacterium..siraeum\n##  2024-10-06 07:46:11.559164 INFO::Fitting model to feature number 125, X.Ruminococcus..gnavus\n##  2024-10-06 07:46:11.561473 INFO::Fitting model to feature number 126, X.Ruminococcus..lactaris\n##  2024-10-06 07:46:11.563926 INFO::Fitting model to feature number 127, X.Ruminococcus..torques\n##  2024-10-06 07:46:11.584654 INFO::Counting total values for each feature\n##  2024-10-06 07:46:11.596548 INFO::Writing filtered data to file output_species/features/filtered_data.tsv\n##  2024-10-06 07:46:11.609069 INFO::Writing filtered, normalized data to file output_species/features/filtered_data_norm.tsv\n##  2024-10-06 07:46:11.621103 INFO::Writing filtered, normalized, transformed data to file output_species/features/filtered_data_norm_transformed.tsv\n##  2024-10-06 07:46:11.638504 INFO::Writing residuals to file output_species/fits/residuals.rds\n##  2024-10-06 07:46:11.64448 INFO::Writing fitted values to file output_species/fits/fitted.rds\n##  2024-10-06 07:46:11.649747 INFO::Writing all results to file (ordered by increasing q-values): output_species/all_results.tsv\n##  2024-10-06 07:46:11.652587 INFO::Writing the significant results (those which are less than or equal to the threshold of 0.250000 ) to file (ordered by increasing q-values): output_species/significant_results.tsv\n##  2024-10-06 07:46:11.65343 INFO::Writing heatmap of significant results to file: output_species/heatmap.pdf\n##  2024-10-06 07:46:11.758974 INFO::Writing association plots (one for each significant association) to output folder: output_species\n##  2024-10-06 07:46:11.761796 INFO::Plotting associations from most to least significant, grouped by metadata\n##  2024-10-06 07:46:11.762441 INFO::Plotting data for metadata number 1, age\n##  2024-10-06 07:46:11.763392 INFO::Creating scatter plot for continuous data, age vs Alistipes.indistinctus\n##  2024-10-06 07:46:11.991035 INFO::Creating scatter plot for continuous data, age vs Lacrimispora.saccharolytica\n##  2024-10-06 07:46:12.22065 INFO::Creating scatter plot for continuous data, age vs Ruminococcus.bicirculans\n##  2024-10-06 07:46:12.343108 INFO::Creating scatter plot for continuous data, age vs Ruminococcus.bromii\n##  2024-10-06 07:46:12.467867 INFO::Creating scatter plot for continuous data, age vs Bifidobacterium.pseudocatenulatum\n##  2024-10-06 07:46:12.593468 INFO::Creating scatter plot for continuous data, age vs Haemophilus.parainfluenzae\n##  2024-10-06 07:46:12.725881 INFO::Creating scatter plot for continuous data, age vs Lachnospira.eligens\n##  2024-10-06 07:46:12.85218 INFO::Creating scatter plot for continuous data, age vs X.Ruminococcus..gnavus\n##  2024-10-06 07:46:13.02367 INFO::Creating scatter plot for continuous data, age vs Butyricimonas.virosa\n##  2024-10-06 07:46:13.147363 INFO::Creating scatter plot for continuous data, age vs Lawsonibacter.asaccharolyticus\n##  2024-10-06 07:46:13.27139 INFO::Creating scatter plot for continuous data, age vs X.Eubacterium..siraeum\n##  2024-10-06 07:46:13.39777 INFO::Creating scatter plot for continuous data, age vs Butyricimonas.synergistica\n##  2024-10-06 07:46:13.525269 INFO::Creating scatter plot for continuous data, age vs Monoglobus.pectinilyticus\n##  2024-10-06 07:46:13.6525 INFO::Creating scatter plot for continuous data, age vs Veillonella.atypica\n##  2024-10-06 07:46:15.273669 INFO::Plotting data for metadata number 2, disease\n##  2024-10-06 07:46:15.275054 INFO::Creating boxplot for categorical data, disease vs Alistipes.putredinis\n##  2024-10-06 07:46:15.430881 INFO::Creating boxplot for categorical data, disease vs Gemmiger.formicilis\n##  2024-10-06 07:46:15.567265 INFO::Creating boxplot for categorical data, disease vs X.Ruminococcus..torques\n##  2024-10-06 07:46:15.70337 INFO::Creating boxplot for categorical data, disease vs Ruminococcus.bicirculans\n##  2024-10-06 07:46:15.817649 INFO::Creating boxplot for categorical data, disease vs Sellimonas.intestinalis\n##  2024-10-06 07:46:15.932436 INFO::Creating boxplot for categorical data, disease vs X.Clostridium..leptum\n##  2024-10-06 07:46:16.055452 INFO::Creating boxplot for categorical data, disease vs Alistipes.shahii\n##  2024-10-06 07:46:17.148405 INFO::Plotting data for metadata number 3, antibiotics_current_use\n##  2024-10-06 07:46:17.149836 INFO::Creating boxplot for categorical data, antibiotics_current_use vs Coprobacter.fastidiosus\n##  2024-10-06 07:46:17.263946 INFO::Creating boxplot for categorical data, antibiotics_current_use vs X.Eubacterium..rectale\n##  2024-10-06 07:46:17.378474 INFO::Creating boxplot for categorical data, antibiotics_current_use vs Agathobaculum.butyriciproducens\n\nUnlike gene expression studies, we do not have well-defined signatures or modules for microbiome data. Here, we will construct data-driven modules using weighted gene co-expression network analysis (WGCNA) (Langfelder and Horvath 2008), (Geistlinger et al. 2023). We aim to ensure that the effect of disease and other covariates has been removed by working on the residuals. Following the WGCNA tutorial, our first step will be to check whether there are any outliers in our data.\n\nLangfelder, Peter, and Steve Horvath. 2008. “WGCNA: An r Package for Weighted Correlation Network Analysis.” BMC Bioinformatics 9: 559. https://doi.org/https://doi.org/10.1186/1471-2105-9-559.\n\nGeistlinger, Ludwig, Chloe Mirzayi, Fatima Zohra, Rimsha Azhar, Shaimaa Elsafoury, Clare Grieve, Jennifer Wokaty, et al. 2023. “BugSigDB Captures Patterns of Differential Abundance Across a Broad Range of Host-Associated Microbial Signatures.” Nature Biotechnology 42 (5): 790–802. https://doi.org/https://doi.org/10.1038/s41587-023-01872-y.\n\n\nlibrary(WGCNA)\n\ndatExpr &lt;- as.data.frame(t(fit_data$residuals))\ngsg = goodSamplesGenes(datExpr, verbose = 3)\n##   Flagging genes and samples with too many missing values...\n##    ..step 1\n##    ..Excluding 6 samples from the calculation due to too many missing genes.\n##    ..step 2\ngsg$allOK\n##  [1] FALSE\n\nIf the last statement returns TRUE, no outliers are identified. If not, we need to remove the outliers from the data.\n\n\nif (!gsg$allOK)\n{if (sum(!gsg$goodGenes) &gt; 0)\n    printFlush(paste(\n        \"Removing genes:\",\n        paste(names(datExpr)[!gsg$goodGenes], collapse = \", \")));\n    if (sum(!gsg$goodSamples) &gt; 0)\n        printFlush(paste(\n            \"Removing samples:\",\n            paste(rownames(datExpr)[!gsg$goodSamples], collapse =\", \")))\n    datExpr = datExpr[gsg$goodSamples, gsg$goodGenes]\n}\n##  Removing samples: CSM5MCVB_P, CSM79HNY_P, ESM5GEYY_P, ESM718U9_P, MSM6J2N6_P, MSM9VZLX_P\n\nAfter removing the outliers, we need to choose a suitable soft threshold parameter for creating the modules as part of the WGCNA algorithm. This power value must produce a graph similar to a scale-free network. We can use the mean connectivity graphic for the selection of this power parameter.\n\n\n# Choose a set of soft threshold parameters\npowers = c(c(1:20), seq(from = 22, to=30, by=2))\nsft = pickSoftThreshold(\n    datExpr, powerVector = powers, verbose = 5, dataIsExpr = TRUE,\n    RsquaredCut = 0.30)\n##  pickSoftThreshold: will use block size 127.\n##   pickSoftThreshold: calculating connectivity for given powers...\n##     ..working on genes 1 through 127 of 127\n##     Power SFT.R.sq  slope truncated.R.sq  mean.k. median.k.  max.k.\n##  1      1   0.1790 -0.972        0.85700 15.00000  1.48e+01 23.0000\n##  2      2   0.3450 -0.729        0.63500  2.95000  2.85e+00  5.6900\n##  3      3   0.2400 -4.130        0.12700  0.80400  7.36e-01  2.6100\n##  4      4   0.3100 -4.870        0.19900  0.29200  2.14e-01  1.6700\n##  5      5   0.2150 -4.030       -0.00880  0.13700  7.02e-02  1.2200\n##  6      6   0.1800 -2.930       -0.05130  0.07910  2.46e-02  0.9570\n##  7      7   0.1380 -2.240       -0.10100  0.05320  9.33e-03  0.7900\n##  8      8   0.2200 -2.790       -0.00259  0.03940  3.71e-03  0.6690\n##  9      9   0.0872 -1.450       -0.09130  0.03100  1.50e-03  0.5760\n##  10    10   0.1190 -1.630       -0.07660  0.02540  6.73e-04  0.5020\n##  11    11   0.0562 -1.250       -0.03470  0.02130  2.66e-04  0.4410\n##  12    12   0.1620 -2.150       -0.07720  0.01810  1.12e-04  0.3910\n##  13    13   0.2120 -2.350       -0.00949  0.01560  4.84e-05  0.3480\n##  14    14   0.2480 -2.410        0.04950  0.01360  2.12e-05  0.3110\n##  15    15   0.2890 -2.470        0.15200  0.01190  9.53e-06  0.2810\n##  16    16   0.3030 -2.420        0.18400  0.01050  4.33e-06  0.2580\n##  17    17   0.2410 -2.380        0.02450  0.00933  1.98e-06  0.2380\n##  18    18   0.3190 -2.640        0.15400  0.00830  9.03e-07  0.2180\n##  19    19   0.3320 -2.600        0.17700  0.00741  4.03e-07  0.2010\n##  20    20   0.2370 -2.050        0.02180  0.00664  1.70e-07  0.1840\n##  21    22   0.2350 -2.000        0.07520  0.00536  3.40e-08  0.1560\n##  22    24   0.2430 -2.230        0.09560  0.00437  6.98e-09  0.1310\n##  23    26   0.2370 -2.120        0.26200  0.00358  1.44e-09  0.1110\n##  24    28   0.2490 -2.080        0.26200  0.00294  2.93e-10  0.0937\n##  25    30   0.2490 -2.290        0.30100  0.00243  5.67e-11  0.0791\n\nIn this step, we will conduct a one-step module detection based on the selected soft threshold parameter selected above.\n\n\npower = sft$powerEstimate\nnet = blockwiseModules(\n    datExpr,\n    power = power,\n    corFnc=\"bicor\",\n    corOptions=list(maxPOutliers=0.1),\n    networkType =\"unsigned\",\n    maxBlockSize = ncol(datExpr),\n    minModuleSize = 3,\n    TOMType = \"unsigned\",\n    reassignThreshold = 0,\n    mergeCutHeight = 0,\n    verbose = 3)\n##   Calculating module eigengenes block-wise from all genes\n##     Flagging genes and samples with too many missing values...\n##      ..step 1\n##   ..Working on block 1 .\n##      TOM calculation: adjacency..\n##      ..will not use multithreading.\n##       Fraction of slow calculations: 0.000000\n##      ..connectivity..\n##      ..matrix multiplication (system BLAS)..\n##      ..normalization..\n##      ..done.\n##   ....clustering..\n##   ....detecting modules..\n##   ....calculating module eigengenes..\n##   ....checking kME in modules..\n##       ..removing 3 genes from module 1 because their KME is too low.\n##       ..removing 3 genes from module 2 because their KME is too low.\n##       ..removing 2 genes from module 3 because their KME is too low.\n##       ..removing 1 genes from module 5 because their KME is too low.\n##       ..removing 1 genes from module 7 because their KME is too low.\n##   ..merging modules that are too close..\n##       mergeCloseModules: Merging modules whose distance is less than 0\n##         Calculating new MEs...\n\n####################\n# How many modules #\n####################\n\nncol(net$MEs)\n##  [1] 14\ntable(net$colors)\n##  \n##        black        blue       brown       green greenyellow        grey \n##            7          14          13          12           5          10 \n##      magenta        pink      purple         red      salmon         tan \n##            6           6           5          11           3           5 \n##    turquoise      yellow \n##           18          12\n\nThe WGCNA algorithm produced 14 modules which we can visualize as follows.\n\n\n##########################\n# Plot module dendrogram #\n##########################\n\neigenGenes &lt;- net$MEs\nMEDiss = 1-cor(eigenGenes)\nMETree = hclust(as.dist(MEDiss), method = \"average\")\nplot(METree, main = \"Clustering of module eigengenes\", xlab = \"\", sub = \"\")\n\n\n\n\n\n\n\nNext, we calculate hub genes for the modules and create the mapping files to proceed with the MSEA.\n\n\n###########################################\n# Re-calculate modules and find hub genes #\n###########################################\n\nmoduleColors &lt;- net$colors\nMEs0 = moduleEigengenes(datExpr, moduleColors)$eigengenes\nmodules_data = orderMEs(MEs0)\n\n#######################\n# Create mapping file #\n#######################\n\nlibrary(tidyverse)\n\nfeature_by_modules &lt;- as.data.frame(net$colors)\nfeature_by_modules &lt;- rownames_to_column(feature_by_modules)\ncolnames(feature_by_modules) &lt;- c('Feature', 'Module')\nfeatures_mapping &lt;- feature_by_modules\nfeatures_mapping$Module &lt;- paste('ME', features_mapping$Module, sep = '')\n\nFinally, we will run the MSEA analysis on the modules we constructed using WGCNA. Here, we first create a wrapper for the MSEA analysis using the gsEasy package.\n\n\nlibrary(reshape2)\nlibrary(gsEasy)\n\n################\n# MSEA Wrapper #\n################\n\nrun_MSEA &lt;- function(\n        microbeSet, # A list\n        ranked_features, # Ranked list of featured\n        filter.count = 3,\n        seed = 1234,\n        fdr.correction = 'BH') {\n\n    ###################\n    # Filter out sets #\n    ##################\n\n    microbeSet0 &lt;- microbeSet\n    cond &lt;- sapply(microbeSet0, function(x) length(x) &gt; filter.count)\n    microbeSet &lt;- microbeSet0[cond]\n    lengthmicrobeSet &lt;- as.data.frame(\n        reshape2::melt(lapply(microbeSet, function(x) length(x))))\n    colnames(lengthmicrobeSet) &lt;- c('Freq','Set')\n\n    ################\n    # Classic MSEA #\n    ################\n\n    set.seed(seed)\n    enrichment &lt;- as.data.frame(\n        sapply(microbeSet, function(set) gset(S = set, r = ranked_features)))\n    colnames(enrichment)&lt;-'ES'\n    enrichment &lt;- rownames_to_column(enrichment, 'Set')\n    enrichment &lt;- merge(enrichment, lengthmicrobeSet, 'Set')\n    enrichment$qval &lt;- p.adjust(enrichment$ES, fdr.correction)\n\n    ##########\n    # Return #\n    ##########\n\n    return(enrichment)\n\n}\n\nBefore running the MSEA, we also need to rank the differential analysis results from MaAsLin2. We use the topGo package to create a list of microbe sets from the mapping file created above.\n\n\n###################\n# Rank DA results #\n###################\n\nresults &lt;- fit_data$results |&gt; filter(metadata == 'disease')\nresults$qval &lt;- p.adjust(results$pval, 'BH')\nresults &lt;- results[order(results$qval, decreasing = FALSE), ]\n\n###################\n# MSEA Processing #\n###################\n\nlibrary(topGO)\nmodule_map &lt;- features_mapping\nmod.gs &lt;- tapply(module_map$Module, module_map$Feature, as.character)\nmicrobeSet &lt;- inverseList(mod.gs)\nmicrobeSet\n##  $MEblack\n##  [1] \"Anaeromassilibacillus.sp..An250\" \"Anaerotruncus.colihominis\"      \n##  [3] \"Blautia.wexlerae\"                \"Eisenbergiella.tayi\"            \n##  [5] \"Firmicutes.bacterium.CAG.94\"     \"Ruthenibacterium.lactatiformans\"\n##  [7] \"Sellimonas.intestinalis\"        \n##  \n##  $MEblue\n##   [1] \"Clostridium.sp..CAG.58\"         \"Erysipelatoclostridium.ramosum\"\n##   [3] \"Haemophilus.parainfluenzae\"     \"Intestinibacter.bartlettii\"    \n##   [5] \"Klebsiella.pneumoniae\"          \"Klebsiella.variicola\"          \n##   [7] \"Lawsonibacter.asaccharolyticus\" \"Streptococcus.parasanguinis\"   \n##   [9] \"Streptococcus.salivarius\"       \"Veillonella.atypica\"           \n##  [11] \"Veillonella.dispar\"             \"Veillonella.infantium\"         \n##  [13] \"Veillonella.parvula\"            \"Veillonella.sp..T11011.6\"      \n##  \n##  $MEbrown\n##   [1] \"Alistipes.finegoldii\"        \"Alistipes.indistinctus\"     \n##   [3] \"Alistipes.putredinis\"        \"Alistipes.shahii\"           \n##   [5] \"Bacteroides.xylanisolvens\"   \"Bilophila.wadsworthia\"      \n##   [7] \"Firmicutes.bacterium.CAG.83\" \"Odoribacter.splanchnicus\"   \n##   [9] \"Oscillibacter.sp..57_20\"     \"Oscillibacter.sp..CAG.241\"  \n##  [11] \"Phocaeicola.dorei\"           \"Ruminococcus.bromii\"        \n##  [13] \"X.Eubacterium..siraeum\"     \n##  \n##  $MEgreen\n##   [1] \"Blautia.sp..CAG.257\"            \"Clostridium.bolteae.CAG.59\"    \n##   [3] \"Eggerthella.lenta\"              \"Eisenbergiella.massiliensis\"   \n##   [5] \"Enterocloster.aldenensis\"       \"Enterocloster.bolteae\"         \n##   [7] \"Enterocloster.citroniae\"        \"Enterocloster.clostridioformis\"\n##   [9] \"Enterocloster.lavalensis\"       \"Flavonifractor.plautii\"        \n##  [11] \"Lacrimispora.saccharolytica\"    \"X.Clostridium..symbiosum\"      \n##  \n##  $MEgreenyellow\n##  [1] \"Coprobacter.fastidiosus\" \"Escherichia.coli\"       \n##  [3] \"Hungatella.hathewayi\"    \"X.Clostridium..innocuum\"\n##  [5] \"X.Ruminococcus..gnavus\" \n##  \n##  $MEgrey\n##   [1] \"Anaerotignum.lactatifermentans\"   \"Bacteroides.cellulosilyticus\"    \n##   [3] \"Bacteroides.fragilis\"             \"Collinsella.intestinalis\"        \n##   [5] \"Eubacterium.sp..CAG.38\"           \"Haemophilus.sp..HMSC71H05\"       \n##   [7] \"Intestinimonas.butyriciproducens\" \"Lachnospira.eligens\"             \n##   [9] \"Roseburia.intestinalis\"           \"Roseburia.sp..CAG.471\"           \n##  \n##  $MEmagenta\n##  [1] \"Bacteroides.finegoldii\"     \"Paraprevotella.clara\"      \n##  [3] \"Paraprevotella.xylaniphila\" \"Phocaeicola.coprocola\"     \n##  [5] \"Phocaeicola.plebeius\"       \"Prevotella.copri\"          \n##  \n##  $MEpink\n##  [1] \"Bacteroides.galacturonicus\"        \"Bifidobacterium.pseudocatenulatum\"\n##  [3] \"Eubacterium.sp..CAG.251\"           \"Lachnospira.pectinoschiza\"        \n##  [5] \"Lactobacillus.rogosae\"             \"Phocaeicola.massiliensis\"         \n##  \n##  $MEpurple\n##  [1] \"Barnesiella.intestinihominis\" \"Butyricimonas.synergistica\"  \n##  [3] \"Butyricimonas.virosa\"         \"Coprococcus.eutactus\"        \n##  [5] \"Ruminococcus.bicirculans\"    \n##  \n##  $MEred\n##   [1] \"Akkermansia.muciniphila\"          \"Bacteroides.intestinalis\"        \n##   [3] \"Clostridium.sp..CAG.299\"          \"Dialister.invisus\"               \n##   [5] \"Dielma.fastidiosa\"                \"Holdemania.filiformis\"           \n##   [7] \"Monoglobus.pectinilyticus\"        \"Parasutterella.excrementihominis\"\n##   [9] \"Proteobacteria.bacterium.CAG.139\" \"Turicimonas.muris\"               \n##  [11] \"X.Clostridium..leptum\"           \n##  \n##  $MEsalmon\n##  [1] \"Bacteroides.faecis\"            \"Bacteroides.faecis.CAG.32\"    \n##  [3] \"Phascolarctobacterium.faecium\"\n##  \n##  $MEtan\n##  [1] \"Bacteroides.salyersiae\"       \"Bifidobacterium.adolescentis\"\n##  [3] \"Bifidobacterium.bifidum\"      \"Bifidobacterium.longum\"      \n##  [5] \"Collinsella.aerofaciens\"     \n##  \n##  $MEturquoise\n##   [1] \"Agathobaculum.butyriciproducens\" \"Anaerobutyricum.hallii\"         \n##   [3] \"Anaerostipes.hadrus\"             \"Bacteroides.eggerthii\"          \n##   [5] \"Blautia.obeum\"                   \"Coprococcus.catus\"              \n##   [7] \"Coprococcus.comes\"               \"Dorea.formicigenerans\"          \n##   [9] \"Dorea.longicatena\"               \"Eubacterium.ramulus\"            \n##  [11] \"Faecalibacterium.prausnitzii\"    \"Fusicatenibacter.saccharivorans\"\n##  [13] \"Gemmiger.formicilis\"             \"Roseburia.faecis\"               \n##  [15] \"Roseburia.hominis\"               \"Roseburia.inulinivorans\"        \n##  [17] \"X.Eubacterium..rectale\"          \"X.Ruminococcus..torques\"        \n##  \n##  $MEyellow\n##   [1] \"Acidaminococcus.intestini\"     \"Bacteroides.caccae\"           \n##   [3] \"Bacteroides.ovatus\"            \"Bacteroides.stercoris\"        \n##   [5] \"Bacteroides.thetaiotaomicron\"  \"Bacteroides.uniformis\"        \n##   [7] \"Eubacterium.ventriosum\"        \"Parabacteroides.distasonis\"   \n##   [9] \"Parabacteroides.merdae\"        \"Phocaeicola.vulgatus\"         \n##  [11] \"Ruminococcaceae.bacterium.D16\" \"X.Ruminococcus..lactaris\"\n\nWe are now ready to run the MSEA analysis. We run \\(100,000\\) permutations to calculate the enrichment scores.\n\n\nMSEA &lt;- run_MSEA(microbeSet, results$feature)\nMSEA &lt;- MSEA[\n    , c('Set', 'Freq', 'ES', setdiff(names(MSEA), c('Set', 'Freq', 'ES')))]\ncolnames(MSEA) &lt;- c('ID', 'Size', 'pval', 'qval')\nMSEA$ID &lt;- paste(MSEA$ID, ' (', MSEA$Size, ')', sep = '')\n\nWe can plot the enrichment scores to visualize the MSEA results.\n\n\np &lt;- MSEA |&gt;\n    arrange(-pval) |&gt;\n    mutate(ID = factor(ID, levels = ID)) |&gt;\n    ggplot(aes(y = -log10(pval), x = ID)) +\n    geom_bar(stat = \"identity\", fill = 'cornflowerblue') + theme_bw() +\n    coord_flip() +\n    ggtitle('Statistically significant modules associated with disease') +\n    xlab('') +\n    ylab('MSEA enrichment score')\n\nprint(p)\n\n\n\n\n\n\n\nBased on the MSEA results, we obtain 13 enriched modules of microbial species. We can also examine the members of the top enriched modules.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Microbe Set Enrichment Analysis (MSEA)</span>"
    ]
  },
  {
    "objectID": "pages/msea.html#print-the-most-significant-modules-for-species-relative-abundance-data",
    "href": "pages/msea.html#print-the-most-significant-modules-for-species-relative-abundance-data",
    "title": "Appendix A — Microbe Set Enrichment Analysis (MSEA)",
    "section": "\nA.3 Print the most significant modules for species relative abundance data",
    "text": "A.3 Print the most significant modules for species relative abundance data\n\n\nmicrobeSet[[\"MEpurple\"]]\n##  [1] \"Barnesiella.intestinihominis\" \"Butyricimonas.synergistica\"  \n##  [3] \"Butyricimonas.virosa\"         \"Coprococcus.eutactus\"        \n##  [5] \"Ruminococcus.bicirculans\"\nmicrobeSet[[\"MEbrown\"]]\n##   [1] \"Alistipes.finegoldii\"        \"Alistipes.indistinctus\"     \n##   [3] \"Alistipes.putredinis\"        \"Alistipes.shahii\"           \n##   [5] \"Bacteroides.xylanisolvens\"   \"Bilophila.wadsworthia\"      \n##   [7] \"Firmicutes.bacterium.CAG.83\" \"Odoribacter.splanchnicus\"   \n##   [9] \"Oscillibacter.sp..57_20\"     \"Oscillibacter.sp..CAG.241\"  \n##  [11] \"Phocaeicola.dorei\"           \"Ruminococcus.bromii\"        \n##  [13] \"X.Eubacterium..siraeum\"",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Microbe Set Enrichment Analysis (MSEA)</span>"
    ]
  },
  {
    "objectID": "pages/msea.html#performing-the-msea-analysis-with-pathway-relative-abundance-data",
    "href": "pages/msea.html#performing-the-msea-analysis-with-pathway-relative-abundance-data",
    "title": "Appendix A — Microbe Set Enrichment Analysis (MSEA)",
    "section": "\nA.4 Performing the MSEA analysis with pathway relative abundance data",
    "text": "A.4 Performing the MSEA analysis with pathway relative abundance data\nNext, we repeat the MSEA with the pathway relative abundance data from the iHMP project and follow the same steps as before.\n\n\n##########################\n# Load HMP2 pathway data #\n##########################\n\nse_pathway &lt;- sampleMetadata |&gt;\n    filter(study_name == \"HMP_2019_ibdmdb\") |&gt;\n    returnSamples(\"pathway_abundance\", rownames = \"short\")\n\n##########################\n# Create sample metadata #\n##########################\n\nsample_metadata &lt;- colData(se_pathway) |&gt;\n    as.data.frame() |&gt; filter(visit_number == 1) |&gt;\n    dplyr::select(\"age\", \"disease\", \"antibiotics_current_use\")\n\n# Set reference\nsample_metadata$disease &lt;- as.factor(sample_metadata$disease)\nsample_metadata$disease &lt;- relevel(sample_metadata$disease, 'healthy')\n\n###########################\n# Create Pathway Features #\n###########################\n\nfeature_pwys_t &lt;- as.data.frame(assay(se_pathway))\nfeature_pwys_t &lt;- rownames_to_column(feature_pwys_t, \"ID\")\nfeature_pwys_t &lt;- feature_pwys_t |&gt;\n    filter(!grepl(\"\\\\|\", ID)) |&gt;\n    filter(!ID %in% c('UNMAPPED', 'UNINTEGRATED')) |&gt;\n    column_to_rownames('ID') |&gt;\n    as.data.frame()\n\n##############################\n# Subset to baseline samples #\n##############################\n\nfeature_pwys &lt;- as.data.frame(t(feature_pwys_t))\nfeature_pwys &lt;- feature_pwys[rownames(sample_metadata),]\nfeature_pwys &lt;- feature_pwys / 100\nrm(feature_pwys_t); rm(se_pathway)\n\nAs before, we first run a MaAsLin2 analysis using default settings and construct the modules using residuals from the MaAsLin2 models.\n\n\nfit_data = Maaslin2(\n    input_data = feature_pwys,\n    input_metadata = sample_metadata,\n    normalization = \"NONE\",\n    output = \"output_pwys\",\n    fixed_effects = c(\"disease\", \"age\", \"antibiotics_current_use\"))\n##  [1] \"Creating output folder\"\n##  [1] \"Creating output feature tables folder\"\n##  [1] \"Creating output fits folder\"\n##  [1] \"Creating output figures folder\"\n##  2024-10-06 07:46:42.245261 INFO::Writing function arguments to log file\n##  2024-10-06 07:46:42.249005 INFO::Verifying options selected are valid\n##  2024-10-06 07:46:42.249468 INFO::Determining format of input files\n##  2024-10-06 07:46:42.249949 INFO::Input format is data samples as rows and metadata samples as rows\n##  2024-10-06 07:46:42.25529 INFO::Formula for fixed effects: expr ~  disease + age + antibiotics_current_use\n##  2024-10-06 07:46:42.255896 INFO::Factor detected for categorial metadata 'disease'. Provide a reference argument or manually set factor ordering to change reference level.\n##  2024-10-06 07:46:42.256493 INFO::Filter data based on min abundance and min prevalence\n##  2024-10-06 07:46:42.256958 INFO::Total samples in data: 136\n##  2024-10-06 07:46:42.257373 INFO::Min samples required with min abundance for a feature not to be filtered: 13.600000\n##  2024-10-06 07:46:42.262849 INFO::Total filtered features: 113\n##  2024-10-06 07:46:42.263409 INFO::Filtered feature names from abundance and prevalence filtering: PWY.5044..purine.nucleotides.degradation.I..plants., PROPFERM.PWY..L.alanine.fermentation.to.propanoate.and.acetate, PWY.6596..adenosine.nucleotides.degradation.I, PWY.5004..superpathway.of.L.citrulline.metabolism, UDPNACETYLGALSYN.PWY..UDP.N.acetyl.D.glucosamine.biosynthesis.II, PWY66.367..ketogenesis, PWY.5392..reductive.TCA.cycle.II, PWY.101..photosynthesis.light.reactions, PWY.7031..protein.N.glycosylation..bacterial., PWY.5265..peptidoglycan.biosynthesis.II..staphylococci., PWY.7268..NAD.NADP.NADH.NADPH.cytosolic.interconversion..yeast., PWY.7165..L.ascorbate.biosynthesis.VI..engineered.pathway., CATECHOL.ORTHO.CLEAVAGE.PWY..catechol.degradation.to..beta..ketoadipate, PWY.5417..catechol.degradation.III..ortho.cleavage.pathway., PWY.5431..aromatic.compounds.degradation.via..beta..ketoadipate, PWY3DJ.35471..L.ascorbate.biosynthesis.IV, PWY.6185..4.methylcatechol.degradation..ortho.cleavage., PWY.7245..superpathway.NAD.NADP...NADH.NADPH.interconversion..yeast., PWY.5181..toluene.degradation.III..aerobic...via.p.cresol., PWY.6562..norspermidine.biosynthesis, PWY.7431..aromatic.biogenic.amine.degradation..bacteria., PWY.6307..L.tryptophan.degradation.X..mammalian..via.tryptamine., PWY.6313..serotonin.degradation, URSIN.PWY..ureide.biosynthesis, LIPASYN.PWY..phospholipases, DHGLUCONATE.PYR.CAT.PWY..glucose.degradation..oxidative., DENITRIFICATION.PWY..nitrate.reduction.I..denitrification., PWY.6662..superpathway.of.quinolone.and.alkylquinolone.biosynthesis, PWY.6660..2.heptyl.3.hydroxy.4.1H..quinolone.biosynthesis, PWY.6182..superpathway.of.salicylate.degradation, P165.PWY..superpathway.of.purines.degradation.in.plants, PWY66.388..fatty.acid..alpha..oxidation.III, TYRFUMCAT.PWY..L.tyrosine.degradation.I, PWY.5101..L.isoleucine.biosynthesis.II, PWY.6167..flavin.biosynthesis.II..archaea., PWY.6748..nitrate.reduction.VII..denitrification., PWY.7039..phosphatidate.metabolism..as.a.signaling.molecule, VALDEG.PWY..L.valine.degradation.I, PWY.5198..factor.420.biosynthesis, PWY.6215..4.chlorobenzoate.degradation, AEROBACTINSYN.PWY..aerobactin.biosynthesis, P562.PWY..myo.inositol.degradation.I, PWY.7409..phospholipid.remodeling..phosphatidylethanolamine..yeast., PWY.4722..creatinine.degradation.II, PWY.3801..sucrose.degradation.II..sucrose.synthase., PWY.7345..superpathway.of.anaerobic.sucrose.degradation, P125.PWY..superpathway.of..R.R..butanediol.biosynthesis, PWY.5994..palmitate.biosynthesis.I..animals.and.fungi., PWY.4321..L.glutamate.degradation.IV, PWY.7528..L.methionine.salvage.cycle.I..bacteria.and.plants., PWY.4361..S.methyl.5.thio..alpha..D.ribose.1.phosphate.degradation, PWY.1541..superpathway.of.taurine.degradation, PWY.5654..2.amino.3.carboxymuconate.semialdehyde.degradation.to.2.oxopentenoate, PWY.6210..2.aminophenol.degradation, PWY.6071..superpathway.of.phenylethylamine.degradation, PWY0.321..phenylacetate.degradation.I..aerobic., PWY.7200..superpathway.of.pyrimidine.deoxyribonucleoside.salvage, PWY.2221..Entner.Doudoroff.pathway.III..semi.phosphorylative., PWY.6992..1.5.anhydrofructose.degradation, PWY.7294..xylose.degradation.IV, PWY.6145..superpathway.of.sialic.acids.and.CMP.sialic.acids.biosynthesis, PWY.5180..toluene.degradation.I..aerobic...via.o.cresol., PWY.5182..toluene.degradation.II..aerobic...via.4.methylcatechol., PWY.5415..catechol.degradation.I..meta.cleavage.pathway., PWY.6785..hydrogen.production.VIII, PWY.5509..adenosylcobalamin.biosynthesis.from.cobyrinate.a.c.diamide.I, PWY.6641..superpathway.of.sulfolactate.degradation, PWY.7527..L.methionine.salvage.cycle.III, PWY.6396..superpathway.of.2.3.butanediol.biosynthesis, PWY.6467..Kdo.transfer.to.lipid.IVA.III..Chlamydia., X7ALPHADEHYDROX.PWY..cholate.degradation..bacteria..anaerobic., PWY.7374..1.4.dihydroxy.6.naphthoate.biosynthesis.I, PWY.6906..chitin.derivatives.degradation, PWY.5514..UDP.N.acetyl.D.galactosamine.biosynthesis.II, PWY.7317..superpathway.of.dTDP.glucose.derived.O.antigen.building.blocks.biosynthesis, PWY.7218..photosynthetic.3.hydroxybutanoate.biosynthesis..engineered., PHOTOALL.PWY..oxygenic.photosynthesis, PWY.6344..L.ornithine.degradation.II..Stickland.reaction., P621.PWY..nylon.6.oligomer.degradation, PWY.5028..L.histidine.degradation.II, CRNFORCAT.PWY..creatinine.degradation.I, PWY.6269..adenosylcobalamin.salvage.from.cobinamide.II, PWY.7389..superpathway.of.anaerobic.energy.metabolism..invertebrates., PWY.7384..anaerobic.energy.metabolism..invertebrates..mitochondrial., PWY.6165..chorismate.biosynthesis.II..archaea., PWY5F9.12..biphenyl.degradation, PWY.5647..2.nitrobenzoate.degradation.I, PWY.6138..CMP.N.acetylneuraminate.biosynthesis.I..eukaryotes., PWY.5910..superpathway.of.geranylgeranyldiphosphate.biosynthesis.I..via.mevalonate., PWY.922..mevalonate.pathway.I, PWY.6435..4.hydroxybenzoate.biosynthesis.V, PWY3O.1109..superpathway.of.4.hydroxybenzoate.biosynthesis..yeast., PWY.5754..4.hydroxybenzoate.biosynthesis.I..eukaryotes., PWY1G.0..mycothiol.biosynthesis, PWY.1501..mandelate.degradation.I, PWY.6107..chlorosalicylate.degradation, PWY.5534..propylene.degradation, PWY.7118..chitin.degradation.to.ethanol, PWY.7290..Escherichia.coli.serotype.O86.O.antigen.biosynthesis, PWY.181..photorespiration, PWY.1622..formaldehyde.assimilation.I..serine.pathway., CODH.PWY..reductive.acetyl.coenzyme.A.pathway, PWY.6349..CDP.archaeol.biosynthesis, PWY.6174..mevalonate.pathway.II..archaea., PWY.7286..7..3.amino.3.carboxypropyl..wyosine.biosynthesis, METHANOGENESIS.PWY..methanogenesis.from.H2.and.CO2, PWY.7391..isoprene.biosynthesis.II..engineered., PWY.5055..nicotinate.degradation.III, PWY.7399..methylphosphonate.degradation.II, P241.PWY..coenzyme.B.biosynthesis, PWY.5178..toluene.degradation.IV..aerobic...via.catechol., PWY.5420..catechol.degradation.II..meta.cleavage.pathway., PWY.5419..catechol.degradation.to.2.oxopent.4.enoate.II\n##  2024-10-06 07:46:42.269695 INFO::Total filtered features with variance filtering: 0\n##  2024-10-06 07:46:42.270211 INFO::Filtered feature names from variance filtering:\n##  2024-10-06 07:46:42.270628 INFO::Running selected normalization method: NONE\n##  2024-10-06 07:46:42.271052 INFO::Applying z-score to standardize continuous metadata\n##  2024-10-06 07:46:42.274454 INFO::Running selected transform method: LOG\n##  2024-10-06 07:46:42.282371 INFO::Running selected analysis method: LM\n##  2024-10-06 07:46:42.282931 INFO::Fitting model to feature number 1, PWY.1042..glycolysis.IV..plant.cytosol.\n##  2024-10-06 07:46:42.285619 INFO::Fitting model to feature number 2, DTDPRHAMSYN.PWY..dTDP.L.rhamnose.biosynthesis.I\n##  2024-10-06 07:46:42.287971 INFO::Fitting model to feature number 3, PWY.5695..urate.biosynthesis.inosine.5..phosphate.degradation\n##  2024-10-06 07:46:42.290309 INFO::Fitting model to feature number 4, PWY.6936..seleno.amino.acid.biosynthesis\n##  2024-10-06 07:46:42.29264 INFO::Fitting model to feature number 5, ILEUSYN.PWY..L.isoleucine.biosynthesis.I..from.threonine.\n##  2024-10-06 07:46:42.295002 INFO::Fitting model to feature number 6, PWY.7111..pyruvate.fermentation.to.isobutanol..engineered.\n##  2024-10-06 07:46:42.297343 INFO::Fitting model to feature number 7, VALSYN.PWY..L.valine.biosynthesis\n##  2024-10-06 07:46:42.29967 INFO::Fitting model to feature number 8, PWY.6609..adenine.and.adenosine.salvage.III\n##  2024-10-06 07:46:42.302016 INFO::Fitting model to feature number 9, PWY.6737..starch.degradation.V\n##  2024-10-06 07:46:42.30437 INFO::Fitting model to feature number 10, PWY.7219..adenosine.ribonucleotides.de.novo.biosynthesis\n##  2024-10-06 07:46:42.306705 INFO::Fitting model to feature number 11, PWY0.1586..peptidoglycan.maturation..meso.diaminopimelate.containing.\n##  2024-10-06 07:46:42.309053 INFO::Fitting model to feature number 12, ASPASN.PWY..superpathway.of.L.aspartate.and.L.asparagine.biosynthesis\n##  2024-10-06 07:46:42.311364 INFO::Fitting model to feature number 13, PWY.5973..cis.vaccenate.biosynthesis\n##  2024-10-06 07:46:42.313679 INFO::Fitting model to feature number 14, PWY.7221..guanosine.ribonucleotides.de.novo.biosynthesis\n##  2024-10-06 07:46:42.31601 INFO::Fitting model to feature number 15, PWY.5686..UMP.biosynthesis\n##  2024-10-06 07:46:42.318312 INFO::Fitting model to feature number 16, X1CMET2.PWY..N10.formyl.tetrahydrofolate.biosynthesis\n##  2024-10-06 07:46:42.320629 INFO::Fitting model to feature number 17, PWY.6122..5.aminoimidazole.ribonucleotide.biosynthesis.II\n##  2024-10-06 07:46:42.322986 INFO::Fitting model to feature number 18, PWY.6277..superpathway.of.5.aminoimidazole.ribonucleotide.biosynthesis\n##  2024-10-06 07:46:42.325319 INFO::Fitting model to feature number 19, PWY.6385..peptidoglycan.biosynthesis.III..mycobacteria.\n##  2024-10-06 07:46:42.327653 INFO::Fitting model to feature number 20, PWY.3841..folate.transformations.II\n##  2024-10-06 07:46:42.329997 INFO::Fitting model to feature number 21, RIBOSYN2.PWY..flavin.biosynthesis.I..bacteria.and.plants.\n##  2024-10-06 07:46:42.332382 INFO::Fitting model to feature number 22, PWY.6387..UDP.N.acetylmuramoyl.pentapeptide.biosynthesis.I..meso.diaminopimelate.containing.\n##  2024-10-06 07:46:42.334748 INFO::Fitting model to feature number 23, THISYNARA.PWY..superpathway.of.thiamin.diphosphate.biosynthesis.III..eukaryotes.\n##  2024-10-06 07:46:42.337083 INFO::Fitting model to feature number 24, PWY.7663..gondoate.biosynthesis..anaerobic.\n##  2024-10-06 07:46:42.339402 INFO::Fitting model to feature number 25, PWY.6386..UDP.N.acetylmuramoyl.pentapeptide.biosynthesis.II..lysine.containing.\n##  2024-10-06 07:46:42.341723 INFO::Fitting model to feature number 26, PWY.6700..queuosine.biosynthesis\n##  2024-10-06 07:46:42.34407 INFO::Fitting model to feature number 27, PEPTIDOGLYCANSYN.PWY..peptidoglycan.biosynthesis.I..meso.diaminopimelate.containing.\n##  2024-10-06 07:46:42.346399 INFO::Fitting model to feature number 28, TRNA.CHARGING.PWY..tRNA.charging\n##  2024-10-06 07:46:42.348708 INFO::Fitting model to feature number 29, PWY.6121..5.aminoimidazole.ribonucleotide.biosynthesis.I\n##  2024-10-06 07:46:42.35104 INFO::Fitting model to feature number 30, HISTSYN.PWY..L.histidine.biosynthesis\n##  2024-10-06 07:46:42.353343 INFO::Fitting model to feature number 31, PWY.7229..superpathway.of.adenosine.nucleotides.de.novo.biosynthesis.I\n##  2024-10-06 07:46:42.355662 INFO::Fitting model to feature number 32, PWY.7199..pyrimidine.deoxyribonucleosides.salvage\n##  2024-10-06 07:46:42.358014 INFO::Fitting model to feature number 33, PANTO.PWY..phosphopantothenate.biosynthesis.I\n##  2024-10-06 07:46:42.360426 INFO::Fitting model to feature number 34, PWY.2942..L.lysine.biosynthesis.III\n##  2024-10-06 07:46:42.362784 INFO::Fitting model to feature number 35, PWY.7237..myo...chiro..and.scillo.inositol.degradation\n##  2024-10-06 07:46:42.365103 INFO::Fitting model to feature number 36, PWY.6168..flavin.biosynthesis.III..fungi.\n##  2024-10-06 07:46:42.367432 INFO::Fitting model to feature number 37, COA.PWY.1..coenzyme.A.biosynthesis.II..mammalian.\n##  2024-10-06 07:46:42.369783 INFO::Fitting model to feature number 38, PWY.5667..CDP.diacylglycerol.biosynthesis.I\n##  2024-10-06 07:46:42.372111 INFO::Fitting model to feature number 39, PWY0.1319..CDP.diacylglycerol.biosynthesis.II\n##  2024-10-06 07:46:42.374416 INFO::Fitting model to feature number 40, PWY.5097..L.lysine.biosynthesis.VI\n##  2024-10-06 07:46:42.376749 INFO::Fitting model to feature number 41, ANAGLYCOLYSIS.PWY..glycolysis.III..from.glucose.\n##  2024-10-06 07:46:42.379158 INFO::Fitting model to feature number 42, PWY.6123..inosine.5..phosphate.biosynthesis.I\n##  2024-10-06 07:46:42.381494 INFO::Fitting model to feature number 43, ARGININE.SYN4.PWY..L.ornithine.de.novo..biosynthesis\n##  2024-10-06 07:46:42.383838 INFO::Fitting model to feature number 44, PWY.6163..chorismate.biosynthesis.from.3.dehydroquinate\n##  2024-10-06 07:46:42.386169 INFO::Fitting model to feature number 45, THRESYN.PWY..superpathway.of.L.threonine.biosynthesis\n##  2024-10-06 07:46:42.388489 INFO::Fitting model to feature number 46, PYRIDNUCSYN.PWY..NAD.biosynthesis.I..from.aspartate.\n##  2024-10-06 07:46:42.390832 INFO::Fitting model to feature number 47, PWY.6124..inosine.5..phosphate.biosynthesis.II\n##  2024-10-06 07:46:42.393194 INFO::Fitting model to feature number 48, PWY.6147..6.hydroxymethyl.dihydropterin.diphosphate.biosynthesis.I\n##  2024-10-06 07:46:42.395528 INFO::Fitting model to feature number 49, PWY.7539..6.hydroxymethyl.dihydropterin.diphosphate.biosynthesis.III..Chlamydia.\n##  2024-10-06 07:46:42.397882 INFO::Fitting model to feature number 50, PWY.6151..S.adenosyl.L.methionine.cycle.I\n##  2024-10-06 07:46:42.400192 INFO::Fitting model to feature number 51, SER.GLYSYN.PWY..superpathway.of.L.serine.and.glycine.biosynthesis.I\n##  2024-10-06 07:46:42.402488 INFO::Fitting model to feature number 52, PWY.6126..superpathway.of.adenosine.nucleotides.de.novo.biosynthesis.II\n##  2024-10-06 07:46:42.404824 INFO::Fitting model to feature number 53, PANTOSYN.PWY..pantothenate.and.coenzyme.A.biosynthesis.I\n##  2024-10-06 07:46:42.407177 INFO::Fitting model to feature number 54, PWY.7228..superpathway.of.guanosine.nucleotides.de.novo.biosynthesis.I\n##  2024-10-06 07:46:42.409483 INFO::Fitting model to feature number 55, COA.PWY..coenzyme.A.biosynthesis.I\n##  2024-10-06 07:46:42.411809 INFO::Fitting model to feature number 56, PWY.4242..pantothenate.and.coenzyme.A.biosynthesis.III\n##  2024-10-06 07:46:42.414115 INFO::Fitting model to feature number 57, PWY.6703..preQ0.biosynthesis\n##  2024-10-06 07:46:42.416427 INFO::Fitting model to feature number 58, THISYN.PWY..superpathway.of.thiamin.diphosphate.biosynthesis.I\n##  2024-10-06 07:46:42.41877 INFO::Fitting model to feature number 59, HISDEG.PWY..L.histidine.degradation.I\n##  2024-10-06 07:46:42.421095 INFO::Fitting model to feature number 60, PWY.5659..GDP.mannose.biosynthesis\n##  2024-10-06 07:46:42.423403 INFO::Fitting model to feature number 61, PWY.5030..L.histidine.degradation.III\n##  2024-10-06 07:46:42.425788 INFO::Fitting model to feature number 62, PWY.5484..glycolysis.II..from.fructose.6.phosphate.\n##  2024-10-06 07:46:42.428148 INFO::Fitting model to feature number 63, PWY.3001..superpathway.of.L.isoleucine.biosynthesis.I\n##  2024-10-06 07:46:42.430451 INFO::Fitting model to feature number 64, PWY.6125..superpathway.of.guanosine.nucleotides.de.novo.biosynthesis.II\n##  2024-10-06 07:46:42.432791 INFO::Fitting model to feature number 65, TRPSYN.PWY..L.tryptophan.biosynthesis\n##  2024-10-06 07:46:42.435104 INFO::Fitting model to feature number 66, GLYCOLYSIS..glycolysis.I..from.glucose.6.phosphate.\n##  2024-10-06 07:46:42.43741 INFO::Fitting model to feature number 67, PWY.724..superpathway.of.L.lysine..L.threonine.and.L.methionine.biosynthesis.II\n##  2024-10-06 07:46:42.439707 INFO::Fitting model to feature number 68, PWY.6897..thiamin.salvage.II\n##  2024-10-06 07:46:42.442028 INFO::Fitting model to feature number 69, BRANCHED.CHAIN.AA.SYN.PWY..superpathway.of.branched.amino.acid.biosynthesis\n##  2024-10-06 07:46:42.444324 INFO::Fitting model to feature number 70, CALVIN.PWY..Calvin.Benson.Bassham.cycle\n##  2024-10-06 07:46:42.446652 INFO::Fitting model to feature number 71, PWY.841..superpathway.of.purine.nucleotides.de.novo.biosynthesis.I\n##  2024-10-06 07:46:42.44898 INFO::Fitting model to feature number 72, COMPLETE.ARO.PWY..superpathway.of.aromatic.amino.acid.biosynthesis\n##  2024-10-06 07:46:42.451308 INFO::Fitting model to feature number 73, PWY.7220..adenosine.deoxyribonucleotides.de.novo.biosynthesis.II\n##  2024-10-06 07:46:42.453683 INFO::Fitting model to feature number 74, PWY.7222..guanosine.deoxyribonucleotides.de.novo.biosynthesis.II\n##  2024-10-06 07:46:42.456048 INFO::Fitting model to feature number 75, DENOVOPURINE2.PWY..superpathway.of.purine.nucleotides.de.novo.biosynthesis.II\n##  2024-10-06 07:46:42.458339 INFO::Fitting model to feature number 76, PWY.7357..thiamin.formation.from.pyrithiamine.and.oxythiamine..yeast.\n##  2024-10-06 07:46:42.460639 INFO::Fitting model to feature number 77, PWY.5103..L.isoleucine.biosynthesis.III\n##  2024-10-06 07:46:42.462985 INFO::Fitting model to feature number 78, ARO.PWY..chorismate.biosynthesis.I\n##  2024-10-06 07:46:42.465283 INFO::Fitting model to feature number 79, PWY.7282..4.amino.2.methyl.5.phosphomethylpyrimidine.biosynthesis..yeast.\n##  2024-10-06 07:46:42.467607 INFO::Fitting model to feature number 80, PWY0.845..superpathway.of.pyridoxal.5..phosphate.biosynthesis.and.salvage\n##  2024-10-06 07:46:42.46991 INFO::Fitting model to feature number 81, ANAEROFRUCAT.PWY..homolactic.fermentation\n##  2024-10-06 07:46:42.472205 INFO::Fitting model to feature number 82, PWY.6892..thiazole.biosynthesis.I..E..coli.\n##  2024-10-06 07:46:42.47451 INFO::Fitting model to feature number 83, RHAMCAT.PWY..L.rhamnose.degradation.I\n##  2024-10-06 07:46:42.476843 INFO::Fitting model to feature number 84, PYRIDOXSYN.PWY..pyridoxal.5..phosphate.biosynthesis.I\n##  2024-10-06 07:46:42.479162 INFO::Fitting model to feature number 85, PWY.1269..CMP.3.deoxy.D.manno.octulosonate.biosynthesis.I\n##  2024-10-06 07:46:42.481456 INFO::Fitting model to feature number 86, PHOSLIPSYN.PWY..superpathway.of.phospholipid.biosynthesis.I..bacteria.\n##  2024-10-06 07:46:42.483774 INFO::Fitting model to feature number 87, CITRULBIO.PWY..L.citrulline.biosynthesis\n##  2024-10-06 07:46:42.486137 INFO::Fitting model to feature number 88, NAGLIPASYN.PWY..lipid.IVA.biosynthesis\n##  2024-10-06 07:46:42.488425 INFO::Fitting model to feature number 89, BIOTIN.BIOSYNTHESIS.PWY..biotin.biosynthesis.I\n##  2024-10-06 07:46:42.490741 INFO::Fitting model to feature number 90, PWY.5154..L.arginine.biosynthesis.III..via.N.acetyl.L.citrulline.\n##  2024-10-06 07:46:42.49306 INFO::Fitting model to feature number 91, FASYN.ELONG.PWY..fatty.acid.elongation....saturated\n##  2024-10-06 07:46:42.495378 INFO::Fitting model to feature number 92, PENTOSE.P.PWY..pentose.phosphate.pathway\n##  2024-10-06 07:46:42.497688 INFO::Fitting model to feature number 93, PWYG.321..mycolate.biosynthesis\n##  2024-10-06 07:46:42.500019 INFO::Fitting model to feature number 94, PWY.6519..8.amino.7.oxononanoate.biosynthesis.I\n##  2024-10-06 07:46:42.502331 INFO::Fitting model to feature number 95, PWY.7664..oleate.biosynthesis.IV..anaerobic.\n##  2024-10-06 07:46:42.504631 INFO::Fitting model to feature number 96, PWY.4981..L.proline.biosynthesis.II..from.arginine.\n##  2024-10-06 07:46:42.507006 INFO::Fitting model to feature number 97, GLYCOGENSYNTH.PWY..glycogen.biosynthesis.I..from.ADP.D.Glucose.\n##  2024-10-06 07:46:42.509375 INFO::Fitting model to feature number 98, PWY.7388..octanoyl..acyl.carrier.protein..biosynthesis..mitochondria..yeast.\n##  2024-10-06 07:46:42.511706 INFO::Fitting model to feature number 99, NONOXIPENT.PWY..pentose.phosphate.pathway..non.oxidative.branch.\n##  2024-10-06 07:46:42.514037 INFO::Fitting model to feature number 100, COBALSYN.PWY..adenosylcobalamin.salvage.from.cobinamide.I\n##  2024-10-06 07:46:42.516433 INFO::Fitting model to feature number 101, PWY.5989..stearate.biosynthesis.II..bacteria.and.plants.\n##  2024-10-06 07:46:42.518782 INFO::Fitting model to feature number 102, PWY.6282..palmitoleate.biosynthesis.I..from..5Z..dodec.5.enoate.\n##  2024-10-06 07:46:42.521163 INFO::Fitting model to feature number 103, PWY0.862...5Z..dodec.5.enoate.biosynthesis\n##  2024-10-06 07:46:42.52348 INFO::Fitting model to feature number 104, PWY.7400..L.arginine.biosynthesis.IV..archaebacteria.\n##  2024-10-06 07:46:42.525807 INFO::Fitting model to feature number 105, ARGSYN.PWY..L.arginine.biosynthesis.I..via.L.ornithine.\n##  2024-10-06 07:46:42.528115 INFO::Fitting model to feature number 106, PWY.4984..urea.cycle\n##  2024-10-06 07:46:42.530421 INFO::Fitting model to feature number 107, FASYN.INITIAL.PWY..superpathway.of.fatty.acid.biosynthesis.initiation..E..coli.\n##  2024-10-06 07:46:42.532766 INFO::Fitting model to feature number 108, PWY4FS.7..phosphatidylglycerol.biosynthesis.I..plastidic.\n##  2024-10-06 07:46:42.535088 INFO::Fitting model to feature number 109, PWY4FS.8..phosphatidylglycerol.biosynthesis.II..non.plastidic.\n##  2024-10-06 07:46:42.53741 INFO::Fitting model to feature number 110, ARGSYNBSUB.PWY..L.arginine.biosynthesis.II..acetyl.cycle.\n##  2024-10-06 07:46:42.539845 INFO::Fitting model to feature number 111, PWY.6317..galactose.degradation.I..Leloir.pathway.\n##  2024-10-06 07:46:42.542188 INFO::Fitting model to feature number 112, PWY66.422..D.galactose.degradation.V..Leloir.pathway.\n##  2024-10-06 07:46:42.544511 INFO::Fitting model to feature number 113, GLUTORN.PWY..L.ornithine.biosynthesis\n##  2024-10-06 07:46:42.546862 INFO::Fitting model to feature number 114, PWY.2941..L.lysine.biosynthesis.II\n##  2024-10-06 07:46:42.549209 INFO::Fitting model to feature number 115, PWY0.1296..purine.ribonucleosides.degradation\n##  2024-10-06 07:46:42.551533 INFO::Fitting model to feature number 116, NAD.BIOSYNTHESIS.II..NAD.salvage.pathway.II\n##  2024-10-06 07:46:42.553898 INFO::Fitting model to feature number 117, HSERMETANA.PWY..L.methionine.biosynthesis.III\n##  2024-10-06 07:46:42.556238 INFO::Fitting model to feature number 118, PWY0.162..superpathway.of.pyrimidine.ribonucleotides.de.novo.biosynthesis\n##  2024-10-06 07:46:42.558557 INFO::Fitting model to feature number 119, PWY.7208..superpathway.of.pyrimidine.nucleobases.salvage\n##  2024-10-06 07:46:42.560888 INFO::Fitting model to feature number 120, TEICHOICACID.PWY..teichoic.acid..poly.glycerol..biosynthesis\n##  2024-10-06 07:46:42.563186 INFO::Fitting model to feature number 121, PWY.6305..putrescine.biosynthesis.IV\n##  2024-10-06 07:46:42.565514 INFO::Fitting model to feature number 122, GLUCONEO.PWY..gluconeogenesis.I\n##  2024-10-06 07:46:42.567833 INFO::Fitting model to feature number 123, PWY.621..sucrose.degradation.III..sucrose.invertase.\n##  2024-10-06 07:46:42.570132 INFO::Fitting model to feature number 124, PWY.6901..superpathway.of.glucose.and.xylose.degradation\n##  2024-10-06 07:46:42.572442 INFO::Fitting model to feature number 125, POLYISOPRENSYN.PWY..polyisoprenoid.biosynthesis..E..coli.\n##  2024-10-06 07:46:42.574772 INFO::Fitting model to feature number 126, PWY.7323..superpathway.of.GDP.mannose.derived.O.antigen.building.blocks.biosynthesis\n##  2024-10-06 07:46:42.577127 INFO::Fitting model to feature number 127, PWY.5941..glycogen.degradation.II..eukaryotic.\n##  2024-10-06 07:46:42.579435 INFO::Fitting model to feature number 128, PWY.6527..stachyose.degradation\n##  2024-10-06 07:46:42.581746 INFO::Fitting model to feature number 129, PWY0.1261..anhydromuropeptides.recycling\n##  2024-10-06 07:46:42.58405 INFO::Fitting model to feature number 130, PWY66.400..glycolysis.VI..metazoan.\n##  2024-10-06 07:46:42.586346 INFO::Fitting model to feature number 131, PWY0.166..superpathway.of.pyrimidine.deoxyribonucleotides.de.novo.biosynthesis..E..coli.\n##  2024-10-06 07:46:42.588651 INFO::Fitting model to feature number 132, GLYCOLYSIS.E.D..superpathway.of.glycolysis.and.Entner.Doudoroff\n##  2024-10-06 07:46:42.590965 INFO::Fitting model to feature number 133, PWY.7187..pyrimidine.deoxyribonucleotides.de.novo.biosynthesis.II\n##  2024-10-06 07:46:42.593269 INFO::Fitting model to feature number 134, PWY.7456..mannan.degradation\n##  2024-10-06 07:46:42.595579 INFO::Fitting model to feature number 135, PWY.7184..pyrimidine.deoxyribonucleotides.de.novo.biosynthesis.I\n##  2024-10-06 07:46:42.597888 INFO::Fitting model to feature number 136, OANTIGEN.PWY..O.antigen.building.blocks.biosynthesis..E..coli.\n##  2024-10-06 07:46:42.600172 INFO::Fitting model to feature number 137, COLANSYN.PWY..colanic.acid.building.blocks.biosynthesis\n##  2024-10-06 07:46:42.602481 INFO::Fitting model to feature number 138, PWY.6545..pyrimidine.deoxyribonucleotides.de.novo.biosynthesis.III\n##  2024-10-06 07:46:42.604863 INFO::Fitting model to feature number 139, PWY.6895..superpathway.of.thiamin.diphosphate.biosynthesis.II\n##  2024-10-06 07:46:42.607189 INFO::Fitting model to feature number 140, PWY.6608..guanosine.nucleotides.degradation.III\n##  2024-10-06 07:46:42.609545 INFO::Fitting model to feature number 141, TCA..TCA.cycle.I..prokaryotic.\n##  2024-10-06 07:46:42.611908 INFO::Fitting model to feature number 142, PWY.6859..all.trans.farnesol.biosynthesis\n##  2024-10-06 07:46:42.614241 INFO::Fitting model to feature number 143, PWY.5100..pyruvate.fermentation.to.acetate.and.lactate.II\n##  2024-10-06 07:46:42.616577 INFO::Fitting model to feature number 144, PWY.6572..chondroitin.sulfate.degradation.I..bacterial.\n##  2024-10-06 07:46:42.618902 INFO::Fitting model to feature number 145, PWY.6471..peptidoglycan.biosynthesis.IV..Enterococcus.faecium.\n##  2024-10-06 07:46:42.621326 INFO::Fitting model to feature number 146, PWY.6470..peptidoglycan.biosynthesis.V...beta..lactam.resistance.\n##  2024-10-06 07:46:42.623672 INFO::Fitting model to feature number 147, PWY.5188..tetrapyrrole.biosynthesis.I..from.glutamate.\n##  2024-10-06 07:46:42.626074 INFO::Fitting model to feature number 148, GLUCUROCAT.PWY..superpathway.of..beta..D.glucuronide.and.D.glucuronate.degradation\n##  2024-10-06 07:46:42.628451 INFO::Fitting model to feature number 149, PWY.6749..CMP.legionaminate.biosynthesis.I\n##  2024-10-06 07:46:42.630837 INFO::Fitting model to feature number 150, P164.PWY..purine.nucleobases.degradation.I..anaerobic.\n##  2024-10-06 07:46:42.633178 INFO::Fitting model to feature number 151, PWY.7198..pyrimidine.deoxyribonucleotides.de.novo.biosynthesis.IV\n##  2024-10-06 07:46:42.635495 INFO::Fitting model to feature number 152, PWY.7211..superpathway.of.pyrimidine.deoxyribonucleotides.de.novo.biosynthesis\n##  2024-10-06 07:46:42.637868 INFO::Fitting model to feature number 153, PWY66.409..superpathway.of.purine.nucleotide.salvage\n##  2024-10-06 07:46:42.640253 INFO::Fitting model to feature number 154, GALACT.GLUCUROCAT.PWY..superpathway.of.hexuronide.and.hexuronate.degradation\n##  2024-10-06 07:46:42.642665 INFO::Fitting model to feature number 155, UDPNAGSYN.PWY..UDP.N.acetyl.D.glucosamine.biosynthesis.I\n##  2024-10-06 07:46:42.645352 INFO::Fitting model to feature number 156, PWY.6353..purine.nucleotides.degradation.II..aerobic.\n##  2024-10-06 07:46:42.647796 INFO::Fitting model to feature number 157, PWY.7197..pyrimidine.deoxyribonucleotide.phosphorylation\n##  2024-10-06 07:46:42.650136 INFO::Fitting model to feature number 158, PWY.7242..D.fructuronate.degradation\n##  2024-10-06 07:46:42.652453 INFO::Fitting model to feature number 159, PWY.7196..superpathway.of.pyrimidine.ribonucleosides.salvage\n##  2024-10-06 07:46:42.654798 INFO::Fitting model to feature number 160, PWY.5690..TCA.cycle.II..plants.and.fungi.\n##  2024-10-06 07:46:42.657118 INFO::Fitting model to feature number 161, PWY.5177..glutaryl.CoA.degradation\n##  2024-10-06 07:46:42.659419 INFO::Fitting model to feature number 162, PWY.6478..GDP.D.glycero..alpha..D.manno.heptose.biosynthesis\n##  2024-10-06 07:46:42.661701 INFO::Fitting model to feature number 163, HEXITOLDEGSUPER.PWY..superpathway.of.hexitol.degradation..bacteria.\n##  2024-10-06 07:46:42.664025 INFO::Fitting model to feature number 164, GALACTUROCAT.PWY..D.galacturonate.degradation.I\n##  2024-10-06 07:46:42.666361 INFO::Fitting model to feature number 165, PWY.5104..L.isoleucine.biosynthesis.IV\n##  2024-10-06 07:46:42.668689 INFO::Fitting model to feature number 166, PWY.5505..L.glutamate.and.L.glutamine.biosynthesis\n##  2024-10-06 07:46:42.671018 INFO::Fitting model to feature number 167, P441.PWY..superpathway.of.N.acetylneuraminate.degradation\n##  2024-10-06 07:46:42.673343 INFO::Fitting model to feature number 168, PWY.6606..guanosine.nucleotides.degradation.II\n##  2024-10-06 07:46:42.675637 INFO::Fitting model to feature number 169, SALVADEHYPOX.PWY..adenosine.nucleotides.degradation.II\n##  2024-10-06 07:46:42.677983 INFO::Fitting model to feature number 170, PWY.5005..biotin.biosynthesis.II\n##  2024-10-06 07:46:42.680343 INFO::Fitting model to feature number 171, PWY.6549..L.glutamine.biosynthesis.III\n##  2024-10-06 07:46:42.682698 INFO::Fitting model to feature number 172, GLCMANNANAUT.PWY..superpathway.of.N.acetylglucosamine..N.acetylmannosamine.and.N.acetylneuraminate.degradation\n##  2024-10-06 07:46:42.685033 INFO::Fitting model to feature number 173, PWY0.1241..ADP.L.glycero..beta..D.manno.heptose.biosynthesis\n##  2024-10-06 07:46:42.687366 INFO::Fitting model to feature number 174, PWY.6507..4.deoxy.L.threo.hex.4.enopyranuronate.degradation\n##  2024-10-06 07:46:42.6897 INFO::Fitting model to feature number 175, GALACTARDEG.PWY..D.galactarate.degradation.I\n##  2024-10-06 07:46:42.692082 INFO::Fitting model to feature number 176, GLUCARGALACTSUPER.PWY..superpathway.of.D.glucarate.and.D.galactarate.degradation\n##  2024-10-06 07:46:42.694433 INFO::Fitting model to feature number 177, PWY.5676..acetyl.CoA.fermentation.to.butanoate.II\n##  2024-10-06 07:46:42.696871 INFO::Fitting model to feature number 178, PWY.5347..superpathway.of.L.methionine.biosynthesis..transsulfuration.\n##  2024-10-06 07:46:42.699242 INFO::Fitting model to feature number 179, PWY.5138..unsaturated..even.numbered.fatty.acid..beta..oxidation\n##  2024-10-06 07:46:42.701643 INFO::Fitting model to feature number 180, MET.SAM.PWY..superpathway.of.S.adenosyl.L.methionine.biosynthesis\n##  2024-10-06 07:46:42.704069 INFO::Fitting model to feature number 181, PWY66.399..gluconeogenesis.III\n##  2024-10-06 07:46:42.706487 INFO::Fitting model to feature number 182, PWY0.1297..superpathway.of.purine.deoxyribonucleosides.degradation\n##  2024-10-06 07:46:42.708963 INFO::Fitting model to feature number 183, METSYN.PWY..L.homoserine.and.L.methionine.biosynthesis\n##  2024-10-06 07:46:42.711303 INFO::Fitting model to feature number 184, PWY.7332..superpathway.of.UDP.N.acetylglucosamine.derived.O.antigen.building.blocks.biosynthesis\n##  2024-10-06 07:46:42.713654 INFO::Fitting model to feature number 185, PWY.6588..pyruvate.fermentation.to.acetone\n##  2024-10-06 07:46:42.716036 INFO::Fitting model to feature number 186, PWY.6891..thiazole.biosynthesis.II..Bacillus.\n##  2024-10-06 07:46:42.718399 INFO::Fitting model to feature number 187, GLUCARDEG.PWY..D.glucarate.degradation.I\n##  2024-10-06 07:46:42.72076 INFO::Fitting model to feature number 188, METH.ACETATE.PWY..methanogenesis.from.acetate\n##  2024-10-06 07:46:42.723098 INFO::Fitting model to feature number 189, PWY.7013..L.1.2.propanediol.degradation\n##  2024-10-06 07:46:42.725461 INFO::Fitting model to feature number 190, PWY.6590..superpathway.of.Clostridium.acetobutylicum.acidogenic.fermentation\n##  2024-10-06 07:46:42.727819 INFO::Fitting model to feature number 191, FAO.PWY..fatty.acid..beta..oxidation.I\n##  2024-10-06 07:46:42.730153 INFO::Fitting model to feature number 192, PWY.6318..L.phenylalanine.degradation.IV..mammalian..via.side.chain.\n##  2024-10-06 07:46:42.732486 INFO::Fitting model to feature number 193, CENTFERM.PWY..pyruvate.fermentation.to.butanoate\n##  2024-10-06 07:46:42.734844 INFO::Fitting model to feature number 194, GOLPDLCAT.PWY..superpathway.of.glycerol.degradation.to.1.3.propanediol\n##  2024-10-06 07:46:42.737203 INFO::Fitting model to feature number 195, PWY.5136..fatty.acid..beta..oxidation.II..peroxisome.\n##  2024-10-06 07:46:42.739534 INFO::Fitting model to feature number 196, PWY66.391..fatty.acid..beta..oxidation.VI..peroxisome.\n##  2024-10-06 07:46:42.741891 INFO::Fitting model to feature number 197, HOMOSER.METSYN.PWY..L.methionine.biosynthesis.I\n##  2024-10-06 07:46:42.744228 INFO::Fitting model to feature number 198, METHGLYUT.PWY..superpathway.of.methylglyoxal.degradation\n##  2024-10-06 07:46:42.746565 INFO::Fitting model to feature number 199, PWY.7288..fatty.acid..beta..oxidation..peroxisome..yeast.\n##  2024-10-06 07:46:42.749003 INFO::Fitting model to feature number 200, PWY.7383..anaerobic.energy.metabolism..invertebrates..cytosol.\n##  2024-10-06 07:46:42.751356 INFO::Fitting model to feature number 201, P162.PWY..L.glutamate.degradation.V..via.hydroxyglutarate.\n##  2024-10-06 07:46:42.753767 INFO::Fitting model to feature number 202, PWY.4041...gamma..glutamyl.cycle\n##  2024-10-06 07:46:42.756121 INFO::Fitting model to feature number 203, P108.PWY..pyruvate.fermentation.to.propanoate.I\n##  2024-10-06 07:46:42.758487 INFO::Fitting model to feature number 204, PWY.5022..4.aminobutanoate.degradation.V\n##  2024-10-06 07:46:42.760853 INFO::Fitting model to feature number 205, GLUDEG.I.PWY..GABA.shunt\n##  2024-10-06 07:46:42.763207 INFO::Fitting model to feature number 206, PWY.5677..succinate.fermentation.to.butanoate\n##  2024-10-06 07:46:42.765584 INFO::Fitting model to feature number 207, P163.PWY..L.lysine.fermentation.to.acetate.and.butanoate\n##  2024-10-06 07:46:42.767945 INFO::Fitting model to feature number 208, PWY.3781..aerobic.respiration.I..cytochrome.c.\n##  2024-10-06 07:46:42.77029 INFO::Fitting model to feature number 209, PWY.5083..NAD.NADH.phosphorylation.and.dephosphorylation\n##  2024-10-06 07:46:42.772627 INFO::Fitting model to feature number 210, DAPLYSINESYN.PWY..L.lysine.biosynthesis.I\n##  2024-10-06 07:46:42.774986 INFO::Fitting model to feature number 211, P461.PWY..hexitol.fermentation.to.lactate..formate..ethanol.and.acetate\n##  2024-10-06 07:46:42.777332 INFO::Fitting model to feature number 212, PWY.1861..formaldehyde.assimilation.II..RuMP.Cycle.\n##  2024-10-06 07:46:42.779672 INFO::Fitting model to feature number 213, PWY.7312..dTDP.D..beta..fucofuranose.biosynthesis\n##  2024-10-06 07:46:42.78206 INFO::Fitting model to feature number 214, PWY.6630..superpathway.of.L.tyrosine.biosynthesis\n##  2024-10-06 07:46:42.784398 INFO::Fitting model to feature number 215, PWY.6595..superpathway.of.guanosine.nucleotides.degradation..plants.\n##  2024-10-06 07:46:42.786754 INFO::Fitting model to feature number 216, ARG.POLYAMINE.SYN..superpathway.of.arginine.and.polyamine.biosynthesis\n##  2024-10-06 07:46:42.789097 INFO::Fitting model to feature number 217, PWY.7003..glycerol.degradation.to.butanol\n##  2024-10-06 07:46:42.791449 INFO::Fitting model to feature number 218, P185.PWY..formaldehyde.assimilation.III..dihydroxyacetone.cycle.\n##  2024-10-06 07:46:42.793811 INFO::Fitting model to feature number 219, POLYAMSYN.PWY..superpathway.of.polyamine.biosynthesis.I\n##  2024-10-06 07:46:42.796149 INFO::Fitting model to feature number 220, PWY0.1298..superpathway.of.pyrimidine.deoxyribonucleosides.degradation\n##  2024-10-06 07:46:42.798489 INFO::Fitting model to feature number 221, LACTOSECAT.PWY..lactose.and.galactose.degradation.I\n##  2024-10-06 07:46:42.800842 INFO::Fitting model to feature number 222, PWY4LZ.257..superpathway.of.fermentation..Chlamydomonas.reinhardtii.\n##  2024-10-06 07:46:42.803174 INFO::Fitting model to feature number 223, P161.PWY..acetylene.degradation\n##  2024-10-06 07:46:42.805515 INFO::Fitting model to feature number 224, RUMP.PWY..formaldehyde.oxidation.I\n##  2024-10-06 07:46:42.807882 INFO::Fitting model to feature number 225, PPGPPMET.PWY..ppGpp.biosynthesis\n##  2024-10-06 07:46:42.810222 INFO::Fitting model to feature number 226, PWY.5304..superpathway.of.sulfur.oxidation..Acidianus.ambivalens.\n##  2024-10-06 07:46:42.812573 INFO::Fitting model to feature number 227, PWY.6531..mannitol.cycle\n##  2024-10-06 07:46:42.814964 INFO::Fitting model to feature number 228, FUC.RHAMCAT.PWY..superpathway.of.fucose.and.rhamnose.degradation\n##  2024-10-06 07:46:42.817299 INFO::Fitting model to feature number 229, PWY.7315..dTDP.N.acetylthomosamine.biosynthesis\n##  2024-10-06 07:46:42.819622 INFO::Fitting model to feature number 230, FUCCAT.PWY..fucose.degradation\n##  2024-10-06 07:46:42.821984 INFO::Fitting model to feature number 231, PWY.7210..pyrimidine.deoxyribonucleotides.biosynthesis.from.CTP\n##  2024-10-06 07:46:42.824334 INFO::Fitting model to feature number 232, FOLSYN.PWY..superpathway.of.tetrahydrofolate.biosynthesis.and.salvage\n##  2024-10-06 07:46:42.826717 INFO::Fitting model to feature number 233, PWY.6612..superpathway.of.tetrahydrofolate.biosynthesis\n##  2024-10-06 07:46:42.829251 INFO::Fitting model to feature number 234, PWY0.1061..superpathway.of.L.alanine.biosynthesis\n##  2024-10-06 07:46:42.831591 INFO::Fitting model to feature number 235, PWY.5189..tetrapyrrole.biosynthesis.II..from.glycine.\n##  2024-10-06 07:46:42.833956 INFO::Fitting model to feature number 236, PWY.6876..isopropanol.biosynthesis\n##  2024-10-06 07:46:42.836295 INFO::Fitting model to feature number 237, PWY0.781..aspartate.superpathway\n##  2024-10-06 07:46:42.838625 INFO::Fitting model to feature number 238, P4.PWY..superpathway.of.L.lysine..L.threonine.and.L.methionine.biosynthesis.I\n##  2024-10-06 07:46:42.840981 INFO::Fitting model to feature number 239, PWY0.1479..tRNA.processing\n##  2024-10-06 07:46:42.84335 INFO::Fitting model to feature number 240, GLYCOLYSIS.TCA.GLYOX.BYPASS..superpathway.of.glycolysis..pyruvate.dehydrogenase..TCA..and.glyoxylate.bypass\n##  2024-10-06 07:46:42.845691 INFO::Fitting model to feature number 241, PYRIDNUCSAL.PWY..NAD.salvage.pathway.I\n##  2024-10-06 07:46:42.848079 INFO::Fitting model to feature number 242, GLYCOCAT.PWY..glycogen.degradation.I..bacterial.\n##  2024-10-06 07:46:42.850455 INFO::Fitting model to feature number 243, PWY.5723..Rubisco.shunt\n##  2024-10-06 07:46:42.852842 INFO::Fitting model to feature number 244, TCA.GLYOX.BYPASS..superpathway.of.glyoxylate.bypass.and.TCA\n##  2024-10-06 07:46:42.85527 INFO::Fitting model to feature number 245, PWY.7385..1.3.propanediol.biosynthesis..engineered.\n##  2024-10-06 07:46:42.857627 INFO::Fitting model to feature number 246, PWY.7254..TCA.cycle.VII..acetate.producers.\n##  2024-10-06 07:46:42.85998 INFO::Fitting model to feature number 247, GLYOXYLATE.BYPASS..glyoxylate.cycle\n##  2024-10-06 07:46:42.862354 INFO::Fitting model to feature number 248, PWY.6731..starch.degradation.III\n##  2024-10-06 07:46:42.864695 INFO::Fitting model to feature number 249, PWY.7328..superpathway.of.UDP.glucose.derived.O.antigen.building.blocks.biosynthesis\n##  2024-10-06 07:46:42.867049 INFO::Fitting model to feature number 250, POLYAMINSYN3.PWY..superpathway.of.polyamine.biosynthesis.II\n##  2024-10-06 07:46:42.869403 INFO::Fitting model to feature number 251, PWY.2723..trehalose.degradation.V\n##  2024-10-06 07:46:42.871776 INFO::Fitting model to feature number 252, GLUCOSE1PMETAB.PWY..glucose.and.glucose.1.phosphate.degradation\n##  2024-10-06 07:46:42.874112 INFO::Fitting model to feature number 253, PWY.5384..sucrose.degradation.IV..sucrose.phosphorylase.\n##  2024-10-06 07:46:42.876446 INFO::Fitting model to feature number 254, PWY.7046..4.coumarate.degradation..anaerobic.\n##  2024-10-06 07:46:42.878802 INFO::Fitting model to feature number 255, PWY66.389..phytol.degradation\n##  2024-10-06 07:46:42.88123 INFO::Fitting model to feature number 256, PWY.5971..palmitate.biosynthesis.II..bacteria.and.plants.\n##  2024-10-06 07:46:42.883597 INFO::Fitting model to feature number 257, PWY.6629..superpathway.of.L.tryptophan.biosynthesis\n##  2024-10-06 07:46:42.885961 INFO::Fitting model to feature number 258, PWY.5345..superpathway.of.L.methionine.biosynthesis..by.sulfhydrylation.\n##  2024-10-06 07:46:42.88831 INFO::Fitting model to feature number 259, SULFATE.CYS.PWY..superpathway.of.sulfate.assimilation.and.cysteine.biosynthesis\n##  2024-10-06 07:46:42.890649 INFO::Fitting model to feature number 260, PWY.5838..superpathway.of.menaquinol.8.biosynthesis.I\n##  2024-10-06 07:46:42.893013 INFO::Fitting model to feature number 261, PRPP.PWY..superpathway.of.histidine..purine..and.pyrimidine.biosynthesis\n##  2024-10-06 07:46:42.89536 INFO::Fitting model to feature number 262, PWY.5845..superpathway.of.menaquinol.9.biosynthesis\n##  2024-10-06 07:46:42.897687 INFO::Fitting model to feature number 263, PWY.6113..superpathway.of.mycolate.biosynthesis\n##  2024-10-06 07:46:42.900043 INFO::Fitting model to feature number 264, PWY.5897..superpathway.of.menaquinol.11.biosynthesis\n##  2024-10-06 07:46:42.902397 INFO::Fitting model to feature number 265, PWY.5898..superpathway.of.menaquinol.12.biosynthesis\n##  2024-10-06 07:46:42.904801 INFO::Fitting model to feature number 266, PWY.5899..superpathway.of.menaquinol.13.biosynthesis\n##  2024-10-06 07:46:42.907163 INFO::Fitting model to feature number 267, PWY.7117..C4.photosynthetic.carbon.assimilation.cycle..PEPCK.type\n##  2024-10-06 07:46:42.909496 INFO::Fitting model to feature number 268, PWY.6969..TCA.cycle.V..2.oxoglutarate.ferredoxin.oxidoreductase.\n##  2024-10-06 07:46:42.911852 INFO::Fitting model to feature number 269, PWY.6628..superpathway.of.L.phenylalanine.biosynthesis\n##  2024-10-06 07:46:42.914209 INFO::Fitting model to feature number 270, PWY.5861..superpathway.of.demethylmenaquinol.8.biosynthesis\n##  2024-10-06 07:46:42.916544 INFO::Fitting model to feature number 271, PWY.5862..superpathway.of.demethylmenaquinol.9.biosynthesis\n##  2024-10-06 07:46:42.918922 INFO::Fitting model to feature number 272, FERMENTATION.PWY..mixed.acid.fermentation\n##  2024-10-06 07:46:42.921278 INFO::Fitting model to feature number 273, PWY.241..C4.photosynthetic.carbon.assimilation.cycle..NADP.ME.type\n##  2024-10-06 07:46:42.923614 INFO::Fitting model to feature number 274, SO4ASSIM.PWY..sulfate.reduction.I..assimilatory.\n##  2024-10-06 07:46:42.92598 INFO::Fitting model to feature number 275, KETOGLUCONMET.PWY..ketogluconate.metabolism\n##  2024-10-06 07:46:42.92831 INFO::Fitting model to feature number 276, PWY.5840..superpathway.of.menaquinol.7.biosynthesis\n##  2024-10-06 07:46:42.930639 INFO::Fitting model to feature number 277, PWY.5850..superpathway.of.menaquinol.6.biosynthesis.I\n##  2024-10-06 07:46:42.933003 INFO::Fitting model to feature number 278, PWY.5896..superpathway.of.menaquinol.10.biosynthesis\n##  2024-10-06 07:46:42.935349 INFO::Fitting model to feature number 279, P105.PWY..TCA.cycle.IV..2.oxoglutarate.decarboxylase.\n##  2024-10-06 07:46:42.937695 INFO::Fitting model to feature number 280, PWY.5913..TCA.cycle.VI..obligate.autotrophs.\n##  2024-10-06 07:46:42.940055 INFO::Fitting model to feature number 281, PWY.561..superpathway.of.glyoxylate.cycle.and.fatty.acid.degradation\n##  2024-10-06 07:46:42.942405 INFO::Fitting model to feature number 282, PWY.4702..phytate.degradation.I\n##  2024-10-06 07:46:42.944778 INFO::Fitting model to feature number 283, PWY.6803..phosphatidylcholine.acyl.editing\n##  2024-10-06 07:46:42.947145 INFO::Fitting model to feature number 284, PWY.7115..C4.photosynthetic.carbon.assimilation.cycle..NAD.ME.type\n##  2024-10-06 07:46:42.949486 INFO::Fitting model to feature number 285, PWY.5918..superpathay.of.heme.biosynthesis.from.glutamate\n##  2024-10-06 07:46:42.951865 INFO::Fitting model to feature number 286, PWY.7234..inosine.5..phosphate.biosynthesis.III\n##  2024-10-06 07:46:42.954213 INFO::Fitting model to feature number 287, PWY.6285..superpathway.of.fatty.acids.biosynthesis..E..coli.\n##  2024-10-06 07:46:42.956619 INFO::Fitting model to feature number 288, PWY.5860..superpathway.of.demethylmenaquinol.6.biosynthesis.I\n##  2024-10-06 07:46:42.958991 INFO::Fitting model to feature number 289, PWY.5863..superpathway.of.phylloquinol.biosynthesis\n##  2024-10-06 07:46:42.961342 INFO::Fitting model to feature number 290, HEME.BIOSYNTHESIS.II..heme.biosynthesis.I..aerobic.\n##  2024-10-06 07:46:42.963706 INFO::Fitting model to feature number 291, PWY.821..superpathway.of.sulfur.amino.acid.biosynthesis..Saccharomyces.cerevisiae.\n##  2024-10-06 07:46:42.9661 INFO::Fitting model to feature number 292, PWY.5675..nitrate.reduction.V..assimilatory.\n##  2024-10-06 07:46:42.968433 INFO::Fitting model to feature number 293, PWY.5791..1.4.dihydroxy.2.naphthoate.biosynthesis.II..plants.\n##  2024-10-06 07:46:42.970783 INFO::Fitting model to feature number 294, PWY.5837..1.4.dihydroxy.2.naphthoate.biosynthesis.I\n##  2024-10-06 07:46:42.973228 INFO::Fitting model to feature number 295, PWY.5920..superpathway.of.heme.biosynthesis.from.glycine\n##  2024-10-06 07:46:42.975578 INFO::Fitting model to feature number 296, PWY.7204..pyridoxal.5..phosphate.salvage.II..plants.\n##  2024-10-06 07:46:42.977936 INFO::Fitting model to feature number 297, ENTBACSYN.PWY..enterobactin.biosynthesis\n##  2024-10-06 07:46:43.009808 INFO::Fitting model to feature number 298, PWY0.1415..superpathway.of.heme.biosynthesis.from.uroporphyrinogen.III\n##  2024-10-06 07:46:43.013886 INFO::Fitting model to feature number 299, HEMESYN2.PWY..heme.biosynthesis.II..anaerobic.\n##  2024-10-06 07:46:43.016241 INFO::Fitting model to feature number 300, PWY.6284..superpathway.of.unsaturated.fatty.acids.biosynthesis..E..coli.\n##  2024-10-06 07:46:43.018564 INFO::Fitting model to feature number 301, P42.PWY..incomplete.reductive.TCA.cycle\n##  2024-10-06 07:46:43.020897 INFO::Fitting model to feature number 302, PWY.5656..mannosylglycerate.biosynthesis.I\n##  2024-10-06 07:46:43.023201 INFO::Fitting model to feature number 303, PWY.5173..superpathway.of.acetyl.CoA.biosynthesis\n##  2024-10-06 07:46:43.025503 INFO::Fitting model to feature number 304, ECASYN.PWY..enterobacterial.common.antigen.biosynthesis\n##  2024-10-06 07:46:43.027953 INFO::Fitting model to feature number 305, AST.PWY..L.arginine.degradation.II..AST.pathway.\n##  2024-10-06 07:46:43.030286 INFO::Fitting model to feature number 306, PWY3O.355..stearate.biosynthesis.III..fungi.\n##  2024-10-06 07:46:43.032597 INFO::Fitting model to feature number 307, PWY0.42..2.methylcitrate.cycle.I\n##  2024-10-06 07:46:43.034949 INFO::Fitting model to feature number 308, PWY.7094..fatty.acid.salvage\n##  2024-10-06 07:46:43.03726 INFO::Fitting model to feature number 309, PWY.5747..2.methylcitrate.cycle.II\n##  2024-10-06 07:46:43.039568 INFO::Fitting model to feature number 310, PWY.5367..petroselinate.biosynthesis\n##  2024-10-06 07:46:43.041897 INFO::Fitting model to feature number 311, PWY0.1533..methylphosphonate.degradation.I\n##  2024-10-06 07:46:43.0442 INFO::Fitting model to feature number 312, PWY.6823..molybdenum.cofactor.biosynthesis\n##  2024-10-06 07:46:43.046521 INFO::Fitting model to feature number 313, PWY.5705..allantoin.degradation.to.glyoxylate.III\n##  2024-10-06 07:46:43.048872 INFO::Fitting model to feature number 314, LPSSYN.PWY..superpathway.of.lipopolysaccharide.biosynthesis\n##  2024-10-06 07:46:43.051188 INFO::Fitting model to feature number 315, REDCITCYC..TCA.cycle.VIII..helicobacter.\n##  2024-10-06 07:46:43.053543 INFO::Fitting model to feature number 316, GLYCOL.GLYOXDEG.PWY..superpathway.of.glycol.metabolism.and.degradation\n##  2024-10-06 07:46:43.055871 INFO::Fitting model to feature number 317, P122.PWY..heterolactic.fermentation\n##  2024-10-06 07:46:43.058176 INFO::Fitting model to feature number 318, KDO.NAGLIPASYN.PWY..superpathway.of..Kdo.2.lipid.A.biosynthesis\n##  2024-10-06 07:46:43.06048 INFO::Fitting model to feature number 319, PWY.7446..sulfoglycolysis\n##  2024-10-06 07:46:43.062808 INFO::Fitting model to feature number 320, PWY490.3..nitrate.reduction.VI..assimilatory.\n##  2024-10-06 07:46:43.065124 INFO::Fitting model to feature number 321, PWY.7209..superpathway.of.pyrimidine.ribonucleosides.degradation\n##  2024-10-06 07:46:43.06742 INFO::Fitting model to feature number 322, UBISYN.PWY..superpathway.of.ubiquinol.8.biosynthesis..prokaryotic.\n##  2024-10-06 07:46:43.069704 INFO::Fitting model to feature number 323, PWY0.41..allantoin.degradation.IV..anaerobic.\n##  2024-10-06 07:46:43.072036 INFO::Fitting model to feature number 324, PWY.5855..ubiquinol.7.biosynthesis..prokaryotic.\n##  2024-10-06 07:46:43.074341 INFO::Fitting model to feature number 325, PWY.5856..ubiquinol.9.biosynthesis..prokaryotic.\n##  2024-10-06 07:46:43.076648 INFO::Fitting model to feature number 326, PWY.5857..ubiquinol.10.biosynthesis..prokaryotic.\n##  2024-10-06 07:46:43.079003 INFO::Fitting model to feature number 327, PWY.6708..ubiquinol.8.biosynthesis..prokaryotic.\n##  2024-10-06 07:46:43.081328 INFO::Fitting model to feature number 328, PWY.5692..allantoin.degradation.to.glyoxylate.II\n##  2024-10-06 07:46:43.083625 INFO::Fitting model to feature number 329, URDEGR.PWY..superpathway.of.allantoin.degradation.in.plants\n##  2024-10-06 07:46:43.085963 INFO::Fitting model to feature number 330, PWY0.1338..polymyxin.resistance\n##  2024-10-06 07:46:43.088275 INFO::Fitting model to feature number 331, P221.PWY..octane.oxidation\n##  2024-10-06 07:46:43.090576 INFO::Fitting model to feature number 332, THREOCAT.PWY..superpathway.of.L.threonine.metabolism\n##  2024-10-06 07:46:43.0929 INFO::Fitting model to feature number 333, NONMEVIPP.PWY..methylerythritol.phosphate.pathway.I\n##  2024-10-06 07:46:43.095233 INFO::Fitting model to feature number 334, PWY.7560..methylerythritol.phosphate.pathway.II\n##  2024-10-06 07:46:43.097609 INFO::Fitting model to feature number 335, PWY.5121..superpathway.of.geranylgeranyl.diphosphate.biosynthesis.II..via.MEP.\n##  2024-10-06 07:46:43.099941 INFO::Fitting model to feature number 336, PWY.7392..taxadiene.biosynthesis..engineered.\n##  2024-10-06 07:46:43.102255 INFO::Fitting model to feature number 337, PWY.6143..CMP.pseudaminate.biosynthesis\n##  2024-10-06 07:46:43.104562 INFO::Fitting model to feature number 338, PWY.6270..isoprene.biosynthesis.I\n##  2024-10-06 07:46:43.106909 INFO::Fitting model to feature number 339, ALLANTOINDEG.PWY..superpathway.of.allantoin.degradation.in.yeast\n##  2024-10-06 07:46:43.109221 INFO::Fitting model to feature number 340, PWY.6263..superpathway.of.menaquinol.8.biosynthesis.II\n##  2024-10-06 07:46:43.111576 INFO::Fitting model to feature number 341, PWY.7371..1.4.dihydroxy.6.naphthoate.biosynthesis.II\n##  2024-10-06 07:46:43.113903 INFO::Fitting model to feature number 342, ARGORNPROST.PWY..arginine..ornithine.and.proline.interconversion\n##  2024-10-06 07:46:43.116212 INFO::Fitting model to feature number 343, PWY66.398..TCA.cycle.III..animals.\n##  2024-10-06 07:46:43.118514 INFO::Fitting model to feature number 344, PWY.5464..superpathway.of.cytosolic.glycolysis..plants...pyruvate.dehydrogenase.and.TCA.cycle\n##  2024-10-06 07:46:43.120844 INFO::Fitting model to feature number 345, ORNDEG.PWY..superpathway.of.ornithine.degradation\n##  2024-10-06 07:46:43.123151 INFO::Fitting model to feature number 346, P23.PWY..reductive.TCA.cycle.I\n##  2024-10-06 07:46:43.125472 INFO::Fitting model to feature number 347, PWY0.1277..3.phenylpropanoate.and.3..3.hydroxyphenyl.propanoate.degradation\n##  2024-10-06 07:46:43.127789 INFO::Fitting model to feature number 348, ARGDEG.PWY..superpathway.of.L.arginine..putrescine..and.4.aminobutanoate.degradation\n##  2024-10-06 07:46:43.130087 INFO::Fitting model to feature number 349, ORNARGDEG.PWY..superpathway.of.L.arginine.and.L.ornithine.degradation\n##  2024-10-06 07:46:43.132385 INFO::Fitting model to feature number 350, HCAMHPDEG.PWY..3.phenylpropanoate.and.3..3.hydroxyphenyl.propanoate.degradation.to.2.oxopent.4.enoate\n##  2024-10-06 07:46:43.134696 INFO::Fitting model to feature number 351, PWY.6690..cinnamate.and.3.hydroxycinnamate.degradation.to.2.oxopent.4.enoate\n##  2024-10-06 07:46:43.13702 INFO::Fitting model to feature number 352, PROTOCATECHUATE.ORTHO.CLEAVAGE.PWY..protocatechuate.degradation.II..ortho.cleavage.pathway.\n##  2024-10-06 07:46:43.13932 INFO::Fitting model to feature number 353, P124.PWY..Bifidobacterium.shunt\n##  2024-10-06 07:46:43.141618 INFO::Fitting model to feature number 354, PWY.622..starch.biosynthesis\n##  2024-10-06 07:46:43.14406 INFO::Fitting model to feature number 355, PWY.7269..NAD.NADP.NADH.NADPH.mitochondrial.interconversion..yeast.\n##  2024-10-06 07:46:43.146387 INFO::Fitting model to feature number 356, PWY.7316..dTDP.N.acetylviosamine.biosynthesis\n##  2024-10-06 07:46:43.148717 INFO::Fitting model to feature number 357, PWY.7279..aerobic.respiration.II..cytochrome.c...yeast.\n##  2024-10-06 07:46:43.151044 INFO::Fitting model to feature number 358, PWY.6837..fatty.acid.beta.oxidation.V..unsaturated..odd.number..di.isomerase.dependent.\n##  2024-10-06 07:46:43.153362 INFO::Fitting model to feature number 359, X3.HYDROXYPHENYLACETATE.DEGRADATION.PWY..4.hydroxyphenylacetate.degradation\n##  2024-10-06 07:46:43.155681 INFO::Fitting model to feature number 360, PWY.6953..dTDP.3.acetamido.3.6.dideoxy..alpha..D.galactose.biosynthesis\n##  2024-10-06 07:46:43.158008 INFO::Fitting model to feature number 361, PWY.7616..methanol.oxidation.to.carbon.dioxide\n##  2024-10-06 07:46:43.160323 INFO::Fitting model to feature number 362, PWY.5088..L.glutamate.degradation.VIII..to.propanoate.\n##  2024-10-06 07:46:43.162621 INFO::Fitting model to feature number 363, PWY0.881..superpathway.of.fatty.acid.biosynthesis.I..E..coli.\n##  2024-10-06 07:46:43.212576 INFO::Counting total values for each feature\n##  2024-10-06 07:46:43.244164 INFO::Writing filtered data to file output_pwys/features/filtered_data.tsv\n##  2024-10-06 07:46:43.282449 INFO::Writing filtered, normalized data to file output_pwys/features/filtered_data_norm.tsv\n##  2024-10-06 07:46:43.32042 INFO::Writing filtered, normalized, transformed data to file output_pwys/features/filtered_data_norm_transformed.tsv\n##  2024-10-06 07:46:43.369788 INFO::Writing residuals to file output_pwys/fits/residuals.rds\n##  2024-10-06 07:46:43.39328 INFO::Writing fitted values to file output_pwys/fits/fitted.rds\n##  2024-10-06 07:46:43.409461 INFO::Writing all results to file (ordered by increasing q-values): output_pwys/all_results.tsv\n##  2024-10-06 07:46:43.415594 INFO::Writing the significant results (those which are less than or equal to the threshold of 0.250000 ) to file (ordered by increasing q-values): output_pwys/significant_results.tsv\n##  2024-10-06 07:46:43.41637 INFO::Writing heatmap of significant results to file: output_pwys/heatmap.pdf\n##  [1] \"There are no associations to plot!\"\n##  2024-10-06 07:46:43.417337 INFO::Writing association plots (one for each significant association) to output folder: output_pwys\n##  2024-10-06 07:46:43.420581 INFO::Plotting associations from most to least significant, grouped by metadata\n##  2024-10-06 07:46:43.421156 INFO::Plotting data for metadata number 1, antibiotics_current_use\n##  2024-10-06 07:46:43.422237 INFO::Creating boxplot for categorical data, antibiotics_current_use vs POLYAMINSYN3.PWY..superpathway.of.polyamine.biosynthesis.II\n\n##########################\n# Extract the residuals #\n##########################\n\ndatExpr &lt;- as.data.frame(t(fit_data$residuals))\n\n########################\n# Create WGCNA modules #\n########################\n\ngsg = goodSamplesGenes(datExpr, verbose = 3)\n##   Flagging genes and samples with too many missing values...\n##    ..step 1\n##    ..Excluding 6 samples from the calculation due to too many missing genes.\n##    ..step 2\ngsg$allOK\n##  [1] FALSE\n\nif (!gsg$allOK)\n{if (sum(!gsg$goodGenes) &gt; 0)\n  printFlush(paste(\n      \"Removing genes:\",\n      paste(names(datExpr)[!gsg$goodGenes], collapse = \", \")));\n  if (sum(!gsg$goodSamples) &gt; 0)\n    printFlush(paste(\n        \"Removing samples:\",\n        paste(rownames(datExpr)[!gsg$goodSamples], collapse =\", \")))\n  datExpr = datExpr[gsg$goodSamples, gsg$goodGenes]\n}\n##  Removing samples: CSM5MCVB_P, CSM79HNY_P, ESM5GEYY_P, ESM718U9_P, MSM6J2N6_P, MSM9VZLX_P\n\ngsg = goodSamplesGenes(datExpr, verbose = 3)\n##   Flagging genes and samples with too many missing values...\n##    ..step 1\ngsg$allOK # TRUE\n##  [1] TRUE\n\n###################################\n# Choose soft threshold parameter #\n###################################\n\npowers = c(c(1:20), seq(from = 22, to=30, by=2))\nsft = pickSoftThreshold(\n    datExpr, powerVector = powers, verbose = 5, dataIsExpr = TRUE,\n    RsquaredCut = 0.30)\n##  pickSoftThreshold: will use block size 363.\n##   pickSoftThreshold: calculating connectivity for given powers...\n##     ..working on genes 1 through 363 of 363\n##     Power SFT.R.sq   slope truncated.R.sq mean.k. median.k. max.k.\n##  1      1    0.722  1.8100         0.7110  124.00   130.000 162.00\n##  2      2    0.596  0.6920         0.6290   63.10    68.700  95.70\n##  3      3    0.393  0.2300         0.2310   38.40    39.700  69.30\n##  4      4    0.124 -0.0902         0.0162   25.90    24.800  55.00\n##  5      5    0.561 -0.3550         0.5860   18.70    16.300  46.60\n##  6      6    0.673 -0.5190         0.6680   14.20    11.400  40.40\n##  7      7    0.781 -0.6230         0.8100   11.20     8.380  35.60\n##  8      8    0.815 -0.7040         0.8450    9.07     6.520  31.80\n##  9      9    0.861 -0.8180         0.9260    7.54     5.100  28.60\n##  10    10    0.847 -0.8620         0.9070    6.39     4.100  26.00\n##  11    11    0.835 -0.9150         0.9140    5.50     3.430  23.80\n##  12    12    0.847 -0.9540         0.9130    4.80     2.870  21.90\n##  13    13    0.868 -0.9730         0.9370    4.24     2.380  20.20\n##  14    14    0.864 -0.9990         0.9160    3.78     2.060  18.70\n##  15    15    0.890 -1.0300         0.9590    3.40     1.720  17.40\n##  16    16    0.898 -1.0400         0.9670    3.09     1.530  16.20\n##  17    17    0.888 -1.0600         0.9570    2.82     1.370  15.20\n##  18    18    0.877 -1.0600         0.9290    2.59     1.280  14.20\n##  19    19    0.864 -1.0500         0.9170    2.40     1.180  13.30\n##  20    20    0.844 -1.0600         0.8690    2.23     1.100  12.50\n##  21    22    0.854 -1.0700         0.8890    1.95     0.997  11.20\n##  22    24    0.820 -1.0600         0.8720    1.74     0.899   9.98\n##  23    26    0.797 -0.9790         0.8720    1.57     0.793   8.97\n##  24    28    0.829 -0.9390         0.8720    1.43     0.718   8.10\n##  25    30    0.807 -0.9130         0.8140    1.31     0.673   7.35\n\n##############################\n#  One-step module detection #\n##############################\n\npower = sft$powerEstimate\nnet = blockwiseModules(\n    datExpr,\n    power = power,\n    corFnc = \"bicor\",\n    corOptions = list(maxPOutliers = 0.1),\n    networkType =\"unsigned\",\n    maxBlockSize = ncol(datExpr),\n    minModuleSize = 3,\n    TOMType = \"unsigned\",\n    reassignThreshold = 0,\n    mergeCutHeight = 0,\n    verbose = 3)\n##   Calculating module eigengenes block-wise from all genes\n##     Flagging genes and samples with too many missing values...\n##      ..step 1\n##   ..Working on block 1 .\n##      TOM calculation: adjacency..\n##      ..will not use multithreading.\n##       Fraction of slow calculations: 0.000000\n##      ..connectivity..\n##      ..matrix multiplication (system BLAS)..\n##      ..normalization..\n##      ..done.\n##   ....clustering..\n##   ....detecting modules..\n##   ....calculating module eigengenes..\n##   ....checking kME in modules..\n##       ..removing 3 genes from module 1 because their KME is too low.\n##       ..removing 11 genes from module 2 because their KME is too low.\n##       ..removing 2 genes from module 3 because their KME is too low.\n##   ..merging modules that are too close..\n##       mergeCloseModules: Merging modules whose distance is less than 0\n##         Calculating new MEs...\n\n####################\n# How many modules #\n####################\n\nncol(net$MEs)\n##  [1] 4\ntable(net$colors)\n##  \n##       blue     brown      grey turquoise \n##        139        18        16       190\n\n##########################\n# Plot module dendrogram #\n##########################\n\neigenGenes &lt;- net$MEs\nMEDiss = 1-cor(eigenGenes)\nMETree = hclust(as.dist(MEDiss), method = \"average\")\nplot(METree, main = \"Clustering of module eigengenes\", xlab = \"\", sub = \"\")\n\n\n\n\n\n\n\n###########################################\n# Re-calculate modules and find hub genes #\n###########################################\n\nmoduleColors &lt;- net$colors\nMEs0 = moduleEigengenes(datExpr, moduleColors)$eigengenes\nmodules_data = orderMEs(MEs0)\n\n#######################\n# Create mapping file #\n#######################\n\nfeature_by_modules &lt;- as.data.frame(net$colors)\nfeature_by_modules &lt;- rownames_to_column(feature_by_modules)\ncolnames(feature_by_modules) &lt;- c('Feature', 'Module')\nfeatures_mapping &lt;- feature_by_modules\nfeatures_mapping$Module &lt;- paste('ME', features_mapping$Module, sep = '')\n\nWe perform the MSEA as before using the modules from the WGCNA analysis on the pathways.\n\n\n###################\n# Rank DA results #\n###################\n\nresults &lt;- fit_data$results |&gt; filter(metadata=='disease')\nresults$qval &lt;- p.adjust(results$pval, 'BH')\nsum(results$qval &lt; 0.05)\n##  [1] 0\nresults &lt;- results[order(results$qval, decreasing = FALSE),]\n\n###################\n# MSEA Processing #\n##################\n\nmodule_map &lt;- features_mapping\nmod.gs &lt;- tapply(module_map$Module, module_map$Feature, as.character)\nmicrobeSet &lt;- inverseList(mod.gs)\nmicrobeSet\n##  $MEblue\n##    [1] \"ANAEROFRUCAT.PWY..homolactic.fermentation\"                                                       \n##    [2] \"ANAGLYCOLYSIS.PWY..glycolysis.III..from.glucose.\"                                                \n##    [3] \"ARGININE.SYN4.PWY..L.ornithine.de.novo..biosynthesis\"                                            \n##    [4] \"ARGSYN.PWY..L.arginine.biosynthesis.I..via.L.ornithine.\"                                         \n##    [5] \"ARGSYNBSUB.PWY..L.arginine.biosynthesis.II..acetyl.cycle.\"                                       \n##    [6] \"ARO.PWY..chorismate.biosynthesis.I\"                                                              \n##    [7] \"ASPASN.PWY..superpathway.of.L.aspartate.and.L.asparagine.biosynthesis\"                           \n##    [8] \"BRANCHED.CHAIN.AA.SYN.PWY..superpathway.of.branched.amino.acid.biosynthesis\"                     \n##    [9] \"CALVIN.PWY..Calvin.Benson.Bassham.cycle\"                                                         \n##   [10] \"CITRULBIO.PWY..L.citrulline.biosynthesis\"                                                        \n##   [11] \"COA.PWY..coenzyme.A.biosynthesis.I\"                                                              \n##   [12] \"COA.PWY.1..coenzyme.A.biosynthesis.II..mammalian.\"                                               \n##   [13] \"COBALSYN.PWY..adenosylcobalamin.salvage.from.cobinamide.I\"                                       \n##   [14] \"COLANSYN.PWY..colanic.acid.building.blocks.biosynthesis\"                                         \n##   [15] \"COMPLETE.ARO.PWY..superpathway.of.aromatic.amino.acid.biosynthesis\"                              \n##   [16] \"DENOVOPURINE2.PWY..superpathway.of.purine.nucleotides.de.novo.biosynthesis.II\"                   \n##   [17] \"DTDPRHAMSYN.PWY..dTDP.L.rhamnose.biosynthesis.I\"                                                 \n##   [18] \"GALACT.GLUCUROCAT.PWY..superpathway.of.hexuronide.and.hexuronate.degradation\"                    \n##   [19] \"GALACTUROCAT.PWY..D.galacturonate.degradation.I\"                                                 \n##   [20] \"GLUCONEO.PWY..gluconeogenesis.I\"                                                                 \n##   [21] \"GLUCUROCAT.PWY..superpathway.of..beta..D.glucuronide.and.D.glucuronate.degradation\"              \n##   [22] \"GLUTORN.PWY..L.ornithine.biosynthesis\"                                                           \n##   [23] \"GLYCOGENSYNTH.PWY..glycogen.biosynthesis.I..from.ADP.D.Glucose.\"                                 \n##   [24] \"GLYCOLYSIS..glycolysis.I..from.glucose.6.phosphate.\"                                             \n##   [25] \"HISDEG.PWY..L.histidine.degradation.I\"                                                           \n##   [26] \"HISTSYN.PWY..L.histidine.biosynthesis\"                                                           \n##   [27] \"HSERMETANA.PWY..L.methionine.biosynthesis.III\"                                                   \n##   [28] \"ILEUSYN.PWY..L.isoleucine.biosynthesis.I..from.threonine.\"                                       \n##   [29] \"NAGLIPASYN.PWY..lipid.IVA.biosynthesis\"                                                          \n##   [30] \"NONOXIPENT.PWY..pentose.phosphate.pathway..non.oxidative.branch.\"                                \n##   [31] \"OANTIGEN.PWY..O.antigen.building.blocks.biosynthesis..E..coli.\"                                  \n##   [32] \"P108.PWY..pyruvate.fermentation.to.propanoate.I\"                                                 \n##   [33] \"PANTO.PWY..phosphopantothenate.biosynthesis.I\"                                                   \n##   [34] \"PANTOSYN.PWY..pantothenate.and.coenzyme.A.biosynthesis.I\"                                        \n##   [35] \"PENTOSE.P.PWY..pentose.phosphate.pathway\"                                                        \n##   [36] \"PEPTIDOGLYCANSYN.PWY..peptidoglycan.biosynthesis.I..meso.diaminopimelate.containing.\"            \n##   [37] \"PHOSLIPSYN.PWY..superpathway.of.phospholipid.biosynthesis.I..bacteria.\"                          \n##   [38] \"POLYISOPRENSYN.PWY..polyisoprenoid.biosynthesis..E..coli.\"                                       \n##   [39] \"PWY.1042..glycolysis.IV..plant.cytosol.\"                                                         \n##   [40] \"PWY.1269..CMP.3.deoxy.D.manno.octulosonate.biosynthesis.I\"                                       \n##   [41] \"PWY.2941..L.lysine.biosynthesis.II\"                                                              \n##   [42] \"PWY.2942..L.lysine.biosynthesis.III\"                                                             \n##   [43] \"PWY.3001..superpathway.of.L.isoleucine.biosynthesis.I\"                                           \n##   [44] \"PWY.3841..folate.transformations.II\"                                                             \n##   [45] \"PWY.4242..pantothenate.and.coenzyme.A.biosynthesis.III\"                                          \n##   [46] \"PWY.4981..L.proline.biosynthesis.II..from.arginine.\"                                             \n##   [47] \"PWY.4984..urea.cycle\"                                                                            \n##   [48] \"PWY.5030..L.histidine.degradation.III\"                                                           \n##   [49] \"PWY.5097..L.lysine.biosynthesis.VI\"                                                              \n##   [50] \"PWY.5103..L.isoleucine.biosynthesis.III\"                                                         \n##   [51] \"PWY.5154..L.arginine.biosynthesis.III..via.N.acetyl.L.citrulline.\"                               \n##   [52] \"PWY.5304..superpathway.of.sulfur.oxidation..Acidianus.ambivalens.\"                               \n##   [53] \"PWY.5484..glycolysis.II..from.fructose.6.phosphate.\"                                             \n##   [54] \"PWY.5505..L.glutamate.and.L.glutamine.biosynthesis\"                                              \n##   [55] \"PWY.5659..GDP.mannose.biosynthesis\"                                                              \n##   [56] \"PWY.5667..CDP.diacylglycerol.biosynthesis.I\"                                                     \n##   [57] \"PWY.5686..UMP.biosynthesis\"                                                                      \n##   [58] \"PWY.5695..urate.biosynthesis.inosine.5..phosphate.degradation\"                                   \n##   [59] \"PWY.5941..glycogen.degradation.II..eukaryotic.\"                                                  \n##   [60] \"PWY.5973..cis.vaccenate.biosynthesis\"                                                            \n##   [61] \"PWY.6121..5.aminoimidazole.ribonucleotide.biosynthesis.I\"                                        \n##   [62] \"PWY.6122..5.aminoimidazole.ribonucleotide.biosynthesis.II\"                                       \n##   [63] \"PWY.6123..inosine.5..phosphate.biosynthesis.I\"                                                   \n##   [64] \"PWY.6124..inosine.5..phosphate.biosynthesis.II\"                                                  \n##   [65] \"PWY.6125..superpathway.of.guanosine.nucleotides.de.novo.biosynthesis.II\"                         \n##   [66] \"PWY.6126..superpathway.of.adenosine.nucleotides.de.novo.biosynthesis.II\"                         \n##   [67] \"PWY.6147..6.hydroxymethyl.dihydropterin.diphosphate.biosynthesis.I\"                              \n##   [68] \"PWY.6151..S.adenosyl.L.methionine.cycle.I\"                                                       \n##   [69] \"PWY.6163..chorismate.biosynthesis.from.3.dehydroquinate\"                                         \n##   [70] \"PWY.6168..flavin.biosynthesis.III..fungi.\"                                                       \n##   [71] \"PWY.621..sucrose.degradation.III..sucrose.invertase.\"                                            \n##   [72] \"PWY.6277..superpathway.of.5.aminoimidazole.ribonucleotide.biosynthesis\"                          \n##   [73] \"PWY.6305..putrescine.biosynthesis.IV\"                                                            \n##   [74] \"PWY.6317..galactose.degradation.I..Leloir.pathway.\"                                              \n##   [75] \"PWY.6385..peptidoglycan.biosynthesis.III..mycobacteria.\"                                         \n##   [76] \"PWY.6386..UDP.N.acetylmuramoyl.pentapeptide.biosynthesis.II..lysine.containing.\"                 \n##   [77] \"PWY.6387..UDP.N.acetylmuramoyl.pentapeptide.biosynthesis.I..meso.diaminopimelate.containing.\"    \n##   [78] \"PWY.6507..4.deoxy.L.threo.hex.4.enopyranuronate.degradation\"                                     \n##   [79] \"PWY.6545..pyrimidine.deoxyribonucleotides.de.novo.biosynthesis.III\"                              \n##   [80] \"PWY.6572..chondroitin.sulfate.degradation.I..bacterial.\"                                         \n##   [81] \"PWY.6609..adenine.and.adenosine.salvage.III\"                                                     \n##   [82] \"PWY.6700..queuosine.biosynthesis\"                                                                \n##   [83] \"PWY.6703..preQ0.biosynthesis\"                                                                    \n##   [84] \"PWY.6737..starch.degradation.V\"                                                                  \n##   [85] \"PWY.6859..all.trans.farnesol.biosynthesis\"                                                       \n##   [86] \"PWY.6892..thiazole.biosynthesis.I..E..coli.\"                                                     \n##   [87] \"PWY.6897..thiamin.salvage.II\"                                                                    \n##   [88] \"PWY.6901..superpathway.of.glucose.and.xylose.degradation\"                                        \n##   [89] \"PWY.6936..seleno.amino.acid.biosynthesis\"                                                        \n##   [90] \"PWY.7111..pyruvate.fermentation.to.isobutanol..engineered.\"                                      \n##   [91] \"PWY.7184..pyrimidine.deoxyribonucleotides.de.novo.biosynthesis.I\"                                \n##   [92] \"PWY.7187..pyrimidine.deoxyribonucleotides.de.novo.biosynthesis.II\"                               \n##   [93] \"PWY.7197..pyrimidine.deoxyribonucleotide.phosphorylation\"                                        \n##   [94] \"PWY.7199..pyrimidine.deoxyribonucleosides.salvage\"                                               \n##   [95] \"PWY.7208..superpathway.of.pyrimidine.nucleobases.salvage\"                                        \n##   [96] \"PWY.7210..pyrimidine.deoxyribonucleotides.biosynthesis.from.CTP\"                                 \n##   [97] \"PWY.7211..superpathway.of.pyrimidine.deoxyribonucleotides.de.novo.biosynthesis\"                  \n##   [98] \"PWY.7219..adenosine.ribonucleotides.de.novo.biosynthesis\"                                        \n##   [99] \"PWY.7220..adenosine.deoxyribonucleotides.de.novo.biosynthesis.II\"                                \n##  [100] \"PWY.7221..guanosine.ribonucleotides.de.novo.biosynthesis\"                                        \n##  [101] \"PWY.7222..guanosine.deoxyribonucleotides.de.novo.biosynthesis.II\"                                \n##  [102] \"PWY.7228..superpathway.of.guanosine.nucleotides.de.novo.biosynthesis.I\"                          \n##  [103] \"PWY.7229..superpathway.of.adenosine.nucleotides.de.novo.biosynthesis.I\"                          \n##  [104] \"PWY.7234..inosine.5..phosphate.biosynthesis.III\"                                                 \n##  [105] \"PWY.724..superpathway.of.L.lysine..L.threonine.and.L.methionine.biosynthesis.II\"                 \n##  [106] \"PWY.7242..D.fructuronate.degradation\"                                                            \n##  [107] \"PWY.7282..4.amino.2.methyl.5.phosphomethylpyrimidine.biosynthesis..yeast.\"                       \n##  [108] \"PWY.7323..superpathway.of.GDP.mannose.derived.O.antigen.building.blocks.biosynthesis\"            \n##  [109] \"PWY.7332..superpathway.of.UDP.N.acetylglucosamine.derived.O.antigen.building.blocks.biosynthesis\"\n##  [110] \"PWY.7357..thiamin.formation.from.pyrithiamine.and.oxythiamine..yeast.\"                           \n##  [111] \"PWY.7383..anaerobic.energy.metabolism..invertebrates..cytosol.\"                                  \n##  [112] \"PWY.7400..L.arginine.biosynthesis.IV..archaebacteria.\"                                           \n##  [113] \"PWY.7456..mannan.degradation\"                                                                    \n##  [114] \"PWY.7539..6.hydroxymethyl.dihydropterin.diphosphate.biosynthesis.III..Chlamydia.\"                \n##  [115] \"PWY.7663..gondoate.biosynthesis..anaerobic.\"                                                     \n##  [116] \"PWY.841..superpathway.of.purine.nucleotides.de.novo.biosynthesis.I\"                              \n##  [117] \"PWY0.1296..purine.ribonucleosides.degradation\"                                                   \n##  [118] \"PWY0.1319..CDP.diacylglycerol.biosynthesis.II\"                                                   \n##  [119] \"PWY0.1586..peptidoglycan.maturation..meso.diaminopimelate.containing.\"                           \n##  [120] \"PWY0.162..superpathway.of.pyrimidine.ribonucleotides.de.novo.biosynthesis\"                       \n##  [121] \"PWY0.166..superpathway.of.pyrimidine.deoxyribonucleotides.de.novo.biosynthesis..E..coli.\"        \n##  [122] \"PWY0.845..superpathway.of.pyridoxal.5..phosphate.biosynthesis.and.salvage\"                       \n##  [123] \"PWY4FS.7..phosphatidylglycerol.biosynthesis.I..plastidic.\"                                       \n##  [124] \"PWY4FS.8..phosphatidylglycerol.biosynthesis.II..non.plastidic.\"                                  \n##  [125] \"PWY66.399..gluconeogenesis.III\"                                                                  \n##  [126] \"PWY66.422..D.galactose.degradation.V..Leloir.pathway.\"                                           \n##  [127] \"PYRIDNUCSYN.PWY..NAD.biosynthesis.I..from.aspartate.\"                                            \n##  [128] \"PYRIDOXSYN.PWY..pyridoxal.5..phosphate.biosynthesis.I\"                                           \n##  [129] \"RHAMCAT.PWY..L.rhamnose.degradation.I\"                                                           \n##  [130] \"RIBOSYN2.PWY..flavin.biosynthesis.I..bacteria.and.plants.\"                                       \n##  [131] \"SER.GLYSYN.PWY..superpathway.of.L.serine.and.glycine.biosynthesis.I\"                             \n##  [132] \"TEICHOICACID.PWY..teichoic.acid..poly.glycerol..biosynthesis\"                                    \n##  [133] \"THISYN.PWY..superpathway.of.thiamin.diphosphate.biosynthesis.I\"                                  \n##  [134] \"THISYNARA.PWY..superpathway.of.thiamin.diphosphate.biosynthesis.III..eukaryotes.\"                \n##  [135] \"THRESYN.PWY..superpathway.of.L.threonine.biosynthesis\"                                           \n##  [136] \"TRNA.CHARGING.PWY..tRNA.charging\"                                                                \n##  [137] \"TRPSYN.PWY..L.tryptophan.biosynthesis\"                                                           \n##  [138] \"VALSYN.PWY..L.valine.biosynthesis\"                                                               \n##  [139] \"X1CMET2.PWY..N10.formyl.tetrahydrofolate.biosynthesis\"                                           \n##  \n##  $MEbrown\n##   [1] \"GLCMANNANAUT.PWY..superpathway.of.N.acetylglucosamine..N.acetylmannosamine.and.N.acetylneuraminate.degradation\"\n##   [2] \"GLYCOLYSIS.E.D..superpathway.of.glycolysis.and.Entner.Doudoroff\"                                               \n##   [3] \"METH.ACETATE.PWY..methanogenesis.from.acetate\"                                                                 \n##   [4] \"PWY.5100..pyruvate.fermentation.to.acetate.and.lactate.II\"                                                     \n##   [5] \"PWY.5104..L.isoleucine.biosynthesis.IV\"                                                                        \n##   [6] \"PWY.5177..glutaryl.CoA.degradation\"                                                                            \n##   [7] \"PWY.5690..TCA.cycle.II..plants.and.fungi.\"                                                                     \n##   [8] \"PWY.6470..peptidoglycan.biosynthesis.V...beta..lactam.resistance.\"                                             \n##   [9] \"PWY.6527..stachyose.degradation\"                                                                               \n##  [10] \"PWY.6595..superpathway.of.guanosine.nucleotides.degradation..plants.\"                                          \n##  [11] \"PWY.6608..guanosine.nucleotides.degradation.III\"                                                               \n##  [12] \"PWY.7196..superpathway.of.pyrimidine.ribonucleosides.salvage\"                                                  \n##  [13] \"PWY.7198..pyrimidine.deoxyribonucleotides.de.novo.biosynthesis.IV\"                                             \n##  [14] \"PWY0.1061..superpathway.of.L.alanine.biosynthesis\"                                                             \n##  [15] \"PWY0.1261..anhydromuropeptides.recycling\"                                                                      \n##  [16] \"PWY66.400..glycolysis.VI..metazoan.\"                                                                           \n##  [17] \"TCA..TCA.cycle.I..prokaryotic.\"                                                                                \n##  [18] \"UDPNAGSYN.PWY..UDP.N.acetyl.D.glucosamine.biosynthesis.I\"                                                      \n##  \n##  $MEgrey\n##   [1] \"NAD.BIOSYNTHESIS.II..NAD.salvage.pathway.II\"                            \n##   [2] \"P162.PWY..L.glutamate.degradation.V..via.hydroxyglutarate.\"             \n##   [3] \"P163.PWY..L.lysine.fermentation.to.acetate.and.butanoate\"               \n##   [4] \"PWY.3781..aerobic.respiration.I..cytochrome.c.\"                         \n##   [5] \"PWY.6143..CMP.pseudaminate.biosynthesis\"                                \n##   [6] \"PWY.622..starch.biosynthesis\"                                           \n##   [7] \"PWY.6263..superpathway.of.menaquinol.8.biosynthesis.II\"                 \n##   [8] \"PWY.6478..GDP.D.glycero..alpha..D.manno.heptose.biosynthesis\"           \n##   [9] \"PWY.6749..CMP.legionaminate.biosynthesis.I\"                             \n##  [10] \"PWY.6953..dTDP.3.acetamido.3.6.dideoxy..alpha..D.galactose.biosynthesis\"\n##  [11] \"PWY.7237..myo...chiro..and.scillo.inositol.degradation\"                 \n##  [12] \"PWY.7312..dTDP.D..beta..fucofuranose.biosynthesis\"                      \n##  [13] \"PWY.7316..dTDP.N.acetylviosamine.biosynthesis\"                          \n##  [14] \"PWY.7371..1.4.dihydroxy.6.naphthoate.biosynthesis.II\"                   \n##  [15] \"PWY490.3..nitrate.reduction.VI..assimilatory.\"                          \n##  [16] \"RUMP.PWY..formaldehyde.oxidation.I\"                                     \n##  \n##  $MEturquoise\n##    [1] \"ALLANTOINDEG.PWY..superpathway.of.allantoin.degradation.in.yeast\"                                           \n##    [2] \"ARG.POLYAMINE.SYN..superpathway.of.arginine.and.polyamine.biosynthesis\"                                     \n##    [3] \"ARGDEG.PWY..superpathway.of.L.arginine..putrescine..and.4.aminobutanoate.degradation\"                       \n##    [4] \"ARGORNPROST.PWY..arginine..ornithine.and.proline.interconversion\"                                           \n##    [5] \"AST.PWY..L.arginine.degradation.II..AST.pathway.\"                                                           \n##    [6] \"BIOTIN.BIOSYNTHESIS.PWY..biotin.biosynthesis.I\"                                                             \n##    [7] \"CENTFERM.PWY..pyruvate.fermentation.to.butanoate\"                                                           \n##    [8] \"DAPLYSINESYN.PWY..L.lysine.biosynthesis.I\"                                                                  \n##    [9] \"ECASYN.PWY..enterobacterial.common.antigen.biosynthesis\"                                                    \n##   [10] \"ENTBACSYN.PWY..enterobactin.biosynthesis\"                                                                   \n##   [11] \"FAO.PWY..fatty.acid..beta..oxidation.I\"                                                                     \n##   [12] \"FASYN.ELONG.PWY..fatty.acid.elongation....saturated\"                                                        \n##   [13] \"FASYN.INITIAL.PWY..superpathway.of.fatty.acid.biosynthesis.initiation..E..coli.\"                            \n##   [14] \"FERMENTATION.PWY..mixed.acid.fermentation\"                                                                  \n##   [15] \"FOLSYN.PWY..superpathway.of.tetrahydrofolate.biosynthesis.and.salvage\"                                      \n##   [16] \"FUC.RHAMCAT.PWY..superpathway.of.fucose.and.rhamnose.degradation\"                                           \n##   [17] \"FUCCAT.PWY..fucose.degradation\"                                                                             \n##   [18] \"GALACTARDEG.PWY..D.galactarate.degradation.I\"                                                               \n##   [19] \"GLUCARDEG.PWY..D.glucarate.degradation.I\"                                                                   \n##   [20] \"GLUCARGALACTSUPER.PWY..superpathway.of.D.glucarate.and.D.galactarate.degradation\"                           \n##   [21] \"GLUCOSE1PMETAB.PWY..glucose.and.glucose.1.phosphate.degradation\"                                            \n##   [22] \"GLUDEG.I.PWY..GABA.shunt\"                                                                                   \n##   [23] \"GLYCOCAT.PWY..glycogen.degradation.I..bacterial.\"                                                           \n##   [24] \"GLYCOL.GLYOXDEG.PWY..superpathway.of.glycol.metabolism.and.degradation\"                                     \n##   [25] \"GLYCOLYSIS.TCA.GLYOX.BYPASS..superpathway.of.glycolysis..pyruvate.dehydrogenase..TCA..and.glyoxylate.bypass\"\n##   [26] \"GLYOXYLATE.BYPASS..glyoxylate.cycle\"                                                                        \n##   [27] \"GOLPDLCAT.PWY..superpathway.of.glycerol.degradation.to.1.3.propanediol\"                                     \n##   [28] \"HCAMHPDEG.PWY..3.phenylpropanoate.and.3..3.hydroxyphenyl.propanoate.degradation.to.2.oxopent.4.enoate\"      \n##   [29] \"HEME.BIOSYNTHESIS.II..heme.biosynthesis.I..aerobic.\"                                                        \n##   [30] \"HEMESYN2.PWY..heme.biosynthesis.II..anaerobic.\"                                                             \n##   [31] \"HEXITOLDEGSUPER.PWY..superpathway.of.hexitol.degradation..bacteria.\"                                        \n##   [32] \"HOMOSER.METSYN.PWY..L.methionine.biosynthesis.I\"                                                            \n##   [33] \"KDO.NAGLIPASYN.PWY..superpathway.of..Kdo.2.lipid.A.biosynthesis\"                                            \n##   [34] \"KETOGLUCONMET.PWY..ketogluconate.metabolism\"                                                                \n##   [35] \"LACTOSECAT.PWY..lactose.and.galactose.degradation.I\"                                                        \n##   [36] \"LPSSYN.PWY..superpathway.of.lipopolysaccharide.biosynthesis\"                                                \n##   [37] \"MET.SAM.PWY..superpathway.of.S.adenosyl.L.methionine.biosynthesis\"                                          \n##   [38] \"METHGLYUT.PWY..superpathway.of.methylglyoxal.degradation\"                                                   \n##   [39] \"METSYN.PWY..L.homoserine.and.L.methionine.biosynthesis\"                                                     \n##   [40] \"NONMEVIPP.PWY..methylerythritol.phosphate.pathway.I\"                                                        \n##   [41] \"ORNARGDEG.PWY..superpathway.of.L.arginine.and.L.ornithine.degradation\"                                      \n##   [42] \"ORNDEG.PWY..superpathway.of.ornithine.degradation\"                                                          \n##   [43] \"P105.PWY..TCA.cycle.IV..2.oxoglutarate.decarboxylase.\"                                                      \n##   [44] \"P122.PWY..heterolactic.fermentation\"                                                                        \n##   [45] \"P124.PWY..Bifidobacterium.shunt\"                                                                            \n##   [46] \"P161.PWY..acetylene.degradation\"                                                                            \n##   [47] \"P164.PWY..purine.nucleobases.degradation.I..anaerobic.\"                                                     \n##   [48] \"P185.PWY..formaldehyde.assimilation.III..dihydroxyacetone.cycle.\"                                           \n##   [49] \"P221.PWY..octane.oxidation\"                                                                                 \n##   [50] \"P23.PWY..reductive.TCA.cycle.I\"                                                                             \n##   [51] \"P4.PWY..superpathway.of.L.lysine..L.threonine.and.L.methionine.biosynthesis.I\"                              \n##   [52] \"P42.PWY..incomplete.reductive.TCA.cycle\"                                                                    \n##   [53] \"P441.PWY..superpathway.of.N.acetylneuraminate.degradation\"                                                  \n##   [54] \"P461.PWY..hexitol.fermentation.to.lactate..formate..ethanol.and.acetate\"                                    \n##   [55] \"POLYAMINSYN3.PWY..superpathway.of.polyamine.biosynthesis.II\"                                                \n##   [56] \"POLYAMSYN.PWY..superpathway.of.polyamine.biosynthesis.I\"                                                    \n##   [57] \"PPGPPMET.PWY..ppGpp.biosynthesis\"                                                                           \n##   [58] \"PROTOCATECHUATE.ORTHO.CLEAVAGE.PWY..protocatechuate.degradation.II..ortho.cleavage.pathway.\"                \n##   [59] \"PRPP.PWY..superpathway.of.histidine..purine..and.pyrimidine.biosynthesis\"                                   \n##   [60] \"PWY.1861..formaldehyde.assimilation.II..RuMP.Cycle.\"                                                        \n##   [61] \"PWY.241..C4.photosynthetic.carbon.assimilation.cycle..NADP.ME.type\"                                         \n##   [62] \"PWY.2723..trehalose.degradation.V\"                                                                          \n##   [63] \"PWY.4041...gamma..glutamyl.cycle\"                                                                           \n##   [64] \"PWY.4702..phytate.degradation.I\"                                                                            \n##   [65] \"PWY.5005..biotin.biosynthesis.II\"                                                                           \n##   [66] \"PWY.5022..4.aminobutanoate.degradation.V\"                                                                   \n##   [67] \"PWY.5083..NAD.NADH.phosphorylation.and.dephosphorylation\"                                                   \n##   [68] \"PWY.5088..L.glutamate.degradation.VIII..to.propanoate.\"                                                     \n##   [69] \"PWY.5121..superpathway.of.geranylgeranyl.diphosphate.biosynthesis.II..via.MEP.\"                             \n##   [70] \"PWY.5136..fatty.acid..beta..oxidation.II..peroxisome.\"                                                      \n##   [71] \"PWY.5138..unsaturated..even.numbered.fatty.acid..beta..oxidation\"                                           \n##   [72] \"PWY.5173..superpathway.of.acetyl.CoA.biosynthesis\"                                                          \n##   [73] \"PWY.5188..tetrapyrrole.biosynthesis.I..from.glutamate.\"                                                     \n##   [74] \"PWY.5189..tetrapyrrole.biosynthesis.II..from.glycine.\"                                                      \n##   [75] \"PWY.5345..superpathway.of.L.methionine.biosynthesis..by.sulfhydrylation.\"                                   \n##   [76] \"PWY.5347..superpathway.of.L.methionine.biosynthesis..transsulfuration.\"                                     \n##   [77] \"PWY.5367..petroselinate.biosynthesis\"                                                                       \n##   [78] \"PWY.5384..sucrose.degradation.IV..sucrose.phosphorylase.\"                                                   \n##   [79] \"PWY.5464..superpathway.of.cytosolic.glycolysis..plants...pyruvate.dehydrogenase.and.TCA.cycle\"              \n##   [80] \"PWY.561..superpathway.of.glyoxylate.cycle.and.fatty.acid.degradation\"                                       \n##   [81] \"PWY.5656..mannosylglycerate.biosynthesis.I\"                                                                 \n##   [82] \"PWY.5675..nitrate.reduction.V..assimilatory.\"                                                               \n##   [83] \"PWY.5676..acetyl.CoA.fermentation.to.butanoate.II\"                                                          \n##   [84] \"PWY.5677..succinate.fermentation.to.butanoate\"                                                              \n##   [85] \"PWY.5692..allantoin.degradation.to.glyoxylate.II\"                                                           \n##   [86] \"PWY.5705..allantoin.degradation.to.glyoxylate.III\"                                                          \n##   [87] \"PWY.5723..Rubisco.shunt\"                                                                                    \n##   [88] \"PWY.5747..2.methylcitrate.cycle.II\"                                                                         \n##   [89] \"PWY.5791..1.4.dihydroxy.2.naphthoate.biosynthesis.II..plants.\"                                              \n##   [90] \"PWY.5837..1.4.dihydroxy.2.naphthoate.biosynthesis.I\"                                                        \n##   [91] \"PWY.5838..superpathway.of.menaquinol.8.biosynthesis.I\"                                                      \n##   [92] \"PWY.5840..superpathway.of.menaquinol.7.biosynthesis\"                                                        \n##   [93] \"PWY.5845..superpathway.of.menaquinol.9.biosynthesis\"                                                        \n##   [94] \"PWY.5850..superpathway.of.menaquinol.6.biosynthesis.I\"                                                      \n##   [95] \"PWY.5855..ubiquinol.7.biosynthesis..prokaryotic.\"                                                           \n##   [96] \"PWY.5856..ubiquinol.9.biosynthesis..prokaryotic.\"                                                           \n##   [97] \"PWY.5857..ubiquinol.10.biosynthesis..prokaryotic.\"                                                          \n##   [98] \"PWY.5860..superpathway.of.demethylmenaquinol.6.biosynthesis.I\"                                              \n##   [99] \"PWY.5861..superpathway.of.demethylmenaquinol.8.biosynthesis\"                                                \n##  [100] \"PWY.5862..superpathway.of.demethylmenaquinol.9.biosynthesis\"                                                \n##  [101] \"PWY.5863..superpathway.of.phylloquinol.biosynthesis\"                                                        \n##  [102] \"PWY.5896..superpathway.of.menaquinol.10.biosynthesis\"                                                       \n##  [103] \"PWY.5897..superpathway.of.menaquinol.11.biosynthesis\"                                                       \n##  [104] \"PWY.5898..superpathway.of.menaquinol.12.biosynthesis\"                                                       \n##  [105] \"PWY.5899..superpathway.of.menaquinol.13.biosynthesis\"                                                       \n##  [106] \"PWY.5913..TCA.cycle.VI..obligate.autotrophs.\"                                                               \n##  [107] \"PWY.5918..superpathay.of.heme.biosynthesis.from.glutamate\"                                                  \n##  [108] \"PWY.5920..superpathway.of.heme.biosynthesis.from.glycine\"                                                   \n##  [109] \"PWY.5971..palmitate.biosynthesis.II..bacteria.and.plants.\"                                                  \n##  [110] \"PWY.5989..stearate.biosynthesis.II..bacteria.and.plants.\"                                                   \n##  [111] \"PWY.6113..superpathway.of.mycolate.biosynthesis\"                                                            \n##  [112] \"PWY.6270..isoprene.biosynthesis.I\"                                                                          \n##  [113] \"PWY.6282..palmitoleate.biosynthesis.I..from..5Z..dodec.5.enoate.\"                                           \n##  [114] \"PWY.6284..superpathway.of.unsaturated.fatty.acids.biosynthesis..E..coli.\"                                   \n##  [115] \"PWY.6285..superpathway.of.fatty.acids.biosynthesis..E..coli.\"                                               \n##  [116] \"PWY.6318..L.phenylalanine.degradation.IV..mammalian..via.side.chain.\"                                       \n##  [117] \"PWY.6353..purine.nucleotides.degradation.II..aerobic.\"                                                      \n##  [118] \"PWY.6471..peptidoglycan.biosynthesis.IV..Enterococcus.faecium.\"                                             \n##  [119] \"PWY.6519..8.amino.7.oxononanoate.biosynthesis.I\"                                                            \n##  [120] \"PWY.6531..mannitol.cycle\"                                                                                   \n##  [121] \"PWY.6549..L.glutamine.biosynthesis.III\"                                                                     \n##  [122] \"PWY.6588..pyruvate.fermentation.to.acetone\"                                                                 \n##  [123] \"PWY.6590..superpathway.of.Clostridium.acetobutylicum.acidogenic.fermentation\"                               \n##  [124] \"PWY.6606..guanosine.nucleotides.degradation.II\"                                                             \n##  [125] \"PWY.6612..superpathway.of.tetrahydrofolate.biosynthesis\"                                                    \n##  [126] \"PWY.6628..superpathway.of.L.phenylalanine.biosynthesis\"                                                     \n##  [127] \"PWY.6629..superpathway.of.L.tryptophan.biosynthesis\"                                                        \n##  [128] \"PWY.6630..superpathway.of.L.tyrosine.biosynthesis\"                                                          \n##  [129] \"PWY.6690..cinnamate.and.3.hydroxycinnamate.degradation.to.2.oxopent.4.enoate\"                               \n##  [130] \"PWY.6708..ubiquinol.8.biosynthesis..prokaryotic.\"                                                           \n##  [131] \"PWY.6731..starch.degradation.III\"                                                                           \n##  [132] \"PWY.6803..phosphatidylcholine.acyl.editing\"                                                                 \n##  [133] \"PWY.6823..molybdenum.cofactor.biosynthesis\"                                                                 \n##  [134] \"PWY.6837..fatty.acid.beta.oxidation.V..unsaturated..odd.number..di.isomerase.dependent.\"                    \n##  [135] \"PWY.6876..isopropanol.biosynthesis\"                                                                         \n##  [136] \"PWY.6891..thiazole.biosynthesis.II..Bacillus.\"                                                              \n##  [137] \"PWY.6895..superpathway.of.thiamin.diphosphate.biosynthesis.II\"                                              \n##  [138] \"PWY.6969..TCA.cycle.V..2.oxoglutarate.ferredoxin.oxidoreductase.\"                                           \n##  [139] \"PWY.7003..glycerol.degradation.to.butanol\"                                                                  \n##  [140] \"PWY.7013..L.1.2.propanediol.degradation\"                                                                    \n##  [141] \"PWY.7046..4.coumarate.degradation..anaerobic.\"                                                              \n##  [142] \"PWY.7094..fatty.acid.salvage\"                                                                               \n##  [143] \"PWY.7115..C4.photosynthetic.carbon.assimilation.cycle..NAD.ME.type\"                                         \n##  [144] \"PWY.7117..C4.photosynthetic.carbon.assimilation.cycle..PEPCK.type\"                                          \n##  [145] \"PWY.7204..pyridoxal.5..phosphate.salvage.II..plants.\"                                                       \n##  [146] \"PWY.7209..superpathway.of.pyrimidine.ribonucleosides.degradation\"                                           \n##  [147] \"PWY.7254..TCA.cycle.VII..acetate.producers.\"                                                                \n##  [148] \"PWY.7269..NAD.NADP.NADH.NADPH.mitochondrial.interconversion..yeast.\"                                        \n##  [149] \"PWY.7279..aerobic.respiration.II..cytochrome.c...yeast.\"                                                    \n##  [150] \"PWY.7288..fatty.acid..beta..oxidation..peroxisome..yeast.\"                                                  \n##  [151] \"PWY.7315..dTDP.N.acetylthomosamine.biosynthesis\"                                                            \n##  [152] \"PWY.7328..superpathway.of.UDP.glucose.derived.O.antigen.building.blocks.biosynthesis\"                       \n##  [153] \"PWY.7385..1.3.propanediol.biosynthesis..engineered.\"                                                        \n##  [154] \"PWY.7388..octanoyl..acyl.carrier.protein..biosynthesis..mitochondria..yeast.\"                               \n##  [155] \"PWY.7392..taxadiene.biosynthesis..engineered.\"                                                              \n##  [156] \"PWY.7446..sulfoglycolysis\"                                                                                  \n##  [157] \"PWY.7560..methylerythritol.phosphate.pathway.II\"                                                            \n##  [158] \"PWY.7616..methanol.oxidation.to.carbon.dioxide\"                                                             \n##  [159] \"PWY.7664..oleate.biosynthesis.IV..anaerobic.\"                                                               \n##  [160] \"PWY.821..superpathway.of.sulfur.amino.acid.biosynthesis..Saccharomyces.cerevisiae.\"                         \n##  [161] \"PWY0.1241..ADP.L.glycero..beta..D.manno.heptose.biosynthesis\"                                               \n##  [162] \"PWY0.1277..3.phenylpropanoate.and.3..3.hydroxyphenyl.propanoate.degradation\"                                \n##  [163] \"PWY0.1297..superpathway.of.purine.deoxyribonucleosides.degradation\"                                         \n##  [164] \"PWY0.1298..superpathway.of.pyrimidine.deoxyribonucleosides.degradation\"                                     \n##  [165] \"PWY0.1338..polymyxin.resistance\"                                                                            \n##  [166] \"PWY0.1415..superpathway.of.heme.biosynthesis.from.uroporphyrinogen.III\"                                     \n##  [167] \"PWY0.1479..tRNA.processing\"                                                                                 \n##  [168] \"PWY0.1533..methylphosphonate.degradation.I\"                                                                 \n##  [169] \"PWY0.41..allantoin.degradation.IV..anaerobic.\"                                                              \n##  [170] \"PWY0.42..2.methylcitrate.cycle.I\"                                                                           \n##  [171] \"PWY0.781..aspartate.superpathway\"                                                                           \n##  [172] \"PWY0.862...5Z..dodec.5.enoate.biosynthesis\"                                                                 \n##  [173] \"PWY0.881..superpathway.of.fatty.acid.biosynthesis.I..E..coli.\"                                              \n##  [174] \"PWY3O.355..stearate.biosynthesis.III..fungi.\"                                                               \n##  [175] \"PWY4LZ.257..superpathway.of.fermentation..Chlamydomonas.reinhardtii.\"                                       \n##  [176] \"PWY66.389..phytol.degradation\"                                                                              \n##  [177] \"PWY66.391..fatty.acid..beta..oxidation.VI..peroxisome.\"                                                     \n##  [178] \"PWY66.398..TCA.cycle.III..animals.\"                                                                         \n##  [179] \"PWY66.409..superpathway.of.purine.nucleotide.salvage\"                                                       \n##  [180] \"PWYG.321..mycolate.biosynthesis\"                                                                            \n##  [181] \"PYRIDNUCSAL.PWY..NAD.salvage.pathway.I\"                                                                     \n##  [182] \"REDCITCYC..TCA.cycle.VIII..helicobacter.\"                                                                   \n##  [183] \"SALVADEHYPOX.PWY..adenosine.nucleotides.degradation.II\"                                                     \n##  [184] \"SO4ASSIM.PWY..sulfate.reduction.I..assimilatory.\"                                                           \n##  [185] \"SULFATE.CYS.PWY..superpathway.of.sulfate.assimilation.and.cysteine.biosynthesis\"                            \n##  [186] \"TCA.GLYOX.BYPASS..superpathway.of.glyoxylate.bypass.and.TCA\"                                                \n##  [187] \"THREOCAT.PWY..superpathway.of.L.threonine.metabolism\"                                                       \n##  [188] \"UBISYN.PWY..superpathway.of.ubiquinol.8.biosynthesis..prokaryotic.\"                                         \n##  [189] \"URDEGR.PWY..superpathway.of.allantoin.degradation.in.plants\"                                                \n##  [190] \"X3.HYDROXYPHENYLACETATE.DEGRADATION.PWY..4.hydroxyphenylacetate.degradation\"\n\n############\n# Run MSEA #\n############\n\nMSEA &lt;- run_MSEA(microbeSet, results$feature)\nMSEA &lt;- MSEA[\n    , c('Set', 'Freq', 'ES', setdiff(names(MSEA), c('Set', 'Freq', 'ES')))]\ncolnames(MSEA) &lt;- c('ID', 'Size', 'pval', 'qval')\nMSEA$ID &lt;- paste(MSEA$ID, ' (', MSEA$Size, ')', sep = '')\n\n########\n# Plot #\n########\n\np &lt;- MSEA |&gt;\n  arrange(-pval) |&gt;\n  mutate(ID = factor(ID, levels = ID)) |&gt;\n  ggplot(aes(y = -log10(pval), x = ID)) +\n  geom_bar(stat = \"identity\", fill = 'cornflowerblue') + theme_bw() +\n  coord_flip() +\n  ggtitle('Statistically significant modules associated with disease') +\n  xlab('') +\n  ylab('MSEA enrichment score')\n\np\n\n\n\n\n\n\n\nBased on the MSEA results, we obtain 4 enriched modules of microbial pathways. We can similarly examine the members of the top enriched modules.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Microbe Set Enrichment Analysis (MSEA)</span>"
    ]
  },
  {
    "objectID": "pages/msea.html#print-the-most-significant-modules-for-pathway-abundance-data",
    "href": "pages/msea.html#print-the-most-significant-modules-for-pathway-abundance-data",
    "title": "Appendix A — Microbe Set Enrichment Analysis (MSEA)",
    "section": "\nA.5 Print the most significant modules for pathway abundance data",
    "text": "A.5 Print the most significant modules for pathway abundance data\n\n\n# Print the most significant modules\nmicrobeSet[[\"MEpurple\"]]\n##  NULL\nmicrobeSet[[\"MEbrown\"]]\n##   [1] \"GLCMANNANAUT.PWY..superpathway.of.N.acetylglucosamine..N.acetylmannosamine.and.N.acetylneuraminate.degradation\"\n##   [2] \"GLYCOLYSIS.E.D..superpathway.of.glycolysis.and.Entner.Doudoroff\"                                               \n##   [3] \"METH.ACETATE.PWY..methanogenesis.from.acetate\"                                                                 \n##   [4] \"PWY.5100..pyruvate.fermentation.to.acetate.and.lactate.II\"                                                     \n##   [5] \"PWY.5104..L.isoleucine.biosynthesis.IV\"                                                                        \n##   [6] \"PWY.5177..glutaryl.CoA.degradation\"                                                                            \n##   [7] \"PWY.5690..TCA.cycle.II..plants.and.fungi.\"                                                                     \n##   [8] \"PWY.6470..peptidoglycan.biosynthesis.V...beta..lactam.resistance.\"                                             \n##   [9] \"PWY.6527..stachyose.degradation\"                                                                               \n##  [10] \"PWY.6595..superpathway.of.guanosine.nucleotides.degradation..plants.\"                                          \n##  [11] \"PWY.6608..guanosine.nucleotides.degradation.III\"                                                               \n##  [12] \"PWY.7196..superpathway.of.pyrimidine.ribonucleosides.salvage\"                                                  \n##  [13] \"PWY.7198..pyrimidine.deoxyribonucleotides.de.novo.biosynthesis.IV\"                                             \n##  [14] \"PWY0.1061..superpathway.of.L.alanine.biosynthesis\"                                                             \n##  [15] \"PWY0.1261..anhydromuropeptides.recycling\"                                                                      \n##  [16] \"PWY66.400..glycolysis.VI..metazoan.\"                                                                           \n##  [17] \"TCA..TCA.cycle.I..prokaryotic.\"                                                                                \n##  [18] \"UDPNAGSYN.PWY..UDP.N.acetyl.D.glucosamine.biosynthesis.I\"",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>A</span>  <span class='chapter-title'>Microbe Set Enrichment Analysis (MSEA)</span>"
    ]
  },
  {
    "objectID": "pages/mmuphin_meta_analysis.html",
    "href": "pages/mmuphin_meta_analysis.html",
    "title": "Appendix B — Meta-analyses",
    "section": "",
    "text": "B.1 Meta-analysis of cancer microbiome studies using relative abundance data\nRecent work has indicated a possible involvement of the gut microbiome in influencing the efficacy of immune checkpoint inhibitor (ICI) treatment strategies for PD-1/PD-L1 (Programmed Cell Death Protein 1/Programmed Cell Death Ligand 1) targeting checkpoint inhibitors Peters et al. (2019). Several investigations into the microbiome have provided clinical data suggesting that the gut microbiome modulates the response to inhibitors of the PD-1/PD-L1 axis. However, published cancer microbiome studies face challenges, such as limited sample sizes, inconsistent data analysis methods, and a lack of functionally relevant consensus signatures.\nElucidation of the mechanisms by which the gut microbiome alters the function of the immune system to enable or promote cancer development may reveal novel pathways to explore in cancer therapy. Consequently, a high-quality re-analysis of public cancer microbiome data through a systematic meta-analysis approach could provide valuable insights into the microbiome’s role in cancer development and progression in a rapid and cost-effective manner.\nUsing advanced melanoma as a model, extensively studied in the context of PD-1/PD-L1 immune checkpoint inhibitors, our aim is to identify functional biomarkers positively and negatively associated with ICI response by analyzing both taxonomic and functional profiles with ICI response.\nlibrary(curatedMetagenomicData)\nIn the following section, we provide detailed examples of how to perform batch (study) effect correction and meta-analytic differential abundance testing on publicly available cancer microbiome data from multiple studies. We use the R package MMUPHin for these tasks. MMUPHin is a recently developed R/Bioconductor package designed for meta-analysis of microbiome taxonomic and functional profiles. It is agnostic to the data type and leverages another R/Bioconductor package, MaAsLin2 (Mallick et al. 2021), as a backend to conduct the meta-analysis. MaAsLin2 is particularly designed to be applicable to various microbial community data types (taxonomy or functional profiles) and environments (human or otherwise). It is modular, including implementations of alternative normalization/transformation schemes and statistical models (e.g., amplicon vs. shotgun metagenomic profiles). Leveraging this flexible framework under the hood, MMUPHin performs normalization, study (batch) effect correction, and meta-analysis using the default random effects meta-regression.\nHere, we will first perform the batch effect correction analysis. We use both the relative abundance data and the pathway abundance data from 5 public datasets: Frankel et al. (2017), K. A. Lee et al. (2022), Matson et al. (2018), Peters et al. (2019), and Wind et al. (2020). All these datasets are available from the curatedMetagenomicData package, with a total of 285 subjects included.\n######################\n# Load melanoma data #\n######################\n\nlibrary(dplyr)\n\nse_relative &lt;- sampleMetadata |&gt;\n    filter(study_name %in% c(\n        \"FrankelAE_2017\", \"GopalakrishnanV_2018\", \"LeeKA_2022\",\n        \"MatsonV_2018\", \"PetersBA_2019\", \"WindTT_2020\")) |&gt;\n    returnSamples(\"relative_abundance\", rownames = \"short\")\n\nse_pathway &lt;- sampleMetadata |&gt;\n    filter(study_name %in% c(\n        \"FrankelAE_2017\", \"GopalakrishnanV_2018\", \"LeeKA_2022\",\n        \"MatsonV_2018\", \"PetersBA_2019\", \"WindTT_2020\")) |&gt;\n    returnSamples(\"pathway_abundance\", rownames = \"short\")\nFirst, let’s look into the relative abundance data.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Meta-analyses</span>"
    ]
  },
  {
    "objectID": "pages/mmuphin_meta_analysis.html#meta-analysis-of-cancer-microbiome-studies-using-relative-abundance-data",
    "href": "pages/mmuphin_meta_analysis.html#meta-analysis-of-cancer-microbiome-studies-using-relative-abundance-data",
    "title": "Appendix B — Meta-analyses",
    "section": "",
    "text": "Mallick, Himel, Ali Rahnavard, Lauren J. McIver, Siyuan Ma, Yancong Zhang, Long H. Nguyen, Timothy L. Tickle, et al. 2021. “Multivariable Association Discovery in Population-Scale Meta-Omics Studies.” PLOS Computational Biology 17 (11): e1009442. https://doi.org/https://doi.org/10.1371/journal.pcbi.1009442.\n\nFrankel, Arthur E, Laura A Coughlin, Jiwoong Kim, Thomas W Froehlich, Yang Xie, Eugene P Frenkel, and Andrew Y Koh. 2017. “Metagenomic Shotgun Sequencing and Unbiased Metabolomic Profiling Identify Specific Human Gut Microbiota and Metabolites Associated with Immune Checkpoint Therapy Efficacy in Melanoma Patients.” Neoplasia 19 (10): 848–55. https://doi.org/10.1016/j.neo.2017.08.004.\n\nLee, Karla A., Andrew Maltez Thomas, Laura A. Bolte, Johannes R. Björk, Laura Kist de Ruijter, Federica Armanini, Francesco Asnicar, et al. 2022. “Cross-Cohort Gut Microbiome Associations with Immune Checkpoint Inhibitor Response in Advanced Melanoma.” Nature Medicine 28 (3): 535–44. https://doi.org/https://doi.org/10.1038/s41591-022-01695-5.\n\nMatson, Vyara, Jessica Fessler, Riyue Bao, Tara Chongsuwat, Yuanyuan Zha, Maria-Luisa Alegre, Jason J Luke, and Thomas F Gajewski. 2018. “The Commensal Microbiome Is Associated with Anti-PD-1 Efficacy in Metastatic Melanoma Patients.” Science 359 (6371): 104–8. https://doi.org/10.1126/science.aao3290.\n\nPeters, Brandilyn A., Melissa Wilson, Una Moran, Anna Pavlick, Allison Izsak, Todd Wechter, Jeffrey S. Weber, Iman Osman, and Jiyoung Ahn. 2019. “Relating the Gut Metagenome and Metatranscriptome to Immunotherapy Responses in Melanoma Patients.” Genome Medicine 11 (1): 61. https://doi.org/10.1186/s13073-019-0672-4.\n\nWind, Thijs T, Ranko Gacesa, Arnau Vich Vila, Jacco J de Haan, Mathilde Jalving, Rinse K Weersma, and Geke A P Hospers. 2020. “Gut Microbial Species and Metabolic Pathways Associated with Response to Treatment with Immune Checkpoint Inhibitors in Metastatic Melanoma.” Melanoma Research 30 (3): 235–46. https://doi.org/10.1097/CMR.0000000000000656.\n\n\n\n\nB.1.1 Performing batch (study) effect adjustment with adjust_batch for relative abundance\nIn this analysis, we are using two input files. The first input file is the relative abundance data file, which consists of a feature-by-sample matrix. The second input is the metadata associated with the relative abundance file, which includes the study names and overall response rate (ORR) the response variable along with other metadata. By the end of this step, we obtain a batch-adjusted relative abundance matrix.\n\n\nlibrary(MMUPHin)\n\n##########################\n# Create sample metadata #\n##########################\ndata_meta &lt;- select(\n    as.data.frame(colData(se_relative)),\n    c(\"study_name\", \"ORR\", \"PFS12\", \"anti_PD_1\"))\n\n# Define response variable\ndata_meta$resvar &lt;- NA\ndata_meta$anti_PD_1[data_meta$anti_PD_1 == \"responder\"] &lt;- \"yes\"\ndata_meta$anti_PD_1[data_meta$anti_PD_1 == \"non_responder\"] &lt;- \"no\"\ndata_meta$resvar[!is.na(data_meta$anti_PD_1)] &lt;- data_meta$anti_PD_1[\n    !is.na(data_meta$anti_PD_1)]\ndata_meta$resvar[!is.na(data_meta$PFS12)] &lt;- data_meta$PFS12[\n    !is.na(data_meta$PFS12)]\ndata_meta$resvar[!is.na(data_meta$ORR)] &lt;- data_meta$ORR[!is.na(data_meta$ORR)]\n\n# Filter individuals without response variable\ndata_meta &lt;- data_meta[!is.na(data_meta$resvar), c(\"study_name\", \"resvar\")]\n\n# Convert the \"study_name\" to factor variable\ndata_meta$study_name &lt;- as.factor(data_meta$study_name)\n\n###########################\n# Create Species Features #\n###########################\n# Transpose the abundance matrix and change the value of abundance data to\n# proportion unit\ndata_abd &lt;- assay(se_relative)\ndata_abd &lt;- data_abd / 100\n\n# Match the individuals in the data_abd\ndata_abd &lt;- data_abd[, colnames(data_abd) %in% rownames(data_meta)]\n\n#  Change the rownames names for variables of interest\nrownames(data_abd) &lt;- sub('.*s__', '', rownames(data_abd))\n\n# Use adjust_batch to correct for differences in the five studies, while\n# controlling for the effect of cases versus control (variable resvar in\n# data_meta).\nfit_adjust_batch &lt;- adjust_batch(\n    feature_abd = data_abd,\n    batch = \"study_name\",\n    covariates = \"resvar\",\n    data = data_meta,\n    control = list(verbose = FALSE, diagnostic_plot = NULL))\n\ndata_abd_adj &lt;- fit_adjust_batch$feature_abd_adj\n\nThe first figure shows the relationship between the original batch mean parameters (Gamma) and the shrunk (regularized) batch mean parameters (Gamma (shrunken)). The points represent the 5 different study groups within the dataset. The var_batch points represent the variance within each batch, with different colors indicating different levels or categories of variance. The scatter plot on the right represents the change in mean abundance between the original and adjusted ones, displaying an obvious decrease after the batch effect adjustment analysis.\n\nB.1.2 Evaluation for batch effect adjustment\nAfter obtaining the adjusted abundance matrix, we can evaluate the improvement of the batch effect adjustment. Here, the total variation from study difference will be assessed through the PERMANOVA test (Tang, Chen, and Alekseyenko 2016).\n\nTang, Zhengzheng, Guanhua Chen, and Alexander V Alekseyenko. 2016. “PERMANOVA-S: Association Test for Microbial Community Composition That Accommodates Confounders and Multiple Distances.” Bioinformatics 32 (17): 2618–25. https://doi.org/10.1093/bioinformatics/btw311.\n\n\nlibrary(vegan)\n\nD_before &lt;- vegdist(t(data_abd))\nD_after &lt;- vegdist(t(data_abd_adj))\n\nset.seed(1)\nfit_adonis_before &lt;- adonis2(D_before ~ study_name, data = data_meta)\nfit_adonis_after &lt;- adonis2(D_after ~ study_name, data = data_meta)\n\nprint(fit_adonis_before$aov.tab)\n##  NULL\nprint(fit_adonis_after$aov.tab)\n##  NULL\n\nBased on the results, we can see that the study differences can explain a total of 11.922% (\\(R^2\\)) of the variability in microbial abundance profiles before study effect adjustment, whereas after adjustment this was reduced to 2.806% (\\(R^2\\)).\nLet’s visualize the results of the PERMANOVA test.\n\n\nlibrary(ggplot2)\nlibrary(patchwork)\n\n##############\n# Ordination #\n##############\n\n# Before\nR2_before &lt;- round(fit_adonis_before$aov.tab[1, 5]*100, 1)\npcoa_before &lt;- cmdscale(D_before, eig = TRUE)\nord_before &lt;- as.data.frame(pcoa_before$points)\npercent_var_before &lt;- round(pcoa_before$eig / sum(pcoa_before$eig) * 100, 1)[1:2]\nbefore_labels &lt;- c(\n    paste('Axis 1 (', percent_var_before[1], '%)', sep = ''),\n    paste('Axis 2 (', percent_var_before[2], '%)', sep = ''))\n\nbefore_phrase &lt;- paste('Before (PERMANOVA R2 = ', R2_before, '%)', sep = '')\ncolnames(ord_before) &lt;- c('PC1', 'PC2')\nord_before$Study &lt;- data_meta$study_name\n\n# After\nR2_after &lt;- round(fit_adonis_after$aov.tab[1, 5]*100, 1)\npcoa_after &lt;- cmdscale(D_after, eig = TRUE)\nord_after &lt;- as.data.frame(pcoa_after$points)\npercent_var_after &lt;- round(pcoa_after$eig / sum(pcoa_after$eig) * 100, 1)[1:2]\nafter_labels &lt;- c(paste('Axis 1 (', percent_var_after[1], '%)', sep = ''),\n                paste('Axis 2 (', percent_var_after[2], '%)', sep = ''))\n\nafter_phrase &lt;- paste('After (PERMANOVA R2 = ', R2_after, '%)', sep = '')\ncolnames(ord_after) &lt;- c('PC1', 'PC2')\nord_after$Study &lt;- data_meta$study_name\n\n# Ordination Plot\np_before &lt;- ggplot(ord_before, aes(x = PC1, y = PC2, color = Study)) +\n    geom_point(size = 4) +\n    theme_bw() +\n    xlab(before_labels[1]) +\n    ylab(before_labels[2]) +\n    ggtitle(before_phrase) +\n    theme(plot.title = element_text(hjust = 0.5)) +\n    theme(legend.position =\"none\")\n\np_after &lt;- ggplot(ord_after, aes(x = PC1, y = PC2, color = Study)) +\n    geom_point(size = 4) +\n    theme_bw() +\n    xlab(after_labels[1]) +\n    ylab(after_labels[2]) +\n    ggtitle(after_phrase) +\n    theme(plot.title = element_text(hjust = 0.5)) +\n    theme(legend.position =\"none\")\n\np_before + p_after\n\n\n\n\n\n\n\n\nB.1.3 Meta-analytical differential abundance testing with lm_meta\nHere, we illustrate the details of the meta-analytical differential abundance testing. We have several choices for the analysis methods. First, we apply linear models (LM) for individual study-specific analyses with various transformations.\n\n\nlibrary(Maaslin2)\n\ntransform &lt;- c(\"NONE\", \"AST\", \"LOGIT\", \"LOG\")\nnum &lt;- NULL\n\nfor (i in 1:length(transform)) {\n    fit_lm_meta &lt;- lm_meta(\n        feature_abd = data_abd_adj,\n        batch = \"study_name\",\n        exposure = \"resvar\",\n        data = data_meta,\n        control = list(analysis_method = 'LM', transform = transform[i]))\n\n    num[i] &lt;- sum(fit_lm_meta$meta_fits$qval.fdr &lt; 0.05, na.rm = TRUE)\n}\n\nprint(num)\n##  [1] 0 0 0 0\n\nSince none of the linear models are able to generate significant results, we next apply the Tweedie model (using the “CPLM” analysis method in MaAsLin2, also implemented in the R package Tweedieverse (Mallick et al. 2022).\n\nMallick, Himel, Suvo Chatterjee, Shrabanti Chowdhury, Saptarshi Chatterjee, Ali Rahnavard, and Stephanie C Hicks. 2022. “Differential Expression of Single-Cell RNA-Seq Data Using Tweedie Models.” Statistics in Medicine 41 (18): 3492–3510. https://doi.org/10.1002/sim.9430.\n\nfit_lm_meta &lt;- lm_meta(\n    feature_abd = data_abd_adj,\n    batch = \"study_name\",\n    exposure = \"resvar\",\n    data = data_meta,\n    control = list(analysis_method = 'CPLM', transform = 'NONE'))\n\nmeta_fits &lt;- fit_lm_meta$meta_fits\n\nmeta_fits |&gt;\n    filter(qval.fdr &lt; 0.05) |&gt;\n    arrange(coef) |&gt;\n    mutate(feature = factor(feature, levels = feature)) |&gt;\n    ggplot(aes(y = coef, x = feature)) +\n    geom_bar(stat = \"identity\") +\n    coord_flip()\n\n\n\n\n\n\n\nBased on the results, we see that there are 22 significant features in total, among which the has the strongest positive effect, while the species has the strongest negative effect.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Meta-analyses</span>"
    ]
  },
  {
    "objectID": "pages/mmuphin_meta_analysis.html#sec-meta-analysis-pathway",
    "href": "pages/mmuphin_meta_analysis.html#sec-meta-analysis-pathway",
    "title": "Appendix B — Meta-analyses",
    "section": "\nB.2 Meta-analysis for pathway abundance data",
    "text": "B.2 Meta-analysis for pathway abundance data\nIn this section, we repeat all the analysis mentioned above using the pathway relative abundance data. We first prepare the input data for the analysis.\n\n\n# Prepare the meta data\ndata_meta &lt;- select(\n    as.data.frame(colData(se_pathway)),\n    c(\"study_name\", \"ORR\", \"PFS12\", \"anti_PD_1\"))\n\n# Define response variable\ndata_meta$resvar &lt;- NA\ndata_meta$anti_PD_1[data_meta$anti_PD_1 == \"responder\"] &lt;- \"yes\"\ndata_meta$anti_PD_1[data_meta$anti_PD_1 == \"non_responder\"] &lt;- \"no\"\ndata_meta$resvar[!is.na(data_meta$anti_PD_1)] &lt;- data_meta$anti_PD_1[\n    !is.na(data_meta$anti_PD_1)]\ndata_meta$resvar[!is.na(data_meta$PFS12)] &lt;- data_meta$PFS12[\n    !is.na(data_meta$PFS12)]\ndata_meta$resvar[!is.na(data_meta$ORR)] &lt;- data_meta$ORR[!is.na(data_meta$ORR)]\n\n# Filter individuals without response variable\ndata_meta &lt;- data_meta[!is.na(data_meta$resvar), c(\"study_name\", \"resvar\")]\n\n# Convert the \"study_name\" to factor variable\ndata_meta$study_name &lt;- as.factor(data_meta$study_name)\n\n# Prepare the abundance data\n# Transpose the abundance matrix and change the value of abundance data to\n# proportion unit\ndata_abd &lt;- assay(se_pathway)\ndata_abd &lt;- data_abd/100\n\n# Filter out stratified features\ndata_abd&lt;-data_abd[!grepl(\"\\\\|\", rownames(data_abd)),]\ndata_abd&lt;-as.data.frame(data_abd)\ndata_abd&lt;-data_abd[-c(1:2), ]\n\n# Match the individuals in the data_abd\ndata_abd &lt;- data_abd[, colnames(data_abd) %in% rownames(data_meta)]\n\n# Use adjust_batch to correct for differences in the five studies, while\n# controlling for the effect of cases versus control (variable resvar in\n# data_meta).\nfit_adjust_batch &lt;- adjust_batch(\n    feature_abd = data_abd,\n    batch = \"study_name\",\n    covariates = \"resvar\",\n    data = data_meta,\n    control = list(verbose = FALSE, diagnostic_plot = NULL))\n\ndata_abd_adj &lt;- fit_adjust_batch$feature_abd_adj\n\nNext, we will evaluate the improvement of the batch effect adjustment and apply the PERMANOVA test.\n\n\nD_before &lt;- vegdist(t(data_abd))\nD_after &lt;- vegdist(t(data_abd_adj))\n\nset.seed(1)\nfit_adonis_before &lt;- adonis(D_before ~ study_name, data = data_meta)\nfit_adonis_after &lt;- adonis(D_after ~ study_name, data = data_meta)\n\nprint(fit_adonis_before$aov.tab)\n##  Permutation: free\n##  Number of permutations: 999\n##  \n##  Terms added sequentially (first to last)\n##  \n##              Df SumsOfSqs MeanSqs F.Model    R2 Pr(&gt;F)    \n##  study_name   4      2.01   0.503    20.6 0.229  0.001 ***\n##  Residuals  278      6.78   0.024         0.771           \n##  Total      282      8.80                 1.000           \n##  ---\n##  Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nprint(fit_adonis_after$aov.tab)\n##  Permutation: free\n##  Number of permutations: 999\n##  \n##  Terms added sequentially (first to last)\n##  \n##              Df SumsOfSqs MeanSqs F.Model    R2 Pr(&gt;F)    \n##  study_name   4      1.00  0.2510    10.1 0.127  0.001 ***\n##  Residuals  278      6.88  0.0248         0.873           \n##  Total      282      7.89                 1.000           \n##  ---\n##  Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nBased on the results, we see that the study differences can explain a total of 15.508% (\\(R^2\\)) of the variability in microbial pathway profiles before study effect adjustment, whereas after adjustment this was reduced to 5.037% (\\(R^2\\)).\nLet’s also visualize the results of the PERMANOVA test.\n\n\n# Ordination\n# Before\nR2_before &lt;- round(fit_adonis_before$aov.tab[1, 5]*100, 1)\npcoa_before &lt;- cmdscale(D_before, eig = TRUE)\nord_before &lt;- as.data.frame(pcoa_before$points)\npercent_var_before &lt;- round(pcoa_before$eig / sum(pcoa_before$eig) * 100, 1)[1:2]\nbefore_labels &lt;- c(\n    paste('Axis 1 (', percent_var_before[1], '%)', sep = ''),\n    paste('Axis 2 (', percent_var_before[2], '%)', sep = ''))\n\nbefore_phrase &lt;- paste('Before (PERMANOVA R2 = ', R2_before, '%)', sep = '')\ncolnames(ord_before) &lt;- c('PC1', 'PC2')\nord_before$Study &lt;- data_meta$study_name\n\n# After\nR2_after &lt;- round(fit_adonis_after$aov.tab[1, 5]*100, 1)\npcoa_after &lt;- cmdscale(D_after, eig = TRUE)\nord_after &lt;- as.data.frame(pcoa_after$points)\npercent_var_after &lt;- round(pcoa_after$eig / sum(pcoa_after$eig) * 100, 1)[1:2]\nafter_labels &lt;- c(\n    paste('Axis 1 (', percent_var_after[1], '%)', sep = ''),\n    paste('Axis 2 (', percent_var_after[2], '%)', sep = ''))\n\nafter_phrase &lt;- paste('After (PERMANOVA R2 = ', R2_after, '%)', sep = '')\ncolnames(ord_after) &lt;- c('PC1', 'PC2')\nord_after$Study &lt;- data_meta$study_name\n\n# Ordination Plot\np_before &lt;- ggplot(ord_before, aes(x = PC1, y = PC2, color = Study)) +\n    geom_point(size = 4) +\n    theme_bw() +\n    xlab(before_labels[1]) +\n    ylab(before_labels[2]) +\n    ggtitle(before_phrase) +\n    theme(plot.title = element_text(hjust = 0.5)) +\n    theme(legend.position =\"none\")\n\np_after &lt;- ggplot(ord_after, aes(x = PC1, y = PC2, color = Study)) +\n    geom_point(size = 4) +\n    theme_bw() +\n    xlab(after_labels[1]) +\n    ylab(after_labels[2]) +\n    ggtitle(after_phrase) +\n    theme(plot.title = element_text(hjust = 0.5)) +\n    theme(legend.position =\"none\")\n\np &lt;- p_before + p_after\np\n\n\n\n\n\n\n\nAs before, we have several choices on the analysis methods. However, since we don’t have significance at the FDR level, we use the unadjusted p-values to showcase the ``top hits’’.\n\ntransform &lt;- c(\"NONE\", \"AST\", \"LOGIT\", \"LOG\")\nnum &lt;- NULL\n\nfor (i in 1:length(transform)) {\n    fit_lm_meta &lt;- lm_meta(\n        feature_abd = data_abd_adj,\n        batch = \"study_name\",\n        exposure = \"resvar\",\n        data = data_meta,\n        control = list(analysis_method = 'LM', transform = transform[i]))\n\n    num[i] &lt;- sum(fit_lm_meta$meta_fits$pval &lt; 0.05, na.rm = TRUE)\n}\n\nprint(num)\n##  [1] 11 10  9 11\n\n\nfit_lm_meta2 &lt;- lm_meta(\n    feature_abd = data_abd_adj,\n    batch = \"study_name\",\n    exposure = \"resvar\",\n    data = data_meta,\n    control = list(analysis_method = 'CPLM', transform = 'NONE'))\n\nnum &lt;- sum(fit_lm_meta2$meta_fits$pval &lt; 0.05, na.rm = TRUE)\nprint(num)\n##  [1] 15\n\nHere is the summary table for the number of significant pathways using various meta-analytic differential analysis methods and transformations:\n\n\nlibrary(knitr)\n\nanalysis_data &lt;- data.frame(\n    Analysis_Method = c(\"LM\", \"LM\", \"LM\", \"LM\", \"CPLM\"),\n    Transform_Parameter = c(\"NONE\", \"AST\", \"LOGIT\", \"LOG\", \"NONE\"),\n    Number_Of_Significant_Pathways = c(11, 10, 9, 11, 15)\n)\n\nnames(analysis_data) &lt;- c(\n    \"Analysis Method\", \"Transformation\", \"Number of Significant Pathways\")\n\nkable(analysis_data, caption = \"Analysis Results\", align = c('l','l','r'))\n\n\nAnalysis Results\n\nAnalysis Method\nTransformation\nNumber of Significant Pathways\n\n\n\nLM\nNONE\n11\n\n\nLM\nAST\n10\n\n\nLM\nLOGIT\n9\n\n\nLM\nLOG\n11\n\n\nCPLM\nNONE\n15\n\n\n\n\n\nFinally, let’s visualize the results using the “CPLM” analysis method, which identified largest number of significant pathways.\n\n\n# Extract the results\nmeta_fits2 &lt;- fit_lm_meta2$meta_fits\n# meta_fits3 &lt;- meta_fits2[meta_fits2$pval &lt; 0.05 & !is.na(meta_fits2$pval), ]\n\n# Create the figure\nmeta_fits2 |&gt;\n    filter(pval &lt; 0.05) |&gt;\n    arrange(coef) |&gt;\n    mutate(feature = factor(feature, levels = feature)) |&gt;\n    ggplot(aes(y = coef, x = feature)) +\n    theme(axis.text.y = element_text(size = 10)) +\n    geom_bar(stat = \"identity\") +\n    coord_flip()\n\n\n\n\n\n\n\nBased on the results, we observe 15 significant features in total. Among these, queuosine biosynthesis exhibits the strongest negative effects. Additionally, L-lysine degradation XI is the most positively significant pathway, while xylose degradation IV is the most negatively significant pathway.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>B</span>  <span class='chapter-title'>Meta-analyses</span>"
    ]
  },
  {
    "objectID": "pages/extra_material.html",
    "href": "pages/extra_material.html",
    "title": "Appendix C — Extra material",
    "section": "",
    "text": "C.1 phyloseq vs TreeSE cheatsheet\nThis section has a cheatsheet for translating common functions in phyloseq to TreeSE/mia with example code.\n# Download libraries\nlibrary(mia)\nlibrary(phyloseq)\nlibrary(dplyr)\nlibrary(ggplot2)\nStart by loading data as a phyloseq object “phy” and as TreeSE object “tse”.\n# Loading example data\n# Using GlobalPatterns dataset\n\ndata(package = \"phyloseq\", \"GlobalPatterns\") # phyloseq object\nphy &lt;- GlobalPatterns # Rename\nphy # Check the phyloseq object\n##  phyloseq-class experiment-level object\n##  otu_table()   OTU Table:         [ 19216 taxa and 26 samples ]\n##  sample_data() Sample Data:       [ 26 samples by 7 sample variables ]\n##  tax_table()   Taxonomy Table:    [ 19216 taxa by 7 taxonomic ranks ]\n##  phy_tree()    Phylogenetic Tree: [ 19216 tips and 19215 internal nodes ]\n\ndata(package = \"mia\", \"GlobalPatterns\") # TreeSE object\ntse &lt;- GlobalPatterns # Rename\ntse # Check the tse object\n##  class: TreeSummarizedExperiment \n##  dim: 19216 26 \n##  metadata(0):\n##  assays(1): counts\n##  rownames(19216): 549322 522457 ... 200359 271582\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(26): CL3 CC1 ... Even2 Even3\n##  colData names(7): X.SampleID Primer ... SampleType Description\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: a LinkDataFrame (19216 rows)\n##  rowTree: 1 phylo tree(s) (19216 leaves)\n##  colLinks: NULL\n##  colTree: NULL",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Extra material</span>"
    ]
  },
  {
    "objectID": "pages/extra_material.html#phyloseq-vs-treese-cheatsheet",
    "href": "pages/extra_material.html#phyloseq-vs-treese-cheatsheet",
    "title": "Appendix C — Extra material",
    "section": "",
    "text": "C.1.1 Accessing different types of data in phyloseq versus TreeSE\n\nOften microbiome datasets contain three different types of tables, one which defines the microbes’ taxonomy from domain to species level, one that describes sample level information like whether the sample is from a healthy or a diseased person, and one that has the abundances of taxa from mapping, like an OTU table.\nThere are slightly different names for these tables in phyloseq and tse, but they can be retrieved from the phyloseq and tse containers in analogous ways.\nAccessing the table of taxonomic names: tax_table = rowData\nphyloseq and TreeSE objects’ taxonomy tables can be accessed with tax_table and rowData commands.\n\nphy_taxtable &lt;-\n    tax_table(phy)  |&gt; # Access the phyloseq taxonomic name table\n    data.frame() # Make into a data frame\n\ntse_taxtable &lt;- rowData(tse) |&gt; # Same for tse\n    data.frame()\n\nAccessing sample data: sample_data = colData\nSample data can be accessed with sample_data and colData commands.\n\nphy_sampledata &lt;-\n    sample_data(phy) |&gt; data.frame()\n\ntse_sampledata &lt;-\n    colData(tse) |&gt; data.frame()\n\nAccessing operational taxonomic unit (OTU) abundance objects: otu_table = assay\nOTU tables can be accessed with otu_table and assay commands. The assay can also hold other types of information like taxa abundances from shotgun metagenomic annotation, or functional gene abundances.\n\nphy_otutable &lt;-\n    otu_table(phy) |&gt; data.frame()\n\ntse_otutable &lt;-\n    assay(tse) |&gt; data.frame()\n\n\nC.1.2 Building phyloseq objects vs TreeSE objects: phyloseq = TreeSummarizedExperiment\nAfter learning how to access various data types from TreeSE, let’s see how creating TreeSE objects compares to creating phyloseq objects. We will use the vanilla dataframes we created from the phyloseq object to demonstrate making both types of data objects. These are identical to the equivalent tse dataframes but for demonstration we will use ones created from phy.\nLet’s start by checking what we have.\n\nphy_otutable |&gt; head()\n##         CL3 CC1 SV1 M31Fcsw M11Fcsw M31Plmr M11Plmr F21Plmr M31Tong M11Tong\n##  549322   0   0   0       0       0       0       0       0       0       0\n##  522457   0   0   0       0       0       0       0       0       0       0\n##  951      0   0   0       0       0       0       1       0       0       0\n##  244423   0   0   0       0       0       0       0       0       0       0\n##  586076   0   0   0       0       0       0       0       0       0       0\n##  246140   0   0   0       0       0       0       0       0       0       0\n##         LMEpi24M SLEpi20M AQC1cm AQC4cm AQC7cm NP2 NP3 NP5 TRRsed1 TRRsed2\n##  549322        0        1     27    100    130   1   0   0       0       0\n##  522457        0        0      0      2      6   0   0   0       0       0\n##  951           0        0      0      0      0   0   0   0       0       0\n##  244423        0        0      0     22     29   0   0   0       0       0\n##  586076        0        0      0      2      1   0   0   0       0       0\n##  246140        0        0      0      1      3   0   0   0       0       0\n##         TRRsed3 TS28 TS29 Even1 Even2 Even3\n##  549322       0    0    0     0     0     0\n##  522457       0    0    0     0     0     0\n##  951          0    0    0     0     0     0\n##  244423       0    0    0     0     0     0\n##  586076       0    0    0     0     0     0\n##  246140       0    0    0     0     0     0\nphy_sampledata |&gt; head()\n##          X.SampleID  Primer Final_Barcode Barcode_truncated_plus_T\n##  CL3            CL3 ILBC_01        AACGCA                   TGCGTT\n##  CC1            CC1 ILBC_02        AACTCG                   CGAGTT\n##  SV1            SV1 ILBC_03        AACTGT                   ACAGTT\n##  M31Fcsw    M31Fcsw ILBC_04        AAGAGA                   TCTCTT\n##  M11Fcsw    M11Fcsw ILBC_05        AAGCTG                   CAGCTT\n##  M31Plmr    M31Plmr ILBC_07        AATCGT                   ACGATT\n##          Barcode_full_length SampleType\n##  CL3             CTAGCGTGCGT       Soil\n##  CC1             CATCGACGAGT       Soil\n##  SV1             GTACGCACAGT       Soil\n##  M31Fcsw         TCGACATCTCT      Feces\n##  M11Fcsw         CGACTGCAGCT      Feces\n##  M31Plmr         CGAGTCACGAT       Skin\n##                                         Description\n##  CL3       Calhoun South Carolina Pine soil, pH 4.9\n##  CC1       Cedar Creek Minnesota, grassland, pH 6.1\n##  SV1     Sevilleta new Mexico, desert scrub, pH 8.3\n##  M31Fcsw    M3, Day 1, fecal swab, whole body study\n##  M11Fcsw   M1, Day 1, fecal swab, whole body study \n##  M31Plmr    M3, Day 1, right palm, whole body study\nphy_taxtable |&gt; head()\n##         Kingdom        Phylum        Class        Order        Family\n##  549322 Archaea Crenarchaeota Thermoprotei         &lt;NA&gt;          &lt;NA&gt;\n##  522457 Archaea Crenarchaeota Thermoprotei         &lt;NA&gt;          &lt;NA&gt;\n##  951    Archaea Crenarchaeota Thermoprotei Sulfolobales Sulfolobaceae\n##  244423 Archaea Crenarchaeota        Sd-NA         &lt;NA&gt;          &lt;NA&gt;\n##  586076 Archaea Crenarchaeota        Sd-NA         &lt;NA&gt;          &lt;NA&gt;\n##  246140 Archaea Crenarchaeota        Sd-NA         &lt;NA&gt;          &lt;NA&gt;\n##              Genus                  Species\n##  549322       &lt;NA&gt;                     &lt;NA&gt;\n##  522457       &lt;NA&gt;                     &lt;NA&gt;\n##  951    Sulfolobus Sulfolobusacidocaldarius\n##  244423       &lt;NA&gt;                     &lt;NA&gt;\n##  586076       &lt;NA&gt;                     &lt;NA&gt;\n##  246140       &lt;NA&gt;                     &lt;NA&gt;\n\nOk, these are all normal data frames which could come from upstream bioinformatics, like OTU tables that come from 16S analysis, and taxonomy tables.\nLet’s demo how to create the TreeSE object, how it compares to creating phyloseq and how assay in TreeSE compares to otu_table in phyloseq.\n\n\n# Create phyloseq object\nOTU_phy &lt;- otu_table(as.matrix(phy_otutable), taxa_are_rows = TRUE) # Make OTU table\nTAX_phy &lt;- tax_table(as.matrix(phy_taxtable)) # Make TAX table\nSAMPLE_phy &lt;- sample_data(phy_sampledata) # Make sample data table\n\nphy &lt;- phyloseq(OTU_phy, TAX_phy, SAMPLE_phy) # Combine into phyloseq object\nphy # Inspect\n##  phyloseq-class experiment-level object\n##  otu_table()   OTU Table:         [ 19216 taxa and 26 samples ]\n##  sample_data() Sample Data:       [ 26 samples by 7 sample variables ]\n##  tax_table()   Taxonomy Table:    [ 19216 taxa by 7 taxonomic ranks ]\n\nLet’s start by checking our otu table, and see if it is counts or already normalized. We will use the same data frame extracted from the phy object as before.\n\n# Check if we have counts or normalized data\n\nphy_otutable |&gt; head()\n##         CL3 CC1 SV1 M31Fcsw M11Fcsw M31Plmr M11Plmr F21Plmr M31Tong M11Tong\n##  549322   0   0   0       0       0       0       0       0       0       0\n##  522457   0   0   0       0       0       0       0       0       0       0\n##  951      0   0   0       0       0       0       1       0       0       0\n##  244423   0   0   0       0       0       0       0       0       0       0\n##  586076   0   0   0       0       0       0       0       0       0       0\n##  246140   0   0   0       0       0       0       0       0       0       0\n##         LMEpi24M SLEpi20M AQC1cm AQC4cm AQC7cm NP2 NP3 NP5 TRRsed1 TRRsed2\n##  549322        0        1     27    100    130   1   0   0       0       0\n##  522457        0        0      0      2      6   0   0   0       0       0\n##  951           0        0      0      0      0   0   0   0       0       0\n##  244423        0        0      0     22     29   0   0   0       0       0\n##  586076        0        0      0      2      1   0   0   0       0       0\n##  246140        0        0      0      1      3   0   0   0       0       0\n##         TRRsed3 TS28 TS29 Even1 Even2 Even3\n##  549322       0    0    0     0     0     0\n##  522457       0    0    0     0     0     0\n##  951          0    0    0     0     0     0\n##  244423       0    0    0     0     0     0\n##  586076       0    0    0     0     0     0\n##  246140       0    0    0     0     0     0\n\nWe have counts!\nSince TreeSEs can hold many different versions of the OTU table, most commonly either relative abundances or counts, we will need to give our assay (which corresponds to otu_table in Phyloseq) a name and list the different types of assays or transformations we have. In this example we only have one item ‘counts’ in the list.\nLet’s convert the data frame to a matrix and make the list of assays.\n\n# Create TreeSE\ncounts &lt;- as.matrix(phy_otutable) # Convert to a matrix\nassays &lt;- SimpleList(counts = counts)\ntse &lt;- TreeSummarizedExperiment(\n    assays = assays,\n    colData = phy_sampledata,\n    rowData = phy_taxtable\n)\n\nLet’s check the different assay names we have.\n\nassayNames(tse)\n##  [1] \"counts\"\n\n\nC.1.3 Handling different OTU table normalizations in phyloseq vs TreeSE\nAdding the assays as a list might seem inconvenient if you only have one type of OTU table (counts in our example), but let’s see why it is actually very convenient to be able to hold multiple assays in one data object.\nHere we’ll show an example of how to add relative abundances and CLR normalized OTU tables to your tse assays.\nWith phyloseq you would need three different phyloseq objects, each taking up 7.7 MB of memory, whilst the tse with the three assays takes up only 18.3 MB.\n\n# Add another assay that holds the relative abundance normalized OTU table\ntse &lt;- transformAssay(tse, assay.type = \"counts\", method = \"relabundance\")\nassays(tse) # Let's check\n##  List of length 2\n##  names(2): counts relabundance\n\n# With phyloseq you would need to have two different phyloseq objects\nphy_relab  = transform_sample_counts(phy, function(x)\n  x / sum(x))\n\n# Let's add clr transformed data just for the fun of it :)\ntse &lt;- transformAssay(\n    tse,\n    assay.type = \"counts\",\n    method = \"clr\",\n    pseudocount = 1)\n\nassays(tse) # Let's check\n##  List of length 3\n##  names(3): counts relabundance clr\n\n# With phyloseq you would need to have a third phyloseq object.\n# phy_CLR &lt;- microbiome::transform(phy, 'clr') # Example, don't run\n\n\nC.1.4 Subsetting samples and taxa\nSubsetting samples: subset_samples = indexing columns\nNext let’s learn how to subset samples. In phyloseq we use subset_samples command, but since the sample data is stored in columns in the TreeSe, we can access it by indexing columns.\nIn this section we will remove the “Mock” samples and make new data objects.\n\nphy_nomock &lt;- subset_samples(\n    phy, !SampleType == \"Mock\") # Removing mock samples in phyloseq\n\ntse_nomock &lt;- tse[,!tse$SampleType == \"Mock\"] # tse uses indexing columns\n\nLet’s see what we have now.\n\nphy |&gt; sample_names() |&gt; length()\n##  [1] 26\nphy_nomock |&gt; sample_names() |&gt; length()\n##  [1] 23\ncolnames(tse) |&gt; length()\n##  [1] 26\ncolnames(tse_nomock) |&gt; length()\n##  [1] 23\n\nWe have removed three samples that where SampleType “Mock”.\nSubsetting taxa: subset_taxa = indexing rows\nTaxa are stored in rows in TreeSE and the TreeSE equivalent to subset_taxa is indexing rows.\n\nphy_nomock_bacteria &lt;-\n  subset_taxa(phy_nomock, Kingdom == \"Bacteria\")\ntse_nomock_bacteria &lt;-\n  tse[tse$Kingdom == \"Bacteria\", ]\n\nphy_nomock_bacteria # We have 19008 taxa (only bacteria) and before 19216\n##  phyloseq-class experiment-level object\n##  otu_table()   OTU Table:         [ 19008 taxa and 23 samples ]\n##  sample_data() Sample Data:       [ 23 samples by 7 sample variables ]\n##  tax_table()   Taxonomy Table:    [ 19008 taxa by 7 taxonomic ranks ]\ntse_nomock_bacteria\n##  class: TreeSummarizedExperiment \n##  dim: 0 26 \n##  metadata(0):\n##  assays(3): counts relabundance clr\n##  rownames(0):\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(26): CL3 CC1 ... Even2 Even3\n##  colData names(7): X.SampleID Primer ... SampleType Description\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: NULL\n##  rowTree: NULL\n##  colLinks: NULL\n##  colTree: NULL\n\n\nC.1.5 Calculating alpha diversity: estimate_richness = estimateDiversity\nNow we know how data stored in TreeSE can be accessed and the TreeSE data objects created. Let’s look at how we can calculate alpha diversity using mia compared to phyloseq package.\nThe mia command estimateDiversity() will return a TreeSE and the results are stored in colData, unlike the phyloseq command that outputs a data frame with just the diversity estimates.\nIn phyloseq you would need to add the alpha diversity separately to your sample data to keep it safe with the other sample level data.\n\n# Alpha diversity with phyloseq\ndf &lt;- estimate_richness(phy, measures = \"Shannon\")\ndf |&gt; head() # Inspect\n##           Shannon\n##  CL3     6.576517\n##  CC1     6.776603\n##  SV1     6.498494\n##  M31Fcsw 3.828368\n##  M11Fcsw 3.287666\n##  M31Plmr 4.289269\n\n# Add Shannon to the sample_data to keep results safe with other sample data\nphy_sampledata &lt;- sample_data(phy) |&gt; data.frame()\nphy_sampledata$shannon &lt;- df$Shannon\nsample_data(phy) &lt;- phy_sampledata\nsample_data(phy) |&gt; head()  # Inspect\n##          X.SampleID  Primer Final_Barcode Barcode_truncated_plus_T\n##  CL3            CL3 ILBC_01        AACGCA                   TGCGTT\n##  CC1            CC1 ILBC_02        AACTCG                   CGAGTT\n##  SV1            SV1 ILBC_03        AACTGT                   ACAGTT\n##  M31Fcsw    M31Fcsw ILBC_04        AAGAGA                   TCTCTT\n##  M11Fcsw    M11Fcsw ILBC_05        AAGCTG                   CAGCTT\n##  M31Plmr    M31Plmr ILBC_07        AATCGT                   ACGATT\n##          Barcode_full_length SampleType\n##  CL3             CTAGCGTGCGT       Soil\n##  CC1             CATCGACGAGT       Soil\n##  SV1             GTACGCACAGT       Soil\n##  M31Fcsw         TCGACATCTCT      Feces\n##  M11Fcsw         CGACTGCAGCT      Feces\n##  M31Plmr         CGAGTCACGAT       Skin\n##                                         Description  shannon\n##  CL3       Calhoun South Carolina Pine soil, pH 4.9 6.576517\n##  CC1       Cedar Creek Minnesota, grassland, pH 6.1 6.776603\n##  SV1     Sevilleta new Mexico, desert scrub, pH 8.3 6.498494\n##  M31Fcsw    M3, Day 1, fecal swab, whole body study 3.828368\n##  M11Fcsw   M1, Day 1, fecal swab, whole body study  3.287666\n##  M31Plmr    M3, Day 1, right palm, whole body study 4.289269\n\nFor the tse we will need to specify which assay (which normalization of the OTU table) we want to use, since we have three options now with the counts, relative abundance and CLR. We can check the assay names first.\n\nassayNames(tse) # Check the assay names\n##  [1] \"counts\"       \"relabundance\" \"clr\"\n\ntse &lt;- estimateDiversity(tse, assay.type = \"counts\", index = \"shannon\") # Let's use counts\n# Inspect the new colData with added alpha diversity estimate\ncolData(tse) |&gt; names() # shannon has been added to the colData\n##  [1] \"X.SampleID\"               \"Primer\"                  \n##  [3] \"Final_Barcode\"            \"Barcode_truncated_plus_T\"\n##  [5] \"Barcode_full_length\"      \"SampleType\"              \n##  [7] \"Description\"              \"shannon\"\n\nIf we want to extract a data frame that only has the alpha diversity it can be done easily.\n\n# Extract\ndf &lt;- colData(tse) |&gt; data.frame() |&gt; dplyr::select(matches(\"shannon\"))\n\n\nC.1.6 Calculating beta diversity: ordinate = runMDS\nWe can calculate PCoA with Bray-Curtis distances in phyloseq using the ordinate() command. The beta diversity calculation in mia outputs a TreeSE with a new type of data, reduced dimensions or reducedDim.\nHere we will use the scater package that runs the PCoA with runMDS(). (PCoA and MDS mean the same thing)\nIn phyloseq you would again need to add the dimensions to the sample data if you want to keep them safe with other metadata.\n\n# Run PCoA on the relative abundance data and store in phy_ord list\nphy_ord &lt;- ordinate(phy_relab, method = \"PCoA\", distance = \"bray\")\n\nlibrary(scater)\n\n# Ordinate with runMDS and implement the vegan's Bray-Curtis dissimilarity\n# distance calculation\ntse &lt;- runMDS(\n    tse,\n    FUN = getDissimilarity,\n    method = \"bray\",\n    assay.type = \"relabundance\",\n    name = \"MDS_bray\",\n    ncomponents = 10) # Let's also define how many dimensions\ntse # Inspect, now we have new reducedDim \"MDS_bray\"\n##  class: TreeSummarizedExperiment \n##  dim: 19216 26 \n##  metadata(0):\n##  assays(3): counts relabundance clr\n##  rownames(19216): 549322 522457 ... 200359 271582\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(26): CL3 CC1 ... Even2 Even3\n##  colData names(8): X.SampleID Primer ... Description shannon\n##  reducedDimNames(1): MDS_bray\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: NULL\n##  rowTree: NULL\n##  colLinks: NULL\n##  colTree: NULL\n\n\nC.1.7 Plotting ordinations: plot_ordination() = plotReducedDim()\n\nphyloseq has it’s own plotting fuction for ordinations.\n\nplot_ordination(physeq = phy, ordination = phy_ord, color = \"SampleType\")\n\n\n\n\n\n\n\nIt is also easy to plot the ordination stored in reducedDim in the tse using the plotReducedDim() function. We can first check what the name of the Bray-Curtis MDS/PCoA was incase we forgot.\n\n# Check reduced dim names\nreducedDimNames(tse)\n##  [1] \"MDS_bray\"\n\nOk, let’s plot.\n\n# Plot\nplotReducedDim(tse, \"MDS_bray\", color_by = \"SampleType\")\n\n\n\n\n\n\n# The sign is given arbitrarily. We can change it to match the plot_ordination\nreducedDim(tse)[, 1] &lt;- -reducedDim(tse)[, 1]\nreducedDim(tse)[, 2] &lt;- -reducedDim(tse)[, 2]\nplotReducedDim(tse, \"MDS_bray\", color_by = \"SampleType\")\n\n\n\n\n\n\n\n\nC.1.8 Agglomerating taxa: tax_glom() = agglomerateByRank()\n\nOften you might want to study your data using different taxonomic ranks, for example check if you see differences in the abundances of higher taxonomic levels.\n\nphy_fam &lt;- tax_glom(phy, taxrank = \"Family\")\n\nThis family level data object can again be conveniently stored in a tse object under altExp.\ntax_glom() removes the taxa which have not been assigned to the level given in taxrank by default (NArm = TRUE). So we will add the na.rm = TRUE to agglomerateByRank() function which is equivalent to the default behaviour of tax_glom().\n\naltExp(tse, \"Family\") &lt;- agglomerateByRank(tse, rank = \"Family\")\naltExp(tse, \"Family\")\n##  class: TreeSummarizedExperiment \n##  dim: 341 26 \n##  metadata(1): agglomerated_by_rank\n##  assays(3): counts relabundance clr\n##  rownames(341): 125ds10 211ds20 ... vadinHA31 wb1_P06\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(26): CL3 CC1 ... Even2 Even3\n##  colData names(8): X.SampleID Primer ... Description shannon\n##  reducedDimNames(1): MDS_bray\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: NULL\n##  rowTree: NULL\n##  colLinks: NULL\n##  colTree: NULL\n\n\nC.1.9 Cheatsheet\n\n\n\n\n\n\n\n\n\nFunctionality\nphyloseq\nmia.TreeSE\n\n\n\nAccess sample data\nsample_data()\nIndex columns\n\n\nAccess tax table\ntax_table()\nIndex rows\n\n\nAccess OTU table\notu_table()\nassays()\n\n\nBuild data object\nphyloseq()\nTreeSummarizedExperiment()\n\n\nCalculate alpha diversity\nestimate_richness()\nestimateDiversity()\n\n\nCalculate beta diversity\nordinate()\nrunMDS()\n\n\nPlot ordination\nplot_ordination()\nplotReducedDim()\n\n\nSubset taxa\nsubset_taxa()\nIndex rows\n\n\nSubset samples\nsubset_samples()\nIndex columns\n\n\nAggromerate taxa\ntax_glom()\nagglomerateByRank()\n\n\n\n\n\n\n\nData_type\nphyloseq\nTreeSE\n\n\n\nOTU table\notu_table\nassay\n\n\nTaxonomy table\ntax_table\nrowData\n\n\nSample data table\nsample_data\ncolData",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Extra material</span>"
    ]
  },
  {
    "objectID": "pages/extra_material.html#sec-16s-workflow",
    "href": "pages/extra_material.html#sec-16s-workflow",
    "title": "Appendix C — Extra material",
    "section": "\nC.2 16S workflow",
    "text": "C.2 16S workflow\nResult of amplicon sequencing is a large number of files that include all the sequences that were read from samples. Those sequences need to be matched with taxa. Additionally, we need to know how many times each taxa were found from each sample.\nThere are several algorithms to do that, and DADA2 is one of the most common. You can find DADA2 pipeline tutorial, for example, here. After the DADA2 portion of the tutorial is completed, the data is stored into phyloseq object (Bonus: Handoff to phyloseq). To store the data to TreeSE, follow the example below.\nYou can find full workflow script without further explanations and comments from Rmd file\nLoad required packages.\n\nlibrary(mia)\nlibrary(BiocManager)\nlibrary(Biostrings)\n\nCreate arbitrary example sample metadata like it was done in the tutorial. Usually, sample metadata is imported as a file.\n\nsamples.out &lt;- rownames(seqtab.nochim)\nsubject &lt;- sapply(strsplit(samples.out, \"D\"), `[`, 1)\ngender &lt;- substr(subject,1,1)\nsubject &lt;- substr(subject,2,999)\nday &lt;- as.integer(sapply(strsplit(samples.out, \"D\"), `[`, 2))\nsamdf &lt;- data.frame(Subject=subject, Gender=gender, Day=day)\nsamdf$When &lt;- \"Early\"\nsamdf$When[samdf$Day&gt;100] &lt;- \"Late\"\nrownames(samdf) &lt;- samples.out\n\nConvert data into right format and create a _TreeSE_ object.\n\n# Create a list that contains assays\ncounts &lt;- t(seqtab.nochim)\ncounts &lt;- as.matrix(counts)\nassays &lt;- SimpleList(counts = counts)\n\n# Convert `colData` and `rowData` into `DataFrame`\nsamdf &lt;- DataFrame(samdf)\ntaxa &lt;- DataFrame(taxa)\n\n# Create TreeSE\ntse &lt;- TreeSummarizedExperiment(\n    assays = assays,\n    colData = samdf,\n    rowData = taxa\n    )\n\n# Remove mock sample like it is also done in DADA2 pipeline tutorial\ntse &lt;- tse[ , colnames(tse) != \"mock\"]\n\nAdd sequences into referenceSeq slot and convert rownames into simpler format.\n\n# Convert sequences into right format\ndna &lt;- Biostrings::DNAStringSet( rownames(tse) )\n# Add sequences into referenceSeq slot\nreferenceSeq(tse) &lt;- dna\n# Convert rownames into ASV_number format\nrownames(tse) &lt;- paste0(\"ASV\", seq( nrow(tse) ))\ntse\n##  class: TreeSummarizedExperiment \n##  dim: 232 20 \n##  metadata(0):\n##  assays(1): counts\n##  rownames(232): ASV1 ASV2 ... ASV231 ASV232\n##  rowData names(7): Kingdom Phylum ... Genus Species\n##  colnames(20): F3D0 F3D1 ... F3D9 Mock\n##  colData names(4): Subject Gender Day When\n##  reducedDimNames(0):\n##  mainExpName: NULL\n##  altExpNames(0):\n##  rowLinks: NULL\n##  rowTree: NULL\n##  colLinks: NULL\n##  colTree: NULL\n##  referenceSeq: a DNAStringSet (232 sequences)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Extra material</span>"
    ]
  },
  {
    "objectID": "pages/extra_material.html#bayesian-multinomial-logistic-normal-models-sec-fido",
    "href": "pages/extra_material.html#bayesian-multinomial-logistic-normal-models-sec-fido",
    "title": "Appendix C — Extra material",
    "section": "\nC.3 Bayesian Multinomial Logistic-Normal Models {sec-fido}",
    "text": "C.3 Bayesian Multinomial Logistic-Normal Models {sec-fido}\nAnalysis using such model could be performed with the function pibble() from the fido package, wihch is in form of a Multinomial Logistic-Normal Linear Regression model; see vignette of package.\nThe following presents such an exemplary analysis based on the data of Sprockett et al. (2020) available through microbiomeDataSets package.\n\nSprockett, Daniel D., Melanie Martin, Elizabeth K. Costello, Adam R. Burns, Susan P. Holmes, Michael D. Gurven, and David A. Relman. 2020. “Microbiota Assembly, Structure, and Dynamics Among Tsimane Horticulturalists of the Bolivian Amazon.” Nat Commun 11 (1): 3772. https://doi.org/10.1038/s41467-020-17541-6.\n\nlibrary(fido)\n\nLoading the libraries and importing data:\n\nlibrary(fido)\n\n\nlibrary(microbiomeDataSets)\ntse &lt;- SprockettTHData()\n\nWe pick three covariates (“Sex”,“Age_Years”,“Delivery_Mode”) during this analysis as an example, and beforehand we check for missing data:\n\nlibrary(mia)\ncov_names &lt;- c(\"Sex\",\"Age_Years\",\"Delivery_Mode\")\nna_counts &lt;- apply(is.na(colData(tse)[,cov_names]), 2, sum)\nna_summary&lt;-as.data.frame(na_counts,row.names=cov_names)\n\nWe drop missing values of the covariates:\n\ntse &lt;- tse[ , !is.na(colData(tse)$Delivery_Mode) ]\ntse &lt;- tse[ , !is.na(colData(tse)$Age_Years) ]\n\nWe agglomerate microbiome data to Phylum:\n\ntse_phylum &lt;- agglomerateByRank(tse, \"Phylum\")\n\nWe extract the counts assay and covariate data to build the model matrix:\n\nY &lt;- assays(tse_phylum)$counts\n# design matrix\n# taking 3 covariates\nsample_data&lt;-as.data.frame(colData(tse_phylum)[,cov_names])\nX &lt;- t(model.matrix(~Sex+Age_Years+Delivery_Mode,data=sample_data))\n\nBuilding the parameters for the pibble() call to build the model; see more at vignette:\n\nn_taxa&lt;-nrow(Y)\nupsilon &lt;- n_taxa+3\nOmega &lt;- diag(n_taxa)\nG &lt;- cbind(diag(n_taxa-1), -1)\nXi &lt;- (upsilon-n_taxa)*G%*%Omega%*%t(G)\nTheta &lt;- matrix(0, n_taxa-1, nrow(X))\nGamma &lt;- diag(nrow(X))\n\nAutomatically initializing the priors and visualizing their distributions:\n\npriors &lt;- pibble(NULL, X, upsilon, Theta, Gamma, Xi)\nnames_covariates(priors) &lt;- rownames(X)\nplot(priors, pars=\"Lambda\") + ggplot2::xlim(c(-5, 5))\n\n\n\n\n\n\n\nEstimating the posterior by including our response data Y. Note: Some computational failures could occur (see discussion) the arguments multDirichletBoot calcGradHess could be passed in such case.\n\npriors$Y &lt;- Y\nposterior &lt;- refit(priors, optim_method=\"adam\", multDirichletBoot=0.5) #calcGradHess=FALSE\n\nPrinting a summary about the posterior:\n\nppc_summary(posterior)\n##  Proportions of Observations within 95% Credible Interval: 0.9968944\n\nPlotting the summary of the posterior distributions of the regression parameters:\n\nnames_categories(posterior) &lt;- rownames(Y)\nplot(posterior,par=\"Lambda\",focus.cov=rownames(X)[2:4])\n\n\n\n\n\n\n\nTaking a closer look at “Sex” and “Delivery_Mode”:\n\nplot(posterior, par=\"Lambda\", focus.cov = rownames(X)[c(2,4)])",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Extra material</span>"
    ]
  },
  {
    "objectID": "pages/extra_material.html#biclustering",
    "href": "pages/extra_material.html#biclustering",
    "title": "Appendix C — Extra material",
    "section": "\nC.4 Biclustering",
    "text": "C.4 Biclustering\nBiclustering methods cluster rows and columns simultaneously in order to find subsets of correlated features/samples.\nHere, we use following packages:\n\nbiclust\ncobiclust\n\ncobiclust is especially developed for microbiome data whereas biclust is more general method. In this section, we show two different cases and example solutions to apply biclustering to them.\n\nTaxa vs samples\nTaxa vs biomolecule/biomarker\n\nBiclusters can be visualized using heatmap or boxplot, for instance. For checking purposes, also scatter plot might be valid choice.\nCheck out more ideas for heatmaps from chapters Appendix D and Chapter 12.\n\nC.4.1 Taxa vs samples\nWhen you have microbial abundance matrices, we suggest to use cobiclust which is designed for microbial data.\nLoad example data\n\nlibrary(cobiclust)\ndata(\"HintikkaXOData\")\nmae &lt;- HintikkaXOData\n\nOnly the most prevalent taxa are included in analysis.\n\n# Subset data in the first experiment\nmae[[1]] &lt;- subsetByPrevalent(\n    mae[[1]], rank = \"Genus\", prevalence = 0.2, detection = 0.001)\n\n# rclr-transform in the first experiment\nmae[[1]] &lt;- transformAssay(mae[[1]], method = \"rclr\")\n\ncobiclust() takes counts table as an input and gives cobiclust object as an output. It includes clusters for taxa and samples.\n\n# Do clustering using counts table\nclusters &lt;- cobiclust(assay(mae[[1]], \"counts\"))\n\n# Get clusters\nrow_clusters &lt;- clusters$classification$rowclass\ncol_clusters &lt;- clusters$classification$colclass\n\n# Add clusters to rowdata and coldata\nrowData(mae[[1]])$clusters &lt;- factor(row_clusters)\ncolData(mae[[1]])$clusters &lt;- factor(col_clusters)\n\n# Order data based on clusters\nmae[[1]] &lt;- mae[[1]][\n    order(rowData(mae[[1]])$clusters), order(colData(mae[[1]])$clusters)]\n\n# Print clusters\nclusters$classification\n##  $rowclass\n##    [1] 1 1 1 1 1 1 1 1 1 1 2 2 1 2 1 1 1 1 1 2 1 1 2 1 1 2 1 1 1 1 1 1 1 1 1 1\n##   [37] 2 2 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 1 1 1 2 1 1 1 2 1 2 1 1 1 1 1 1\n##   [73] 1 1 2 2 1 1 1 1 1 1 2 1 1 1 1 1 1 1 2 2 1 1 2 1 1 2 2 1 1 1 1 1 2 1 1 1\n##  [109] 2 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 2 1 1 2 2 1 1 1\n##  \n##  $colclass\n##   C1  C2  C3  C4  C5  C6  C7  C8  C9 C10 C11 C12 C13 C14 C15 C16 C17 C18 C19 \n##    1   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2   2 \n##  C20 C21 C22 C23 C24 C25 C26 C27 C28 C29 C30 C31 C32 C33 C34 C35 C36 C37 C38 \n##    2   2   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3   3 \n##  C39 C40 \n##    3   1\n\nNext we can plot clusters. Annotated heatmap is a common choice.\n\nlibrary(ComplexHeatmap)\n# z-transform for heatmap\nmae[[1]] &lt;- transformAssay(\n    mae[[1]], assay.type = \"rclr\", MARGIN = \"features\", method = \"z\",\n    name = \"rclr_z\")\n\n# Create annotations. When column names are equal, they should share levels.\n# Here samples include 3 clusters, and taxa 2. That is why we have to make\n# column names unique.\nannotation_col &lt;- data.frame(colData(mae[[1]])[, \"clusters\", drop = FALSE])\ncolnames(annotation_col) &lt;- \"col_clusters\"\n\nannotation_row &lt;- data.frame(rowData(mae[[1]])[, \"clusters\", drop = FALSE])\ncolnames(annotation_row) &lt;- \"row_clusters\"\n\nPlot the heatmap.\n\npheatmap(\n    assay(mae[[1]], \"rclr_z\"), cluster_rows = F, cluster_cols = F,\n    annotation_col = annotation_col, annotation_row = annotation_row)\n\n\n\n\n\n\n\nBoxplot is commonly used to summarize the results:\n\nlibrary(ggplot2)\nlibrary(patchwork)\n\n# ggplot requires data in melted format\nmelt_assay &lt;- meltSE(\n    mae[[1]], assay.type = \"rclr\",\n    add_col_data = TRUE, add_row_data = TRUE)\n\n# patchwork two plots side-by-side\np1 &lt;- ggplot(melt_assay) +\n    geom_boxplot(aes(x = clusters.x, y = rclr)) +\n    labs(x = \"Taxa clusters\")\n\np2 &lt;- ggplot(melt_assay) +\n    geom_boxplot(aes(x = clusters.y, y = rclr)) +\n    labs(x = \"Sample clusters\")\n\np1 + p2\n\n\n\n\n\n\n\n\nC.4.2 Taxa vs biomolecules\nHere, we analyze cross-correlation between taxa and metabolites. This is a case, where we use biclust method which is suitable for numeric matrices in general. First we pre-process the data.\n\n# Samples must be in equal order\n# (Only 1st experiment was ordered in cobiclust step leading to unequal order)\nmae[[1]] &lt;- mae[[1]][, colnames(mae[[2]])]\n\n# Make rownames unique, since it is required by other steps\nrownames(mae[[1]]) &lt;- make.unique(rownames(mae[[1]]))\n\n# Transform the metabolites to be in log basis\nmae[[2]] &lt;- transformAssay(mae[[2]], assay.type = \"nmr\", method = \"log10\")\n\n# Add missing data to the metabolites\nreplace_na &lt;- function(row) {\n    na_indices &lt;- which(is.na(row))\n    non_na_values &lt;- row[!is.na(row)]\n    row[na_indices] &lt;- sample(non_na_values, length(na_indices), replace = TRUE)\n    row\n}\nassay(mae[[2]], \"log10\") &lt;- t(apply(assay(mae[[2]], \"log10\"), 1, replace_na))\n\nNext, we compute the Spearman correlation matrix.\n\n# Calculate correlations\ncorr &lt;- getExperimentCrossCorrelation(\n    mae, 1, 2, assay.type1 = \"rclr\", assay.type2 = \"log10\",\n    mode = \"matrix\", correlation = \"spearman\")\n\nbiclust() takes a matrix as an input and returns a biclust object.\n\nlibrary(biclust)\n# Set seed for reproducibility\nset.seed(3973)\n\n# Find biclusters\nbc &lt;- biclust(corr, method = BCPlaid(), verbose = FALSE)\n\nbc\n##  \n##  An object of class Biclust \n##  \n##  call:\n##      biclust(x = corr, method = BCPlaid(), verbose = FALSE)\n##  \n##  Number of Clusters found:  4 \n##  \n##  First  4  Cluster sizes:\n##                     BC 1 BC 2 BC 3 BC 4\n##  Number of Rows:      15   14   18    2\n##  Number of Columns:   14   13    9   10\n\nThe object includes cluster information. However compared to cobiclust, biclust object includes only information about clusters that were found, not general cluster.\nMeaning that if one cluster size of 5 features was found out of 20 features, those 15 features do not belong to any cluster. That is why we have to create an additional cluster for features/samples that are not assigned into any cluster.\n\n# Functions for obtaining biclust information\n\n# Get clusters for rows and columns\n.get_biclusters_from_biclust &lt;- function(bc, assay) {\n    # Get cluster information for columns and rows\n    bc_columns &lt;- t(bc@NumberxCol)\n    bc_columns &lt;- data.frame(bc_columns)\n    bc_rows &lt;- bc@RowxNumber\n    bc_rows &lt;- data.frame(bc_rows)\n\n    # Get data into right format\n    bc_columns &lt;- .manipulate_bc_data(bc_columns, assay, \"col\")\n    bc_rows &lt;- .manipulate_bc_data(bc_rows, assay, \"row\")\n\n    return(list(bc_columns = bc_columns, bc_rows = bc_rows))\n}\n\n# Input clusters, and how many observations there should be, i.e.,\n# the number of samples or features\n.manipulate_bc_data &lt;- function(bc_clusters, assay, row_col) {\n    # Get right dimension\n    dim &lt;- ifelse(row_col == \"col\", ncol(assay), nrow(assay))\n    # Get column/row names\n    if (row_col == \"col\") {\n        names &lt;- colnames(assay)\n    } else {\n        names &lt;- rownames(assay)\n    }\n\n    # If no clusters were found, create one. Otherwise create additional\n    # cluster which\n    # contain those samples that are not included in clusters that were found.\n    if (nrow(bc_clusters) != dim) {\n        bc_clusters &lt;- data.frame(cluster = rep(TRUE, dim))\n    } else {\n        # Create additional cluster that includes those samples/features that\n        # are not included in other clusters.\n        vec &lt;- ifelse(rowSums(bc_clusters) &gt; 0, FALSE, TRUE)\n\n        # If additional cluster contains samples, then add it\n        if (any(vec)) {\n            bc_clusters &lt;- cbind(bc_clusters, vec)\n        }\n    }\n\n    # Adjust row and column names\n    rownames(bc_clusters) &lt;- names\n    colnames(bc_clusters) &lt;- paste0(\"cluster_\", 1:ncol(bc_clusters))\n    return(bc_clusters)\n}\n\n\n# Get biclusters\nbcs &lt;- .get_biclusters_from_biclust(bc, corr)\n\nbicluster_rows &lt;- bcs$bc_rows\nbicluster_columns &lt;- bcs$bc_columns\n\n# Print biclusters for rows\nbicluster_rows |&gt; head()\n##                   cluster_1 cluster_2 cluster_3 cluster_4 cluster_5\n##  Ambiguous_taxa_1     FALSE     FALSE     FALSE     FALSE      TRUE\n##  Ambiguous_taxa_3      TRUE     FALSE      TRUE     FALSE     FALSE\n##  Ambiguous_taxa_4     FALSE     FALSE     FALSE     FALSE      TRUE\n##  Ambiguous_taxa_5     FALSE     FALSE     FALSE     FALSE      TRUE\n##  Ambiguous_taxa_7     FALSE     FALSE     FALSE     FALSE      TRUE\n##  Ambiguous_taxa_9     FALSE     FALSE     FALSE     FALSE      TRUE\n\nLet’s collect information for the scatter plot.\n\n# Function for obtaining sample-wise sum, mean, median, and mean variance\n# for each cluster\n\n.sum_mean_median_var &lt;- function(tse1, tse2, assay.type1, assay.type2, clusters1, clusters2) {\n    list &lt;- list()\n    # Create a data frame that includes all the information\n    for (i in 1:ncol(clusters1)) {\n        # Subset data based on cluster\n        tse_subset1 &lt;- tse1[clusters1[, i], ]\n        tse_subset2 &lt;- tse2[clusters2[, i], ]\n        # Get assay\n        assay1 &lt;- assay(tse_subset1, assay.type1)\n        assay2 &lt;- assay(tse_subset2, assay.type2)\n        # Calculate sum, mean, median, and mean variance\n        sum1 &lt;- colSums2(assay1, na.rm = T)\n        mean1 &lt;- colMeans2(assay1, na.rm = T)\n        median1 &lt;- colMedians(assay1, na.rm = T)\n        var1 &lt;- colVars(assay1, na.rm = T)\n\n        sum2 &lt;- colSums2(assay2, na.rm = T)\n        mean2 &lt;- colMeans2(assay2, na.rm = T)\n        median2 &lt;- colMedians(assay2, na.rm = T)\n        var2 &lt;- colVars(assay2, na.rm = T)\n\n        list[[i]] &lt;- data.frame(sample = colnames(tse1), sum1, sum2, mean1,\n                                 mean2, median1, median2, var1, var2)\n    }\n    return(list)\n}\n\n# Calculate info\ndf &lt;- .sum_mean_median_var(mae[[1]], mae[[2]], \"rclr\", \"log10\", bicluster_rows, bicluster_columns)\n\nNow we can create a scatter plot. X-axis includes median clr abundance of microbiome and y-axis median absolute concentration of each metabolite. Each data point represents a single sample.\nFrom the plots, we can see that there is low negative correlation in both cluster 1 and 3. This means that when abundance of bacteria belonging to cluster 1 or 3 is higher, the concentration of metabolites of cluster 1 or 3 is lower, and vice versa.\n\npics &lt;- list()\nfor (i in seq_along(df)) {\n    pics[[i]] &lt;- ggplot(df[[i]]) +\n        geom_point(aes(x = median1, y = median2)) +\n        labs(title = paste0(\"Cluster \", i), x = \"Taxa (rclr median)\",\n             y = \"Metabolites (abs. median)\")\n    print(pics[[i]])\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\npics[[1]] + pics[[2]] + pics[[3]]\n\n\n\n\n\n\n\npheatmap does not allow boolean values, so they must be converted into factors.\n\nbicluster_columns &lt;- data.frame(apply(bicluster_columns, 2, as.factor))\nbicluster_rows &lt;- data.frame(apply(bicluster_rows, 2, as.factor))\n\nAgain, we can plot clusters with heatmap.\n\n# Adjust colors for all clusters\nif (ncol(bicluster_rows) &gt; ncol(bicluster_columns)) {\n    cluster_names &lt;- colnames(bicluster_rows)\n} else {\n    cluster_names &lt;- colnames(bicluster_columns)\n}\nannotation_colors &lt;- list()\nfor (name in cluster_names) {\n    annotation_colors[[name]] &lt;- c(\"TRUE\" = \"red\", \"FALSE\" = \"white\")\n}\n\n# Create a heatmap\npheatmap(corr, cluster_cols = F, cluster_rows = F,\n         annotation_col = bicluster_columns, annotation_row = bicluster_rows,\n         annotation_colors = annotation_colors)",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>C</span>  <span class='chapter-title'>Extra material</span>"
    ]
  },
  {
    "objectID": "pages/visualization.html",
    "href": "pages/visualization.html",
    "title": "Appendix D — Visualization",
    "section": "",
    "text": "D.1 Pre-analysis exploration",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "pages/visualization.html#pre-analysis-exploration",
    "href": "pages/visualization.html#pre-analysis-exploration",
    "title": "Appendix D — Visualization",
    "section": "",
    "text": "D.1.1 Accessing row and column data\nSCE and TreeSE objects contain multiple layers of information in the form of rows, columns and meta data. The scater package supports in accessing, modifying and graphing the meta data related to features as well as samples.\n\n# list row meta data\nnames(rowData(tse))\n##  [1] \"Kingdom\" \"Phylum\"  \"Class\"   \"Order\"   \"Family\"  \"Genus\"   \"Species\"\n# list column meta data\nnames(colData(tse))\n##  [1] \"X.SampleID\"               \"Primer\"                  \n##  [3] \"Final_Barcode\"            \"Barcode_truncated_plus_T\"\n##  [5] \"Barcode_full_length\"      \"SampleType\"              \n##  [7] \"Description\"\n\nSuch meta data can be directly plotted with the functions plotRowData() and plotColData().\n\n# obtain QC data\ntse &lt;- addPerCellQC(tse)\ntse &lt;- addPerFeatureQC(tse)\n# plot QC Mean against Species\nplotRowData(tse, \"mean\", \"Species\") +\n    theme(axis.text.x = element_blank()) +\n    labs(x = \"Species\", y = \"QC Mean\")\n\n\n\n\n\n\n# plot QC Sum against Sample ID, colour-labeled by Sample Type\nplotColData(tse, \"sum\", \"X.SampleID\", colour_by = \"SampleType\") +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n    labs(x = \"Sample ID\", y = \"QC Sum\")\n\n\n\n\n\n\n\nAlternatively, they can be converted to a data.frame object and passed to ggplot.\n\n# store colData into a data frame\n# plot Number of Samples against Sampling Site\nggplot(colData(tse), aes(x = SampleType)) +\n    geom_bar(width = 0.5) +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +\n    labs(\n        x = \"Sampling Site\",\n        y = \"Number of Samples\")\n\n\n\n\n\n\n\nFurther methods of application can be found in the chapters Section 11.3 and in a few external tutorials with open data. Additionally, rowData and colData allow manipulation and subsetting of large data sets into smaller units, as explained in chapter Chapter 9.\n\nD.1.2 Viewing abundance and prevalence patterns\nPrior-to-analysis exploration may involve questions such as how microorganisms are distributed across samples (abundance) and what microorganisms are present in most of the samples (prevalence). The information on abundance and prevalence can be summarized into a jitter or density plot and a tree, respectively, with the miaViz package.\nSpecifically, the functions plotAbundance(), plotAbundanceDensity() and plotRowTree() are used, and examples on their usage are discussed throughout chapter Chapter 11.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "pages/visualization.html#diversity-estimation",
    "href": "pages/visualization.html#diversity-estimation",
    "title": "Appendix D — Visualization",
    "section": "\nD.2 Diversity estimation",
    "text": "D.2 Diversity estimation\nAlpha diversity is commonly measured as one of the diversity indices explained in chapter Chapter 13. Because the focus lies on each sample separately, one-dimensional plots, such as scatter, violin and box plots, are suitable.\nBeta diversity is generally evaluated as one of the dissimilarity indices reported in chapter Chapter 14. Unlike alpha diversity, samples are compared collectively to estimate the heterogeneity across them, therefore multidimensional plots, such as Shepard and ordination plots are suitable.\n\n\n\n\n\n\n\n\nalpha diversity\nbeta diversity\n\n\n\nused metrics\ndiversity indices\ndissimilarity indices\n\n\nmetric dimensionality\none-dimensional\nmultidimensional\n\n\nsuitable visualization\nscatter, violin, box plots\nShepard, ordination plots\n\n\n\nIn conclusion, visualization techniques for alpha and beta diversity significantly differ from one another.\n\nD.2.1 Alpha diversity with scatter, violin and box plots\nThe basic method to visualize the diversity values assigned to the different samples in a TSE object includes the following, where each data point represents one sample:\n\n# estimate shannon diversity index\ntse &lt;- addAlpha(tse, assay.type = \"counts\", index = c(\"shannon\", \"faith\"))\n# plot shannon diversity index, colour-labeled by Sample Type\nplotColData(tse, \"shannon\", colour_by = \"SampleType\")\n\n\n\n\n\n\n\nThe several indices available for the evaluation of alpha diversity often return slightly divergent results, which can be visually compared with a multiple violin or box plot. For this purpose, plotColData() (for violin plots) or ggplot (for box plots) are recursively applied to a number of diversity indices with the function lapply() and the multi-panel plotting functionality of the patchwork package is then exploited.\n\n# generate plots for shannon and faith indices\n# and store them into a list\nplots &lt;- lapply(\n    c(\"shannon\", \"faith\"), function(i)\n        ggplot(colData(tse), aes_string(y = i)) +\n        geom_boxplot() +\n        theme(\n            axis.text.x = element_blank(),\n            axis.ticks.x = element_blank())\n    )\n# combine plots with patchwork\nplots[[1]] + plots[[2]]\n\n\n\n\n\n\n\nThe analogous output in the form of a violin plot is obtained in chapter Section 13.1.2. In addition, box plots that group samples according to certain information, such as origin, sex, age and health condition, can be labeled with p-values for significant differences with the package ggpubr package, as shown in chapter Chapter 13.\n\nD.2.2 Beta diversity with Shepard and coordination plots\nThe scater package offers the general function plotReducedDim(). In its basic form, it takes a TreeSE object and the results on sample similarity stored in the same object, which can be evaluated with the following coordination methods:\n\nrunMDS()\nrunNMDS()\nrunPCA()\nrunTSNE()\nrunUMAP()\n\nSince these clustering techniques allow for multiple coordinates or components, coordination plots can also span multiple dimensions, which is explained in chapter Appendix C.\n\n# perform NMDS coordination method\ntse &lt;- runNMDS(tse, FUN = vegan::vegdist, name = \"NMDS\")\n##  initial  value 47.733208 \n##  iter   5 value 33.853364\n##  iter  10 value 32.891200\n##  final  value 32.823570 \n##  converged\n# plot results of a 2-component NMDS on tse,\n# coloured-scaled by shannon diversity index\nplotReducedDim(tse, \"NMDS\", colour_by = \"shannon\")\n\n\n\n\n\n\n\nMultiple combinations of coordinates or dimensions can also be integrated into a multi-panel arrangement.\n\n# perform MDS coordination method\ntse &lt;- runMDS(\n    tse,\n    FUN = vegan::vegdist,\n    method = \"bray\",\n    name = \"MDS\",\n    assay.type = \"counts\",\n    ncomponents = 3)\n# plot results of a 3-component MDS on tse,\n# coloured-scaled by faith diversity index\nplotReducedDim(tse, \"MDS\", ncomponents = c(1:3), colour_by = \"faith\")\n\n\n\n\n\n\n\nSimilarly to iterating plotColData() over indices of alpha diversity, lapply() can be used in combination with patchwork to recursively apply plotReducedDim() and visually compare results among various coordination methods.\n\n# generate plots for MDS and NMDS methods\n# and store them into a list\nplots &lt;- lapply(\n    c(\"MDS\", \"NMDS\"),\n    plotReducedDim,\n    object = tse,\n    colour_by = \"shannon\")\n# combine plots with patchwork\nplots[[1]] + plots[[2]] +\n    plot_layout(guides = \"collect\")\n\n\n\n\n\n\n\nFor similar examples, readers are referred to chapter Chapter 14. Further material on the graphic capabilities of patchwork is available in its official package tutorial.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "pages/visualization.html#heatmaps",
    "href": "pages/visualization.html#heatmaps",
    "title": "Appendix D — Visualization",
    "section": "\nD.3 Heatmaps",
    "text": "D.3 Heatmaps\nAs described in chapter Chapter 12, bar plots and heatmaps can offer a useful insight into the composition of a community. Simple methods involve the functions plotAbundance() and geom_tile() in combination with scale_fill_gradientn() from the packages miaViz and ggplot2, respectively.\nFor instance, below the composition of multiple samples (x axis) is reported in terms of relative abundances (y axis) for the top 10 taxa at the Order rank. Bar plots and heatmaps with analogous information at the Phylum level are available in the aforementioned chapter.\n\n# agglomerate tse by Order\ntse_order &lt;- agglomerateByRank(tse, rank = \"Order\")\n# transform counts into relative abundance\ntse_order &lt;- transformAssay(\n    tse_order, assay.type = \"counts\", method = \"relabundance\")\n# get top orders\ntop_taxa &lt;- getTop(tse_order, top = 10)\n# leave only names for top 10 orders and label the rest with \"Other\"\norder_renamed &lt;- lapply(\n    rowData(tse_order)$Order,\n    function(x){if (x %in% top_taxa) {x} else {\"Other\"}})\nrowData(tse_order)$Order &lt;- as.character(order_renamed)\n# plot composition as a bar plot\nplotAbundance(\n    tse_order,\n    assay.type = \"relabundance\",\n    rank = \"Order\",\n    order.row.by = \"abund\",\n    order.col.by = \"Clostridiales\")\n\n\n\n\n\n\n\nTo add a sample annotation, you can combine plots that you get from the output of plotAbundance().\n\n# Create plots\nplots &lt;- plotAbundance(\n    tse_order,\n    assay.type = \"relabundance\",\n    rank = \"Order\",\n    order.row.by = \"abund\",\n    order.col.by = \"Clostridiales\",\n    features = \"SampleType\")\n\n# Modify the legend of the first plot to be smaller\nplots[[1]] &lt;- plots[[1]] +\n    theme(\n        legend.key.size = unit(0.3, 'cm'),\n        legend.text = element_text(size = 6),\n        legend.title = element_text(size = 8))\n\n# Modify the legend of the second plot to be smaller\nplots[[2]] &lt;- plots[[2]] +\n    theme(\n        legend.key.height = unit(0.3, 'cm'),\n        legend.key.width = unit(0.3, 'cm'),\n        legend.text = element_text(size = 6),\n        legend.title = element_text(size = 8),\n        legend.direction = \"vertical\")\n\n# Load required packages\nlibrary(ggpubr)\nlibrary(patchwork)\n# Combine legends\nlegend &lt;- wrap_plots(\n    as_ggplot(get_legend(plots[[1]])),\n    as_ggplot(get_legend(plots[[2]])),\n    ncol = 1)\n\n# Removes legends from the plots\nplots[[1]] &lt;- plots[[1]] + theme(legend.position = \"none\")\nplots[[2]] &lt;- plots[[2]] +\n    theme(legend.position = \"none\", axis.title.x=element_blank())\n\n# Combine plots\nplot &lt;- wrap_plots(plots[[2]], plots[[1]], ncol = 1, heights = c(2, 10))\n# Combine the plot with the legend\nwrap_plots(plot, legend, nrow = 1, widths = c(2, 1))\n\n\n\n\n\n\n\nFor more sophisticated visualizations than those produced with plotAbundance() and ggplot2, the packages pheatmap and sechm provide methods to include feature and sample clusters in a heatmap, along with further functionality.\n\n# Agglomerate tse by phylum\ntse_phylum &lt;- agglomerateByRank(tse, rank = \"Phylum\")\n\n# Add clr-transformation on samples\ntse_phylum &lt;- transformAssay(\n    tse_phylum, MARGIN = \"cols\", method = \"clr\", assay.type = \"counts\",\n    pseudocount = 1)\n\n# Add standardize-transformation on features (taxa)\ntse_phylum &lt;- transformAssay(\n    tse_phylum, assay.type = \"clr\", MARGIN = \"rows\",\n    method = \"standardize\", name = \"clr_z\")\n\n# Take subset: only samples from feces, skin, or tongue\ntse_phylum_subset &lt;- tse_phylum[\n    , tse_phylum$SampleType %in% c(\"Feces\", \"Skin\", \"Tongue\") ]\n\n# Add clr-transformation\ntse_phylum_subset &lt;- transformAssay(\n    tse_phylum_subset, method = \"clr\", MARGIN=\"cols\",\n    assay.type = \"counts\", pseudocount = 1)\n\n# Does standardize-transformation\ntse_phylum_subset &lt;- transformAssay(\n    tse_phylum_subset, assay.type = \"clr\", MARGIN = \"rows\",\n    method = \"standardize\", name = \"clr_z\")\n\n# Get n most abundant taxa, and subsets the data by them\ntop_taxa &lt;- getTop(tse_phylum_subset, top = 20)\ntse_phylum_subset &lt;- tse_phylum_subset[top_taxa, ]\n\n# Gets the assay table\nmat &lt;- assay(tse_phylum_subset, \"clr_z\")\n\n# Creates the heatmap\npheatmap(mat)\n\n\n\n\n\n\n\nWe can cluster both samples and features hierarchically and add them to the x and y axes of the heatmap, respectively.\n\n# Hierarchical clustering\ntaxa_hclust &lt;- hclust(dist(mat), method = \"complete\")\n\n# Creates a phylogenetic tree\ntaxa_tree &lt;- as.phylo(taxa_hclust)\n\n# Plot taxa tree\ntaxa_tree &lt;- ggtree(taxa_tree) +\n  theme(plot.margin=margin(0,0,0,0)) # removes margins\n\n# Get order of taxa in plot\ntaxa_ordered &lt;- get_taxa_name(taxa_tree)\n\n# to view the tree, run\n# taxa_tree\n\nBased on phylo tree, we decide to create three clusters.\n\n# Creates clusters\ntaxa_clusters &lt;- cutree(tree = taxa_hclust, k = 3)\n\n# Converts into data frame\ntaxa_clusters &lt;- data.frame(clusters = taxa_clusters)\ntaxa_clusters$clusters &lt;- factor(taxa_clusters$clusters)\n\n# Order data so that it's same as in phylo tree\ntaxa_clusters &lt;- taxa_clusters[taxa_ordered, , drop = FALSE]\n\n# Prints taxa and their clusters\ntaxa_clusters\n##                   clusters\n##  Chloroflexi             3\n##  Actinobacteria          3\n##  Crenarchaeota           3\n##  Planctomycetes          3\n##  Gemmatimonadetes        3\n##  Thermi                  3\n##  Acidobacteria           3\n##  Spirochaetes            2\n##  Fusobacteria            2\n##  SR1                     2\n##  Cyanobacteria           2\n##  Proteobacteria          2\n##  Synergistetes           2\n##  Lentisphaerae           1\n##  Bacteroidetes           1\n##  Verrucomicrobia         1\n##  Tenericutes             1\n##  Firmicutes              1\n##  Euryarchaeota           1\n##  SAR406                  1\n\nThe information on the clusters is then added to the feature meta data.\n\n# Adds information to rowData\nrowData(tse_phylum_subset)$clusters &lt;- taxa_clusters[order(match(rownames(taxa_clusters), rownames(tse_phylum_subset))), ]\n\n# Prints taxa and their clusters\nrowData(tse_phylum_subset)$clusters\n##   [1] 1 1 2 3 2 2 1 1 1 1 3 2 3 3 3 2 2 3 3 1\n##  Levels: 1 2 3\n\nSimilarly, samples are hierarchically grouped into clusters, the most suitable number of clusters for the plot is selected and the new information is stored into the sample meta data.\n\n# Hierarchical clustering\nsample_hclust &lt;- hclust(dist(t(mat)), method = \"complete\")\n\n# Creates a phylogenetic tree\nsample_tree &lt;- as.phylo(sample_hclust)\n\n# Plot sample tree\nsample_tree &lt;- ggtree(sample_tree) + layout_dendrogram() +\n  theme(plot.margin=margin(0,0,0,0)) # removes margins\n\n# Get order of samples in plot\nsamples_ordered &lt;- rev(get_taxa_name(sample_tree))\n\n# to view the tree, run\n# sample_tree\n\n# Creates clusters\nsample_clusters &lt;- factor(cutree(tree = sample_hclust, k = 3))\n\n# Converts into data frame\nsample_data &lt;- data.frame(clusters = sample_clusters)\n\n# Order data so that it's same as in phylo tree\nsample_data &lt;- sample_data[samples_ordered, , drop = FALSE]\n\n# Order data based on\ntse_phylum_subset &lt;- tse_phylum_subset[ , rownames(sample_data)]\n\n# Add sample type data\nsample_data$sample_types &lt;- unfactor(colData(tse_phylum_subset)$SampleType)\n\nsample_data\n##          clusters sample_types\n##  M11Plmr        2         Skin\n##  M31Plmr        2         Skin\n##  F21Plmr        2         Skin\n##  M31Fcsw        1        Feces\n##  M11Fcsw        1        Feces\n##  TS28           3        Feces\n##  TS29           3        Feces\n##  M31Tong        3       Tongue\n##  M11Tong        3       Tongue\n\nNow we can create heatmap with additional annotations.\n\n# Determines the scaling of colors\n# Scale colors\nbreaks &lt;- seq(-ceiling(max(abs(mat))), ceiling(max(abs(mat))),\n              length.out = ifelse( max(abs(mat))&gt;5, 2*ceiling(max(abs(mat))), 10 ) )\ncolors &lt;- colorRampPalette(c(\"darkblue\", \"blue\", \"white\", \"red\", \"darkred\"))(length(breaks)-1)\n\npheatmap(\n    mat, annotation_row = taxa_clusters,\n    annotation_col = sample_data,\n    breaks = breaks,\n    color = colors)\n\n\n\n\n\n\n\nThe package sechm allows for further visual capabilities and flexibility. In this case, the clustering step is automatically performed by the plotting function and does not need to be executed in advance.\n\n# Stores annotation colros to metadata\nmetadata(tse_phylum_subset)$anno_colors$SampleType &lt;- c(\n    Feces = \"blue\", Skin = \"red\", Tongue = \"gray\")\n\n# Create a plot\nsechm(\n    tse_phylum_subset,\n    features = rownames(tse_phylum_subset),\n    assayName = \"clr\",\n    do.scale = TRUE,\n    top_annotation = c(\"SampleType\"),\n    gaps_at = \"SampleType\",\n    cluster_cols = TRUE, cluster_rows = TRUE)\n\n\n\n\n\n\n\nIt is also possible to create an analogous heatmap by just using the ggplot2 package. However, a relatively long code is required to generate an identical output.\n\n# Add feature names to column as a factor\ntaxa_clusters$Feature &lt;- rownames(taxa_clusters)\ntaxa_clusters$Feature &lt;- factor(taxa_clusters$Feature, levels = taxa_clusters$Feature)\n\n# Create annotation plot\nrow_annotation &lt;- ggplot(taxa_clusters) +\n    geom_tile(aes(x = NA, y = Feature, fill = clusters)) +\n    coord_equal(ratio = 1) +\n    theme(\n        axis.text.x = element_blank(),\n        axis.text.y = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.title.y = element_blank(),\n        axis.title.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n        plot.margin = margin(0, 0, 0, 0)\n    ) +\n    labs(fill = \"Clusters\", x = \"Clusters\")\n\n# Add sample names to one of the columns\nsample_data$sample &lt;- factor(\n    rownames(sample_data), levels = rownames(sample_data))\n\n# Create annotation plot\nsample_types_annotation &lt;- ggplot(sample_data) +\n    scale_y_discrete(position = \"right\", expand = c(0,0)) +\n    geom_tile(aes(y = NA, x = sample, fill = sample_types)) +\n    coord_equal(ratio = 1) +\n    theme(\n        axis.text.x = element_blank(),\n        axis.text.y = element_blank(),\n        axis.title.x = element_blank(),\n        axis.ticks.x = element_blank(),\n        plot.margin = margin(0, 0, 0, 0),\n        axis.title.y.right = element_text(angle = 0, vjust = 0.5)\n    ) +\n    labs(fill = \"Sample types\", y = \"Sample types\")\n\nsample_clusters_annotation &lt;- ggplot(sample_data) +\n    scale_y_discrete(position = \"right\", expand = c(0,0)) +\n    geom_tile(aes(y = NA, x = sample, fill = clusters)) +\n    coord_equal(ratio = 1) +\n    theme(\n        axis.text.x = element_blank(),\n        axis.text.y = element_blank(),\n        axis.title.x = element_blank(),\n        axis.ticks.x = element_blank(),\n        plot.margin = margin(0, 0, 0, 0),\n        axis.title.y.right = element_text(angle = 0, vjust = 0.5)\n    ) +\n    labs(fill = \"Clusters\", y = \"Clusters\")\n\n# Order data based on clusters and sample types\nmat &lt;- mat[unfactor(taxa_clusters$Feature), unfactor(sample_data$sample)]\n\n# ggplot requires data in melted format\nmelted_mat &lt;- melt(mat)\ncolnames(melted_mat) &lt;- c(\"Taxa\", \"Sample\", \"clr_z\")\n\n# Determines the scaling of colors\nmaxval &lt;- round(max(abs(melted_mat$clr_z)))\nlimits &lt;- c(-maxval, maxval)\nbreaks &lt;- seq(from = min(limits), to = max(limits), by = 0.5)\ncolours &lt;- c(\"darkblue\", \"blue\", \"white\", \"red\", \"darkred\")\n\nheatmap &lt;- ggplot(melted_mat) +\n    geom_tile(aes(x = Sample, y = Taxa, fill = clr_z)) +\n    theme(\n        axis.title.y = element_blank(),\n        axis.title.x = element_blank(),\n        axis.ticks.y = element_blank(),\n        axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1),\n        plot.margin = margin(0, 0, 0, 0), # removes margins\n        legend.key.height = unit(1, 'cm')\n    ) +\n    scale_fill_gradientn(\n        name = \"CLR + Z transform\",\n        breaks = breaks,\n        limits = limits,\n        colours = colours) +\n    scale_y_discrete(position = \"right\")\n\nheatmap\n\n\n\n\n\n\n\n\nlibrary(patchwork)\n\n# Create layout\ndesign &lt;- c(\n      patchwork::area(3, 1, 4, 1),\n      patchwork::area(1, 2, 1, 3),\n      patchwork::area(2, 2, 2, 3),\n      patchwork::area(3, 2, 4, 3)\n)\n# to view the design, run\n# plot(design)\n\n# Combine plots\nplot &lt;- row_annotation +\n    sample_clusters_annotation +\n    sample_types_annotation +\n    heatmap  +\n    plot_layout(\n        design = design, guides = \"collect\",\n        # Specify layout, collect legends\n\n        # Adjust widths and heights to align plots.\n        # When annotation plot is larger, it might not fit into\n        # its column/row.\n        # Then you need to make column/row larger.\n\n        # Relative widths and heights of each column and row:\n        # Currently, the width of the first column is 15 % and the height of\n        # first two rows are 30 % the size of others\n\n        # To get this work most of the times, you can adjust all sizes to be\n        # 1, i.e. equal, but then the gaps between plots are larger.\n        widths = c(0.15, 1, 1),\n        heights = c(0.3, 0.3, 1, 1))\n\nplot\n\n\n\n\n\n\n\n\n# Create layout\ndesign &lt;- c(\n      patchwork::area(4, 1, 5, 1),\n      patchwork::area(4, 2, 5, 2),\n      patchwork::area(1, 3, 1, 4),\n      patchwork::area(2, 3, 2, 4),\n      patchwork::area(3, 3, 3, 4),\n      patchwork::area(4, 3, 5, 4)\n)\n\n# to view the design, run\n# plot(design)\n\n# Combine plots\nplot &lt;- taxa_tree +\n    row_annotation +\n    sample_tree +\n    sample_clusters_annotation +\n    sample_types_annotation +\n    heatmap +\n    plot_layout(\n        design = design, guides = \"collect\", # Specify layout, collect legends\n        widths = c(0.2, 0.15, 1, 1, 1),\n        heights = c(0.1, 0.15, 0.15, 0.25, 1, 1))\n\nplot\n\n\n\n\n\n\n\nHeatmaps find several other applications in biclustering and multi-assay analyses. These are discussed further in chapters Chapter 15 and Section 20.1.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "pages/visualization.html#interactive-3d-plots",
    "href": "pages/visualization.html#interactive-3d-plots",
    "title": "Appendix D — Visualization",
    "section": "\nD.4 Interactive 3D Plots",
    "text": "D.4 Interactive 3D Plots\n\n# Load libraries\nlibrary(rgl)\nlibrary(plotly)\n\n\nlibrary(knitr)\nknitr::knit_hooks$set(webgl = hook_webgl)\n\nIn this section we make a 3D version of the earlier PCoA plot (see @ref(quality-control)), with the help of the plotly (Sievert 2020).\n\nSievert, Carson. 2020. Interactive Web-Based Data Visualization with r, Plotly, and Shiny. Chapman; Hall/CRC. https://plotly-r.com.\n\n# Importing necessary libraries\nlibrary(curatedMetagenomicData)\nlibrary(dplyr)\nlibrary(DT)\nlibrary(mia)\nlibrary(scater)\n\n# Querying the data\ntse &lt;- sampleMetadata |&gt;\n    filter(age &gt;= 18) |&gt; # taking only data of age 18 or above\n    filter(!is.na(alcohol)) |&gt; # excluding missing values\n    returnSamples(\"relative_abundance\")\n\ntse_Genus &lt;- agglomerateByRank(tse, rank=\"genus\")\n\n# Performing PCoA with Bray-Curtis dissimilarity.\ntse_Genus &lt;- runMDS(\n    tse_Genus, # adds reduced dimensionalities to tse_Genus\n    FUN = vegan::vegdist,\n    method = \"bray\",\n    ncomponents = 3, # calculates three principal coordinates\n    assay.type = \"relative_abundance\", # calculates Bray-Curtis from relative abundace\n    name = \"MDS_bray\") #name of the PCoA within the tse\n\ne &lt;- attr(reducedDim(tse_Genus, \"MDS_bray\"), \"eig\")\nrel_eig &lt;- e / sum(e[e &gt; 0])\n\n# Extract the coordinates as a dataframe\ncoordinates &lt;- as.data.frame(reducedDim(tse_Genus,\"MDS_bray\"))\n\ncoordinates |&gt; head()\n##              V1      V2         V3\n##  WBE003 -0.5424 -0.4722  0.0162063\n##  WBE004 -0.5756 -0.4973  0.0006937\n##  WBE005 -0.5770 -0.5009 -0.0003110\n##  WBE006 -0.5851 -0.5096 -0.0001041\n##  WBE007 -0.5564 -0.4775 -0.0015276\n##  WBE008 -0.5548 -0.4757 -0.0007847\n\n# plot the coordinates using plotly and add the explained variance to the axes\nplot_ly(coordinates, x = ~V1, y = ~V2, z = ~V3, color = ~V3) |&gt;\n  add_markers() |&gt;\n  layout(\n      scene = list(\n          xaxis = list(title = paste(\"PCoA 1 (\", round(100 * rel_eig[1], 1), \"%)\", sep = \"\")),\n          yaxis = list(title = paste(\"PCoA 2 (\", round(100 * rel_eig[2], 1), \"%)\", sep = \"\")),\n          zaxis = list(title = paste(\"PCoA 3 (\", round(100 * rel_eig[3], 1), \"%)\", sep = \"\"))\n    )\n  )\n\n\n\n\n\n\n\n\n\n\n\nTip\n\n\n\nFor more on microbiome visualization techniques, you can check the microbiome tutorials. However, note that these tutorials utilize the microbiome package, so the tools presented there are not directly compatible with the miaverse ecosystem.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>D</span>  <span class='chapter-title'>Visualization</span>"
    ]
  },
  {
    "objectID": "pages/session_info.html",
    "href": "pages/session_info.html",
    "title": "Appendix E — Technical info",
    "section": "",
    "text": "E.1 Docker image\nA Docker image built from this repository is available here:\n👉 ghcr.io/microbiome/oma 🐳",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Technical info</span>"
    ]
  },
  {
    "objectID": "pages/session_info.html#sec-docker-image",
    "href": "pages/session_info.html#sec-docker-image",
    "title": "Appendix E — Technical info",
    "section": "",
    "text": "Get started now 🎉\n\n\n\nYou can get access to all the packages used in this book in &lt; 1 minute, using this command in a terminal:\n\n\n\nbash\n\ndocker run -it ghcr.io/microbiome/oma:devel R",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Technical info</span>"
    ]
  },
  {
    "objectID": "pages/session_info.html#rstudio-server",
    "href": "pages/session_info.html#rstudio-server",
    "title": "Appendix E — Technical info",
    "section": "RStudio Server",
    "text": "RStudio Server\nAn RStudio Server instance can be initiated from the Docker image as follows:\n\n\n\nbash\n\ndocker run \\\n    --volume &lt;local_folder&gt;:&lt;destination_folder&gt; \\\n    -e PASSWORD=OHCA \\\n    -p 8787:8787 \\\n    ghcr.io/microbiome/oma:devel\n\n\nThe initiated RStudio Server instance will be available at https://localhost:8787.",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Technical info</span>"
    ]
  },
  {
    "objectID": "pages/session_info.html#sec-session-info",
    "href": "pages/session_info.html#sec-session-info",
    "title": "Appendix E — Technical info",
    "section": "\nE.2 Session info",
    "text": "E.2 Session info\n\n\n\n\n\n\nClick to expand 👇\n\n\n\n\n\n\nsessioninfo::session_info(\n    installed.packages()[,\"Package\"],\n    include_base = TRUE\n)\n##  ─ Session info ────────────────────────────────────────────────────────────\n##   setting  value\n##   version  R version 4.4.1 (2024-06-14)\n##   os       Ubuntu 22.04.5 LTS\n##   system   x86_64, linux-gnu\n##   ui       X11\n##   language (EN)\n##   collate  C\n##   ctype    en_US.UTF-8\n##   tz       Etc/UTC\n##   date     2024-10-06\n##   pandoc   3.4 @ /usr/bin/ (via rmarkdown)\n##  \n##  ─ Packages ────────────────────────────────────────────────────────────────\n##   package                  * version    date (UTC) lib source\n##   abind                      1.4-8      2024-09-12 [2] RSPM (R 4.4.0)\n##   additivityTests            1.1-4.2    2024-05-14 [2] RSPM (R 4.4.0)\n##   ade4                       1.7-22     2023-02-06 [2] RSPM (R 4.4.0)\n##   ALDEx2                     1.37.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   ANCOMBC                    2.7.0      2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   AnnotationDbi              1.67.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   AnnotationHub              3.13.3     2024-08-19 [2] Bioconductor 3.20 (R 4.4.1)\n##   ape                        5.8        2024-04-11 [2] RSPM (R 4.4.0)\n##   aplot                      0.2.3      2024-06-17 [2] RSPM (R 4.4.0)\n##   arrayhelpers               1.1-0      2020-02-04 [2] RSPM (R 4.4.0)\n##   askpass                    1.2.1      2024-10-04 [2] RSPM (R 4.4.0)\n##   assertthat                 0.2.1      2019-03-21 [2] RSPM (R 4.4.0)\n##   assorthead                 0.99.8     2024-09-17 [2] Bioconductor 3.20 (R 4.4.1)\n##   available                  1.1.0      2022-07-10 [2] RSPM (R 4.4.0)\n##   backports                  1.5.0      2024-05-23 [2] RSPM (R 4.4.0)\n##   bartMachine                1.3.4.1    2023-07-06 [2] RSPM (R 4.4.0)\n##   bartMachineJARs            1.2.1      2022-09-19 [2] RSPM (R 4.4.0)\n##   base                     * 4.4.1      2024-09-24 [3] local\n##   base64enc                  0.1-3      2015-07-28 [2] RSPM (R 4.4.0)\n##   basilisk                   1.17.2     2024-07-28 [2] Bioconductor 3.20 (R 4.4.1)\n##   basilisk.utils             1.17.3     2024-09-10 [2] Bioconductor 3.20 (R 4.4.1)\n##   bayesm                     3.1-6      2023-09-23 [2] RSPM (R 4.4.0)\n##   beachmat                   2.21.6     2024-09-05 [2] Bioconductor 3.20 (R 4.4.1)\n##   beeswarm                   0.4.0      2021-06-01 [2] RSPM (R 4.4.0)\n##   BH                         1.84.0-0   2024-01-10 [2] RSPM (R 4.4.0)\n##   biclust                    2.0.3.1    2023-05-19 [2] RSPM (R 4.4.0)\n##   biglm                      0.9-3      2024-06-12 [2] RSPM (R 4.4.0)\n##   Biobase                    2.65.1     2024-08-28 [2] Bioconductor 3.20 (R 4.4.1)\n##   BiocBaseUtils              1.7.3      2024-08-29 [2] Bioconductor 3.20 (R 4.4.1)\n##   BiocBook                   1.3.0      2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   BiocFileCache              2.13.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   BiocGenerics               0.51.3     2024-10-02 [2] Bioconductor 3.20 (R 4.4.1)\n##   BiocManager                1.30.25    2024-08-28 [2] CRAN (R 4.4.1)\n##   BiocNeighbors              1.99.1     2024-09-22 [2] Bioconductor 3.20 (R 4.4.1)\n##   BiocParallel               1.39.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   BiocSingular               1.21.4     2024-09-22 [2] Bioconductor 3.20 (R 4.4.1)\n##   BiocStyle                  2.33.1     2024-06-12 [2] Bioconductor 3.20 (R 4.4.0)\n##   BiocVersion                3.20.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.1)\n##   biomformat                 1.33.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   Biostrings                 2.73.2     2024-09-26 [2] Bioconductor 3.20 (R 4.4.1)\n##   bit                        4.5.0      2024-09-20 [2] RSPM (R 4.4.0)\n##   bit64                      4.5.2      2024-09-22 [2] RSPM (R 4.4.0)\n##   bitops                     1.0-9      2024-10-03 [2] RSPM (R 4.4.0)\n##   blob                       1.2.4      2023-03-17 [2] RSPM (R 4.4.0)\n##   bluster                    1.15.1     2024-09-06 [2] Bioconductor 3.20 (R 4.4.1)\n##   bookdown                   0.40       2024-07-02 [2] RSPM (R 4.4.0)\n##   boot                       1.3-31     2024-08-28 [2] RSPM (R 4.4.0)\n##   brew                       1.0-10     2023-12-16 [2] RSPM (R 4.4.0)\n##   brio                       1.1.5      2024-04-24 [2] RSPM (R 4.4.0)\n##   broom                      1.0.7      2024-09-26 [2] RSPM (R 4.4.0)\n##   bslib                      0.8.0      2024-07-29 [2] RSPM (R 4.4.0)\n##   ca                         0.71.1     2020-01-24 [2] RSPM (R 4.4.0)\n##   cachem                     1.1.0      2024-05-16 [2] RSPM (R 4.4.0)\n##   Cairo                      1.6-2      2023-11-28 [2] RSPM (R 4.4.0)\n##   callr                      3.7.6      2024-03-25 [2] RSPM (R 4.4.0)\n##   car                        3.1-3      2024-09-27 [2] RSPM (R 4.4.0)\n##   carData                    3.0-5      2022-01-06 [2] RSPM (R 4.4.0)\n##   caret                      6.0-94     2023-03-21 [2] RSPM (R 4.4.0)\n##   caTools                    1.18.3     2024-09-04 [2] RSPM (R 4.4.0)\n##   cellranger                 1.1.0      2016-07-27 [2] RSPM (R 4.4.0)\n##   checkmate                  2.3.2      2024-07-29 [2] RSPM (R 4.4.0)\n##   chemometrics               1.4.4      2023-08-25 [2] RSPM (R 4.4.0)\n##   circlize                   0.4.16     2024-02-20 [2] RSPM (R 4.4.0)\n##   clarabel                   0.9.0.1    2024-09-03 [2] RSPM (R 4.4.0)\n##   class                      7.3-22     2023-05-03 [3] CRAN (R 4.4.1)\n##   cli                        3.6.3      2024-06-21 [2] RSPM (R 4.4.0)\n##   clipr                      0.8.0      2022-02-22 [2] RSPM (R 4.4.0)\n##   clisymbols                 1.2.0      2017-05-21 [2] RSPM (R 4.4.0)\n##   clock                      0.7.1      2024-07-18 [2] RSPM (R 4.4.0)\n##   clue                       0.3-65     2023-09-23 [2] RSPM (R 4.4.0)\n##   cluster                    2.1.6      2023-12-01 [3] CRAN (R 4.4.1)\n##   cobiclust                  0.1.2      2024-02-16 [2] RSPM (R 4.4.0)\n##   coda                       0.19-4.1   2024-01-31 [2] RSPM (R 4.4.0)\n##   CodeDepends                0.6.6      2024-04-07 [2] RSPM (R 4.4.0)\n##   codetools                  0.2-20     2024-03-31 [3] CRAN (R 4.4.1)\n##   colorspace                 2.1-1      2024-07-26 [2] RSPM (R 4.4.0)\n##   commonmark                 1.9.2      2024-10-04 [2] RSPM (R 4.4.0)\n##   compiler                   4.4.1      2024-09-24 [3] local\n##   ComplexHeatmap             2.21.1     2024-09-24 [2] Bioconductor 3.20 (R 4.4.1)\n##   compositions               2.0-8      2024-01-31 [2] RSPM (R 4.4.0)\n##   conflicted                 1.2.0      2023-02-01 [2] RSPM (R 4.4.0)\n##   corpcor                    1.6.10     2021-09-16 [2] RSPM (R 4.4.0)\n##   corrplot                   0.94       2024-08-17 [2] RSPM (R 4.4.0)\n##   cowplot                    1.1.3      2024-01-22 [2] RSPM (R 4.4.0)\n##   cplm                       0.7-12.1   2024-09-21 [2] RSPM (R 4.4.0)\n##   cpp11                      0.5.0      2024-08-27 [2] RSPM (R 4.4.0)\n##   crayon                     1.5.3      2024-06-20 [2] RSPM (R 4.4.0)\n##   credentials                2.0.2      2024-10-04 [2] RSPM (R 4.4.0)\n##   crosstalk                  1.2.1      2023-11-23 [2] RSPM (R 4.4.0)\n##   cubature                   2.1.1      2024-07-14 [2] RSPM (R 4.4.0)\n##   curatedMetagenomicData     3.13.0     2024-05-02 [2] Bioconductor 3.20 (R 4.4.0)\n##   curl                       5.2.3      2024-09-20 [2] RSPM (R 4.4.0)\n##   cvAUC                      1.1.4      2022-01-17 [2] RSPM (R 4.4.0)\n##   CVXR                       1.0-14     2024-06-27 [2] RSPM (R 4.4.0)\n##   dada2                      1.33.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   data.table                 1.16.0     2024-08-27 [2] RSPM (R 4.4.0)\n##   datasets                 * 4.4.1      2024-09-24 [3] local\n##   DBI                        1.2.3      2024-06-02 [2] RSPM (R 4.4.0)\n##   dbplyr                     2.5.0      2024-03-19 [2] RSPM (R 4.4.0)\n##   DECIPHER                   3.1.4      2024-06-12 [2] Bioconductor 3.20 (R 4.4.0)\n##   decontam                   1.25.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   DelayedArray               0.31.14    2024-10-03 [2] Bioconductor 3.20 (R 4.4.1)\n##   DelayedMatrixStats         1.27.3     2024-08-08 [2] Bioconductor 3.20 (R 4.4.1)\n##   deldir                     2.0-4      2024-02-28 [2] RSPM (R 4.4.0)\n##   dendextend                 1.17.1     2023-03-25 [2] RSPM (R 4.4.0)\n##   denstrip                   1.5.4      2018-03-18 [2] RSPM (R 4.4.0)\n##   DEoptimR                   1.1-3      2023-10-07 [2] RSPM (R 4.4.0)\n##   Deriv                      4.1.6      2024-09-13 [2] RSPM (R 4.4.0)\n##   desc                       1.4.3      2023-12-10 [2] RSPM (R 4.4.0)\n##   DescTools                  0.99.57    2024-09-25 [2] RSPM (R 4.4.0)\n##   devtools                   2.4.5      2022-10-11 [2] RSPM (R 4.4.0)\n##   diagram                    1.6.5      2020-09-30 [2] RSPM (R 4.4.0)\n##   diffobj                    0.3.5      2021-10-05 [2] RSPM (R 4.4.0)\n##   digest                     0.6.37     2024-08-19 [2] RSPM (R 4.4.0)\n##   diptest                    0.77-1     2024-04-10 [2] RSPM (R 4.4.0)\n##   dir.expiry                 1.13.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   directlabels               2024.1.21  2024-01-24 [2] RSPM (R 4.4.0)\n##   DirichletMultinomial       1.47.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   distributional             0.5.0      2024-09-17 [2] RSPM (R 4.4.0)\n##   doBy                       4.6.22     2024-06-21 [2] RSPM (R 4.4.0)\n##   docopt                     0.7.1      2020-06-24 [2] RSPM (R 4.4.1)\n##   doFuture                   1.0.1      2023-12-20 [2] RSPM (R 4.4.0)\n##   doParallel                 1.0.17     2022-02-07 [2] RSPM (R 4.4.0)\n##   doRNG                      1.8.6      2023-01-16 [2] RSPM (R 4.4.0)\n##   doSNOW                     1.0.20     2022-02-04 [2] RSPM (R 4.4.0)\n##   downlit                    0.4.4      2024-06-10 [2] RSPM (R 4.4.0)\n##   dplyr                      1.1.4      2023-11-17 [2] RSPM (R 4.4.0)\n##   dqrng                      0.4.1      2024-05-28 [2] RSPM (R 4.4.0)\n##   DT                         0.33       2024-04-04 [2] RSPM (R 4.4.0)\n##   dtplyr                     1.3.1      2023-03-22 [2] RSPM (R 4.4.0)\n##   dynamicTreeCut             1.63-1     2016-03-11 [2] RSPM (R 4.4.0)\n##   e1071                      1.7-16     2024-09-16 [2] RSPM (R 4.4.0)\n##   ECOSolveR                  0.5.5      2023-05-15 [2] RSPM (R 4.4.0)\n##   edgeR                      4.3.16     2024-09-22 [2] Bioconductor 3.20 (R 4.4.1)\n##   egg                        0.4.5      2019-07-13 [2] RSPM (R 4.4.0)\n##   ellipse                    0.5.0      2023-07-20 [2] RSPM (R 4.4.0)\n##   ellipsis                   0.3.2      2021-04-29 [2] RSPM (R 4.4.0)\n##   emmeans                    1.10.4     2024-08-21 [2] RSPM (R 4.4.0)\n##   energy                     1.7-12     2024-08-24 [2] RSPM (R 4.4.0)\n##   estimability               1.5.1      2024-05-12 [2] RSPM (R 4.4.0)\n##   evaluate                   1.0.0      2024-09-17 [2] RSPM (R 4.4.0)\n##   Exact                      3.3        2024-07-21 [2] RSPM (R 4.4.0)\n##   ExperimentHub              2.13.1     2024-07-31 [2] Bioconductor 3.20 (R 4.4.1)\n##   expm                       1.0-0      2024-08-19 [2] RSPM (R 4.4.0)\n##   factoextra                 1.0.7      2020-04-01 [2] RSPM (R 4.4.0)\n##   FactoMineR                 2.11       2024-04-20 [2] RSPM (R 4.4.0)\n##   fansi                      1.0.6      2023-12-08 [2] RSPM (R 4.4.0)\n##   farver                     2.1.2      2024-05-13 [2] RSPM (R 4.4.0)\n##   fastcluster                1.2.6      2024-01-12 [2] RSPM (R 4.4.0)\n##   fastmap                    1.2.0      2024-05-15 [2] RSPM (R 4.4.0)\n##   fBasics                    4041.97    2024-08-19 [2] RSPM (R 4.4.0)\n##   fdrtool                    1.2.18     2024-08-20 [2] RSPM (R 4.4.0)\n##   fido                       1.1.1      2024-06-05 [2] RSPM (R 4.4.0)\n##   filelock                   1.0.3      2023-12-11 [2] RSPM (R 4.4.0)\n##   filematrix                 1.3        2018-02-27 [2] RSPM (R 4.4.0)\n##   flashClust                 1.01-2     2012-08-21 [2] RSPM (R 4.4.0)\n##   flexclust                  1.4-2      2024-04-27 [2] RSPM (R 4.4.0)\n##   flexmix                    2.3-19     2023-03-16 [2] RSPM (R 4.4.0)\n##   fMultivar                  4031.84    2023-07-11 [2] RSPM (R 4.4.0)\n##   FNN                        1.1.4.1    2024-09-22 [2] RSPM (R 4.4.0)\n##   fontawesome                0.5.2      2023-08-19 [2] RSPM (R 4.4.0)\n##   forcats                    1.0.0      2023-01-29 [2] RSPM (R 4.4.0)\n##   foreach                    1.5.2      2022-02-02 [2] RSPM (R 4.4.0)\n##   foreign                    0.8-87     2024-06-26 [2] RSPM (R 4.4.0)\n##   formatR                    1.14       2023-01-17 [2] RSPM (R 4.4.0)\n##   Formula                    1.2-5      2023-02-24 [2] RSPM (R 4.4.0)\n##   fpc                        2.2-13     2024-09-24 [2] RSPM (R 4.4.0)\n##   fs                         1.6.4      2024-04-25 [2] RSPM (R 4.4.0)\n##   futile.logger              1.4.3      2016-07-10 [2] RSPM (R 4.4.0)\n##   futile.options             1.0.1      2018-04-20 [2] RSPM (R 4.4.0)\n##   future                     1.34.0     2024-07-29 [2] RSPM (R 4.4.0)\n##   future.apply               1.11.2     2024-03-28 [2] RSPM (R 4.4.0)\n##   gam                        1.22-5     2024-09-12 [2] RSPM (R 4.4.0)\n##   gargle                     1.5.2      2023-07-20 [2] RSPM (R 4.4.0)\n##   gclus                      1.3.2      2019-01-07 [2] RSPM (R 4.4.0)\n##   generics                   0.1.3      2022-07-05 [2] RSPM (R 4.4.0)\n##   GenomeInfoDb               1.41.2     2024-10-02 [2] Bioconductor 3.20 (R 4.4.1)\n##   GenomeInfoDbData           1.2.13     2024-10-06 [2] Bioconductor\n##   GenomicAlignments          1.41.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   GenomicRanges              1.57.1     2024-06-12 [2] Bioconductor 3.20 (R 4.4.0)\n##   geometry                   0.5.0      2024-08-31 [2] RSPM (R 4.4.0)\n##   gert                       2.1.2      2024-09-20 [2] RSPM (R 4.4.0)\n##   getopt                     1.20.4     2023-10-01 [2] RSPM (R 4.4.0)\n##   GetoptLong                 1.0.5      2020-12-15 [2] RSPM (R 4.4.0)\n##   ggbeeswarm                 0.7.2      2023-04-29 [2] RSPM (R 4.4.0)\n##   ggdist                     3.3.2      2024-03-05 [2] RSPM (R 4.4.0)\n##   ggforce                    0.4.2      2024-02-19 [2] RSPM (R 4.4.0)\n##   ggfun                      0.1.6      2024-08-28 [2] RSPM (R 4.4.0)\n##   ggnewscale                 0.5.0      2024-07-19 [2] RSPM (R 4.4.0)\n##   ggplot2                    3.5.1      2024-04-23 [2] RSPM (R 4.4.0)\n##   ggplotify                  0.1.2      2023-08-09 [2] RSPM (R 4.4.0)\n##   ggpubr                     0.6.0      2023-02-10 [2] RSPM (R 4.4.0)\n##   ggraph                     2.2.1      2024-03-07 [2] RSPM (R 4.4.0)\n##   ggrastr                    1.0.2      2023-06-01 [2] RSPM (R 4.4.0)\n##   ggrepel                    0.9.6      2024-09-07 [2] RSPM (R 4.4.0)\n##   ggsci                      3.2.0      2024-06-18 [2] RSPM (R 4.4.0)\n##   ggsignif                   0.6.4      2022-10-13 [2] RSPM (R 4.4.0)\n##   ggtree                     3.13.1     2024-08-18 [2] Bioconductor 3.20 (R 4.4.1)\n##   gh                         1.4.1      2024-03-28 [2] RSPM (R 4.4.0)\n##   gitcreds                   0.1.2      2022-09-08 [2] RSPM (R 4.4.0)\n##   glasso                     1.11       2019-10-01 [2] RSPM (R 4.4.0)\n##   gld                        2.6.6      2022-10-23 [2] RSPM (R 4.4.0)\n##   glmmTMB                    1.1.10     2024-09-26 [2] RSPM (R 4.4.0)\n##   glmnet                     4.1-8      2023-08-22 [2] RSPM (R 4.4.0)\n##   glmnetUtils                1.1.9      2023-09-10 [2] RSPM (R 4.4.0)\n##   GlobalOptions              0.1.2      2020-06-10 [2] RSPM (R 4.4.0)\n##   globals                    0.16.3     2024-03-08 [2] RSPM (R 4.4.0)\n##   glue                       1.8.0      2024-09-30 [2] RSPM (R 4.4.0)\n##   gmp                        0.7-5      2024-08-23 [2] RSPM (R 4.4.0)\n##   GO.db                      3.20.0     2024-10-06 [2] Bioconductor\n##   googledrive                2.1.1      2023-06-11 [2] RSPM (R 4.4.0)\n##   googlesheets4              1.1.1      2023-06-11 [2] RSPM (R 4.4.0)\n##   gower                      1.0.1      2022-12-22 [2] RSPM (R 4.4.0)\n##   GPArotation                2024.3-1   2024-03-02 [2] RSPM (R 4.4.0)\n##   gplots                     3.1.3.1    2024-02-02 [2] RSPM (R 4.4.0)\n##   graph                      1.83.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   graphics                 * 4.4.1      2024-09-24 [3] local\n##   graphlayouts               1.2.0      2024-09-24 [2] RSPM (R 4.4.0)\n##   grDevices                * 4.4.1      2024-09-24 [3] local\n##   grid                       4.4.1      2024-09-24 [3] local\n##   gridBase                   0.4-7      2014-02-24 [2] RSPM (R 4.4.0)\n##   gridExtra                  2.3        2017-09-09 [2] RSPM (R 4.4.0)\n##   gridGraphics               0.5-1      2020-12-13 [2] RSPM (R 4.4.0)\n##   gsEasy                     1.5        2024-02-20 [2] RSPM (R 4.4.0)\n##   gsl                        2.1-8      2023-01-24 [2] RSPM (R 4.4.0)\n##   gss                        2.2-7      2023-08-16 [2] RSPM (R 4.4.0)\n##   gtable                     0.3.5      2024-04-22 [2] RSPM (R 4.4.0)\n##   gtools                     3.9.5      2023-11-20 [2] RSPM (R 4.4.0)\n##   hardhat                    1.4.0      2024-06-02 [2] RSPM (R 4.4.0)\n##   hash                       2.2.6.3    2023-08-19 [2] RSPM (R 4.4.0)\n##   haven                      2.5.4      2023-11-30 [2] RSPM (R 4.4.0)\n##   HDF5Array                  1.33.8     2024-10-04 [2] Bioconductor 3.20 (R 4.4.1)\n##   heatmaply                  1.5.0      2023-10-06 [2] RSPM (R 4.4.0)\n##   here                       1.0.1      2020-12-13 [2] RSPM (R 4.4.0)\n##   highr                      0.11       2024-05-26 [2] RSPM (R 4.4.0)\n##   Hmisc                      5.1-3      2024-05-28 [2] RSPM (R 4.4.0)\n##   hms                        1.1.3      2023-03-21 [2] RSPM (R 4.4.0)\n##   htmlTable                  2.4.3      2024-07-21 [2] RSPM (R 4.4.0)\n##   htmltools                  0.5.8.1    2024-04-04 [2] RSPM (R 4.4.0)\n##   htmlwidgets                1.6.4      2023-12-06 [2] RSPM (R 4.4.0)\n##   httpuv                     1.6.15     2024-03-26 [2] RSPM (R 4.4.0)\n##   httr                       1.4.7      2023-08-15 [2] RSPM (R 4.4.0)\n##   httr2                      1.0.5      2024-09-26 [2] RSPM (R 4.4.0)\n##   huge                       1.3.5      2021-06-30 [2] RSPM (R 4.4.0)\n##   hwriter                    1.3.2.1    2022-04-08 [2] RSPM (R 4.4.0)\n##   ids                        1.0.1      2017-05-31 [2] RSPM (R 4.4.0)\n##   igraph                     2.0.3      2024-03-13 [2] RSPM (R 4.4.0)\n##   impute                     1.79.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   ini                        0.3.1      2018-05-20 [2] RSPM (R 4.4.0)\n##   IntegratedLearner          0.0.1      2024-10-06 [2] Github (himelmallick/IntegratedLearner@b56f9c7)\n##   interp                     1.1-6      2024-01-26 [2] RSPM (R 4.4.0)\n##   ipred                      0.9-15     2024-07-18 [2] RSPM (R 4.4.0)\n##   IRanges                    2.39.2     2024-07-17 [2] Bioconductor 3.20 (R 4.4.1)\n##   irlba                      2.3.5.1    2022-10-03 [2] RSPM (R 4.4.0)\n##   isoband                    0.2.7      2022-12-20 [2] RSPM (R 4.4.0)\n##   iterators                  1.0.14     2022-02-05 [2] RSPM (R 4.4.0)\n##   itertools                  0.1-3      2014-03-12 [2] RSPM (R 4.4.0)\n##   janeaustenr                1.0.0      2022-08-26 [2] RSPM (R 4.4.0)\n##   jpeg                       0.1-10     2022-11-29 [2] RSPM (R 4.4.0)\n##   jquerylib                  0.1.4      2021-04-26 [2] RSPM (R 4.4.0)\n##   jsonlite                   1.8.9      2024-09-20 [2] RSPM (R 4.4.0)\n##   KEGGREST                   1.45.1     2024-06-17 [2] Bioconductor 3.20 (R 4.4.0)\n##   kernlab                    0.9-33     2024-08-13 [2] RSPM (R 4.4.0)\n##   KernSmooth                 2.23-24    2024-05-17 [3] CRAN (R 4.4.1)\n##   knitr                      1.48       2024-07-07 [2] RSPM (R 4.4.0)\n##   labeling                   0.4.3      2023-08-29 [2] RSPM (R 4.4.0)\n##   lambda.r                   1.2.4      2019-09-18 [2] RSPM (R 4.4.0)\n##   lars                       1.3        2022-04-13 [2] RSPM (R 4.4.0)\n##   latentcor                  2.0.1      2022-09-05 [2] RSPM (R 4.4.0)\n##   later                      1.3.2      2023-12-06 [2] RSPM (R 4.4.0)\n##   lattice                    0.22-6     2024-03-20 [3] CRAN (R 4.4.1)\n##   latticeExtra               0.6-30     2022-07-04 [2] RSPM (R 4.4.0)\n##   lava                       1.8.0      2024-03-05 [2] RSPM (R 4.4.0)\n##   lavaan                     0.6-19     2024-09-26 [2] RSPM (R 4.4.0)\n##   lazyeval                   0.2.2      2019-03-15 [2] RSPM (R 4.4.0)\n##   leaps                      3.2        2024-06-10 [2] RSPM (R 4.4.0)\n##   lifecycle                  1.0.4      2023-11-07 [2] RSPM (R 4.4.0)\n##   limma                      3.61.12    2024-09-30 [2] Bioconductor 3.20 (R 4.4.1)\n##   linprog                    0.9-4      2022-03-09 [2] RSPM (R 4.4.0)\n##   listenv                    0.9.1      2024-01-29 [2] RSPM (R 4.4.0)\n##   littler                    0.3.20     2024-03-23 [2] RSPM (R 4.4.1)\n##   lme4                       1.1-35.5   2024-07-03 [2] RSPM (R 4.4.0)\n##   lmerTest                   3.1-3      2020-10-23 [2] RSPM (R 4.4.0)\n##   lmom                       3.2        2024-09-30 [2] RSPM (R 4.4.0)\n##   locfit                     1.5-9.10   2024-06-24 [2] RSPM (R 4.4.0)\n##   logging                    0.10-108   2019-07-14 [2] RSPM (R 4.4.0)\n##   lpSolve                    5.6.21     2024-09-12 [2] RSPM (R 4.4.0)\n##   lubridate                  1.9.3      2023-09-27 [2] RSPM (R 4.4.0)\n##   Maaslin2                   1.19.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   magic                      1.6-1      2022-11-16 [2] RSPM (R 4.4.0)\n##   magrittr                   2.0.3      2022-03-30 [2] RSPM (R 4.4.0)\n##   MASS                       7.3-61     2024-06-13 [2] RSPM (R 4.4.0)\n##   mathjaxr                   1.6-0      2022-02-28 [2] RSPM (R 4.4.0)\n##   Matrix                     1.7-0      2024-04-26 [3] CRAN (R 4.4.1)\n##   MatrixGenerics             1.17.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   MatrixModels               0.5-3      2023-11-06 [2] RSPM (R 4.4.0)\n##   matrixStats                1.4.1      2024-09-08 [2] RSPM (R 4.4.0)\n##   mclust                     6.1.1      2024-04-29 [2] RSPM (R 4.4.0)\n##   mcmcplots                  0.4.3      2018-06-22 [2] RSPM (R 4.4.0)\n##   mediation                  4.5.0      2019-10-08 [2] RSPM (R 4.4.0)\n##   memoise                    2.0.1      2021-11-26 [2] RSPM (R 4.4.0)\n##   metadat                    1.2-0      2022-04-06 [2] RSPM (R 4.4.0)\n##   metafor                    4.6-0      2024-03-28 [2] RSPM (R 4.4.0)\n##   metagenomeSeq              1.47.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   methods                  * 4.4.1      2024-09-24 [3] local\n##   mgcv                       1.9-1      2023-12-21 [3] CRAN (R 4.4.1)\n##   mia                        1.13.45    2024-10-06 [2] Github (microbiome/mia@1923e87)\n##   miaTime                    0.1.22     2024-10-06 [2] Github (microbiome/miaTime@f66d54f)\n##   miaViz                     1.13.11    2024-10-06 [2] Github (microbiome/miaViz@0974c68)\n##   microbenchmark             1.5.0      2024-09-04 [2] RSPM (R 4.4.0)\n##   microbiome                 1.27.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   microbiomeDataSets         1.13.3     2024-07-04 [2] Bioconductor 3.20 (R 4.4.1)\n##   MicrobiomeStat             1.2        2024-04-01 [2] RSPM (R 4.4.0)\n##   mikropml                   1.6.1      2023-08-21 [2] RSPM (R 4.4.0)\n##   mime                       0.12       2021-09-28 [2] RSPM (R 4.4.0)\n##   miniUI                     0.1.1.1    2018-05-18 [2] RSPM (R 4.4.0)\n##   minqa                      1.2.8      2024-08-17 [2] RSPM (R 4.4.0)\n##   missForest                 1.5        2022-04-14 [2] RSPM (R 4.4.0)\n##   mixedCCA                   1.6.2      2022-09-09 [2] RSPM (R 4.4.0)\n##   MLmetrics                  1.1.3      2024-04-13 [2] RSPM (R 4.4.0)\n##   MMUPHin                    1.19.1     2024-05-20 [2] Bioconductor 3.20 (R 4.4.0)\n##   mnormt                     2.1.1      2022-09-26 [2] RSPM (R 4.4.0)\n##   modeest                    2.4.0      2019-11-18 [2] RSPM (R 4.4.0)\n##   ModelMetrics               1.2.2.2    2020-03-17 [2] RSPM (R 4.4.0)\n##   modelr                     0.1.11     2023-03-22 [2] RSPM (R 4.4.0)\n##   modeltools                 0.2-23     2020-03-05 [2] RSPM (R 4.4.0)\n##   MOFA2                      1.15.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   multcomp                   1.4-26     2024-07-18 [2] RSPM (R 4.4.0)\n##   multcompView               0.1-10     2024-03-08 [2] RSPM (R 4.4.0)\n##   MultiAssayExperiment       1.31.5     2024-08-23 [2] Bioconductor 3.20 (R 4.4.1)\n##   multiview                  0.8        2023-03-31 [2] RSPM (R 4.4.0)\n##   multtest                   2.61.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   munsell                    0.5.1      2024-04-01 [2] RSPM (R 4.4.0)\n##   mvtnorm                    1.3-1      2024-09-03 [2] RSPM (R 4.4.0)\n##   NADA                       1.6-1.1    2020-03-22 [2] RSPM (R 4.4.0)\n##   NbClust                    3.0.1      2022-05-02 [2] RSPM (R 4.4.0)\n##   NetCoMi                    1.1.0      2024-10-06 [2] Github (stefpeschel/NetCoMi@0809c7a)\n##   nlme                       3.1-166    2024-08-14 [2] RSPM (R 4.4.0)\n##   nloptr                     2.1.1      2024-06-25 [2] RSPM (R 4.4.0)\n##   NMF                        0.28       2024-08-22 [2] RSPM (R 4.4.1)\n##   nnet                       7.3-19     2023-05-03 [3] CRAN (R 4.4.1)\n##   nnls                       1.5        2023-09-11 [2] RSPM (R 4.4.0)\n##   numDeriv                   2016.8-1.1 2019-06-06 [2] RSPM (R 4.4.0)\n##   OMA                        0.98.28    2024-10-06 [1] Bioconductor\n##   ontologyIndex              2.12       2024-02-27 [2] RSPM (R 4.4.0)\n##   openssl                    2.2.2      2024-09-20 [2] RSPM (R 4.4.0)\n##   openxlsx                   4.2.7.1    2024-09-20 [2] RSPM (R 4.4.0)\n##   optparse                   1.7.5      2024-04-16 [2] RSPM (R 4.4.0)\n##   orca                       1.1-3      2024-09-20 [2] RSPM (R 4.4.0)\n##   osqp                       0.6.3.3    2024-06-08 [2] RSPM (R 4.4.0)\n##   parallel                   4.4.1      2024-09-24 [3] local\n##   parallelly                 1.38.0     2024-07-27 [2] RSPM (R 4.4.0)\n##   patchwork                  1.3.0      2024-09-16 [2] RSPM (R 4.4.0)\n##   pbapply                    1.7-2      2023-06-27 [2] RSPM (R 4.4.0)\n##   pbivnorm                   0.6.0      2015-01-23 [2] RSPM (R 4.4.0)\n##   pbkrtest                   0.5.3      2024-06-26 [2] RSPM (R 4.4.0)\n##   pcaPP                      2.0-5      2024-08-19 [2] RSPM (R 4.4.0)\n##   permute                    0.9-7      2022-01-27 [2] RSPM (R 4.4.0)\n##   pheatmap                   1.0.12     2019-01-04 [2] RSPM (R 4.4.0)\n##   phyloseq                   1.49.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   pillar                     1.9.0      2023-03-22 [2] RSPM (R 4.4.0)\n##   pixmap                     0.4-13     2024-05-03 [2] RSPM (R 4.4.0)\n##   pkgbuild                   1.4.4      2024-03-17 [2] RSPM (R 4.4.0)\n##   pkgconfig                  2.0.3      2019-09-22 [2] RSPM (R 4.4.0)\n##   pkgdown                    2.1.1      2024-09-17 [2] RSPM (R 4.4.0)\n##   pkgload                    1.4.0      2024-06-28 [2] RSPM (R 4.4.0)\n##   plogr                      0.2.0      2018-03-25 [2] RSPM (R 4.4.0)\n##   plotly                     4.10.4     2024-01-13 [2] RSPM (R 4.4.0)\n##   pls                        2.8-5      2024-09-15 [2] RSPM (R 4.4.0)\n##   plyr                       1.8.9      2023-10-02 [2] RSPM (R 4.4.0)\n##   png                        0.1-8      2022-11-29 [2] RSPM (R 4.4.0)\n##   polyclip                   1.10-7     2024-07-23 [2] RSPM (R 4.4.0)\n##   polynom                    1.4-1      2022-04-11 [2] RSPM (R 4.4.0)\n##   posterior                  1.6.0      2024-07-03 [2] RSPM (R 4.4.0)\n##   prabclus                   2.3-4      2024-09-24 [2] RSPM (R 4.4.0)\n##   praise                     1.0.0      2015-08-11 [2] RSPM (R 4.4.0)\n##   preprocessCore             1.67.1     2024-09-26 [2] Bioconductor 3.20 (R 4.4.1)\n##   prettyunits                1.2.0      2023-09-24 [2] RSPM (R 4.4.0)\n##   pROC                       1.18.5     2023-11-01 [2] RSPM (R 4.4.0)\n##   processx                   3.8.4      2024-03-16 [2] RSPM (R 4.4.0)\n##   prodlim                    2024.06.25 2024-06-24 [2] RSPM (R 4.4.0)\n##   profvis                    0.4.0      2024-09-20 [2] RSPM (R 4.4.0)\n##   progress                   1.2.3      2023-12-06 [2] RSPM (R 4.4.0)\n##   progressr                  0.14.0     2023-08-10 [2] RSPM (R 4.4.0)\n##   promises                   1.3.0      2024-04-05 [2] RSPM (R 4.4.0)\n##   proxy                      0.4-27     2022-06-09 [2] RSPM (R 4.4.0)\n##   ps                         1.8.0      2024-09-12 [2] RSPM (R 4.4.0)\n##   pscl                       1.5.9      2024-01-31 [2] RSPM (R 4.4.0)\n##   psych                      2.4.6.26   2024-06-27 [2] RSPM (R 4.4.0)\n##   pulsar                     0.3.11     2023-09-24 [2] RSPM (R 4.4.0)\n##   purrr                      1.0.2      2023-08-10 [2] RSPM (R 4.4.0)\n##   pwalign                    1.1.0      2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   qap                        0.1-2      2022-06-27 [2] RSPM (R 4.4.0)\n##   qgraph                     1.9.8      2023-11-03 [2] RSPM (R 4.4.0)\n##   quadprog                   1.5-8      2019-11-20 [2] RSPM (R 4.4.0)\n##   quantreg                   5.98       2024-05-26 [2] RSPM (R 4.4.0)\n##   quarto                     1.4.4      2024-07-20 [2] RSPM (R 4.4.0)\n##   R.methodsS3                1.8.2      2022-06-13 [2] RSPM (R 4.4.0)\n##   R.oo                       1.26.0     2024-01-24 [2] RSPM (R 4.4.0)\n##   R.utils                    2.12.3     2023-11-18 [2] RSPM (R 4.4.0)\n##   R6                         2.5.1      2021-08-19 [2] RSPM (R 4.4.0)\n##   ragg                       1.3.3      2024-09-11 [2] RSPM (R 4.4.0)\n##   randomcoloR                1.1.0.1    2019-11-24 [2] RSPM (R 4.4.0)\n##   randomForest               4.7-1.2    2024-09-22 [2] RSPM (R 4.4.0)\n##   rappdirs                   0.3.3      2021-01-31 [2] RSPM (R 4.4.0)\n##   rbibutils                  2.3        2024-10-04 [2] RSPM (R 4.4.0)\n##   rbiom                      1.0.3      2021-11-05 [2] RSPM (R 4.4.0)\n##   rcmdcheck                  1.4.0      2021-09-27 [2] RSPM (R 4.4.0)\n##   RColorBrewer               1.1-3      2022-04-03 [2] RSPM (R 4.4.0)\n##   Rcpp                       1.0.13     2024-07-17 [2] RSPM (R 4.4.0)\n##   RcppAnnoy                  0.0.22     2024-01-23 [2] RSPM (R 4.4.0)\n##   RcppArmadillo              14.0.2-1   2024-09-12 [2] RSPM (R 4.4.0)\n##   RcppEigen                  0.3.4.0.2  2024-08-24 [2] RSPM (R 4.4.0)\n##   RcppGSL                    0.3.13     2023-01-13 [2] RSPM (R 4.4.0)\n##   RcppML                     0.3.7      2021-09-21 [2] RSPM (R 4.4.0)\n##   RcppNumerical              0.6-0      2023-09-06 [2] RSPM (R 4.4.0)\n##   RcppParallel               5.1.9      2024-08-19 [2] RSPM (R 4.4.0)\n##   RcppProgress               0.4.2      2020-02-06 [2] RSPM (R 4.4.0)\n##   RcppTOML                   0.2.2      2023-01-29 [2] RSPM (R 4.4.0)\n##   RcppZiggurat               0.1.6      2020-10-20 [2] RSPM (R 4.4.0)\n##   Rdpack                     2.6.1      2024-08-06 [2] RSPM (R 4.4.0)\n##   readr                      2.1.5      2024-01-10 [2] RSPM (R 4.4.0)\n##   readxl                     1.4.3      2023-07-06 [2] RSPM (R 4.4.0)\n##   rebook                     1.15.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   recipes                    1.1.0      2024-07-04 [2] RSPM (R 4.4.0)\n##   reformulas                 0.3.0      2024-06-05 [2] RSPM (R 4.4.0)\n##   registry                   0.5-1      2019-03-05 [2] RSPM (R 4.4.0)\n##   rematch                    2.0.0      2023-08-30 [2] RSPM (R 4.4.0)\n##   rematch2                   2.1.2      2020-05-01 [2] RSPM (R 4.4.0)\n##   remotes                    2.5.0      2024-03-17 [2] RSPM (R 4.4.0)\n##   renv                       1.0.9      2024-09-23 [2] RSPM (R 4.4.0)\n##   reprex                     2.1.1      2024-07-06 [2] RSPM (R 4.4.0)\n##   reshape2                   1.4.4      2020-04-09 [2] RSPM (R 4.4.0)\n##   reticulate                 1.39.0     2024-09-05 [2] RSPM (R 4.4.0)\n##   Rfast                      2.1.0      2023-11-09 [2] RSPM (R 4.4.0)\n##   rgl                        1.3.1      2024-03-05 [2] RSPM (R 4.4.0)\n##   rhdf5                      2.49.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   rhdf5filters               1.17.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   Rhdf5lib                   1.27.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   Rhtslib                    3.1.0      2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   rJava                      1.0-11     2024-01-26 [2] RSPM (R 4.4.0)\n##   rjson                      0.2.23     2024-09-16 [2] RSPM (R 4.4.0)\n##   rlang                      1.1.4      2024-06-04 [2] RSPM (R 4.4.0)\n##   rmarkdown                  2.28       2024-08-17 [2] RSPM (R 4.4.0)\n##   Rmpfr                      0.9-5      2024-01-21 [2] RSPM (R 4.4.0)\n##   rmutil                     1.1.10     2022-10-27 [2] RSPM (R 4.4.0)\n##   rngtools                   1.5.2      2021-09-20 [2] RSPM (R 4.4.0)\n##   robustbase                 0.99-4-1   2024-09-27 [2] RSPM (R 4.4.0)\n##   ROCR                       1.0-11     2020-05-02 [2] RSPM (R 4.4.0)\n##   rootSolve                  1.8.2.4    2023-09-21 [2] RSPM (R 4.4.0)\n##   roxygen2                   7.3.2      2024-06-28 [2] RSPM (R 4.4.0)\n##   rpart                      4.1.23     2023-12-05 [3] CRAN (R 4.4.1)\n##   rprojroot                  2.0.4      2023-11-05 [2] RSPM (R 4.4.0)\n##   Rsamtools                  2.21.2     2024-09-26 [2] Bioconductor 3.20 (R 4.4.1)\n##   RSpectra                   0.16-2     2024-07-18 [2] RSPM (R 4.4.0)\n##   RSQLite                    2.3.7      2024-05-27 [2] RSPM (R 4.4.0)\n##   rstatix                    0.7.2      2023-02-01 [2] RSPM (R 4.4.0)\n##   rstudioapi                 0.16.0     2024-03-24 [2] RSPM (R 4.4.0)\n##   rsvd                       1.0.5      2021-04-16 [2] RSPM (R 4.4.0)\n##   Rtsne                      0.17       2023-12-07 [2] RSPM (R 4.4.0)\n##   rversions                  2.1.2      2022-08-31 [2] RSPM (R 4.4.0)\n##   rvest                      1.0.4      2024-02-12 [2] RSPM (R 4.4.0)\n##   S4Arrays                   1.5.10     2024-09-29 [2] Bioconductor 3.20 (R 4.4.1)\n##   S4Vectors                  0.43.2     2024-07-17 [2] Bioconductor 3.20 (R 4.4.1)\n##   sandwich                   3.1-1      2024-09-15 [2] RSPM (R 4.4.0)\n##   sass                       0.4.9      2024-03-15 [2] RSPM (R 4.4.0)\n##   ScaledMatrix               1.13.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   scales                     1.3.0      2023-11-28 [2] RSPM (R 4.4.0)\n##   scater                     1.33.4     2024-07-21 [2] Bioconductor 3.20 (R 4.4.1)\n##   scatterplot3d              0.3-44     2023-05-05 [2] RSPM (R 4.4.0)\n##   scs                        3.2.4      2023-04-11 [2] RSPM (R 4.4.0)\n##   scuttle                    1.15.4     2024-08-14 [2] Bioconductor 3.20 (R 4.4.1)\n##   sechm                      1.13.1     2024-06-12 [2] Bioconductor 3.20 (R 4.4.0)\n##   selectr                    0.4-2      2019-11-20 [2] RSPM (R 4.4.0)\n##   seriation                  1.5.6      2024-08-19 [2] RSPM (R 4.4.0)\n##   sessioninfo                1.2.2      2021-12-06 [2] RSPM (R 4.4.0)\n##   sfsmisc                    1.1-19     2024-08-19 [2] RSPM (R 4.4.0)\n##   shadowtext                 0.1.4      2024-07-18 [2] RSPM (R 4.4.0)\n##   shape                      1.4.6.1    2024-02-23 [2] RSPM (R 4.4.0)\n##   shiny                      1.9.1      2024-08-01 [2] RSPM (R 4.4.0)\n##   ShortRead                  1.63.2     2024-09-26 [2] Bioconductor 3.20 (R 4.4.1)\n##   SingleCellExperiment       1.27.2     2024-05-24 [2] Bioconductor 3.20 (R 4.4.0)\n##   sitmo                      2.0.2      2021-10-13 [2] RSPM (R 4.4.0)\n##   slam                       0.1-53     2024-09-02 [2] RSPM (R 4.4.0)\n##   sn                         2.1.1      2023-04-04 [2] RSPM (R 4.4.0)\n##   snow                       0.4-4      2021-10-27 [2] RSPM (R 4.4.0)\n##   SnowballC                  0.7.1      2023-04-25 [2] RSPM (R 4.4.0)\n##   som                        0.3-5.2    2024-09-18 [2] RSPM (R 4.4.0)\n##   sourcetools                0.1.7-1    2023-02-01 [2] RSPM (R 4.4.0)\n##   sp                         2.1-4      2024-04-30 [2] RSPM (R 4.4.0)\n##   SparseArray                1.5.43     2024-10-04 [2] Bioconductor 3.20 (R 4.4.1)\n##   SparseM                    1.84-2     2024-07-17 [2] RSPM (R 4.4.0)\n##   sparseMatrixStats          1.17.2     2024-06-12 [2] Bioconductor 3.20 (R 4.4.0)\n##   spatial                    7.3-17     2023-07-20 [3] CRAN (R 4.4.1)\n##   SpiecEasi                  1.1.3      2024-10-06 [2] Github (zdk123/SpiecEasi@5f396da)\n##   splines                    4.4.1      2024-09-24 [3] local\n##   SPRING                     1.0.4      2024-10-06 [2] Github (GraceYoon/SPRING@3d641a4)\n##   SQUAREM                    2021.1     2021-01-13 [2] RSPM (R 4.4.0)\n##   stable                     1.1.6      2022-03-02 [2] RSPM (R 4.4.0)\n##   stabledist                 0.7-2      2024-08-17 [2] RSPM (R 4.4.0)\n##   statip                     0.2.3      2019-11-17 [2] RSPM (R 4.4.0)\n##   statmod                    1.5.0      2023-01-06 [2] RSPM (R 4.4.0)\n##   stats                    * 4.4.1      2024-09-24 [3] local\n##   stats4                     4.4.1      2024-09-24 [3] local\n##   stringdist                 0.9.12     2023-11-28 [2] RSPM (R 4.4.0)\n##   stringi                    1.8.4      2024-05-06 [2] RSPM (R 4.4.0)\n##   stringr                    1.5.1      2023-11-14 [2] RSPM (R 4.4.0)\n##   SummarizedExperiment       1.35.3     2024-10-02 [2] Bioconductor 3.20 (R 4.4.1)\n##   SuperLearner               2.0-29     2024-02-20 [2] RSPM (R 4.4.0)\n##   survival                   3.7-0      2024-06-05 [2] RSPM (R 4.4.0)\n##   svUnit                     1.0.6      2021-04-19 [2] RSPM (R 4.4.0)\n##   sys                        3.4.3      2024-10-04 [2] RSPM (R 4.4.0)\n##   systemfonts                1.1.0      2024-05-15 [2] RSPM (R 4.4.0)\n##   tcltk                      4.4.1      2024-09-24 [3] local\n##   tensorA                    0.36.2.1   2023-12-13 [2] RSPM (R 4.4.0)\n##   testthat                   3.2.1.1    2024-04-14 [2] RSPM (R 4.4.0)\n##   textshaping                0.4.0      2024-05-24 [2] RSPM (R 4.4.0)\n##   TH.data                    1.1-2      2023-04-17 [2] RSPM (R 4.4.0)\n##   tibble                     3.2.1      2023-03-20 [2] RSPM (R 4.4.0)\n##   tidybayes                  3.0.7      2024-09-15 [2] RSPM (R 4.4.0)\n##   tidygraph                  1.3.1      2024-01-30 [2] RSPM (R 4.4.0)\n##   tidyr                      1.3.1      2024-01-24 [2] RSPM (R 4.4.0)\n##   tidyselect                 1.2.1      2024-03-11 [2] RSPM (R 4.4.0)\n##   tidytext                   0.4.2      2024-04-10 [2] RSPM (R 4.4.0)\n##   tidytree                   0.4.6      2023-12-12 [2] RSPM (R 4.4.0)\n##   tidyverse                  2.0.0      2023-02-22 [2] RSPM (R 4.4.0)\n##   timechange                 0.3.0      2024-01-18 [2] RSPM (R 4.4.0)\n##   timeDate                   4041.110   2024-09-22 [2] RSPM (R 4.4.0)\n##   timeSeries                 4041.111   2024-09-22 [2] RSPM (R 4.4.0)\n##   tinytex                    0.53       2024-09-15 [2] RSPM (R 4.4.0)\n##   TMB                        1.9.15     2024-09-09 [2] RSPM (R 4.4.0)\n##   tokenizers                 0.3.0      2022-12-22 [2] RSPM (R 4.4.0)\n##   tools                      4.4.1      2024-09-24 [3] local\n##   topGO                      2.57.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   treeio                     1.29.1     2024-08-18 [2] Bioconductor 3.20 (R 4.4.1)\n##   TreeSummarizedExperiment   2.13.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   truncnorm                  1.0-9      2023-03-20 [2] RSPM (R 4.4.0)\n##   TSP                        1.2-4      2023-04-04 [2] RSPM (R 4.4.0)\n##   tweedie                    2.3.5      2022-08-17 [2] RSPM (R 4.4.0)\n##   tweenr                     2.0.3      2024-02-26 [2] RSPM (R 4.4.0)\n##   tzdb                       0.4.0      2023-05-12 [2] RSPM (R 4.4.0)\n##   UCSC.utils                 1.1.0      2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   urlchecker                 1.0.1      2021-11-30 [2] RSPM (R 4.4.0)\n##   usethis                    3.0.0      2024-07-29 [2] RSPM (R 4.4.0)\n##   utf8                       1.2.4      2023-10-22 [2] RSPM (R 4.4.0)\n##   utils                    * 4.4.1      2024-09-24 [3] local\n##   uuid                       1.2-1      2024-07-29 [2] RSPM (R 4.4.0)\n##   uwot                       0.2.2      2024-04-21 [2] RSPM (R 4.4.0)\n##   V8                         5.0.1      2024-09-20 [2] RSPM (R 4.4.0)\n##   vctrs                      0.6.5      2023-12-01 [2] RSPM (R 4.4.0)\n##   vegan                      2.6-8      2024-08-28 [2] RSPM (R 4.4.0)\n##   VGAM                       1.1-12     2024-09-18 [2] RSPM (R 4.4.0)\n##   vipor                      0.4.7      2023-12-18 [2] RSPM (R 4.4.0)\n##   viridis                    0.6.5      2024-01-29 [2] RSPM (R 4.4.0)\n##   viridisLite                0.4.2      2023-05-02 [2] RSPM (R 4.4.0)\n##   vroom                      1.6.5      2023-12-05 [2] RSPM (R 4.4.0)\n##   waldo                      0.5.3      2024-08-23 [2] RSPM (R 4.4.0)\n##   webshot                    0.5.5      2023-06-26 [2] RSPM (R 4.4.0)\n##   WGCNA                      1.73       2024-09-18 [2] RSPM (R 4.4.1)\n##   whisker                    0.4.1      2022-12-05 [2] RSPM (R 4.4.0)\n##   withr                      3.0.1      2024-07-31 [2] RSPM (R 4.4.0)\n##   Wrench                     1.23.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   xfun                       0.48       2024-10-03 [2] RSPM (R 4.4.0)\n##   xgboost                    1.7.8.1    2024-07-24 [2] RSPM (R 4.4.0)\n##   XML                        3.99-0.17  2024-06-25 [2] RSPM (R 4.4.0)\n##   xml2                       1.3.6      2023-12-04 [2] RSPM (R 4.4.0)\n##   xopen                      1.0.1      2024-04-25 [2] RSPM (R 4.4.0)\n##   xtable                     1.8-4      2019-04-21 [2] RSPM (R 4.4.0)\n##   XVector                    0.45.0     2024-05-01 [2] Bioconductor 3.20 (R 4.4.0)\n##   yaml                       2.3.10     2024-07-26 [2] RSPM (R 4.4.0)\n##   yesno                      0.1.3      2024-07-26 [2] RSPM (R 4.4.0)\n##   yulab.utils                0.1.7      2024-08-26 [2] RSPM (R 4.4.0)\n##   zCompositions              1.5.0-4    2024-06-19 [2] RSPM (R 4.4.0)\n##   zip                        2.3.1      2024-01-27 [2] RSPM (R 4.4.0)\n##   zlibbioc                   1.51.1     2024-06-05 [2] Bioconductor 3.20 (R 4.4.0)\n##   zoo                        1.8-12     2023-04-13 [2] RSPM (R 4.4.0)\n##  \n##   [1] /tmp/Rtmpao7XXn/Rinstb1372869b\n##   [2] /usr/local/lib/R/site-library\n##   [3] /usr/local/lib/R/library\n##  \n##  ─ Python configuration ────────────────────────────────────────────────────\n##   Python is not available\n##  \n##  ───────────────────────────────────────────────────────────────────────────",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Technical info</span>"
    ]
  },
  {
    "objectID": "pages/session_info.html#other-information",
    "href": "pages/session_info.html#other-information",
    "title": "Appendix E — Technical info",
    "section": "\nE.3 Other information",
    "text": "E.3 Other information\n\nHeader image: iStock / ClaudioVentrella",
    "crumbs": [
      "Appendices",
      "<span class='chapter-number'>E</span>  <span class='chapter-title'>Technical info</span>"
    ]
  }
]